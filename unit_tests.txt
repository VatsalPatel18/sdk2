
==== tests/unittests/utils.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import asyncio
import contextlib
from typing import AsyncGenerator
from typing import Generator
from typing import Union

from google.adk.agents.invocation_context import InvocationContext
from google.adk.agents.live_request_queue import LiveRequestQueue
from google.adk.agents.llm_agent import Agent
from google.adk.agents.llm_agent import LlmAgent
from google.adk.agents.run_config import RunConfig
from google.adk.artifacts import InMemoryArtifactService
from google.adk.events.event import Event
from google.adk.memory.in_memory_memory_service import InMemoryMemoryService
from google.adk.models.base_llm import BaseLlm
from google.adk.models.base_llm_connection import BaseLlmConnection
from google.adk.models.llm_request import LlmRequest
from google.adk.models.llm_response import LlmResponse
from google.adk.runners import InMemoryRunner as AfInMemoryRunner
from google.adk.runners import Runner
from google.adk.sessions.in_memory_session_service import InMemorySessionService
from google.adk.sessions.session import Session
from google.genai import types
from google.genai.types import Part
from typing_extensions import override


class UserContent(types.Content):

  def __init__(self, text_or_part: str):
    parts = [
        types.Part.from_text(text=text_or_part)
        if isinstance(text_or_part, str)
        else text_or_part
    ]
    super().__init__(role='user', parts=parts)


class ModelContent(types.Content):

  def __init__(self, parts: list[types.Part]):
    super().__init__(role='model', parts=parts)


async def create_invocation_context(agent: Agent, user_content: str = ''):
  invocation_id = 'test_id'
  artifact_service = InMemoryArtifactService()
  session_service = InMemorySessionService()
  memory_service = InMemoryMemoryService()
  invocation_context = InvocationContext(
      artifact_service=artifact_service,
      session_service=session_service,
      memory_service=memory_service,
      invocation_id=invocation_id,
      agent=agent,
      session=await session_service.create_session(
          app_name='test_app', user_id='test_user'
      ),
      user_content=types.Content(
          role='user', parts=[types.Part.from_text(text=user_content)]
      ),
      run_config=RunConfig(),
  )
  if user_content:
    append_user_content(
        invocation_context, [types.Part.from_text(text=user_content)]
    )
  return invocation_context


def append_user_content(
    invocation_context: InvocationContext, parts: list[types.Part]
) -> Event:
  session = invocation_context.session
  event = Event(
      invocation_id=invocation_context.invocation_id,
      author='user',
      content=types.Content(role='user', parts=parts),
  )
  session.events.append(event)
  return event


# Extracts the contents from the events and transform them into a list of
# (author, simplified_content) tuples.
def simplify_events(events: list[Event]) -> list[(str, types.Part)]:
  return [(event.author, simplify_content(event.content)) for event in events]


# Simplifies the contents into a list of (author, simplified_content) tuples.
def simplify_contents(contents: list[types.Content]) -> list[(str, types.Part)]:
  return [(content.role, simplify_content(content)) for content in contents]


# Simplifies the content so it's easier to assert.
# - If there is only one part, return part
# - If the only part is pure text, return stripped_text
# - If there are multiple parts, return parts
# - remove function_call_id if it exists
def simplify_content(
    content: types.Content,
) -> Union[str, types.Part, list[types.Part]]:
  for part in content.parts:
    if part.function_call and part.function_call.id:
      part.function_call.id = None
    if part.function_response and part.function_response.id:
      part.function_response.id = None
  if len(content.parts) == 1:
    if content.parts[0].text:
      return content.parts[0].text.strip()
    else:
      return content.parts[0]
  return content.parts


def get_user_content(message: types.ContentUnion) -> types.Content:
  return message if isinstance(message, types.Content) else UserContent(message)


class TestInMemoryRunner(AfInMemoryRunner):
  """InMemoryRunner that is tailored for tests, features async run method.

  app_name is hardcoded as InMemoryRunner in the parent class.
  """

  async def run_async_with_new_session(
      self, new_message: types.ContentUnion
  ) -> list[Event]:

    session = await self.session_service.create_session(
        app_name='InMemoryRunner', user_id='test_user'
    )
    collected_events = []

    async for event in self.run_async(
        user_id=session.user_id,
        session_id=session.id,
        new_message=get_user_content(new_message),
    ):
      collected_events.append(event)

    return collected_events


class InMemoryRunner:
  """InMemoryRunner that is tailored for tests."""

  def __init__(
      self,
      root_agent: Union[Agent, LlmAgent],
      response_modalities: list[str] = None,
  ):
    self.root_agent = root_agent
    self.runner = Runner(
        app_name='test_app',
        agent=root_agent,
        artifact_service=InMemoryArtifactService(),
        session_service=InMemorySessionService(),
        memory_service=InMemoryMemoryService(),
    )
    self.session_id = None

  @property
  def session(self) -> Session:
    if not self.session_id:
      session = asyncio.run(
          self.runner.session_service.create_session(
              app_name='test_app', user_id='test_user'
          )
      )
      self.session_id = session.id
      return session
    return asyncio.run(
        self.runner.session_service.get_session(
            app_name='test_app', user_id='test_user', session_id=self.session_id
        )
    )

  def run(self, new_message: types.ContentUnion) -> list[Event]:
    return list(
        self.runner.run(
            user_id=self.session.user_id,
            session_id=self.session.id,
            new_message=get_user_content(new_message),
        )
    )

  def run_live(self, live_request_queue: LiveRequestQueue) -> list[Event]:
    collected_responses = []

    async def consume_responses(session: Session):
      run_res = self.runner.run_live(
          session=session,
          live_request_queue=live_request_queue,
      )

      async for response in run_res:
        collected_responses.append(response)
        # When we have enough response, we should return
        if len(collected_responses) >= 1:
          return

    try:
      session = self.session
      asyncio.run(consume_responses(session))
    except asyncio.TimeoutError:
      print('Returning any partial results collected so far.')

    return collected_responses


class MockModel(BaseLlm):
  model: str = 'mock'

  requests: list[LlmRequest] = []
  responses: list[LlmResponse]
  response_index: int = -1

  @classmethod
  def create(
      cls,
      responses: Union[
          list[types.Part], list[LlmResponse], list[str], list[list[types.Part]]
      ],
  ):
    if not responses:
      return cls(responses=[])
    elif isinstance(responses[0], LlmResponse):
      # responses is list[LlmResponse]
      return cls(responses=responses)
    else:
      responses = [
          LlmResponse(content=ModelContent(item))
          if isinstance(item, list) and isinstance(item[0], types.Part)
          # responses is list[list[Part]]
          else LlmResponse(
              content=ModelContent(
                  # responses is list[str] or list[Part]
                  [Part(text=item) if isinstance(item, str) else item]
              )
          )
          for item in responses
          if item
      ]

      return cls(responses=responses)

  @staticmethod
  def supported_models() -> list[str]:
    return ['mock']

  def generate_content(
      self, llm_request: LlmRequest, stream: bool = False
  ) -> Generator[LlmResponse, None, None]:
    # Increasement of the index has to happen before the yield.
    self.response_index += 1
    self.requests.append(llm_request)
    # yield LlmResponse(content=self.responses[self.response_index])
    yield self.responses[self.response_index]

  @override
  async def generate_content_async(
      self, llm_request: LlmRequest, stream: bool = False
  ) -> AsyncGenerator[LlmResponse, None]:
    # Increasement of the index has to happen before the yield.
    self.response_index += 1
    self.requests.append(llm_request)
    yield self.responses[self.response_index]

  @contextlib.asynccontextmanager
  async def connect(self, llm_request: LlmRequest) -> BaseLlmConnection:
    """Creates a live connection to the LLM."""
    yield MockLlmConnection(self.responses)


class MockLlmConnection(BaseLlmConnection):

  def __init__(self, llm_responses: list[LlmResponse]):
    self.llm_responses = llm_responses

  async def send_history(self, history: list[types.Content]):
    pass

  async def send_content(self, content: types.Content):
    pass

  async def send(self, data):
    pass

  async def send_realtime(self, blob: types.Blob):
    pass

  async def receive(self) -> AsyncGenerator[LlmResponse, None]:
    """Yield each of the pre-defined LlmResponses."""
    for response in self.llm_responses:
      yield response

  async def close(self):
    pass

==== tests/unittests/fast_api/test_fast_api.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import asyncio
import logging
import os
import sys
import time
import types as ptypes
from unittest.mock import MagicMock, patch

from fastapi.testclient import TestClient
from google.adk.agents.base_agent import BaseAgent
from google.adk.agents.run_config import RunConfig
from google.adk.cli.fast_api import get_fast_api_app
from google.adk.cli.utils import envs
from google.adk.events import Event
from google.adk.runners import Runner
from google.adk.sessions.base_session_service import ListSessionsResponse
from google.genai import types
import pytest


# Configure logging to help diagnose server startup issues
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


# Here we create a dummy agent module that get_fast_api_app expects
class DummyAgent(BaseAgent):

  def __init__(self, name):
    super().__init__(name=name)
    self.sub_agents = []


# Set up dummy module and add to sys.modules
dummy_module = ptypes.ModuleType("test_agent")
dummy_module.agent = ptypes.SimpleNamespace(
    root_agent=DummyAgent(name="dummy_agent")
)
sys.modules["test_app"] = dummy_module

# Try to load environment variables, with a fallback for testing
try:
  envs.load_dotenv_for_agent("test_app", ".")
except Exception as e:
  logger.warning(f"Could not load environment variables: {e}")
  # Create a basic .env file if needed
  if not os.path.exists(".env"):
    with open(".env", "w") as f:
      f.write("# Test environment variables\n")


# Create sample events that our mocked runner will return
def _event_1():
  return Event(
      author="dummy agent",
      invocation_id="invocation_id",
      content=types.Content(
          role="model", parts=[types.Part(text="LLM reply", inline_data=None)]
      ),
  )


def _event_2():
  return Event(
      author="dummy agent",
      invocation_id="invocation_id",
      content=types.Content(
          role="model",
          parts=[
              types.Part(
                  text=None,
                  inline_data=types.Blob(
                      mime_type="audio/pcm;rate=24000", data=b"\x00\xFF"
                  ),
              )
          ],
      ),
  )


def _event_3():
  return Event(
      author="dummy agent", invocation_id="invocation_id", interrupted=True
  )


# Define mocked async generator functions for the Runner
async def dummy_run_live(self, session, live_request_queue):
  yield _event_1()
  await asyncio.sleep(0)

  yield _event_2()
  await asyncio.sleep(0)

  yield _event_3()


async def dummy_run_async(
    self,
    user_id,
    session_id,
    new_message,
    run_config: RunConfig = RunConfig(),
):
  yield _event_1()
  await asyncio.sleep(0)

  yield _event_2()
  await asyncio.sleep(0)

  yield _event_3()


#################################################
# Test Fixtures
#################################################


@pytest.fixture(autouse=True)
def patch_runner(monkeypatch):
  """Patch the Runner methods to use our dummy implementations."""
  monkeypatch.setattr(Runner, "run_live", dummy_run_live)
  monkeypatch.setattr(Runner, "run_async", dummy_run_async)


@pytest.fixture
def test_session_info():
  """Return test user and session IDs for testing."""
  return {
      "app_name": "test_app",
      "user_id": "test_user",
      "session_id": "test_session",
  }


@pytest.fixture
def mock_session_service():
  """Create a mock session service that uses an in-memory dictionary."""

  # In-memory database to store sessions during testing
  session_data = {
      "test_app": {
          "test_user": {
              "test_session": {
                  "id": "test_session",
                  "app_name": "test_app",
                  "user_id": "test_user",
                  "events": [],
                  "state": {},
                  "created_at": time.time(),
              }
          }
      }
  }

  # Mock session service class that operates on the in-memory database
  class MockSessionService:

    async def get_session(self, app_name, user_id, session_id):
      """Retrieve a session by ID."""
      if (
          app_name in session_data
          and user_id in session_data[app_name]
          and session_id in session_data[app_name][user_id]
      ):
        return session_data[app_name][user_id][session_id]
      return None

    async def create_session(
        self, app_name, user_id, state=None, session_id=None
    ):
      """Create a new session."""
      if session_id is None:
        session_id = f"session_{int(time.time())}"

      # Initialize app_name and user_id if they don't exist
      if app_name not in session_data:
        session_data[app_name] = {}
      if user_id not in session_data[app_name]:
        session_data[app_name][user_id] = {}

      # Create the session
      session = {
          "id": session_id,
          "app_name": app_name,
          "user_id": user_id,
          "events": [],
          "state": state or {},
      }

      session_data[app_name][user_id][session_id] = session
      return session

    async def list_sessions(self, app_name, user_id):
      """List all sessions for a user."""
      if app_name not in session_data or user_id not in session_data[app_name]:
        return {"sessions": []}

      return ListSessionsResponse(
          sessions=list(session_data[app_name][user_id].values())
      )

    async def delete_session(self, app_name, user_id, session_id):
      """Delete a session."""
      if (
          app_name in session_data
          and user_id in session_data[app_name]
          and session_id in session_data[app_name][user_id]
      ):
        del session_data[app_name][user_id][session_id]

  # Return an instance of our mock service
  return MockSessionService()


@pytest.fixture
def mock_artifact_service():
  """Create a mock artifact service."""

  # Storage for artifacts
  artifacts = {}

  class MockArtifactService:

    async def load_artifact(
        self, app_name, user_id, session_id, filename, version=None
    ):
      """Load an artifact by filename."""
      key = f"{app_name}:{user_id}:{session_id}:{filename}"
      if key not in artifacts:
        return None

      if version is not None:
        # Get a specific version
        for v in artifacts[key]:
          if v["version"] == version:
            return v["artifact"]
        return None

      # Get the latest version
      return sorted(artifacts[key], key=lambda x: x["version"])[-1]["artifact"]

    async def list_artifact_keys(self, app_name, user_id, session_id):
      """List artifact names for a session."""
      prefix = f"{app_name}:{user_id}:{session_id}:"
      return [
          k.split(":")[-1] for k in artifacts.keys() if k.startswith(prefix)
      ]

    async def list_versions(self, app_name, user_id, session_id, filename):
      """List versions of an artifact."""
      key = f"{app_name}:{user_id}:{session_id}:{filename}"
      if key not in artifacts:
        return []
      return [a["version"] for a in artifacts[key]]

    async def delete_artifact(self, app_name, user_id, session_id, filename):
      """Delete an artifact."""
      key = f"{app_name}:{user_id}:{session_id}:{filename}"
      if key in artifacts:
        del artifacts[key]

  return MockArtifactService()


@pytest.fixture
def mock_memory_service():
  """Create a mock memory service."""
  return MagicMock()


@pytest.fixture
def test_app(mock_session_service, mock_artifact_service, mock_memory_service):
  """Create a TestClient for the FastAPI app without starting a server."""

  # Patch multiple services and signal handlers
  with (
      patch("signal.signal", return_value=None),
      patch(
          "google.adk.cli.fast_api.InMemorySessionService",  # Changed this line
          return_value=mock_session_service,
      ),
      patch(
          "google.adk.cli.fast_api.InMemoryArtifactService",  # Make consistent
          return_value=mock_artifact_service,
      ),
      patch(
          "google.adk.cli.fast_api.InMemoryMemoryService",  # Make consistent
          return_value=mock_memory_service,
      ),
  ):
    # Get the FastAPI app, but don't actually run it
    app = get_fast_api_app(
        agent_dir=".", web=True, session_db_url="", allow_origins=["*"]
    )

    # Create a TestClient that doesn't start a real server
    client = TestClient(app)

    return client


@pytest.fixture
async def create_test_session(
    test_app, test_session_info, mock_session_service
):
  """Create a test session using the mocked session service."""

  # Create the session directly through the mock service
  session = await mock_session_service.create_session(
      app_name=test_session_info["app_name"],
      user_id=test_session_info["user_id"],
      session_id=test_session_info["session_id"],
      state={},
  )

  logger.info(f"Created test session: {session['id']}")
  return test_session_info


#################################################
# Test Cases
#################################################


def test_list_apps(test_app):
  """Test listing available applications."""
  # Use the TestClient to make a request
  response = test_app.get("/list-apps")

  # Verify the response
  assert response.status_code == 200
  data = response.json()
  assert isinstance(data, list)
  logger.info(f"Listed apps: {data}")


def test_create_session_with_id(test_app, test_session_info):
  """Test creating a session with a specific ID."""
  new_session_id = "new_session_id"
  url = f"/apps/{test_session_info['app_name']}/users/{test_session_info['user_id']}/sessions/{new_session_id}"
  response = test_app.post(url, json={"state": {}})

  # Verify the response
  assert response.status_code == 200
  data = response.json()
  assert data["id"] == new_session_id
  assert data["appName"] == test_session_info["app_name"]
  assert data["userId"] == test_session_info["user_id"]
  logger.info(f"Created session with ID: {data['id']}")


def test_create_session_without_id(test_app, test_session_info):
  """Test creating a session with a generated ID."""
  url = f"/apps/{test_session_info['app_name']}/users/{test_session_info['user_id']}/sessions"
  response = test_app.post(url, json={"state": {}})

  # Verify the response
  assert response.status_code == 200
  data = response.json()
  assert "id" in data
  assert data["appName"] == test_session_info["app_name"]
  assert data["userId"] == test_session_info["user_id"]
  logger.info(f"Created session with generated ID: {data['id']}")


def test_get_session(test_app, create_test_session):
  """Test retrieving a session by ID."""
  info = create_test_session
  url = f"/apps/{info['app_name']}/users/{info['user_id']}/sessions/{info['session_id']}"
  response = test_app.get(url)

  # Verify the response
  assert response.status_code == 200
  data = response.json()
  assert data["id"] == info["session_id"]
  assert data["appName"] == info["app_name"]
  assert data["userId"] == info["user_id"]
  logger.info(f"Retrieved session: {data['id']}")


def test_list_sessions(test_app, create_test_session):
  """Test listing all sessions for a user."""
  info = create_test_session
  url = f"/apps/{info['app_name']}/users/{info['user_id']}/sessions"
  response = test_app.get(url)

  # Verify the response
  assert response.status_code == 200
  data = response.json()
  assert isinstance(data, list)
  # At least our test session should be present
  assert any(session["id"] == info["session_id"] for session in data)
  logger.info(f"Listed {len(data)} sessions")


def test_delete_session(test_app, create_test_session):
  """Test deleting a session."""
  info = create_test_session
  url = f"/apps/{info['app_name']}/users/{info['user_id']}/sessions/{info['session_id']}"
  response = test_app.delete(url)

  # Verify the response
  assert response.status_code == 200

  # Verify the session is deleted
  response = test_app.get(url)
  assert response.status_code == 404
  logger.info("Session deleted successfully")


def test_agent_run(test_app, create_test_session):
  """Test running an agent with a message."""
  info = create_test_session
  url = "/run"
  payload = {
      "app_name": info["app_name"],
      "user_id": info["user_id"],
      "session_id": info["session_id"],
      "new_message": {"role": "user", "parts": [{"text": "Hello agent"}]},
      "streaming": False,
  }

  response = test_app.post(url, json=payload)

  # Verify the response
  assert response.status_code == 200
  data = response.json()
  assert isinstance(data, list)
  assert len(data) == 3  # We expect 3 events from our dummy_run_async

  # Verify we got the expected events
  assert data[0]["author"] == "dummy agent"
  assert data[0]["content"]["parts"][0]["text"] == "LLM reply"

  # Second event should have binary data
  assert (
      data[1]["content"]["parts"][0]["inlineData"]["mimeType"]
      == "audio/pcm;rate=24000"
  )

  # Third event should have interrupted flag
  assert data[2]["interrupted"] == True

  logger.info("Agent run test completed successfully")


def test_list_artifact_names(test_app, create_test_session):
  """Test listing artifact names for a session."""
  info = create_test_session
  url = f"/apps/{info['app_name']}/users/{info['user_id']}/sessions/{info['session_id']}/artifacts"
  response = test_app.get(url)

  # Verify the response
  assert response.status_code == 200
  data = response.json()
  assert isinstance(data, list)
  logger.info(f"Listed {len(data)} artifacts")


def test_debug_trace(test_app):
  """Test the debug trace endpoint."""
  # This test will likely return 404 since we haven't set up trace data,
  # but it tests that the endpoint exists and handles missing traces correctly.
  url = "/debug/trace/nonexistent-event"
  response = test_app.get(url)

  # Verify we get a 404 for a nonexistent trace
  assert response.status_code == 404
  logger.info("Debug trace test completed successfully")


if __name__ == "__main__":
  pytest.main(["-xvs", __file__])

==== tests/unittests/fast_api/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

==== tests/unittests/auth/test_auth_handler.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import copy
from unittest.mock import patch

import pytest
from fastapi.openapi.models import APIKey
from fastapi.openapi.models import APIKeyIn
from fastapi.openapi.models import OAuth2
from fastapi.openapi.models import OAuthFlowAuthorizationCode
from fastapi.openapi.models import OAuthFlows

from google.adk.auth.auth_credential import AuthCredential
from google.adk.auth.auth_credential import AuthCredentialTypes
from google.adk.auth.auth_credential import OAuth2Auth
from google.adk.auth.auth_handler import AuthHandler
from google.adk.auth.auth_schemes import OpenIdConnectWithConfig
from google.adk.auth.auth_tool import AuthConfig


# Mock classes for testing
class MockState(dict):
  """Mock State class for testing."""

  def __init__(self, *args, **kwargs):
    super().__init__(*args, **kwargs)

  def get(self, key, default=None):
    return super().get(key, default)


class MockOAuth2Session:
  """Mock OAuth2Session for testing."""

  def __init__(
      self,
      client_id=None,
      client_secret=None,
      scope=None,
      redirect_uri=None,
      state=None,
  ):
    self.client_id = client_id
    self.client_secret = client_secret
    self.scope = scope
    self.redirect_uri = redirect_uri
    self.state = state

  def create_authorization_url(self, url, **kwargs):
    return f"{url}?client_id={self.client_id}&scope={self.scope}", "mock_state"

  def fetch_token(
      self,
      token_endpoint,
      authorization_response=None,
      code=None,
      grant_type=None,
  ):
    return {
        "access_token": "mock_access_token",
        "token_type": "bearer",
        "expires_in": 3600,
        "refresh_token": "mock_refresh_token",
    }


# Fixtures for common test objects
@pytest.fixture
def oauth2_auth_scheme():
  """Create an OAuth2 auth scheme for testing."""
  # Create the OAuthFlows object first
  flows = OAuthFlows(
      authorizationCode=OAuthFlowAuthorizationCode(
          authorizationUrl="https://example.com/oauth2/authorize",
          tokenUrl="https://example.com/oauth2/token",
          scopes={"read": "Read access", "write": "Write access"},
      )
  )

  # Then create the OAuth2 object with the flows
  return OAuth2(flows=flows)


@pytest.fixture
def openid_auth_scheme():
  """Create an OpenID Connect auth scheme for testing."""
  return OpenIdConnectWithConfig(
      openIdConnectUrl="https://example.com/.well-known/openid-configuration",
      authorization_endpoint="https://example.com/oauth2/authorize",
      token_endpoint="https://example.com/oauth2/token",
      scopes=["openid", "profile", "email"],
  )


@pytest.fixture
def oauth2_credentials():
  """Create OAuth2 credentials for testing."""
  return AuthCredential(
      auth_type=AuthCredentialTypes.OAUTH2,
      oauth2=OAuth2Auth(
          client_id="mock_client_id",
          client_secret="mock_client_secret",
          redirect_uri="https://example.com/callback",
      ),
  )


@pytest.fixture
def oauth2_credentials_with_token():
  """Create OAuth2 credentials with a token for testing."""
  return AuthCredential(
      auth_type=AuthCredentialTypes.OAUTH2,
      oauth2=OAuth2Auth(
          client_id="mock_client_id",
          client_secret="mock_client_secret",
          redirect_uri="https://example.com/callback",
          access_token="mock_access_token",
          refresh_token="mock_refresh_token",
      ),
  )


@pytest.fixture
def oauth2_credentials_with_auth_uri():
  """Create OAuth2 credentials with an auth URI for testing."""
  return AuthCredential(
      auth_type=AuthCredentialTypes.OAUTH2,
      oauth2=OAuth2Auth(
          client_id="mock_client_id",
          client_secret="mock_client_secret",
          redirect_uri="https://example.com/callback",
          auth_uri="https://example.com/oauth2/authorize?client_id=mock_client_id&scope=read,write",
          state="mock_state",
      ),
  )


@pytest.fixture
def oauth2_credentials_with_auth_code():
  """Create OAuth2 credentials with an auth code for testing."""
  return AuthCredential(
      auth_type=AuthCredentialTypes.OAUTH2,
      oauth2=OAuth2Auth(
          client_id="mock_client_id",
          client_secret="mock_client_secret",
          redirect_uri="https://example.com/callback",
          auth_uri="https://example.com/oauth2/authorize?client_id=mock_client_id&scope=read,write",
          state="mock_state",
          auth_code="mock_auth_code",
          auth_response_uri="https://example.com/callback?code=mock_auth_code&state=mock_state",
      ),
  )


@pytest.fixture
def auth_config(oauth2_auth_scheme, oauth2_credentials):
  """Create an AuthConfig for testing."""
  # Create a copy of the credentials for the exchanged_auth_credential
  exchanged_credential = oauth2_credentials.model_copy(deep=True)

  return AuthConfig(
      auth_scheme=oauth2_auth_scheme,
      raw_auth_credential=oauth2_credentials,
      exchanged_auth_credential=exchanged_credential,
  )


@pytest.fixture
def auth_config_with_exchanged(
    oauth2_auth_scheme, oauth2_credentials, oauth2_credentials_with_auth_uri
):
  """Create an AuthConfig with exchanged credentials for testing."""
  return AuthConfig(
      auth_scheme=oauth2_auth_scheme,
      raw_auth_credential=oauth2_credentials,
      exchanged_auth_credential=oauth2_credentials_with_auth_uri,
  )


@pytest.fixture
def auth_config_with_auth_code(
    oauth2_auth_scheme, oauth2_credentials, oauth2_credentials_with_auth_code
):
  """Create an AuthConfig with auth code for testing."""
  return AuthConfig(
      auth_scheme=oauth2_auth_scheme,
      raw_auth_credential=oauth2_credentials,
      exchanged_auth_credential=oauth2_credentials_with_auth_code,
  )


class TestAuthHandlerInit:
  """Tests for the AuthHandler initialization."""

  def test_init(self, auth_config):
    """Test the initialization of AuthHandler."""
    handler = AuthHandler(auth_config)
    assert handler.auth_config == auth_config


class TestGetCredentialKey:
  """Tests for the get_credential_key method."""

  def test_get_credential_key(self, auth_config):
    """Test generating a unique credential key."""
    handler = AuthHandler(auth_config)
    key = handler.get_credential_key()
    assert key.startswith("temp:adk_oauth2_")
    assert "_oauth2_" in key

  def test_get_credential_key_with_extras(self, auth_config):
    """Test generating a key when model_extra exists."""
    # Add model_extra to test cleanup

    original_key = AuthHandler(auth_config).get_credential_key()
    key = AuthHandler(auth_config).get_credential_key()

    auth_config.auth_scheme.model_extra["extra_field"] = "value"
    auth_config.raw_auth_credential.model_extra["extra_field"] = "value"

    assert original_key == key
    assert "extra_field" in auth_config.auth_scheme.model_extra
    assert "extra_field" in auth_config.raw_auth_credential.model_extra


class TestGenerateAuthUri:
  """Tests for the generate_auth_uri method."""

  @patch("google.adk.auth.auth_handler.OAuth2Session", MockOAuth2Session)
  def test_generate_auth_uri_oauth2(self, auth_config):
    """Test generating an auth URI for OAuth2."""
    handler = AuthHandler(auth_config)
    result = handler.generate_auth_uri()

    assert result.oauth2.auth_uri.startswith(
        "https://example.com/oauth2/authorize"
    )
    assert "client_id=mock_client_id" in result.oauth2.auth_uri
    assert result.oauth2.state == "mock_state"

  @patch("google.adk.auth.auth_handler.OAuth2Session", MockOAuth2Session)
  def test_generate_auth_uri_openid(
      self, openid_auth_scheme, oauth2_credentials
  ):
    """Test generating an auth URI for OpenID Connect."""
    # Create a copy for the exchanged credential
    exchanged = oauth2_credentials.model_copy(deep=True)

    config = AuthConfig(
        auth_scheme=openid_auth_scheme,
        raw_auth_credential=oauth2_credentials,
        exchanged_auth_credential=exchanged,
    )
    handler = AuthHandler(config)
    result = handler.generate_auth_uri()

    assert result.oauth2.auth_uri.startswith(
        "https://example.com/oauth2/authorize"
    )
    assert "client_id=mock_client_id" in result.oauth2.auth_uri
    assert result.oauth2.state == "mock_state"


class TestGenerateAuthRequest:
  """Tests for the generate_auth_request method."""

  def test_non_oauth_scheme(self):
    """Test with a non-OAuth auth scheme."""
    # Use a SecurityBase instance without using APIKey which has validation issues
    api_key_scheme = APIKey(**{"name": "test_api_key", "in": APIKeyIn.header})

    credential = AuthCredential(
        auth_type=AuthCredentialTypes.API_KEY, api_key="test_api_key"
    )

    # Create a copy for the exchanged credential
    exchanged = credential.model_copy(deep=True)

    config = AuthConfig(
        auth_scheme=api_key_scheme,
        raw_auth_credential=credential,
        exchanged_auth_credential=exchanged,
    )

    handler = AuthHandler(config)
    result = handler.generate_auth_request()

    assert result == config

  def test_with_existing_auth_uri(self, auth_config_with_exchanged):
    """Test when auth_uri already exists in exchanged credential."""
    handler = AuthHandler(auth_config_with_exchanged)
    result = handler.generate_auth_request()

    assert (
        result.exchanged_auth_credential.oauth2.auth_uri
        == auth_config_with_exchanged.exchanged_auth_credential.oauth2.auth_uri
    )

  def test_missing_raw_credential(self, oauth2_auth_scheme):
    """Test when raw_auth_credential is missing."""

    config = AuthConfig(
        auth_scheme=oauth2_auth_scheme,
    )
    handler = AuthHandler(config)

    with pytest.raises(ValueError, match="requires auth_credential"):
      handler.generate_auth_request()

  def test_missing_oauth2_in_raw_credential(self, oauth2_auth_scheme):
    """Test when oauth2 is missing in raw_auth_credential."""
    credential = AuthCredential(
        auth_type=AuthCredentialTypes.API_KEY, api_key="test_api_key"
    )

    # Create a copy for the exchanged credential
    exchanged = credential.model_copy(deep=True)

    config = AuthConfig(
        auth_scheme=oauth2_auth_scheme,
        raw_auth_credential=credential,
        exchanged_auth_credential=exchanged,
    )
    handler = AuthHandler(config)

    with pytest.raises(ValueError, match="requires oauth2 in auth_credential"):
      handler.generate_auth_request()

  def test_auth_uri_in_raw_credential(
      self, oauth2_auth_scheme, oauth2_credentials_with_auth_uri
  ):
    """Test when auth_uri exists in raw_credential."""
    config = AuthConfig(
        auth_scheme=oauth2_auth_scheme,
        raw_auth_credential=oauth2_credentials_with_auth_uri,
        exchanged_auth_credential=oauth2_credentials_with_auth_uri.model_copy(
            deep=True
        ),
    )
    handler = AuthHandler(config)
    result = handler.generate_auth_request()

    assert (
        result.exchanged_auth_credential.oauth2.auth_uri
        == oauth2_credentials_with_auth_uri.oauth2.auth_uri
    )

  def test_missing_client_credentials(self, oauth2_auth_scheme):
    """Test when client_id or client_secret is missing."""
    bad_credential = AuthCredential(
        auth_type=AuthCredentialTypes.OAUTH2,
        oauth2=OAuth2Auth(redirect_uri="https://example.com/callback"),
    )

    # Create a copy for the exchanged credential
    exchanged = bad_credential.model_copy(deep=True)

    config = AuthConfig(
        auth_scheme=oauth2_auth_scheme,
        raw_auth_credential=bad_credential,
        exchanged_auth_credential=exchanged,
    )
    handler = AuthHandler(config)

    with pytest.raises(
        ValueError, match="requires both client_id and client_secret"
    ):
      handler.generate_auth_request()

  @patch("google.adk.auth.auth_handler.AuthHandler.generate_auth_uri")
  def test_generate_new_auth_uri(self, mock_generate_auth_uri, auth_config):
    """Test generating a new auth URI."""
    mock_credential = AuthCredential(
        auth_type=AuthCredentialTypes.OAUTH2,
        oauth2=OAuth2Auth(
            client_id="mock_client_id",
            client_secret="mock_client_secret",
            redirect_uri="https://example.com/callback",
            auth_uri="https://example.com/generated",
            state="generated_state",
        ),
    )
    mock_generate_auth_uri.return_value = mock_credential

    handler = AuthHandler(auth_config)
    result = handler.generate_auth_request()

    assert mock_generate_auth_uri.called
    assert result.exchanged_auth_credential == mock_credential


class TestGetAuthResponse:
  """Tests for the get_auth_response method."""

  def test_get_auth_response_exists(
      self, auth_config, oauth2_credentials_with_auth_uri
  ):
    """Test retrieving an existing auth response from state."""
    handler = AuthHandler(auth_config)
    state = MockState()

    # Store a credential in the state
    credential_key = handler.get_credential_key()
    state[credential_key] = oauth2_credentials_with_auth_uri

    result = handler.get_auth_response(state)
    assert result == oauth2_credentials_with_auth_uri

  def test_get_auth_response_not_exists(self, auth_config):
    """Test retrieving a non-existent auth response from state."""
    handler = AuthHandler(auth_config)
    state = MockState()

    result = handler.get_auth_response(state)
    assert result is None


class TestParseAndStoreAuthResponse:
  """Tests for the parse_and_store_auth_response method."""

  def test_non_oauth_scheme(self, auth_config_with_exchanged):
    """Test with a non-OAuth auth scheme."""
    # Modify the auth scheme type to be non-OAuth
    auth_config = copy.deepcopy(auth_config_with_exchanged)
    auth_config.auth_scheme = APIKey(
        **{"name": "test_api_key", "in": APIKeyIn.header}
    )

    handler = AuthHandler(auth_config)
    state = MockState()

    handler.parse_and_store_auth_response(state)

    credential_key = handler.get_credential_key()
    assert state[credential_key] == auth_config.exchanged_auth_credential

  @patch("google.adk.auth.auth_handler.AuthHandler.exchange_auth_token")
  def test_oauth_scheme(self, mock_exchange_token, auth_config_with_exchanged):
    """Test with an OAuth auth scheme."""
    mock_exchange_token.return_value = AuthCredential(
        auth_type=AuthCredentialTypes.OAUTH2,
        oauth2=OAuth2Auth(access_token="exchanged_token"),
    )

    handler = AuthHandler(auth_config_with_exchanged)
    state = MockState()

    handler.parse_and_store_auth_response(state)

    credential_key = handler.get_credential_key()
    assert state[credential_key] == mock_exchange_token.return_value
    assert mock_exchange_token.called


class TestExchangeAuthToken:
  """Tests for the exchange_auth_token method."""

  def test_token_exchange_not_supported(
      self, auth_config_with_auth_code, monkeypatch
  ):
    """Test when token exchange is not supported."""
    monkeypatch.setattr(
        "google.adk.auth.auth_handler.SUPPORT_TOKEN_EXCHANGE", False
    )

    handler = AuthHandler(auth_config_with_auth_code)
    result = handler.exchange_auth_token()

    assert result == auth_config_with_auth_code.exchanged_auth_credential

  def test_openid_missing_token_endpoint(
      self, openid_auth_scheme, oauth2_credentials_with_auth_code
  ):
    """Test OpenID Connect without a token endpoint."""
    # Create a scheme without token_endpoint
    scheme_without_token = copy.deepcopy(openid_auth_scheme)
    delattr(scheme_without_token, "token_endpoint")

    config = AuthConfig(
        auth_scheme=scheme_without_token,
        raw_auth_credential=oauth2_credentials_with_auth_code,
        exchanged_auth_credential=oauth2_credentials_with_auth_code,
    )

    handler = AuthHandler(config)
    result = handler.exchange_auth_token()

    assert result == oauth2_credentials_with_auth_code

  def test_oauth2_missing_token_url(
      self, oauth2_auth_scheme, oauth2_credentials_with_auth_code
  ):
    """Test OAuth2 without a token URL."""
    # Create a scheme without tokenUrl
    scheme_without_token = copy.deepcopy(oauth2_auth_scheme)
    scheme_without_token.flows.authorizationCode.tokenUrl = None

    config = AuthConfig(
        auth_scheme=scheme_without_token,
        raw_auth_credential=oauth2_credentials_with_auth_code,
        exchanged_auth_credential=oauth2_credentials_with_auth_code,
    )

    handler = AuthHandler(config)
    result = handler.exchange_auth_token()

    assert result == oauth2_credentials_with_auth_code

  def test_non_oauth_scheme(self, auth_config_with_auth_code):
    """Test with a non-OAuth auth scheme."""
    # Modify the auth scheme type to be non-OAuth
    auth_config = copy.deepcopy(auth_config_with_auth_code)
    auth_config.auth_scheme = APIKey(
        **{"name": "test_api_key", "in": APIKeyIn.header}
    )

    handler = AuthHandler(auth_config)
    result = handler.exchange_auth_token()

    assert result == auth_config.exchanged_auth_credential

  def test_missing_credentials(self, oauth2_auth_scheme):
    """Test with missing credentials."""
    empty_credential = AuthCredential(auth_type=AuthCredentialTypes.OAUTH2)

    config = AuthConfig(
        auth_scheme=oauth2_auth_scheme,
        exchanged_auth_credential=empty_credential,
    )

    handler = AuthHandler(config)
    result = handler.exchange_auth_token()

    assert result == empty_credential

  def test_credentials_with_token(
      self, auth_config, oauth2_credentials_with_token
  ):
    """Test when credentials already have a token."""
    config = AuthConfig(
        auth_scheme=auth_config.auth_scheme,
        raw_auth_credential=auth_config.raw_auth_credential,
        exchanged_auth_credential=oauth2_credentials_with_token,
    )

    handler = AuthHandler(config)
    result = handler.exchange_auth_token()

    assert result == oauth2_credentials_with_token

  @patch("google.adk.auth.auth_handler.OAuth2Session", MockOAuth2Session)
  def test_successful_token_exchange(self, auth_config_with_auth_code):
    """Test a successful token exchange."""
    handler = AuthHandler(auth_config_with_auth_code)
    result = handler.exchange_auth_token()

    assert result.oauth2.access_token == "mock_access_token"
    assert result.oauth2.refresh_token == "mock_refresh_token"
    assert result.auth_type == AuthCredentialTypes.OAUTH2

==== tests/unittests/models/test_models.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.adk import models
from google.adk.models.anthropic_llm import Claude
from google.adk.models.google_llm import Gemini
from google.adk.models.registry import LLMRegistry
import pytest


@pytest.mark.parametrize(
    'model_name',
    [
        'gemini-1.5-flash',
        'gemini-1.5-flash-001',
        'gemini-1.5-flash-002',
        'gemini-1.5-pro',
        'gemini-1.5-pro-001',
        'gemini-1.5-pro-002',
        'gemini-2.0-flash-exp',
        'projects/123456/locations/us-central1/endpoints/123456',  # finetuned vertex gemini endpoint
        'projects/123456/locations/us-central1/publishers/google/models/gemini-2.0-flash-exp',  # vertex gemini long name
    ],
)
def test_match_gemini_family(model_name):
  assert models.LLMRegistry.resolve(model_name) is Gemini


@pytest.mark.parametrize(
    'model_name',
    [
        'claude-3-5-haiku@20241022',
        'claude-3-5-sonnet-v2@20241022',
        'claude-3-5-sonnet@20240620',
        'claude-3-haiku@20240307',
        'claude-3-opus@20240229',
        'claude-3-sonnet@20240229',
    ],
)
def test_match_claude_family(model_name):
  LLMRegistry.register(Claude)

  assert models.LLMRegistry.resolve(model_name) is Claude


def test_non_exist_model():
  with pytest.raises(ValueError) as e_info:
    models.LLMRegistry.resolve('non-exist-model')
  assert 'Model non-exist-model not found.' in str(e_info.value)

==== tests/unittests/models/test_litellm.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


from unittest.mock import AsyncMock
from unittest.mock import Mock
from google.adk.models.lite_llm import _content_to_message_param
from google.adk.models.lite_llm import _function_declaration_to_tool_param
from google.adk.models.lite_llm import _get_content
from google.adk.models.lite_llm import _message_to_generate_content_response
from google.adk.models.lite_llm import _model_response_to_chunk
from google.adk.models.lite_llm import _to_litellm_role
from google.adk.models.lite_llm import FunctionChunk
from google.adk.models.lite_llm import LiteLlm
from google.adk.models.lite_llm import LiteLLMClient
from google.adk.models.lite_llm import TextChunk
from google.adk.models.lite_llm import UsageMetadataChunk
from google.adk.models.llm_request import LlmRequest
from google.genai import types
from litellm import ChatCompletionAssistantMessage
from litellm import ChatCompletionMessageToolCall
from litellm import Function
from litellm.types.utils import ChatCompletionDeltaToolCall
from litellm.types.utils import Choices
from litellm.types.utils import Delta
from litellm.types.utils import ModelResponse
from litellm.types.utils import StreamingChoices
import pytest

LLM_REQUEST_WITH_FUNCTION_DECLARATION = LlmRequest(
    contents=[
        types.Content(
            role="user", parts=[types.Part.from_text(text="Test prompt")]
        )
    ],
    config=types.GenerateContentConfig(
        tools=[
            types.Tool(
                function_declarations=[
                    types.FunctionDeclaration(
                        name="test_function",
                        description="Test function description",
                        parameters=types.Schema(
                            type=types.Type.OBJECT,
                            properties={
                                "test_arg": types.Schema(
                                    type=types.Type.STRING
                                ),
                                "array_arg": types.Schema(
                                    type=types.Type.ARRAY,
                                    items={
                                        "type": types.Type.STRING,
                                    },
                                ),
                                "nested_arg": types.Schema(
                                    type=types.Type.OBJECT,
                                    properties={
                                        "nested_key1": types.Schema(
                                            type=types.Type.STRING
                                        ),
                                        "nested_key2": types.Schema(
                                            type=types.Type.STRING
                                        ),
                                    },
                                ),
                            },
                        ),
                    )
                ]
            )
        ],
    ),
)


STREAMING_MODEL_RESPONSE = [
    ModelResponse(
        choices=[
            StreamingChoices(
                finish_reason=None,
                delta=Delta(
                    role="assistant",
                    content="zero, ",
                ),
            )
        ]
    ),
    ModelResponse(
        choices=[
            StreamingChoices(
                finish_reason=None,
                delta=Delta(
                    role="assistant",
                    content="one, ",
                ),
            )
        ]
    ),
    ModelResponse(
        choices=[
            StreamingChoices(
                finish_reason=None,
                delta=Delta(
                    role="assistant",
                    content="two:",
                ),
            )
        ]
    ),
    ModelResponse(
        choices=[
            StreamingChoices(
                finish_reason=None,
                delta=Delta(
                    role="assistant",
                    tool_calls=[
                        ChatCompletionDeltaToolCall(
                            type="function",
                            id="test_tool_call_id",
                            function=Function(
                                name="test_function",
                                arguments='{"test_arg": "test_',
                            ),
                            index=0,
                        )
                    ],
                ),
            )
        ]
    ),
    ModelResponse(
        choices=[
            StreamingChoices(
                finish_reason=None,
                delta=Delta(
                    role="assistant",
                    tool_calls=[
                        ChatCompletionDeltaToolCall(
                            type="function",
                            id=None,
                            function=Function(
                                name=None,
                                arguments='value"}',
                            ),
                            index=0,
                        )
                    ],
                ),
            )
        ]
    ),
    ModelResponse(
        choices=[
            StreamingChoices(
                finish_reason="tool_use",
            )
        ]
    ),
]

@pytest.fixture
def mock_response():
  return ModelResponse(
      choices=[
          Choices(
              message=ChatCompletionAssistantMessage(
                  role="assistant",
                  content="Test response",
                  tool_calls=[
                      ChatCompletionMessageToolCall(
                          type="function",
                          id="test_tool_call_id",
                          function=Function(
                              name="test_function",
                              arguments='{"test_arg": "test_value"}',
                          ),
                      )
                  ],
              )
          )
      ]
  )


@pytest.fixture
def mock_acompletion(mock_response):
  return AsyncMock(return_value=mock_response)


@pytest.fixture
def mock_completion(mock_response):
  return Mock(return_value=mock_response)


@pytest.fixture
def mock_client(mock_acompletion, mock_completion):
  return MockLLMClient(mock_acompletion, mock_completion)


@pytest.fixture
def lite_llm_instance(mock_client):
  return LiteLlm(model="test_model", llm_client=mock_client)


class MockLLMClient(LiteLLMClient):

  def __init__(self, acompletion_mock, completion_mock):
    self.acompletion_mock = acompletion_mock
    self.completion_mock = completion_mock

  async def acompletion(self, model, messages, tools, **kwargs):
    return await self.acompletion_mock(
        model=model, messages=messages, tools=tools, **kwargs
    )

  def completion(self, model, messages, tools, stream, **kwargs):
    return self.completion_mock(
        model=model, messages=messages, tools=tools, stream=stream, **kwargs
    )


@pytest.mark.asyncio
async def test_generate_content_async(mock_acompletion, lite_llm_instance):

  async for response in lite_llm_instance.generate_content_async(
      LLM_REQUEST_WITH_FUNCTION_DECLARATION
  ):
    assert response.content.role == "model"
    assert response.content.parts[0].text == "Test response"
    assert response.content.parts[1].function_call.name == "test_function"
    assert response.content.parts[1].function_call.args == {
        "test_arg": "test_value"
    }
    assert response.content.parts[1].function_call.id == "test_tool_call_id"

  mock_acompletion.assert_called_once()

  _, kwargs = mock_acompletion.call_args
  assert kwargs["model"] == "test_model"
  assert kwargs["messages"][0]["role"] == "user"
  assert kwargs["messages"][0]["content"] == "Test prompt"
  assert kwargs["tools"][0]["function"]["name"] == "test_function"
  assert (
      kwargs["tools"][0]["function"]["description"]
      == "Test function description"
  )
  assert (
      kwargs["tools"][0]["function"]["parameters"]["properties"]["test_arg"][
          "type"
      ]
      == "string"
  )


litellm_append_user_content_test_cases = [
  pytest.param(
    LlmRequest(
      contents=[
        types.Content(
          role="developer",
          parts=[types.Part.from_text(text="Test prompt")]
        )
      ]
    ),
    2,
    id="litellm request without user content"
  ),
  pytest.param(
    LlmRequest(
      contents=[
        types.Content(
          role="user",
          parts=[types.Part.from_text(text="user prompt")]
        )
      ]
    ),
    1,
    id="litellm request with user content"
  ),
  pytest.param(
    LlmRequest(
      contents=[
        types.Content(
          role="model",
          parts=[types.Part.from_text(text="model prompt")]
        ),
        types.Content(
          role="user",
          parts=[types.Part.from_text(text="user prompt")]
        ),
        types.Content(
          role="model",
          parts=[types.Part.from_text(text="model prompt")]
        )
      ]
    ),
    4,
    id="user content is not the last message scenario"
  )
]

@pytest.mark.parametrize(
    "llm_request, expected_output",
    litellm_append_user_content_test_cases
)
def test_maybe_append_user_content(lite_llm_instance, llm_request, expected_output):

  lite_llm_instance._maybe_append_user_content(llm_request)

  assert len(llm_request.contents) == expected_output


function_declaration_test_cases = [
    (
        "simple_function",
        types.FunctionDeclaration(
            name="test_function",
            description="Test function description",
            parameters=types.Schema(
                type=types.Type.OBJECT,
                properties={
                    "test_arg": types.Schema(type=types.Type.STRING),
                    "array_arg": types.Schema(
                        type=types.Type.ARRAY,
                        items=types.Schema(
                            type=types.Type.STRING,
                        ),
                    ),
                    "nested_arg": types.Schema(
                        type=types.Type.OBJECT,
                        properties={
                            "nested_key1": types.Schema(type=types.Type.STRING),
                            "nested_key2": types.Schema(type=types.Type.STRING),
                        },
                    ),
                },
            ),
        ),
        {
            "type": "function",
            "function": {
                "name": "test_function",
                "description": "Test function description",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "test_arg": {"type": "string"},
                        "array_arg": {
                            "items": {"type": "string"},
                            "type": "array",
                        },
                        "nested_arg": {
                            "properties": {
                                "nested_key1": {"type": "string"},
                                "nested_key2": {"type": "string"},
                            },
                            "type": "object",
                        },
                    },
                },
            },
        },
    ),
    (
        "no_description",
        types.FunctionDeclaration(
            name="test_function_no_description",
            parameters=types.Schema(
                type=types.Type.OBJECT,
                properties={
                    "test_arg": types.Schema(type=types.Type.STRING),
                },
            ),
        ),
        {
            "type": "function",
            "function": {
                "name": "test_function_no_description",
                "description": "",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "test_arg": {"type": "string"},
                    },
                },
            },
        },
    ),
    (
        "empty_parameters",
        types.FunctionDeclaration(
            name="test_function_empty_params",
            parameters=types.Schema(type=types.Type.OBJECT, properties={}),
        ),
        {
            "type": "function",
            "function": {
                "name": "test_function_empty_params",
                "description": "",
                "parameters": {
                    "type": "object",
                    "properties": {},
                },
            },
        },
    ),
    (
        "nested_array",
        types.FunctionDeclaration(
            name="test_function_nested_array",
            parameters=types.Schema(
                type=types.Type.OBJECT,
                properties={
                    "array_arg": types.Schema(
                        type=types.Type.ARRAY,
                        items=types.Schema(
                            type=types.Type.OBJECT,
                            properties={
                                "nested_key": types.Schema(
                                    type=types.Type.STRING
                                )
                            },
                        ),
                    ),
                },
            ),
        ),
        {
            "type": "function",
            "function": {
                "name": "test_function_nested_array",
                "description": "",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "array_arg": {
                            "items": {
                                "properties": {
                                    "nested_key": {"type": "string"}
                                },
                                "type": "object",
                            },
                            "type": "array",
                        },
                    },
                },
            },
        },
    ),
]


@pytest.mark.parametrize(
    "_, function_declaration, expected_output",
    function_declaration_test_cases,
    ids=[case[0] for case in function_declaration_test_cases],
)
def test_function_declaration_to_tool_param(
    _, function_declaration, expected_output
):
  assert (
      _function_declaration_to_tool_param(function_declaration)
      == expected_output
  )


@pytest.mark.asyncio
async def test_generate_content_async_with_system_instruction(
    lite_llm_instance, mock_acompletion
):
  mock_response_with_system_instruction = ModelResponse(
      choices=[
          Choices(
              message=ChatCompletionAssistantMessage(
                  role="assistant",
                  content="Test response",
              )
          )
      ]
  )
  mock_acompletion.return_value = mock_response_with_system_instruction

  llm_request = LlmRequest(
      contents=[
          types.Content(
              role="user", parts=[types.Part.from_text(text="Test prompt")]
          )
      ],
      config=types.GenerateContentConfig(
          system_instruction="Test system instruction"
      ),
  )

  async for response in lite_llm_instance.generate_content_async(llm_request):
    assert response.content.role == "model"
    assert response.content.parts[0].text == "Test response"

  mock_acompletion.assert_called_once()

  _, kwargs = mock_acompletion.call_args
  assert kwargs["model"] == "test_model"
  assert kwargs["messages"][0]["role"] == "developer"
  assert kwargs["messages"][0]["content"] == "Test system instruction"
  assert kwargs["messages"][1]["role"] == "user"
  assert kwargs["messages"][1]["content"] == "Test prompt"


@pytest.mark.asyncio
async def test_generate_content_async_with_tool_response(
    lite_llm_instance, mock_acompletion
):
  mock_response_with_tool_response = ModelResponse(
      choices=[
          Choices(
              message=ChatCompletionAssistantMessage(
                  role="tool",
                  content='{"result": "test_result"}',
                  tool_call_id="test_tool_call_id",
              )
          )
      ]
  )
  mock_acompletion.return_value = mock_response_with_tool_response

  llm_request = LlmRequest(
      contents=[
          types.Content(
              role="user", parts=[types.Part.from_text(text="Test prompt")]
          ),
          types.Content(
              role="tool",
              parts=[
                  types.Part.from_function_response(
                      name="test_function",
                      response={"result": "test_result"},
                  )
              ],
          ),
      ],
      config=types.GenerateContentConfig(
          system_instruction="test instruction",
      ),
  )
  async for response in lite_llm_instance.generate_content_async(llm_request):
    assert response.content.role == "model"
    assert response.content.parts[0].text == '{"result": "test_result"}'

  mock_acompletion.assert_called_once()

  _, kwargs = mock_acompletion.call_args
  assert kwargs["model"] == "test_model"

  assert kwargs["messages"][2]["role"] == "tool"
  assert kwargs["messages"][2]["content"] == '{"result": "test_result"}'


@pytest.mark.asyncio
async def test_generate_content_async(mock_acompletion, lite_llm_instance):

  async for response in lite_llm_instance.generate_content_async(
      LLM_REQUEST_WITH_FUNCTION_DECLARATION
  ):
    assert response.content.role == "model"
    assert response.content.parts[0].text == "Test response"
    assert response.content.parts[1].function_call.name == "test_function"
    assert response.content.parts[1].function_call.args == {
        "test_arg": "test_value"
    }
    assert response.content.parts[1].function_call.id == "test_tool_call_id"

  mock_acompletion.assert_called_once()

  _, kwargs = mock_acompletion.call_args
  assert kwargs["model"] == "test_model"
  assert kwargs["messages"][0]["role"] == "user"
  assert kwargs["messages"][0]["content"] == "Test prompt"
  assert kwargs["tools"][0]["function"]["name"] == "test_function"
  assert (
      kwargs["tools"][0]["function"]["description"]
      == "Test function description"
  )
  assert (
      kwargs["tools"][0]["function"]["parameters"]["properties"]["test_arg"][
          "type"
      ]
      == "string"
  )


@pytest.mark.asyncio
async def test_generate_content_async_with_usage_metadata(
    lite_llm_instance, mock_acompletion
):
  mock_response_with_usage_metadata = ModelResponse(
      choices=[
          Choices(
              message=ChatCompletionAssistantMessage(
                  role="assistant",
                  content="Test response",
              )
          )
      ],
      usage={
          "prompt_tokens": 10,
          "completion_tokens": 5,
          "total_tokens": 15,
      },
  )
  mock_acompletion.return_value = mock_response_with_usage_metadata

  llm_request = LlmRequest(
      contents=[
          types.Content(
              role="user", parts=[types.Part.from_text(text="Test prompt")]
          ),
      ],
      config=types.GenerateContentConfig(
          system_instruction="test instruction",
      ),
  )
  async for response in lite_llm_instance.generate_content_async(llm_request):
    assert response.content.role == "model"
    assert response.content.parts[0].text == "Test response"
    assert response.usage_metadata.prompt_token_count == 10
    assert response.usage_metadata.candidates_token_count == 5
    assert response.usage_metadata.total_token_count == 15

  mock_acompletion.assert_called_once()


def test_content_to_message_param_user_message():
  content = types.Content(
      role="user", parts=[types.Part.from_text(text="Test prompt")]
  )
  message = _content_to_message_param(content)
  assert message["role"] == "user"
  assert message["content"] == "Test prompt"


def test_content_to_message_param_multi_part_function_response():
  part1 = types.Part.from_function_response(
      name="function_one",
      response={"result": "result_one"},
  )
  part1.function_response.id = "tool_call_1"

  part2 = types.Part.from_function_response(
      name="function_two",
      response={"value": 123},
  )
  part2.function_response.id = "tool_call_2"

  content = types.Content(
      role="tool",
      parts=[part1, part2],
  )
  messages = _content_to_message_param(content)
  assert isinstance(messages, list)
  assert len(messages) == 2

  assert messages[0]["role"] == "tool"
  assert messages[0]["tool_call_id"] == "tool_call_1"
  assert messages[0]["content"] == '{"result": "result_one"}'

  assert messages[1]["role"] == "tool"
  assert messages[1]["tool_call_id"] == "tool_call_2"
  assert messages[1]["content"] == '{"value": 123}'


def test_content_to_message_param_assistant_message():
  content = types.Content(
      role="assistant", parts=[types.Part.from_text(text="Test response")]
  )
  message = _content_to_message_param(content)
  assert message["role"] == "assistant"
  assert message["content"] == "Test response"


def test_content_to_message_param_function_call():
  content = types.Content(
      role="assistant",
      parts=[
          types.Part.from_function_call(
              name="test_function", args={"test_arg": "test_value"}
          )
      ],
  )
  content.parts[0].function_call.id = "test_tool_call_id"
  message = _content_to_message_param(content)
  assert message["role"] == "assistant"
  assert message["content"] == None
  assert message["tool_calls"][0].type == "function"
  assert message["tool_calls"][0].id == "test_tool_call_id"
  assert message["tool_calls"][0].function.name == "test_function"
  assert (
      message["tool_calls"][0].function.arguments
      == '{"test_arg": "test_value"}'
  )


def test_message_to_generate_content_response_text():
  message = ChatCompletionAssistantMessage(
      role="assistant",
      content="Test response",
  )
  response = _message_to_generate_content_response(message)
  assert response.content.role == "model"
  assert response.content.parts[0].text == "Test response"


def test_message_to_generate_content_response_tool_call():
  message = ChatCompletionAssistantMessage(
      role="assistant",
      content=None,
      tool_calls=[
          ChatCompletionMessageToolCall(
              type="function",
              id="test_tool_call_id",
              function=Function(
                  name="test_function",
                  arguments='{"test_arg": "test_value"}',
              ),
          )
      ],
  )

  response = _message_to_generate_content_response(message)
  assert response.content.role == "model"
  assert response.content.parts[0].function_call.name == "test_function"
  assert response.content.parts[0].function_call.args == {
      "test_arg": "test_value"
  }
  assert response.content.parts[0].function_call.id == "test_tool_call_id"


def test_get_content_text():
  parts = [types.Part.from_text(text="Test text")]
  content = _get_content(parts)
  assert content == "Test text"


def test_get_content_image():
  parts = [
      types.Part.from_bytes(data=b"test_image_data", mime_type="image/png")
  ]
  content = _get_content(parts)
  assert content[0]["type"] == "image_url"
  assert content[0]["image_url"] == "data:image/png;base64,dGVzdF9pbWFnZV9kYXRh"


def test_get_content_video():
  parts = [
      types.Part.from_bytes(data=b"test_video_data", mime_type="video/mp4")
  ]
  content = _get_content(parts)
  assert content[0]["type"] == "video_url"
  assert content[0]["video_url"] == "data:video/mp4;base64,dGVzdF92aWRlb19kYXRh"


def test_to_litellm_role():
  assert _to_litellm_role("model") == "assistant"
  assert _to_litellm_role("assistant") == "assistant"
  assert _to_litellm_role("user") == "user"
  assert _to_litellm_role(None) == "user"


@pytest.mark.parametrize(
    "response, expected_chunks, expected_finished",
    [
        (
            ModelResponse(
                choices=[
                    {
                        "message": {
                            "content": "this is a test",
                        }
                    }
                ]
            ),
            [
                TextChunk(text="this is a test"),
                UsageMetadataChunk(
                    prompt_tokens=0, completion_tokens=0, total_tokens=0
                ),
            ],
            "stop",
        ),
        (
            ModelResponse(
                choices=[
                    {
                        "message": {
                            "content": "this is a test",
                        }
                    }
                ],
                usage={
                    "prompt_tokens": 3,
                    "completion_tokens": 5,
                    "total_tokens": 8,
                },
            ),
            [
                TextChunk(text="this is a test"),
                UsageMetadataChunk(
                    prompt_tokens=3, completion_tokens=5, total_tokens=8
                ),
            ],
            "stop",
        ),
        (
            ModelResponse(
                choices=[
                    StreamingChoices(
                        finish_reason=None,
                        delta=Delta(
                            role="assistant",
                            tool_calls=[
                                ChatCompletionDeltaToolCall(
                                    type="function",
                                    id="1",
                                    function=Function(
                                        name="test_function",
                                        arguments='{"key": "va',
                                    ),
                                    index=0,
                                )
                            ],
                        ),
                    )
                ]
            ),
            [
                FunctionChunk(id="1", name="test_function", args='{"key": "va'),
                UsageMetadataChunk(
                    prompt_tokens=0, completion_tokens=0, total_tokens=0
                ),
            ],
            None,
        ),
        (
            ModelResponse(choices=[{"finish_reason": "tool_calls"}]),
            [
                None,
                UsageMetadataChunk(
                    prompt_tokens=0, completion_tokens=0, total_tokens=0
                ),
            ],
            "tool_calls",
        ),
        (
            ModelResponse(choices=[{}]),
            [
                None,
                UsageMetadataChunk(
                    prompt_tokens=0, completion_tokens=0, total_tokens=0
                ),
            ],
            "stop",
        ),
    ],
)
def test_model_response_to_chunk(response, expected_chunks, expected_finished):
  result = list(_model_response_to_chunk(response))
  assert len(result) == 2
  chunk, finished = result[0]
  if expected_chunks:
    assert isinstance(chunk, type(expected_chunks[0]))
    assert chunk == expected_chunks[0]
  else:
    assert chunk is None
  assert finished == expected_finished

  usage_chunk, _ = result[1]
  assert usage_chunk is not None
  assert usage_chunk.prompt_tokens == expected_chunks[1].prompt_tokens
  assert usage_chunk.completion_tokens == expected_chunks[1].completion_tokens
  assert usage_chunk.total_tokens == expected_chunks[1].total_tokens


@pytest.mark.asyncio
async def test_acompletion_additional_args(mock_acompletion, mock_client):
  lite_llm_instance = LiteLlm(
      # valid args
      model="test_model",
      llm_client=mock_client,
      api_key="test_key",
      api_base="some://url",
      api_version="2024-09-12",
      # invalid args (ignored)
      stream=True,
      messages=[{"role": "invalid", "content": "invalid"}],
      tools=[{
          "type": "function",
          "function": {
              "name": "invalid",
          },
      }],
  )

  async for response in lite_llm_instance.generate_content_async(
      LLM_REQUEST_WITH_FUNCTION_DECLARATION
  ):
    assert response.content.role == "model"
    assert response.content.parts[0].text == "Test response"
    assert response.content.parts[1].function_call.name == "test_function"
    assert response.content.parts[1].function_call.args == {
        "test_arg": "test_value"
    }
    assert response.content.parts[1].function_call.id == "test_tool_call_id"

  mock_acompletion.assert_called_once()

  _, kwargs = mock_acompletion.call_args

  assert kwargs["model"] == "test_model"
  assert kwargs["messages"][0]["role"] == "user"
  assert kwargs["messages"][0]["content"] == "Test prompt"
  assert kwargs["tools"][0]["function"]["name"] == "test_function"
  assert "stream" not in kwargs
  assert "llm_client" not in kwargs
  assert kwargs["api_base"] == "some://url"


@pytest.mark.asyncio
async def test_completion_additional_args(mock_completion, mock_client):
  lite_llm_instance = LiteLlm(
      # valid args
      model="test_model",
      llm_client=mock_client,
      api_key="test_key",
      api_base="some://url",
      api_version="2024-09-12",
      # invalid args (ignored)
      stream=False,
      messages=[{"role": "invalid", "content": "invalid"}],
      tools=[{
          "type": "function",
          "function": {
              "name": "invalid",
          },
      }],
  )

  mock_completion.return_value = iter(STREAMING_MODEL_RESPONSE)

  responses = [
      response
      async for response in lite_llm_instance.generate_content_async(
          LLM_REQUEST_WITH_FUNCTION_DECLARATION, stream=True
      )
  ]
  assert len(responses) == 4
  mock_completion.assert_called_once()

  _, kwargs = mock_completion.call_args

  assert kwargs["model"] == "test_model"
  assert kwargs["messages"][0]["role"] == "user"
  assert kwargs["messages"][0]["content"] == "Test prompt"
  assert kwargs["tools"][0]["function"]["name"] == "test_function"
  assert kwargs["stream"]
  assert "llm_client" not in kwargs
  assert kwargs["api_base"] == "some://url"


@pytest.mark.asyncio
async def test_generate_content_async_stream(
    mock_completion, lite_llm_instance
):

  mock_completion.return_value = iter(STREAMING_MODEL_RESPONSE)

  responses = [
      response
      async for response in lite_llm_instance.generate_content_async(
          LLM_REQUEST_WITH_FUNCTION_DECLARATION, stream=True
      )
  ]
  assert len(responses) == 4
  assert responses[0].content.role == "model"
  assert responses[0].content.parts[0].text == "zero, "
  assert responses[1].content.role == "model"
  assert responses[1].content.parts[0].text == "one, "
  assert responses[2].content.role == "model"
  assert responses[2].content.parts[0].text == "two:"
  assert responses[3].content.role == "model"
  assert responses[3].content.parts[0].function_call.name == "test_function"
  assert responses[3].content.parts[0].function_call.args == {
      "test_arg": "test_value"
  }
  assert responses[3].content.parts[0].function_call.id == "test_tool_call_id"
  mock_completion.assert_called_once()

  _, kwargs = mock_completion.call_args
  assert kwargs["model"] == "test_model"
  assert kwargs["messages"][0]["role"] == "user"
  assert kwargs["messages"][0]["content"] == "Test prompt"
  assert kwargs["tools"][0]["function"]["name"] == "test_function"
  assert (
      kwargs["tools"][0]["function"]["description"]
      == "Test function description"
  )
  assert (
      kwargs["tools"][0]["function"]["parameters"]["properties"]["test_arg"][
          "type"
      ]
      == "string"
  )


@pytest.mark.asyncio
async def test_generate_content_async_stream_with_usage_metadata(
    mock_completion, lite_llm_instance
):

  streaming_model_response_with_usage_metadata = [
      *STREAMING_MODEL_RESPONSE,
      ModelResponse(
          usage={
              "prompt_tokens": 10,
              "completion_tokens": 5,
              "total_tokens": 15,
          },
          choices=[
              StreamingChoices(
                  finish_reason=None,
              )
          ],
      ),
  ]

  mock_completion.return_value = iter(
      streaming_model_response_with_usage_metadata
  )

  responses = [
      response
      async for response in lite_llm_instance.generate_content_async(
          LLM_REQUEST_WITH_FUNCTION_DECLARATION, stream=True
      )
  ]
  assert len(responses) == 4
  assert responses[0].content.role == "model"
  assert responses[0].content.parts[0].text == "zero, "
  assert responses[1].content.role == "model"
  assert responses[1].content.parts[0].text == "one, "
  assert responses[2].content.role == "model"
  assert responses[2].content.parts[0].text == "two:"
  assert responses[3].content.role == "model"
  assert responses[3].content.parts[0].function_call.name == "test_function"
  assert responses[3].content.parts[0].function_call.args == {
      "test_arg": "test_value"
  }
  assert responses[3].content.parts[0].function_call.id == "test_tool_call_id"

  assert responses[3].usage_metadata.prompt_token_count == 10
  assert responses[3].usage_metadata.candidates_token_count == 5
  assert responses[3].usage_metadata.total_token_count == 15

  mock_completion.assert_called_once()

  _, kwargs = mock_completion.call_args
  assert kwargs["model"] == "test_model"
  assert kwargs["messages"][0]["role"] == "user"
  assert kwargs["messages"][0]["content"] == "Test prompt"
  assert kwargs["tools"][0]["function"]["name"] == "test_function"
  assert (
      kwargs["tools"][0]["function"]["description"]
      == "Test function description"
  )
  assert (
      kwargs["tools"][0]["function"]["parameters"]["properties"]["test_arg"][
          "type"
      ]
      == "string"
  )

==== tests/unittests/models/test_google_llm.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import sys
from unittest import mock

from google.adk import version
from google.adk.models.gemini_llm_connection import GeminiLlmConnection
from google.adk.models.google_llm import Gemini
from google.adk.models.llm_request import LlmRequest
from google.adk.models.llm_response import LlmResponse
from google.genai import types
from google.genai.types import Content
from google.genai.types import Part
import pytest


@pytest.fixture
def generate_content_response():
  return types.GenerateContentResponse(
      candidates=[
          types.Candidate(
              content=Content(
                  role="model",
                  parts=[Part.from_text(text="Hello, how can I help you?")],
              ),
              finish_reason=types.FinishReason.STOP,
          )
      ]
  )


@pytest.fixture
def gemini_llm():
  return Gemini(model="gemini-1.5-flash")


@pytest.fixture
def llm_request():
  return LlmRequest(
      model="gemini-1.5-flash",
      contents=[Content(role="user", parts=[Part.from_text(text="Hello")])],
      config=types.GenerateContentConfig(
          temperature=0.1,
          response_modalities=[types.Modality.TEXT],
          system_instruction="You are a helpful assistant",
      ),
  )


def test_supported_models():
  models = Gemini.supported_models()
  assert len(models) == 3
  assert models[0] == r"gemini-.*"
  assert models[1] == r"projects\/.+\/locations\/.+\/endpoints\/.+"
  assert (
      models[2]
      == r"projects\/.+\/locations\/.+\/publishers\/google\/models\/gemini.+"
  )


def test_client_version_header():
  model = Gemini(model="gemini-1.5-flash")
  client = model.api_client
  expected_header = (
      f"google-adk/{version.__version__}"
      f" gl-python/{sys.version.split()[0]} google-genai-sdk/"
  )
  assert (
      expected_header
      in client._api_client._http_options.headers["x-goog-api-client"]
  )
  assert (
      expected_header in client._api_client._http_options.headers["user-agent"]
  )


def test_maybe_append_user_content(gemini_llm, llm_request):
  # Test with user content already present
  gemini_llm._maybe_append_user_content(llm_request)
  assert len(llm_request.contents) == 1

  # Test with model content as the last message
  llm_request.contents.append(
      Content(role="model", parts=[Part.from_text(text="Response")])
  )
  gemini_llm._maybe_append_user_content(llm_request)
  assert len(llm_request.contents) == 3
  assert llm_request.contents[-1].role == "user"
  assert "Continue processing" in llm_request.contents[-1].parts[0].text


@pytest.mark.asyncio
async def test_generate_content_async(
    gemini_llm, llm_request, generate_content_response
):
  with mock.patch.object(gemini_llm, "api_client") as mock_client:
    # Create a mock coroutine that returns the generate_content_response
    async def mock_coro():
      return generate_content_response

    # Assign the coroutine to the mocked method
    mock_client.aio.models.generate_content.return_value = mock_coro()

    responses = [
        resp
        async for resp in gemini_llm.generate_content_async(
            llm_request, stream=False
        )
    ]

    assert len(responses) == 1
    assert isinstance(responses[0], LlmResponse)
    assert responses[0].content.parts[0].text == "Hello, how can I help you?"
    mock_client.aio.models.generate_content.assert_called_once()


@pytest.mark.asyncio
async def test_generate_content_async_stream(gemini_llm, llm_request):
  with mock.patch.object(gemini_llm, "api_client") as mock_client:
    # Create mock stream responses
    class MockAsyncIterator:

      def __init__(self, seq):
        self.iter = iter(seq)

      def __aiter__(self):
        return self

      async def __anext__(self):
        try:
          return next(self.iter)
        except StopIteration:
          raise StopAsyncIteration

    mock_responses = [
        types.GenerateContentResponse(
            candidates=[
                types.Candidate(
                    content=Content(
                        role="model", parts=[Part.from_text(text="Hello")]
                    ),
                    finish_reason=None,
                )
            ]
        ),
        types.GenerateContentResponse(
            candidates=[
                types.Candidate(
                    content=Content(
                        role="model", parts=[Part.from_text(text=", how")]
                    ),
                    finish_reason=None,
                )
            ]
        ),
        types.GenerateContentResponse(
            candidates=[
                types.Candidate(
                    content=Content(
                        role="model",
                        parts=[Part.from_text(text=" can I help you?")],
                    ),
                    finish_reason=types.FinishReason.STOP,
                )
            ]
        ),
    ]

    # Create a mock coroutine that returns the MockAsyncIterator
    async def mock_coro():
      return MockAsyncIterator(mock_responses)

    # Set the mock to return the coroutine
    mock_client.aio.models.generate_content_stream.return_value = mock_coro()

    responses = [
        resp
        async for resp in gemini_llm.generate_content_async(
            llm_request, stream=True
        )
    ]

    # Assertions remain the same
    assert len(responses) == 4
    assert responses[0].partial is True
    assert responses[1].partial is True
    assert responses[2].partial is True
    assert responses[3].content.parts[0].text == "Hello, how can I help you?"
    mock_client.aio.models.generate_content_stream.assert_called_once()


@pytest.mark.asyncio
async def test_connect(gemini_llm, llm_request):
  # Create a mock connection
  mock_connection = mock.MagicMock(spec=GeminiLlmConnection)

  # Create a mock context manager
  class MockContextManager:

    async def __aenter__(self):
      return mock_connection

    async def __aexit__(self, *args):
      pass

  # Mock the connect method at the class level
  with mock.patch(
      "google.adk.models.google_llm.Gemini.connect",
      return_value=MockContextManager(),
  ):
    async with gemini_llm.connect(llm_request) as connection:
      assert connection is mock_connection

==== tests/unittests/models/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

==== tests/unittests/streaming/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

==== tests/unittests/streaming/test_streaming.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.adk.agents import Agent
from google.adk.agents import LiveRequestQueue
from google.adk.models import LlmResponse
from google.genai import types
import pytest

from .. import utils


def test_streaming():
  response1 = LlmResponse(
      turn_complete=True,
  )

  mock_model = utils.MockModel.create([response1])

  root_agent = Agent(
      name='root_agent',
      model=mock_model,
      tools=[],
  )

  runner = utils.InMemoryRunner(
      root_agent=root_agent, response_modalities=['AUDIO']
  )
  live_request_queue = LiveRequestQueue()
  live_request_queue.send_realtime(
      blob=types.Blob(data=b'\x00\xFF', mime_type='audio/pcm')
  )
  res_events = runner.run_live(live_request_queue)

  assert res_events is not None, 'Expected a list of events, got None.'
  assert (
      len(res_events) > 0
  ), 'Expected at least one response, but got an empty list.'

==== tests/unittests/agents/test_loop_agent.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Testings for the SequentialAgent."""

from typing import AsyncGenerator

from google.adk.agents.base_agent import BaseAgent
from google.adk.agents.invocation_context import InvocationContext
from google.adk.agents.loop_agent import LoopAgent
from google.adk.events import Event
from google.adk.events import EventActions
from google.adk.sessions.in_memory_session_service import InMemorySessionService
from google.genai import types
import pytest
from typing_extensions import override


class _TestingAgent(BaseAgent):

  @override
  async def _run_async_impl(
      self, ctx: InvocationContext
  ) -> AsyncGenerator[Event, None]:
    yield Event(
        author=self.name,
        invocation_id=ctx.invocation_id,
        content=types.Content(
            parts=[types.Part(text=f'Hello, async {self.name}!')]
        ),
    )

  @override
  async def _run_live_impl(
      self, ctx: InvocationContext
  ) -> AsyncGenerator[Event, None]:
    yield Event(
        author=self.name,
        invocation_id=ctx.invocation_id,
        content=types.Content(
            parts=[types.Part(text=f'Hello, live {self.name}!')]
        ),
    )


class _TestingAgentWithEscalateAction(BaseAgent):

  @override
  async def _run_async_impl(
      self, ctx: InvocationContext
  ) -> AsyncGenerator[Event, None]:
    yield Event(
        author=self.name,
        invocation_id=ctx.invocation_id,
        content=types.Content(
            parts=[types.Part(text=f'Hello, async {self.name}!')]
        ),
        actions=EventActions(escalate=True),
    )


async def _create_parent_invocation_context(
    test_name: str, agent: BaseAgent
) -> InvocationContext:
  session_service = InMemorySessionService()
  session = await session_service.create_session(
      app_name='test_app', user_id='test_user'
  )
  return InvocationContext(
      invocation_id=f'{test_name}_invocation_id',
      agent=agent,
      session=session,
      session_service=session_service,
  )


@pytest.mark.asyncio
async def test_run_async(request: pytest.FixtureRequest):
  agent = _TestingAgent(name=f'{request.function.__name__}_test_agent')
  loop_agent = LoopAgent(
      name=f'{request.function.__name__}_test_loop_agent',
      max_iterations=2,
      sub_agents=[
          agent,
      ],
  )
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, loop_agent
  )
  events = [e async for e in loop_agent.run_async(parent_ctx)]

  assert len(events) == 2
  assert events[0].author == agent.name
  assert events[1].author == agent.name
  assert events[0].content.parts[0].text == f'Hello, async {agent.name}!'
  assert events[1].content.parts[0].text == f'Hello, async {agent.name}!'


@pytest.mark.asyncio
async def test_run_async_with_escalate_action(request: pytest.FixtureRequest):
  non_escalating_agent = _TestingAgent(
      name=f'{request.function.__name__}_test_non_escalating_agent'
  )
  escalating_agent = _TestingAgentWithEscalateAction(
      name=f'{request.function.__name__}_test_escalating_agent'
  )
  loop_agent = LoopAgent(
      name=f'{request.function.__name__}_test_loop_agent',
      sub_agents=[non_escalating_agent, escalating_agent],
  )
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, loop_agent
  )
  events = [e async for e in loop_agent.run_async(parent_ctx)]

  # Only two events are generated because the sub escalating_agent escalates.
  assert len(events) == 2
  assert events[0].author == non_escalating_agent.name
  assert events[1].author == escalating_agent.name
  assert events[0].content.parts[0].text == (
      f'Hello, async {non_escalating_agent.name}!'
  )
  assert events[1].content.parts[0].text == (
      f'Hello, async {escalating_agent.name}!'
  )

==== tests/unittests/agents/test_run_config.py ====
import pytest
import sys
import logging
from unittest.mock import patch, ANY
from google.adk.agents.run_config import RunConfig


def test_validate_max_llm_calls_valid():
  value = RunConfig.validate_max_llm_calls(100)
  assert value == 100


def test_validate_max_llm_calls_negative():
  with patch("google.adk.agents.run_config.logger.warning") as mock_warning:
    value = RunConfig.validate_max_llm_calls(-1)
    mock_warning.assert_called_once_with(ANY)
    assert value == -1


def test_validate_max_llm_calls_warns_on_zero():
  with patch("google.adk.agents.run_config.logger.warning") as mock_warning:
    value = RunConfig.validate_max_llm_calls(0)
    mock_warning.assert_called_once_with(ANY)
    assert value == 0


def test_validate_max_llm_calls_too_large():
  with pytest.raises(
      ValueError, match=f"max_llm_calls should be less than {sys.maxsize}."
  ):
    RunConfig.validate_max_llm_calls(sys.maxsize)

==== tests/unittests/agents/test_live_request_queue.py ====
import pytest
from unittest.mock import MagicMock, AsyncMock, patch
from google.adk.agents.live_request_queue import LiveRequest, LiveRequestQueue
from google.genai import types


@pytest.mark.asyncio
async def test_close_queue():
  queue = LiveRequestQueue()

  with patch.object(queue._queue, "put_nowait") as mock_put_nowait:
    queue.close()
    mock_put_nowait.assert_called_once_with(LiveRequest(close=True))


def test_send_content():
  queue = LiveRequestQueue()
  content = MagicMock(spec=types.Content)

  with patch.object(queue._queue, "put_nowait") as mock_put_nowait:
    queue.send_content(content)
    mock_put_nowait.assert_called_once_with(LiveRequest(content=content))


def test_send_realtime():
  queue = LiveRequestQueue()
  blob = MagicMock(spec=types.Blob)

  with patch.object(queue._queue, "put_nowait") as mock_put_nowait:
    queue.send_realtime(blob)
    mock_put_nowait.assert_called_once_with(LiveRequest(blob=blob))


def test_send():
  queue = LiveRequestQueue()
  req = LiveRequest(content=MagicMock(spec=types.Content))

  with patch.object(queue._queue, "put_nowait") as mock_put_nowait:
    queue.send(req)
    mock_put_nowait.assert_called_once_with(req)


@pytest.mark.asyncio
async def test_get():
  queue = LiveRequestQueue()
  res = MagicMock(spec=types.Content)

  with patch.object(queue._queue, "get", return_value=res) as mock_get:
    result = await queue.get()

    assert result == res
    mock_get.assert_called_once()

==== tests/unittests/agents/test_langgraph_agent.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from unittest.mock import MagicMock

from google.adk.agents.invocation_context import InvocationContext
from google.adk.agents.langgraph_agent import LangGraphAgent
from google.adk.events import Event
from google.genai import types
from langchain_core.messages import AIMessage
from langchain_core.messages import HumanMessage
from langchain_core.messages import SystemMessage
from langgraph.graph.graph import CompiledGraph
import pytest


@pytest.mark.parametrize(
    "checkpointer_value, events_list, expected_messages",
    [
        (
            MagicMock(),
            [
                Event(
                    invocation_id="test_invocation_id",
                    author="user",
                    content=types.Content(
                        role="user",
                        parts=[types.Part.from_text(text="test prompt")],
                    ),
                ),
                Event(
                    invocation_id="test_invocation_id",
                    author="root_agent",
                    content=types.Content(
                        role="model",
                        parts=[types.Part.from_text(text="(some delegation)")],
                    ),
                ),
            ],
            [
                SystemMessage(content="test system prompt"),
                HumanMessage(content="test prompt"),
            ],
        ),
        (
            None,
            [
                Event(
                    invocation_id="test_invocation_id",
                    author="user",
                    content=types.Content(
                        role="user",
                        parts=[types.Part.from_text(text="user prompt 1")],
                    ),
                ),
                Event(
                    invocation_id="test_invocation_id",
                    author="root_agent",
                    content=types.Content(
                        role="model",
                        parts=[
                            types.Part.from_text(text="root agent response")
                        ],
                    ),
                ),
                Event(
                    invocation_id="test_invocation_id",
                    author="weather_agent",
                    content=types.Content(
                        role="model",
                        parts=[
                            types.Part.from_text(text="weather agent response")
                        ],
                    ),
                ),
                Event(
                    invocation_id="test_invocation_id",
                    author="user",
                    content=types.Content(
                        role="user",
                        parts=[types.Part.from_text(text="user prompt 2")],
                    ),
                ),
            ],
            [
                SystemMessage(content="test system prompt"),
                HumanMessage(content="user prompt 1"),
                AIMessage(content="weather agent response"),
                HumanMessage(content="user prompt 2"),
            ],
        ),
        (
            MagicMock(),
            [
                Event(
                    invocation_id="test_invocation_id",
                    author="user",
                    content=types.Content(
                        role="user",
                        parts=[types.Part.from_text(text="user prompt 1")],
                    ),
                ),
                Event(
                    invocation_id="test_invocation_id",
                    author="root_agent",
                    content=types.Content(
                        role="model",
                        parts=[
                            types.Part.from_text(text="root agent response")
                        ],
                    ),
                ),
                Event(
                    invocation_id="test_invocation_id",
                    author="weather_agent",
                    content=types.Content(
                        role="model",
                        parts=[
                            types.Part.from_text(text="weather agent response")
                        ],
                    ),
                ),
                Event(
                    invocation_id="test_invocation_id",
                    author="user",
                    content=types.Content(
                        role="user",
                        parts=[types.Part.from_text(text="user prompt 2")],
                    ),
                ),
            ],
            [
                SystemMessage(content="test system prompt"),
                HumanMessage(content="user prompt 2"),
            ],
        ),
    ],
)
@pytest.mark.asyncio
async def test_langgraph_agent(
    checkpointer_value, events_list, expected_messages
):
  mock_graph = MagicMock(spec=CompiledGraph)
  mock_graph_state = MagicMock()
  mock_graph_state.values = {}
  mock_graph.get_state.return_value = mock_graph_state

  mock_graph.checkpointer = checkpointer_value
  mock_graph.invoke.return_value = {
      "messages": [AIMessage(content="test response")]
  }

  mock_parent_context = MagicMock(spec=InvocationContext)
  mock_session = MagicMock()
  mock_parent_context.session = mock_session
  mock_parent_context.branch = "parent_agent"
  mock_parent_context.end_invocation = False
  mock_session.events = events_list
  mock_parent_context.invocation_id = "test_invocation_id"
  mock_parent_context.model_copy.return_value = mock_parent_context

  weather_agent = LangGraphAgent(
      name="weather_agent",
      description="A agent that answers weather questions",
      instruction="test system prompt",
      graph=mock_graph,
  )

  result_event = None
  async for event in weather_agent.run_async(mock_parent_context):
    result_event = event

  assert result_event.author == "weather_agent"
  assert result_event.content.parts[0].text == "test response"

  mock_graph.invoke.assert_called_once()
  mock_graph.invoke.assert_called_with(
      {"messages": expected_messages},
      {"configurable": {"thread_id": mock_session.id}},
  )

==== tests/unittests/agents/test_base_agent.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Testings for the BaseAgent."""

from enum import Enum
from functools import partial
from typing import AsyncGenerator
from typing import List
from typing import Optional
from typing import Union
from unittest import mock
from google.adk.agents.base_agent import BaseAgent
from google.adk.agents.callback_context import CallbackContext
from google.adk.agents.invocation_context import InvocationContext
from google.adk.events import Event
from google.adk.sessions.in_memory_session_service import InMemorySessionService
from google.genai import types
import pytest
import pytest_mock
from typing_extensions import override
from .. import utils


def _before_agent_callback_noop(callback_context: CallbackContext) -> None:
  pass


async def _async_before_agent_callback_noop(
    callback_context: CallbackContext,
) -> None:
  pass


def _before_agent_callback_bypass_agent(
    callback_context: CallbackContext,
) -> types.Content:
  return types.Content(parts=[types.Part(text='agent run is bypassed.')])


async def _async_before_agent_callback_bypass_agent(
    callback_context: CallbackContext,
) -> types.Content:
  return types.Content(parts=[types.Part(text='agent run is bypassed.')])


def _after_agent_callback_noop(callback_context: CallbackContext) -> None:
  pass


async def _async_after_agent_callback_noop(
    callback_context: CallbackContext,
) -> None:
  pass


def _after_agent_callback_append_agent_reply(
    callback_context: CallbackContext,
) -> types.Content:
  return types.Content(
      parts=[types.Part(text='Agent reply from after agent callback.')]
  )


async def _async_after_agent_callback_append_agent_reply(
    callback_context: CallbackContext,
) -> types.Content:
  return types.Content(
      parts=[types.Part(text='Agent reply from after agent callback.')]
  )


class _IncompleteAgent(BaseAgent):
  pass


class _TestingAgent(BaseAgent):

  @override
  async def _run_async_impl(
      self, ctx: InvocationContext
  ) -> AsyncGenerator[Event, None]:
    yield Event(
        author=self.name,
        branch=ctx.branch,
        invocation_id=ctx.invocation_id,
        content=types.Content(parts=[types.Part(text='Hello, world!')]),
    )

  @override
  async def _run_live_impl(
      self, ctx: InvocationContext
  ) -> AsyncGenerator[Event, None]:
    yield Event(
        author=self.name,
        invocation_id=ctx.invocation_id,
        branch=ctx.branch,
        content=types.Content(parts=[types.Part(text='Hello, live!')]),
    )


async def _create_parent_invocation_context(
    test_name: str, agent: BaseAgent, branch: Optional[str] = None
) -> InvocationContext:
  session_service = InMemorySessionService()
  session = await session_service.create_session(
      app_name='test_app', user_id='test_user'
  )
  return InvocationContext(
      invocation_id=f'{test_name}_invocation_id',
      branch=branch,
      agent=agent,
      session=session,
      session_service=session_service,
  )


def test_invalid_agent_name():
  with pytest.raises(ValueError):
    _ = _TestingAgent(name='not an identifier')


@pytest.mark.asyncio
async def test_run_async(request: pytest.FixtureRequest):
  agent = _TestingAgent(name=f'{request.function.__name__}_test_agent')
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, agent
  )

  events = [e async for e in agent.run_async(parent_ctx)]

  assert len(events) == 1
  assert events[0].author == agent.name
  assert events[0].content.parts[0].text == 'Hello, world!'


@pytest.mark.asyncio
async def test_run_async_with_branch(request: pytest.FixtureRequest):
  agent = _TestingAgent(name=f'{request.function.__name__}_test_agent')
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, agent, branch='parent_branch'
  )

  events = [e async for e in agent.run_async(parent_ctx)]

  assert len(events) == 1
  assert events[0].author == agent.name
  assert events[0].content.parts[0].text == 'Hello, world!'
  assert events[0].branch.endswith(agent.name)


@pytest.mark.asyncio
async def test_run_async_before_agent_callback_noop(
    request: pytest.FixtureRequest,
    mocker: pytest_mock.MockerFixture,
) -> Union[types.Content, None]:
  # Arrange
  agent = _TestingAgent(
      name=f'{request.function.__name__}_test_agent',
      before_agent_callback=_before_agent_callback_noop,
  )
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, agent
  )
  spy_run_async_impl = mocker.spy(agent, BaseAgent._run_async_impl.__name__)
  spy_before_agent_callback = mocker.spy(agent, 'before_agent_callback')

  # Act
  _ = [e async for e in agent.run_async(parent_ctx)]

  # Assert
  spy_before_agent_callback.assert_called_once()
  _, kwargs = spy_before_agent_callback.call_args
  assert 'callback_context' in kwargs
  assert isinstance(kwargs['callback_context'], CallbackContext)

  spy_run_async_impl.assert_called_once()


@pytest.mark.asyncio
async def test_run_async_with_async_before_agent_callback_noop(
    request: pytest.FixtureRequest,
    mocker: pytest_mock.MockerFixture,
) -> Union[types.Content, None]:
  # Arrange
  agent = _TestingAgent(
      name=f'{request.function.__name__}_test_agent',
      before_agent_callback=_async_before_agent_callback_noop,
  )
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, agent
  )
  spy_run_async_impl = mocker.spy(agent, BaseAgent._run_async_impl.__name__)
  spy_before_agent_callback = mocker.spy(agent, 'before_agent_callback')

  # Act
  _ = [e async for e in agent.run_async(parent_ctx)]

  # Assert
  spy_before_agent_callback.assert_called_once()
  _, kwargs = spy_before_agent_callback.call_args
  assert 'callback_context' in kwargs
  assert isinstance(kwargs['callback_context'], CallbackContext)

  spy_run_async_impl.assert_called_once()


@pytest.mark.asyncio
async def test_run_async_before_agent_callback_bypass_agent(
    request: pytest.FixtureRequest,
    mocker: pytest_mock.MockerFixture,
):
  # Arrange
  agent = _TestingAgent(
      name=f'{request.function.__name__}_test_agent',
      before_agent_callback=_before_agent_callback_bypass_agent,
  )
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, agent
  )
  spy_run_async_impl = mocker.spy(agent, BaseAgent._run_async_impl.__name__)
  spy_before_agent_callback = mocker.spy(agent, 'before_agent_callback')

  # Act
  events = [e async for e in agent.run_async(parent_ctx)]

  # Assert
  spy_before_agent_callback.assert_called_once()
  spy_run_async_impl.assert_not_called()

  assert len(events) == 1
  assert events[0].content.parts[0].text == 'agent run is bypassed.'


@pytest.mark.asyncio
async def test_run_async_with_async_before_agent_callback_bypass_agent(
    request: pytest.FixtureRequest,
    mocker: pytest_mock.MockerFixture,
):
  # Arrange
  agent = _TestingAgent(
      name=f'{request.function.__name__}_test_agent',
      before_agent_callback=_async_before_agent_callback_bypass_agent,
  )
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, agent
  )
  spy_run_async_impl = mocker.spy(agent, BaseAgent._run_async_impl.__name__)
  spy_before_agent_callback = mocker.spy(agent, 'before_agent_callback')

  # Act
  events = [e async for e in agent.run_async(parent_ctx)]

  # Assert
  spy_before_agent_callback.assert_called_once()
  spy_run_async_impl.assert_not_called()

  assert len(events) == 1
  assert events[0].content.parts[0].text == 'agent run is bypassed.'


class CallbackType(Enum):
  SYNC = 1
  ASYNC = 2


async def mock_async_agent_cb_side_effect(
    callback_context: CallbackContext,
    ret_value=None,
):
  if ret_value:
    return types.Content(parts=[types.Part(text=ret_value)])
  return None


def mock_sync_agent_cb_side_effect(
    callback_context: CallbackContext,
    ret_value=None,
):
  if ret_value:
    return types.Content(parts=[types.Part(text=ret_value)])
  return None


BEFORE_AGENT_CALLBACK_PARAMS = [
    pytest.param(
        [
            (None, CallbackType.SYNC),
            ('callback_2_response', CallbackType.ASYNC),
            ('callback_3_response', CallbackType.SYNC),
            (None, CallbackType.ASYNC),
        ],
        ['callback_2_response'],
        [1, 1, 0, 0],
        id='middle_async_callback_returns',
    ),
    pytest.param(
        [
            (None, CallbackType.SYNC),
            (None, CallbackType.ASYNC),
            (None, CallbackType.SYNC),
            (None, CallbackType.ASYNC),
        ],
        ['Hello, world!'],
        [1, 1, 1, 1],
        id='all_callbacks_return_none',
    ),
    pytest.param(
        [
            ('callback_1_response', CallbackType.SYNC),
            ('callback_2_response', CallbackType.ASYNC),
        ],
        ['callback_1_response'],
        [1, 0],
        id='first_sync_callback_returns',
    ),
]

AFTER_AGENT_CALLBACK_PARAMS = [
    pytest.param(
        [
            (None, CallbackType.SYNC),
            ('callback_2_response', CallbackType.ASYNC),
            ('callback_3_response', CallbackType.SYNC),
            (None, CallbackType.ASYNC),
        ],
        ['Hello, world!', 'callback_2_response'],
        [1, 1, 0, 0],
        id='middle_async_callback_returns',
    ),
    pytest.param(
        [
            (None, CallbackType.SYNC),
            (None, CallbackType.ASYNC),
            (None, CallbackType.SYNC),
            (None, CallbackType.ASYNC),
        ],
        ['Hello, world!'],
        [1, 1, 1, 1],
        id='all_callbacks_return_none',
    ),
    pytest.param(
        [
            ('callback_1_response', CallbackType.SYNC),
            ('callback_2_response', CallbackType.ASYNC),
        ],
        ['Hello, world!', 'callback_1_response'],
        [1, 0],
        id='first_sync_callback_returns',
    ),
]


@pytest.mark.parametrize(
    'callbacks, expected_responses, expected_calls',
    BEFORE_AGENT_CALLBACK_PARAMS,
)
@pytest.mark.asyncio
async def test_before_agent_callbacks_chain(
    callbacks: List[tuple[str, int]],
    expected_responses: List[str],
    expected_calls: List[int],
    request: pytest.FixtureRequest,
):
  mock_cbs = []
  for response, callback_type in callbacks:

    if callback_type == CallbackType.ASYNC:
      mock_cb = mock.AsyncMock(
          side_effect=partial(
              mock_async_agent_cb_side_effect, ret_value=response
          )
      )
    else:
      mock_cb = mock.Mock(
          side_effect=partial(
              mock_sync_agent_cb_side_effect, ret_value=response
          )
      )
    mock_cbs.append(mock_cb)

  agent = _TestingAgent(
      name=f'{request.function.__name__}_test_agent',
      before_agent_callback=[mock_cb for mock_cb in mock_cbs],
  )
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, agent
  )
  result = [e async for e in agent.run_async(parent_ctx)]
  assert utils.simplify_events(result) == [
      (f'{request.function.__name__}_test_agent', response)
      for response in expected_responses
  ]

  # Assert that the callbacks were called the expected number of times
  for i, mock_cb in enumerate(mock_cbs):
    expected_calls_count = expected_calls[i]
    if expected_calls_count == 1:
      if isinstance(mock_cb, mock.AsyncMock):
        mock_cb.assert_awaited_once()
      else:
        mock_cb.assert_called_once()
    elif expected_calls_count == 0:
      if isinstance(mock_cb, mock.AsyncMock):
        mock_cb.assert_not_awaited()
      else:
        mock_cb.assert_not_called()
    else:
      if isinstance(mock_cb, mock.AsyncMock):
        mock_cb.assert_awaited(expected_calls_count)
      else:
        mock_cb.assert_called(expected_calls_count)


@pytest.mark.parametrize(
    'callbacks, expected_responses, expected_calls',
    AFTER_AGENT_CALLBACK_PARAMS,
)
@pytest.mark.asyncio
async def test_after_agent_callbacks_chain(
    callbacks: List[tuple[str, int]],
    expected_responses: List[str],
    expected_calls: List[int],
    request: pytest.FixtureRequest,
):
  mock_cbs = []
  for response, callback_type in callbacks:

    if callback_type == CallbackType.ASYNC:
      mock_cb = mock.AsyncMock(
          side_effect=partial(
              mock_async_agent_cb_side_effect, ret_value=response
          )
      )
    else:
      mock_cb = mock.Mock(
          side_effect=partial(
              mock_sync_agent_cb_side_effect, ret_value=response
          )
      )
    mock_cbs.append(mock_cb)

  agent = _TestingAgent(
      name=f'{request.function.__name__}_test_agent',
      after_agent_callback=[mock_cb for mock_cb in mock_cbs],
  )
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, agent
  )
  result = [e async for e in agent.run_async(parent_ctx)]
  assert utils.simplify_events(result) == [
      (f'{request.function.__name__}_test_agent', response)
      for response in expected_responses
  ]

  # Assert that the callbacks were called the expected number of times
  for i, mock_cb in enumerate(mock_cbs):
    expected_calls_count = expected_calls[i]
    if expected_calls_count == 1:
      if isinstance(mock_cb, mock.AsyncMock):
        mock_cb.assert_awaited_once()
      else:
        mock_cb.assert_called_once()
    elif expected_calls_count == 0:
      if isinstance(mock_cb, mock.AsyncMock):
        mock_cb.assert_not_awaited()
      else:
        mock_cb.assert_not_called()
    else:
      if isinstance(mock_cb, mock.AsyncMock):
        mock_cb.assert_awaited(expected_calls_count)
      else:
        mock_cb.assert_called(expected_calls_count)


@pytest.mark.asyncio
async def test_run_async_after_agent_callback_noop(
    request: pytest.FixtureRequest,
    mocker: pytest_mock.MockerFixture,
):
  # Arrange
  agent = _TestingAgent(
      name=f'{request.function.__name__}_test_agent',
      after_agent_callback=_after_agent_callback_noop,
  )
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, agent
  )
  spy_after_agent_callback = mocker.spy(agent, 'after_agent_callback')

  # Act
  events = [e async for e in agent.run_async(parent_ctx)]

  # Assert
  spy_after_agent_callback.assert_called_once()
  _, kwargs = spy_after_agent_callback.call_args
  assert 'callback_context' in kwargs
  assert isinstance(kwargs['callback_context'], CallbackContext)
  assert len(events) == 1


@pytest.mark.asyncio
async def test_run_async_with_async_after_agent_callback_noop(
    request: pytest.FixtureRequest,
    mocker: pytest_mock.MockerFixture,
):
  # Arrange
  agent = _TestingAgent(
      name=f'{request.function.__name__}_test_agent',
      after_agent_callback=_async_after_agent_callback_noop,
  )
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, agent
  )
  spy_after_agent_callback = mocker.spy(agent, 'after_agent_callback')

  # Act
  events = [e async for e in agent.run_async(parent_ctx)]

  # Assert
  spy_after_agent_callback.assert_called_once()
  _, kwargs = spy_after_agent_callback.call_args
  assert 'callback_context' in kwargs
  assert isinstance(kwargs['callback_context'], CallbackContext)
  assert len(events) == 1


@pytest.mark.asyncio
async def test_run_async_after_agent_callback_append_reply(
    request: pytest.FixtureRequest,
):
  # Arrange
  agent = _TestingAgent(
      name=f'{request.function.__name__}_test_agent',
      after_agent_callback=_after_agent_callback_append_agent_reply,
  )
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, agent
  )

  # Act
  events = [e async for e in agent.run_async(parent_ctx)]

  # Assert
  assert len(events) == 2
  assert events[1].author == agent.name
  assert (
      events[1].content.parts[0].text
      == 'Agent reply from after agent callback.'
  )


@pytest.mark.asyncio
async def test_run_async_with_async_after_agent_callback_append_reply(
    request: pytest.FixtureRequest,
):
  # Arrange
  agent = _TestingAgent(
      name=f'{request.function.__name__}_test_agent',
      after_agent_callback=_async_after_agent_callback_append_agent_reply,
  )
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, agent
  )

  # Act
  events = [e async for e in agent.run_async(parent_ctx)]

  # Assert
  assert len(events) == 2
  assert events[1].author == agent.name
  assert (
      events[1].content.parts[0].text
      == 'Agent reply from after agent callback.'
  )


@pytest.mark.asyncio
async def test_run_async_incomplete_agent(request: pytest.FixtureRequest):
  agent = _IncompleteAgent(name=f'{request.function.__name__}_test_agent')
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, agent
  )

  with pytest.raises(NotImplementedError):
    [e async for e in agent.run_async(parent_ctx)]


@pytest.mark.asyncio
async def test_run_live(request: pytest.FixtureRequest):
  agent = _TestingAgent(name=f'{request.function.__name__}_test_agent')
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, agent
  )

  events = [e async for e in agent.run_live(parent_ctx)]

  assert len(events) == 1
  assert events[0].author == agent.name
  assert events[0].content.parts[0].text == 'Hello, live!'


@pytest.mark.asyncio
async def test_run_live_with_branch(request: pytest.FixtureRequest):
  agent = _TestingAgent(name=f'{request.function.__name__}_test_agent')
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, agent, branch='parent_branch'
  )

  events = [e async for e in agent.run_live(parent_ctx)]

  assert len(events) == 1
  assert events[0].author == agent.name
  assert events[0].content.parts[0].text == 'Hello, live!'
  assert events[0].branch.endswith(agent.name)


@pytest.mark.asyncio
async def test_run_live_incomplete_agent(request: pytest.FixtureRequest):
  agent = _IncompleteAgent(name=f'{request.function.__name__}_test_agent')
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, agent
  )

  with pytest.raises(NotImplementedError):
    [e async for e in agent.run_live(parent_ctx)]


def test_set_parent_agent_for_sub_agents(request: pytest.FixtureRequest):
  sub_agents: list[BaseAgent] = [
      _TestingAgent(name=f'{request.function.__name__}_sub_agent_1'),
      _TestingAgent(name=f'{request.function.__name__}_sub_agent_2'),
  ]
  parent = _TestingAgent(
      name=f'{request.function.__name__}_parent',
      sub_agents=sub_agents,
  )

  for sub_agent in sub_agents:
    assert sub_agent.parent_agent == parent


def test_find_agent(request: pytest.FixtureRequest):
  grand_sub_agent_1 = _TestingAgent(
      name=f'{request.function.__name__}__grand_sub_agent_1'
  )
  grand_sub_agent_2 = _TestingAgent(
      name=f'{request.function.__name__}__grand_sub_agent_2'
  )
  sub_agent_1 = _TestingAgent(
      name=f'{request.function.__name__}_sub_agent_1',
      sub_agents=[grand_sub_agent_1],
  )
  sub_agent_2 = _TestingAgent(
      name=f'{request.function.__name__}_sub_agent_2',
      sub_agents=[grand_sub_agent_2],
  )
  parent = _TestingAgent(
      name=f'{request.function.__name__}_parent',
      sub_agents=[sub_agent_1, sub_agent_2],
  )

  assert parent.find_agent(parent.name) == parent
  assert parent.find_agent(sub_agent_1.name) == sub_agent_1
  assert parent.find_agent(sub_agent_2.name) == sub_agent_2
  assert parent.find_agent(grand_sub_agent_1.name) == grand_sub_agent_1
  assert parent.find_agent(grand_sub_agent_2.name) == grand_sub_agent_2
  assert sub_agent_1.find_agent(grand_sub_agent_1.name) == grand_sub_agent_1
  assert sub_agent_1.find_agent(grand_sub_agent_2.name) is None
  assert sub_agent_2.find_agent(grand_sub_agent_1.name) is None
  assert sub_agent_2.find_agent(sub_agent_2.name) == sub_agent_2
  assert parent.find_agent('not_exist') is None


def test_find_sub_agent(request: pytest.FixtureRequest):
  grand_sub_agent_1 = _TestingAgent(
      name=f'{request.function.__name__}__grand_sub_agent_1'
  )
  grand_sub_agent_2 = _TestingAgent(
      name=f'{request.function.__name__}__grand_sub_agent_2'
  )
  sub_agent_1 = _TestingAgent(
      name=f'{request.function.__name__}_sub_agent_1',
      sub_agents=[grand_sub_agent_1],
  )
  sub_agent_2 = _TestingAgent(
      name=f'{request.function.__name__}_sub_agent_2',
      sub_agents=[grand_sub_agent_2],
  )
  parent = _TestingAgent(
      name=f'{request.function.__name__}_parent',
      sub_agents=[sub_agent_1, sub_agent_2],
  )

  assert parent.find_sub_agent(sub_agent_1.name) == sub_agent_1
  assert parent.find_sub_agent(sub_agent_2.name) == sub_agent_2
  assert parent.find_sub_agent(grand_sub_agent_1.name) == grand_sub_agent_1
  assert parent.find_sub_agent(grand_sub_agent_2.name) == grand_sub_agent_2
  assert sub_agent_1.find_sub_agent(grand_sub_agent_1.name) == grand_sub_agent_1
  assert sub_agent_1.find_sub_agent(grand_sub_agent_2.name) is None
  assert sub_agent_2.find_sub_agent(grand_sub_agent_1.name) is None
  assert sub_agent_2.find_sub_agent(grand_sub_agent_2.name) == grand_sub_agent_2
  assert parent.find_sub_agent(parent.name) is None
  assert parent.find_sub_agent('not_exist') is None


def test_root_agent(request: pytest.FixtureRequest):
  grand_sub_agent_1 = _TestingAgent(
      name=f'{request.function.__name__}__grand_sub_agent_1'
  )
  grand_sub_agent_2 = _TestingAgent(
      name=f'{request.function.__name__}__grand_sub_agent_2'
  )
  sub_agent_1 = _TestingAgent(
      name=f'{request.function.__name__}_sub_agent_1',
      sub_agents=[grand_sub_agent_1],
  )
  sub_agent_2 = _TestingAgent(
      name=f'{request.function.__name__}_sub_agent_2',
      sub_agents=[grand_sub_agent_2],
  )
  parent = _TestingAgent(
      name=f'{request.function.__name__}_parent',
      sub_agents=[sub_agent_1, sub_agent_2],
  )

  assert parent.root_agent == parent
  assert sub_agent_1.root_agent == parent
  assert sub_agent_2.root_agent == parent
  assert grand_sub_agent_1.root_agent == parent
  assert grand_sub_agent_2.root_agent == parent


def test_set_parent_agent_for_sub_agent_twice(
    request: pytest.FixtureRequest,
):
  sub_agent = _TestingAgent(name=f'{request.function.__name__}_sub_agent')
  _ = _TestingAgent(
      name=f'{request.function.__name__}_parent_1',
      sub_agents=[sub_agent],
  )
  with pytest.raises(ValueError):
    _ = _TestingAgent(
        name=f'{request.function.__name__}_parent_2',
        sub_agents=[sub_agent],
    )

==== tests/unittests/agents/test_llm_agent_callbacks.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from typing import Any
from typing import Optional

from google.adk.agents.callback_context import CallbackContext
from google.adk.agents.llm_agent import Agent
from google.adk.models import LlmRequest
from google.adk.models import LlmResponse
from google.genai import types
from pydantic import BaseModel
import pytest

from .. import utils


class MockBeforeModelCallback(BaseModel):
  mock_response: str

  def __call__(
      self,
      callback_context: CallbackContext,
      llm_request: LlmRequest,
  ) -> LlmResponse:
    return LlmResponse(
        content=utils.ModelContent(
            [types.Part.from_text(text=self.mock_response)]
        )
    )


class MockAfterModelCallback(BaseModel):
  mock_response: str

  def __call__(
      self,
      callback_context: CallbackContext,
      llm_response: LlmResponse,
  ) -> LlmResponse:
    return LlmResponse(
        content=utils.ModelContent(
            [types.Part.from_text(text=self.mock_response)]
        )
    )


class MockAsyncBeforeModelCallback(BaseModel):
  mock_response: str

  async def __call__(
      self,
      callback_context: CallbackContext,
      llm_request: LlmRequest,
  ) -> LlmResponse:
    return LlmResponse(
        content=utils.ModelContent(
            [types.Part.from_text(text=self.mock_response)]
        )
    )


class MockAsyncAfterModelCallback(BaseModel):
  mock_response: str

  async def __call__(
      self,
      callback_context: CallbackContext,
      llm_response: LlmResponse,
  ) -> LlmResponse:
    return LlmResponse(
        content=utils.ModelContent(
            [types.Part.from_text(text=self.mock_response)]
        )
    )


def noop_callback(**kwargs) -> Optional[LlmResponse]:
  pass


async def async_noop_callback(**kwargs) -> Optional[LlmResponse]:
  pass


@pytest.mark.asyncio
async def test_before_model_callback():
  responses = ['model_response']
  mock_model = utils.MockModel.create(responses=responses)
  agent = Agent(
      name='root_agent',
      model=mock_model,
      before_model_callback=MockBeforeModelCallback(
          mock_response='before_model_callback'
      ),
  )

  runner = utils.TestInMemoryRunner(agent)
  assert utils.simplify_events(
      await runner.run_async_with_new_session('test')
  ) == [
      ('root_agent', 'before_model_callback'),
  ]


@pytest.mark.asyncio
async def test_before_model_callback_noop():
  responses = ['model_response']
  mock_model = utils.MockModel.create(responses=responses)
  agent = Agent(
      name='root_agent',
      model=mock_model,
      before_model_callback=noop_callback,
  )

  runner = utils.TestInMemoryRunner(agent)
  assert utils.simplify_events(
      await runner.run_async_with_new_session('test')
  ) == [
      ('root_agent', 'model_response'),
  ]


@pytest.mark.asyncio
async def test_after_model_callback():
  responses = ['model_response']
  mock_model = utils.MockModel.create(responses=responses)
  agent = Agent(
      name='root_agent',
      model=mock_model,
      after_model_callback=MockAfterModelCallback(
          mock_response='after_model_callback'
      ),
  )

  runner = utils.TestInMemoryRunner(agent)
  assert utils.simplify_events(
      await runner.run_async_with_new_session('test')
  ) == [
      ('root_agent', 'after_model_callback'),
  ]


@pytest.mark.asyncio
async def test_async_before_model_callback():
  responses = ['model_response']
  mock_model = utils.MockModel.create(responses=responses)
  agent = Agent(
      name='root_agent',
      model=mock_model,
      before_model_callback=MockAsyncBeforeModelCallback(
          mock_response='async_before_model_callback'
      ),
  )

  runner = utils.TestInMemoryRunner(agent)
  assert utils.simplify_events(
      await runner.run_async_with_new_session('test')
  ) == [
      ('root_agent', 'async_before_model_callback'),
  ]


@pytest.mark.asyncio
async def test_async_before_model_callback_noop():
  responses = ['model_response']
  mock_model = utils.MockModel.create(responses=responses)
  agent = Agent(
      name='root_agent',
      model=mock_model,
      before_model_callback=async_noop_callback,
  )

  runner = utils.TestInMemoryRunner(agent)
  assert utils.simplify_events(
      await runner.run_async_with_new_session('test')
  ) == [
      ('root_agent', 'model_response'),
  ]


@pytest.mark.asyncio
async def test_async_after_model_callback():
  responses = ['model_response']
  mock_model = utils.MockModel.create(responses=responses)
  agent = Agent(
      name='root_agent',
      model=mock_model,
      after_model_callback=MockAsyncAfterModelCallback(
          mock_response='async_after_model_callback'
      ),
  )

  runner = utils.TestInMemoryRunner(agent)
  assert utils.simplify_events(
      await runner.run_async_with_new_session('test')
  ) == [
      ('root_agent', 'async_after_model_callback'),
  ]

==== tests/unittests/agents/test_llm_agent_fields.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Unit tests for canonical_xxx fields in LlmAgent."""

from typing import Any
from typing import Optional, cast

from google.adk.agents.callback_context import CallbackContext
from google.adk.agents.invocation_context import InvocationContext
from google.adk.agents.llm_agent import LlmAgent
from google.adk.agents.loop_agent import LoopAgent
from google.adk.agents.readonly_context import ReadonlyContext
from google.adk.models.llm_request import LlmRequest
from google.adk.models.registry import LLMRegistry
from google.adk.sessions.in_memory_session_service import InMemorySessionService
from google.genai import types
from pydantic import BaseModel
import pytest


async def _create_readonly_context(
    agent: LlmAgent, state: Optional[dict[str, Any]] = None
) -> ReadonlyContext:
  session_service = InMemorySessionService()
  session = await session_service.create_session(
      app_name='test_app', user_id='test_user', state=state
  )
  invocation_context = InvocationContext(
      invocation_id='test_id',
      agent=agent,
      session=session,
      session_service=session_service,
  )
  return ReadonlyContext(invocation_context)


def test_canonical_model_empty():
  agent = LlmAgent(name='test_agent')

  with pytest.raises(ValueError):
    _ = agent.canonical_model


def test_canonical_model_str():
  agent = LlmAgent(name='test_agent', model='gemini-pro')

  assert agent.canonical_model.model == 'gemini-pro'


def test_canonical_model_llm():
  llm = LLMRegistry.new_llm('gemini-pro')
  agent = LlmAgent(name='test_agent', model=llm)

  assert agent.canonical_model == llm


def test_canonical_model_inherit():
  sub_agent = LlmAgent(name='sub_agent')
  parent_agent = LlmAgent(
      name='parent_agent', model='gemini-pro', sub_agents=[sub_agent]
  )

  assert sub_agent.canonical_model == parent_agent.canonical_model


async def test_canonical_instruction_str():
  agent = LlmAgent(name='test_agent', instruction='instruction')
  ctx = await _create_readonly_context(agent)

  canonical_instruction, bypass_state_injection = (
      await agent.canonical_instruction(ctx)
  )
  assert canonical_instruction == 'instruction'
  assert not bypass_state_injection


async def test_canonical_instruction():
  def _instruction_provider(ctx: ReadonlyContext) -> str:
    return f'instruction: {ctx.state["state_var"]}'

  agent = LlmAgent(name='test_agent', instruction=_instruction_provider)
  ctx = await _create_readonly_context(
      agent, state={'state_var': 'state_value'}
  )

  canonical_instruction, bypass_state_injection = (
      await agent.canonical_instruction(ctx)
  )
  assert canonical_instruction == 'instruction: state_value'
  assert bypass_state_injection


async def test_async_canonical_instruction():
  async def _instruction_provider(ctx: ReadonlyContext) -> str:
    return f'instruction: {ctx.state["state_var"]}'

  agent = LlmAgent(name='test_agent', instruction=_instruction_provider)
  ctx = await _create_readonly_context(
      agent, state={'state_var': 'state_value'}
  )

  canonical_instruction, bypass_state_injection = (
      await agent.canonical_instruction(ctx)
  )
  assert canonical_instruction == 'instruction: state_value'
  assert bypass_state_injection


async def test_canonical_global_instruction_str():
  agent = LlmAgent(name='test_agent', global_instruction='global instruction')
  ctx = await _create_readonly_context(agent)

  canonical_instruction, bypass_state_injection = (
      await agent.canonical_global_instruction(ctx)
  )
  assert canonical_instruction == 'global instruction'
  assert not bypass_state_injection


async def test_canonical_global_instruction():
  def _global_instruction_provider(ctx: ReadonlyContext) -> str:
    return f'global instruction: {ctx.state["state_var"]}'

  agent = LlmAgent(
      name='test_agent', global_instruction=_global_instruction_provider
  )
  ctx = await _create_readonly_context(
      agent, state={'state_var': 'state_value'}
  )

  canonical_global_instruction, bypass_state_injection = (
      await agent.canonical_global_instruction(ctx)
  )
  assert canonical_global_instruction == 'global instruction: state_value'
  assert bypass_state_injection

async def test_async_canonical_global_instruction():
  async def _global_instruction_provider(ctx: ReadonlyContext) -> str:
    return f'global instruction: {ctx.state["state_var"]}'

  agent = LlmAgent(
      name='test_agent', global_instruction=_global_instruction_provider
  )
  ctx = await _create_readonly_context(
      agent, state={'state_var': 'state_value'}
  )
  canonical_global_instruction, bypass_state_injection = (
      await agent.canonical_global_instruction(ctx)
  )
  assert canonical_global_instruction == 'global instruction: state_value'
  assert bypass_state_injection


def test_output_schema_will_disable_transfer(caplog: pytest.LogCaptureFixture):
  with caplog.at_level('WARNING'):

    class Schema(BaseModel):
      pass

    agent = LlmAgent(
        name='test_agent',
        output_schema=Schema,
    )

    # Transfer is automatically disabled
    assert agent.disallow_transfer_to_parent
    assert agent.disallow_transfer_to_peers
    assert (
        'output_schema cannot co-exist with agent transfer configurations.'
        in caplog.text
    )


def test_output_schema_with_sub_agents_will_throw():
  class Schema(BaseModel):
    pass

  sub_agent = LlmAgent(
      name='sub_agent',
  )

  with pytest.raises(ValueError):
    _ = LlmAgent(
        name='test_agent',
        output_schema=Schema,
        sub_agents=[sub_agent],
    )


def test_output_schema_with_tools_will_throw():
  class Schema(BaseModel):
    pass

  def _a_tool():
    pass

  with pytest.raises(ValueError):
    _ = LlmAgent(
        name='test_agent',
        output_schema=Schema,
        tools=[_a_tool],
    )


def test_before_model_callback():
  def _before_model_callback(
      callback_context: CallbackContext,
      llm_request: LlmRequest,
  ) -> None:
    return None

  agent = LlmAgent(
      name='test_agent', before_model_callback=_before_model_callback
  )

  # TODO: add more logic assertions later.
  assert agent.before_model_callback is not None


def test_validate_generate_content_config_thinking_config_throw():
  with pytest.raises(ValueError):
    _ = LlmAgent(
        name='test_agent',
        generate_content_config=types.GenerateContentConfig(
            thinking_config=types.ThinkingConfig()
        ),
    )


def test_validate_generate_content_config_tools_throw():
  with pytest.raises(ValueError):
    _ = LlmAgent(
        name='test_agent',
        generate_content_config=types.GenerateContentConfig(
            tools=[types.Tool(function_declarations=[])]
        ),
    )


def test_validate_generate_content_config_system_instruction_throw():
  with pytest.raises(ValueError):
    _ = LlmAgent(
        name='test_agent',
        generate_content_config=types.GenerateContentConfig(
            system_instruction='system instruction'
        ),
    )


def test_validate_generate_content_config_response_schema_throw():
  class Schema(BaseModel):
    pass

  with pytest.raises(ValueError):
    _ = LlmAgent(
        name='test_agent',
        generate_content_config=types.GenerateContentConfig(
            response_schema=Schema
        ),
    )


def test_allow_transfer_by_default():
  sub_agent = LlmAgent(name='sub_agent')
  agent = LlmAgent(name='test_agent', sub_agents=[sub_agent])

  assert not agent.disallow_transfer_to_parent
  assert not agent.disallow_transfer_to_peers

==== tests/unittests/agents/test_sequential_agent.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Testings for the SequentialAgent."""

from typing import AsyncGenerator

from google.adk.agents.base_agent import BaseAgent
from google.adk.agents.invocation_context import InvocationContext
from google.adk.agents.sequential_agent import SequentialAgent
from google.adk.events import Event
from google.adk.sessions.in_memory_session_service import InMemorySessionService
from google.genai import types
import pytest
from typing_extensions import override


class _TestingAgent(BaseAgent):

  @override
  async def _run_async_impl(
      self, ctx: InvocationContext
  ) -> AsyncGenerator[Event, None]:
    yield Event(
        author=self.name,
        invocation_id=ctx.invocation_id,
        content=types.Content(
            parts=[types.Part(text=f'Hello, async {self.name}!')]
        ),
    )

  @override
  async def _run_live_impl(
      self, ctx: InvocationContext
  ) -> AsyncGenerator[Event, None]:
    yield Event(
        author=self.name,
        invocation_id=ctx.invocation_id,
        content=types.Content(
            parts=[types.Part(text=f'Hello, live {self.name}!')]
        ),
    )


async def _create_parent_invocation_context(
    test_name: str, agent: BaseAgent
) -> InvocationContext:
  session_service = InMemorySessionService()
  session = await session_service.create_session(
      app_name='test_app', user_id='test_user'
  )
  return InvocationContext(
      invocation_id=f'{test_name}_invocation_id',
      agent=agent,
      session=session,
      session_service=session_service,
  )


@pytest.mark.asyncio
async def test_run_async(request: pytest.FixtureRequest):
  agent_1 = _TestingAgent(name=f'{request.function.__name__}_test_agent_1')
  agent_2 = _TestingAgent(name=f'{request.function.__name__}_test_agent_2')
  sequential_agent = SequentialAgent(
      name=f'{request.function.__name__}_test_agent',
      sub_agents=[
          agent_1,
          agent_2,
      ],
  )
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, sequential_agent
  )
  events = [e async for e in sequential_agent.run_async(parent_ctx)]

  assert len(events) == 2
  assert events[0].author == agent_1.name
  assert events[1].author == agent_2.name
  assert events[0].content.parts[0].text == f'Hello, async {agent_1.name}!'
  assert events[1].content.parts[0].text == f'Hello, async {agent_2.name}!'


@pytest.mark.asyncio
async def test_run_live(request: pytest.FixtureRequest):
  agent_1 = _TestingAgent(name=f'{request.function.__name__}_test_agent_1')
  agent_2 = _TestingAgent(name=f'{request.function.__name__}_test_agent_2')
  sequential_agent = SequentialAgent(
      name=f'{request.function.__name__}_test_agent',
      sub_agents=[
          agent_1,
          agent_2,
      ],
  )
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, sequential_agent
  )
  events = [e async for e in sequential_agent.run_live(parent_ctx)]

  assert len(events) == 2
  assert events[0].author == agent_1.name
  assert events[1].author == agent_2.name
  assert events[0].content.parts[0].text == f'Hello, live {agent_1.name}!'
  assert events[1].content.parts[0].text == f'Hello, live {agent_2.name}!'

==== tests/unittests/agents/test_readonly_context.py ====
import pytest
from unittest.mock import MagicMock
from types import MappingProxyType
from google.adk.agents.readonly_context import ReadonlyContext


@pytest.fixture
def mock_invocation_context():
  mock_context = MagicMock()
  mock_context.invocation_id = "test-invocation-id"
  mock_context.agent.name = "test-agent-name"
  mock_context.session.state = {"key1": "value1", "key2": "value2"}

  return mock_context


def test_invocation_id(mock_invocation_context):
  readonly_context = ReadonlyContext(mock_invocation_context)
  assert readonly_context.invocation_id == "test-invocation-id"


def test_agent_name(mock_invocation_context):
  readonly_context = ReadonlyContext(mock_invocation_context)
  assert readonly_context.agent_name == "test-agent-name"


def test_state_content(mock_invocation_context):
  readonly_context = ReadonlyContext(mock_invocation_context)
  state = readonly_context.state

  assert isinstance(state, MappingProxyType)
  assert state["key1"] == "value1"
  assert state["key2"] == "value2"

==== tests/unittests/agents/test_model_callback_chain.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from enum import Enum
from functools import partial
from typing import Any
from typing import List
from typing import Optional
from unittest import mock

from google.adk.agents.callback_context import CallbackContext
from google.adk.agents.llm_agent import Agent
from google.adk.models import LlmRequest
from google.adk.models import LlmResponse
from google.genai import types
from pydantic import BaseModel
import pytest

from .. import utils


class CallbackType(Enum):
  SYNC = 1
  ASYNC = 2


async def mock_async_before_cb_side_effect(
    callback_context: CallbackContext,
    llm_request: LlmRequest,
    ret_value=None,
):
  if ret_value:
    return LlmResponse(
        content=utils.ModelContent([types.Part.from_text(text=ret_value)])
    )
  return None


def mock_sync_before_cb_side_effect(
    callback_context: CallbackContext,
    llm_request: LlmRequest,
    ret_value=None,
):
  if ret_value:
    return LlmResponse(
        content=utils.ModelContent([types.Part.from_text(text=ret_value)])
    )
  return None


async def mock_async_after_cb_side_effect(
    callback_context: CallbackContext,
    llm_response: LlmResponse,
    ret_value=None,
):
  if ret_value:
    return LlmResponse(
        content=utils.ModelContent([types.Part.from_text(text=ret_value)])
    )
  return None


def mock_sync_after_cb_side_effect(
    callback_context: CallbackContext,
    llm_response: LlmResponse,
    ret_value=None,
):
  if ret_value:
    return LlmResponse(
        content=utils.ModelContent([types.Part.from_text(text=ret_value)])
    )
  return None


CALLBACK_PARAMS = [
    pytest.param(
        [
            (None, CallbackType.SYNC),
            ("callback_2_response", CallbackType.ASYNC),
            ("callback_3_response", CallbackType.SYNC),
            (None, CallbackType.ASYNC),
        ],
        "callback_2_response",
        [1, 1, 0, 0],
        id="middle_async_callback_returns",
    ),
    pytest.param(
        [
            (None, CallbackType.SYNC),
            (None, CallbackType.ASYNC),
            (None, CallbackType.SYNC),
            (None, CallbackType.ASYNC),
        ],
        "model_response",
        [1, 1, 1, 1],
        id="all_callbacks_return_none",
    ),
    pytest.param(
        [
            ("callback_1_response", CallbackType.SYNC),
            ("callback_2_response", CallbackType.ASYNC),
        ],
        "callback_1_response",
        [1, 0],
        id="first_sync_callback_returns",
    ),
]


@pytest.mark.parametrize(
    "callbacks, expected_response, expected_calls",
    CALLBACK_PARAMS,
)
@pytest.mark.asyncio
async def test_before_model_callbacks_chain(
    callbacks: List[tuple[str, int]],
    expected_response: str,
    expected_calls: List[int],
):
  responses = ["model_response"]
  mock_model = utils.MockModel.create(responses=responses)

  mock_cbs = []
  for response, callback_type in callbacks:

    if callback_type == CallbackType.ASYNC:
      mock_cb = mock.AsyncMock(
          side_effect=partial(
              mock_async_before_cb_side_effect, ret_value=response
          )
      )
    else:
      mock_cb = mock.Mock(
          side_effect=partial(
              mock_sync_before_cb_side_effect, ret_value=response
          )
      )
    mock_cbs.append(mock_cb)
  # Create agent with multiple callbacks
  agent = Agent(
      name="root_agent",
      model=mock_model,
      before_model_callback=[mock_cb for mock_cb in mock_cbs],
  )

  runner = utils.TestInMemoryRunner(agent)
  result = await runner.run_async_with_new_session("test")
  assert utils.simplify_events(result) == [
      ("root_agent", expected_response),
  ]

  # Assert that the callbacks were called the expected number of times
  for i, mock_cb in enumerate(mock_cbs):
    expected_calls_count = expected_calls[i]
    if expected_calls_count == 1:
      if isinstance(mock_cb, mock.AsyncMock):
        mock_cb.assert_awaited_once()
      else:
        mock_cb.assert_called_once()
    elif expected_calls_count == 0:
      if isinstance(mock_cb, mock.AsyncMock):
        mock_cb.assert_not_awaited()
      else:
        mock_cb.assert_not_called()
    else:
      if isinstance(mock_cb, mock.AsyncMock):
        mock_cb.assert_awaited(expected_calls_count)
      else:
        mock_cb.assert_called(expected_calls_count)


@pytest.mark.parametrize(
    "callbacks, expected_response, expected_calls",
    CALLBACK_PARAMS,
)
@pytest.mark.asyncio
async def test_after_model_callbacks_chain(
    callbacks: List[tuple[str, int]],
    expected_response: str,
    expected_calls: List[int],
):
  responses = ["model_response"]
  mock_model = utils.MockModel.create(responses=responses)

  mock_cbs = []
  for response, callback_type in callbacks:

    if callback_type == CallbackType.ASYNC:
      mock_cb = mock.AsyncMock(
          side_effect=partial(
              mock_async_after_cb_side_effect, ret_value=response
          )
      )
    else:
      mock_cb = mock.Mock(
          side_effect=partial(
              mock_sync_after_cb_side_effect, ret_value=response
          )
      )
    mock_cbs.append(mock_cb)
  # Create agent with multiple callbacks
  agent = Agent(
      name="root_agent",
      model=mock_model,
      after_model_callback=[mock_cb for mock_cb in mock_cbs],
  )

  runner = utils.TestInMemoryRunner(agent)
  result = await runner.run_async_with_new_session("test")
  assert utils.simplify_events(result) == [
      ("root_agent", expected_response),
  ]

  # Assert that the callbacks were called the expected number of times
  for i, mock_cb in enumerate(mock_cbs):
    expected_calls_count = expected_calls[i]
    if expected_calls_count == 1:
      if isinstance(mock_cb, mock.AsyncMock):
        mock_cb.assert_awaited_once()
      else:
        mock_cb.assert_called_once()
    elif expected_calls_count == 0:
      if isinstance(mock_cb, mock.AsyncMock):
        mock_cb.assert_not_awaited()
      else:
        mock_cb.assert_not_called()
    else:
      if isinstance(mock_cb, mock.AsyncMock):
        mock_cb.assert_awaited(expected_calls_count)
      else:
        mock_cb.assert_called(expected_calls_count)

==== tests/unittests/agents/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

==== tests/unittests/agents/test_parallel_agent.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Tests for the ParallelAgent."""

import asyncio
from typing import AsyncGenerator

from google.adk.agents.base_agent import BaseAgent
from google.adk.agents.invocation_context import InvocationContext
from google.adk.agents.parallel_agent import ParallelAgent
from google.adk.events import Event
from google.adk.sessions.in_memory_session_service import InMemorySessionService
from google.genai import types
import pytest
from typing_extensions import override


class _TestingAgent(BaseAgent):

  delay: float = 0
  """The delay before the agent generates an event."""

  @override
  async def _run_async_impl(
      self, ctx: InvocationContext
  ) -> AsyncGenerator[Event, None]:
    await asyncio.sleep(self.delay)
    yield Event(
        author=self.name,
        branch=ctx.branch,
        invocation_id=ctx.invocation_id,
        content=types.Content(
            parts=[types.Part(text=f'Hello, async {self.name}!')]
        ),
    )


async def _create_parent_invocation_context(
    test_name: str, agent: BaseAgent
) -> InvocationContext:
  session_service = InMemorySessionService()
  session = await session_service.create_session(
      app_name='test_app', user_id='test_user'
  )
  return InvocationContext(
      invocation_id=f'{test_name}_invocation_id',
      agent=agent,
      session=session,
      session_service=session_service,
  )


@pytest.mark.asyncio
async def test_run_async(request: pytest.FixtureRequest):
  agent1 = _TestingAgent(
      name=f'{request.function.__name__}_test_agent_1',
      delay=0.5,
  )
  agent2 = _TestingAgent(name=f'{request.function.__name__}_test_agent_2')
  parallel_agent = ParallelAgent(
      name=f'{request.function.__name__}_test_parallel_agent',
      sub_agents=[
          agent1,
          agent2,
      ],
  )
  parent_ctx = await _create_parent_invocation_context(
      request.function.__name__, parallel_agent
  )
  events = [e async for e in parallel_agent.run_async(parent_ctx)]

  assert len(events) == 2
  # agent2 generates an event first, then agent1. Because they run in parallel
  # and agent1 has a delay.
  assert events[0].author == agent2.name
  assert events[1].author == agent1.name
  assert events[0].branch.endswith(agent2.name)
  assert events[1].branch.endswith(agent1.name)
  assert events[0].content.parts[0].text == f'Hello, async {agent2.name}!'
  assert events[1].content.parts[0].text == f'Hello, async {agent1.name}!'

==== tests/unittests/artifacts/test_artifact_service.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Tests for the artifact service."""

import enum
from typing import Optional
from typing import Union

from google.adk.artifacts import GcsArtifactService
from google.adk.artifacts import InMemoryArtifactService
from google.genai import types

from unittest import mock
import pytest

Enum = enum.Enum


class ArtifactServiceType(Enum):
  IN_MEMORY = "IN_MEMORY"
  GCS = "GCS"


class MockBlob:
  """Mocks a GCS Blob object.

  This class provides mock implementations for a few common GCS Blob methods,
  allowing the user to test code that interacts with GCS without actually
  connecting to a real bucket.
  """

  def __init__(self, name: str) -> None:
    """Initializes a MockBlob.

    Args:
        name: The name of the blob.
    """
    self.name = name
    self.content: Optional[bytes] = None
    self.content_type: Optional[str] = None

  def upload_from_string(
      self, data: Union[str, bytes], content_type: Optional[str] = None
  ) -> None:
    """Mocks uploading data to the blob (from a string or bytes).

    Args:
        data: The data to upload (string or bytes).
        content_type:  The content type of the data (optional).
    """
    if isinstance(data, str):
      self.content = data.encode("utf-8")
    elif isinstance(data, bytes):
      self.content = data
    else:
      raise TypeError("data must be str or bytes")

    if content_type:
      self.content_type = content_type

  def download_as_bytes(self) -> bytes:
    """Mocks downloading the blob's content as bytes.

    Returns:
        bytes: The content of the blob as bytes.

    Raises:
        Exception: If the blob doesn't exist (hasn't been uploaded to).
    """
    if self.content is None:
      return b""
    return self.content

  def delete(self) -> None:
    """Mocks deleting a blob."""
    self.content = None
    self.content_type = None


class MockBucket:
  """Mocks a GCS Bucket object."""

  def __init__(self, name: str) -> None:
    """Initializes a MockBucket.

    Args:
        name: The name of the bucket.
    """
    self.name = name
    self.blobs: dict[str, MockBlob] = {}

  def blob(self, blob_name: str) -> MockBlob:
    """Mocks getting a Blob object (doesn't create it in storage).

    Args:
        blob_name: The name of the blob.

    Returns:
        A MockBlob instance.
    """
    if blob_name not in self.blobs:
      self.blobs[blob_name] = MockBlob(blob_name)
    return self.blobs[blob_name]


class MockClient:
  """Mocks the GCS Client."""

  def __init__(self) -> None:
    """Initializes MockClient."""
    self.buckets: dict[str, MockBucket] = {}

  def bucket(self, bucket_name: str) -> MockBucket:
    """Mocks getting a Bucket object."""
    if bucket_name not in self.buckets:
      self.buckets[bucket_name] = MockBucket(bucket_name)
    return self.buckets[bucket_name]

  def list_blobs(self, bucket: MockBucket, prefix: Optional[str] = None):
    """Mocks listing blobs in a bucket, optionally with a prefix."""
    if prefix:
      return [
          blob for name, blob in bucket.blobs.items() if name.startswith(prefix)
      ]
    return list(bucket.blobs.values())


def mock_gcs_artifact_service():
  with mock.patch("google.cloud.storage.Client", return_value=MockClient()):
    service = GcsArtifactService(bucket_name="test_bucket")
    service.bucket = service.storage_client.bucket("test_bucket")
    return service


def get_artifact_service(
    service_type: ArtifactServiceType = ArtifactServiceType.IN_MEMORY,
):
  """Creates an artifact service for testing."""
  if service_type == ArtifactServiceType.GCS:
    return mock_gcs_artifact_service()
  return InMemoryArtifactService()


@pytest.mark.asyncio
@pytest.mark.parametrize(
    "service_type", [ArtifactServiceType.IN_MEMORY, ArtifactServiceType.GCS]
)
async def test_load_empty(service_type):
  """Tests loading an artifact when none exists."""
  artifact_service = get_artifact_service(service_type)
  assert not await artifact_service.load_artifact(
      app_name="test_app",
      user_id="test_user",
      session_id="session_id",
      filename="filename",
  )


@pytest.mark.asyncio
@pytest.mark.parametrize(
    "service_type", [ArtifactServiceType.IN_MEMORY, ArtifactServiceType.GCS]
)
async def test_save_load_delete(service_type):
  """Tests saving, loading, and deleting an artifact."""
  artifact_service = get_artifact_service(service_type)
  artifact = types.Part.from_bytes(data=b"test_data", mime_type="text/plain")
  app_name = "app0"
  user_id = "user0"
  session_id = "123"
  filename = "file456"

  await artifact_service.save_artifact(
      app_name=app_name,
      user_id=user_id,
      session_id=session_id,
      filename=filename,
      artifact=artifact,
  )
  assert (
      await artifact_service.load_artifact(
          app_name=app_name,
          user_id=user_id,
          session_id=session_id,
          filename=filename,
      )
      == artifact
  )

  await artifact_service.delete_artifact(
      app_name=app_name,
      user_id=user_id,
      session_id=session_id,
      filename=filename,
  )
  assert not await artifact_service.load_artifact(
      app_name=app_name,
      user_id=user_id,
      session_id=session_id,
      filename=filename,
  )


@pytest.mark.asyncio
@pytest.mark.parametrize(
    "service_type", [ArtifactServiceType.IN_MEMORY, ArtifactServiceType.GCS]
)
async def test_list_keys(service_type):
  """Tests listing keys in the artifact service."""
  artifact_service = get_artifact_service(service_type)
  artifact = types.Part.from_bytes(data=b"test_data", mime_type="text/plain")
  app_name = "app0"
  user_id = "user0"
  session_id = "123"
  filename = "filename"
  filenames = [filename + str(i) for i in range(5)]

  for f in filenames:
    await artifact_service.save_artifact(
        app_name=app_name,
        user_id=user_id,
        session_id=session_id,
        filename=f,
        artifact=artifact,
    )

  assert (
      await artifact_service.list_artifact_keys(
          app_name=app_name, user_id=user_id, session_id=session_id
      )
      == filenames
  )


@pytest.mark.asyncio
@pytest.mark.parametrize(
    "service_type", [ArtifactServiceType.IN_MEMORY, ArtifactServiceType.GCS]
)
async def test_list_versions(service_type):
  """Tests listing versions of an artifact."""
  artifact_service = get_artifact_service(service_type)

  app_name = "app0"
  user_id = "user0"
  session_id = "123"
  filename = "filename"
  versions = [
      types.Part.from_bytes(
          data=i.to_bytes(2, byteorder="big"), mime_type="text/plain"
      )
      for i in range(3)
  ]

  for i in range(3):
    await artifact_service.save_artifact(
        app_name=app_name,
        user_id=user_id,
        session_id=session_id,
        filename=filename,
        artifact=versions[i],
    )

  response_versions = await artifact_service.list_versions(
      app_name=app_name,
      user_id=user_id,
      session_id=session_id,
      filename=filename,
  )

  assert response_versions == list(range(3))

==== tests/unittests/artifacts/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

==== tests/unittests/flows/llm_flows/test_agent_transfer.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.adk.agents.llm_agent import Agent
from google.adk.agents.loop_agent import LoopAgent
from google.adk.agents.sequential_agent import SequentialAgent
from google.adk.tools import exit_loop
from google.genai.types import Part

from ... import utils


def transfer_call_part(agent_name: str) -> Part:
  return Part.from_function_call(
      name='transfer_to_agent', args={'agent_name': agent_name}
  )


TRANSFER_RESPONSE_PART = Part.from_function_response(
    name='transfer_to_agent', response={}
)


def test_auto_to_auto():
  response = [
      transfer_call_part('sub_agent_1'),
      'response1',
      'response2',
  ]
  mockModel = utils.MockModel.create(responses=response)
  # root (auto) - sub_agent_1 (auto)
  sub_agent_1 = Agent(name='sub_agent_1', model=mockModel)
  root_agent = Agent(
      name='root_agent',
      model=mockModel,
      sub_agents=[sub_agent_1],
  )

  runner = utils.InMemoryRunner(root_agent)

  # Asserts the transfer.
  assert utils.simplify_events(runner.run('test1')) == [
      ('root_agent', transfer_call_part('sub_agent_1')),
      ('root_agent', TRANSFER_RESPONSE_PART),
      ('sub_agent_1', 'response1'),
  ]

  # sub_agent_1 should still be the current agent.
  assert utils.simplify_events(runner.run('test2')) == [
      ('sub_agent_1', 'response2'),
  ]


def test_auto_to_single():
  response = [
      transfer_call_part('sub_agent_1'),
      'response1',
      'response2',
  ]
  mockModel = utils.MockModel.create(responses=response)
  # root (auto) - sub_agent_1 (single)
  sub_agent_1 = Agent(
      name='sub_agent_1',
      model=mockModel,
      disallow_transfer_to_parent=True,
      disallow_transfer_to_peers=True,
  )
  root_agent = Agent(
      name='root_agent', model=mockModel, sub_agents=[sub_agent_1]
  )

  runner = utils.InMemoryRunner(root_agent)

  # Asserts the responses.
  assert utils.simplify_events(runner.run('test1')) == [
      ('root_agent', transfer_call_part('sub_agent_1')),
      ('root_agent', TRANSFER_RESPONSE_PART),
      ('sub_agent_1', 'response1'),
  ]

  # root_agent should still be the current agent, becaues sub_agent_1 is single.
  assert utils.simplify_events(runner.run('test2')) == [
      ('root_agent', 'response2'),
  ]


def test_auto_to_auto_to_single():
  response = [
      transfer_call_part('sub_agent_1'),
      # sub_agent_1 transfers to sub_agent_1_1.
      transfer_call_part('sub_agent_1_1'),
      'response1',
      'response2',
  ]
  mockModel = utils.MockModel.create(responses=response)
  # root (auto) - sub_agent_1 (auto) - sub_agent_1_1 (single)
  sub_agent_1_1 = Agent(
      name='sub_agent_1_1',
      model=mockModel,
      disallow_transfer_to_parent=True,
      disallow_transfer_to_peers=True,
  )
  sub_agent_1 = Agent(
      name='sub_agent_1', model=mockModel, sub_agents=[sub_agent_1_1]
  )
  root_agent = Agent(
      name='root_agent', model=mockModel, sub_agents=[sub_agent_1]
  )

  runner = utils.InMemoryRunner(root_agent)

  # Asserts the responses.
  assert utils.simplify_events(runner.run('test1')) == [
      ('root_agent', transfer_call_part('sub_agent_1')),
      ('root_agent', TRANSFER_RESPONSE_PART),
      ('sub_agent_1', transfer_call_part('sub_agent_1_1')),
      ('sub_agent_1', TRANSFER_RESPONSE_PART),
      ('sub_agent_1_1', 'response1'),
  ]

  # sub_agent_1 should still be the current agent. sub_agent_1_1 is single so it should
  # not be the current agent, otherwise the conversation will be tied to
  # sub_agent_1_1 forever.
  assert utils.simplify_events(runner.run('test2')) == [
      ('sub_agent_1', 'response2'),
  ]


def test_auto_to_sequential():
  response = [
      transfer_call_part('sub_agent_1'),
      # sub_agent_1 responds directly instead of transfering.
      'response1',
      'response2',
      'response3',
  ]
  mockModel = utils.MockModel.create(responses=response)
  # root (auto) - sub_agent_1 (sequential) - sub_agent_1_1 (single)
  #                                   \ sub_agent_1_2 (single)
  sub_agent_1_1 = Agent(
      name='sub_agent_1_1',
      model=mockModel,
      disallow_transfer_to_parent=True,
      disallow_transfer_to_peers=True,
  )
  sub_agent_1_2 = Agent(
      name='sub_agent_1_2',
      model=mockModel,
      disallow_transfer_to_parent=True,
      disallow_transfer_to_peers=True,
  )
  sub_agent_1 = SequentialAgent(
      name='sub_agent_1',
      sub_agents=[sub_agent_1_1, sub_agent_1_2],
  )
  root_agent = Agent(
      name='root_agent',
      model=mockModel,
      sub_agents=[sub_agent_1],
  )

  runner = utils.InMemoryRunner(root_agent)

  # Asserts the transfer.
  assert utils.simplify_events(runner.run('test1')) == [
      ('root_agent', transfer_call_part('sub_agent_1')),
      ('root_agent', TRANSFER_RESPONSE_PART),
      ('sub_agent_1_1', 'response1'),
      ('sub_agent_1_2', 'response2'),
  ]

  # root_agent should still be the current agent because sub_agent_1 is sequential.
  assert utils.simplify_events(runner.run('test2')) == [
      ('root_agent', 'response3'),
  ]


def test_auto_to_sequential_to_auto():
  response = [
      transfer_call_part('sub_agent_1'),
      # sub_agent_1 responds directly instead of transfering.
      'response1',
      transfer_call_part('sub_agent_1_2_1'),
      'response2',
      'response3',
      'response4',
  ]
  mockModel = utils.MockModel.create(responses=response)
  # root (auto) - sub_agent_1 (seq) - sub_agent_1_1 (single)
  #                            \ sub_agent_1_2 (auto) - sub_agent_1_2_1 (auto)
  #                            \ sub_agent_1_3 (single)
  sub_agent_1_1 = Agent(
      name='sub_agent_1_1',
      model=mockModel,
      disallow_transfer_to_parent=True,
      disallow_transfer_to_peers=True,
  )
  sub_agent_1_2_1 = Agent(name='sub_agent_1_2_1', model=mockModel)
  sub_agent_1_2 = Agent(
      name='sub_agent_1_2',
      model=mockModel,
      sub_agents=[sub_agent_1_2_1],
  )
  sub_agent_1_3 = Agent(
      name='sub_agent_1_3',
      model=mockModel,
      disallow_transfer_to_parent=True,
      disallow_transfer_to_peers=True,
  )
  sub_agent_1 = SequentialAgent(
      name='sub_agent_1',
      sub_agents=[sub_agent_1_1, sub_agent_1_2, sub_agent_1_3],
  )
  root_agent = Agent(
      name='root_agent',
      model=mockModel,
      sub_agents=[sub_agent_1],
  )

  runner = utils.InMemoryRunner(root_agent)

  # Asserts the transfer.
  assert utils.simplify_events(runner.run('test1')) == [
      ('root_agent', transfer_call_part('sub_agent_1')),
      ('root_agent', TRANSFER_RESPONSE_PART),
      ('sub_agent_1_1', 'response1'),
      ('sub_agent_1_2', transfer_call_part('sub_agent_1_2_1')),
      ('sub_agent_1_2', TRANSFER_RESPONSE_PART),
      ('sub_agent_1_2_1', 'response2'),
      ('sub_agent_1_3', 'response3'),
  ]

  # root_agent should still be the current agent because sub_agent_1 is sequential.
  assert utils.simplify_events(runner.run('test2')) == [
      ('root_agent', 'response4'),
  ]


def test_auto_to_loop():
  response = [
      transfer_call_part('sub_agent_1'),
      # sub_agent_1 responds directly instead of transfering.
      'response1',
      'response2',
      'response3',
      Part.from_function_call(name='exit_loop', args={}),
      'response4',
      'response5',
  ]
  mockModel = utils.MockModel.create(responses=response)
  # root (auto) - sub_agent_1 (loop) - sub_agent_1_1 (single)
  #                             \ sub_agent_1_2 (single)
  sub_agent_1_1 = Agent(
      name='sub_agent_1_1',
      model=mockModel,
      disallow_transfer_to_parent=True,
      disallow_transfer_to_peers=True,
  )
  sub_agent_1_2 = Agent(
      name='sub_agent_1_2',
      model=mockModel,
      disallow_transfer_to_parent=True,
      disallow_transfer_to_peers=True,
      tools=[exit_loop],
  )
  sub_agent_1 = LoopAgent(
      name='sub_agent_1',
      sub_agents=[sub_agent_1_1, sub_agent_1_2],
  )
  root_agent = Agent(
      name='root_agent',
      model=mockModel,
      sub_agents=[sub_agent_1],
  )

  runner = utils.InMemoryRunner(root_agent)

  # Asserts the transfer.
  assert utils.simplify_events(runner.run('test1')) == [
      # Transfers to sub_agent_1.
      ('root_agent', transfer_call_part('sub_agent_1')),
      ('root_agent', TRANSFER_RESPONSE_PART),
      # Loops.
      ('sub_agent_1_1', 'response1'),
      ('sub_agent_1_2', 'response2'),
      ('sub_agent_1_1', 'response3'),
      # Exits.
      ('sub_agent_1_2', Part.from_function_call(name='exit_loop', args={})),
      (
          'sub_agent_1_2',
          Part.from_function_response(name='exit_loop', response={}),
      ),
      # root_agent summarizes.
      ('root_agent', 'response4'),
  ]

  # root_agent should still be the current agent because sub_agent_1 is loop.
  assert utils.simplify_events(runner.run('test2')) == [
      ('root_agent', 'response5'),
  ]

==== tests/unittests/flows/llm_flows/test_async_tool_callbacks.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from enum import Enum
from functools import partial
from typing import Any
from typing import Dict
from typing import List
from typing import Optional
from unittest import mock

from google.adk.agents import Agent
from google.adk.agents.callback_context import CallbackContext
from google.adk.events.event import Event
from google.adk.flows.llm_flows.functions import handle_function_calls_async
from google.adk.tools.function_tool import FunctionTool
from google.adk.tools.tool_context import ToolContext
from google.genai import types
import pytest

from ... import utils


class CallbackType(Enum):
  SYNC = 1
  ASYNC = 2


class AsyncBeforeToolCallback:

  def __init__(self, mock_response: Dict[str, Any]):
    self.mock_response = mock_response

  async def __call__(
      self,
      tool: FunctionTool,
      args: Dict[str, Any],
      tool_context: ToolContext,
  ) -> Optional[Dict[str, Any]]:
    return self.mock_response


class AsyncAfterToolCallback:

  def __init__(self, mock_response: Dict[str, Any]):
    self.mock_response = mock_response

  async def __call__(
      self,
      tool: FunctionTool,
      args: Dict[str, Any],
      tool_context: ToolContext,
      tool_response: Dict[str, Any],
  ) -> Optional[Dict[str, Any]]:
    return self.mock_response


async def invoke_tool_with_callbacks(
    before_cb=None, after_cb=None
) -> Optional[Event]:
  def simple_fn(**kwargs) -> Dict[str, Any]:
    return {"initial": "response"}

  tool = FunctionTool(simple_fn)
  model = utils.MockModel.create(responses=[])
  agent = Agent(
      name="agent",
      model=model,
      tools=[tool],
      before_tool_callback=before_cb,
      after_tool_callback=after_cb,
  )
  invocation_context = await utils.create_invocation_context(
      agent=agent, user_content=""
  )
  # Build function call event
  function_call = types.FunctionCall(name=tool.name, args={})
  content = types.Content(parts=[types.Part(function_call=function_call)])
  event = Event(
      invocation_id=invocation_context.invocation_id,
      author=agent.name,
      content=content,
  )
  tools_dict = {tool.name: tool}
  return await handle_function_calls_async(
      invocation_context,
      event,
      tools_dict,
  )


@pytest.mark.asyncio
async def test_async_before_tool_callback():
  mock_resp = {"test": "before_tool_callback"}
  before_cb = AsyncBeforeToolCallback(mock_resp)
  result_event = await invoke_tool_with_callbacks(before_cb=before_cb)
  assert result_event is not None
  part = result_event.content.parts[0]
  assert part.function_response.response == mock_resp


@pytest.mark.asyncio
async def test_async_after_tool_callback():
  mock_resp = {"test": "after_tool_callback"}
  after_cb = AsyncAfterToolCallback(mock_resp)
  result_event = await invoke_tool_with_callbacks(after_cb=after_cb)
  assert result_event is not None
  part = result_event.content.parts[0]
  assert part.function_response.response == mock_resp


def mock_async_before_cb_side_effect(
    tool: FunctionTool,
    args: Dict[str, Any],
    tool_context: ToolContext,
    ret_value: Optional[Dict[str, Any]] = None,
):
  if ret_value:
    return ret_value
  return None


def mock_sync_before_cb_side_effect(
    tool: FunctionTool,
    args: Dict[str, Any],
    tool_context: ToolContext,
    ret_value: Optional[Dict[str, Any]] = None,
):
  if ret_value:
    return ret_value
  return None


async def mock_async_after_cb_side_effect(
    tool: FunctionTool,
    args: Dict[str, Any],
    tool_context: ToolContext,
    tool_response: Dict[str, Any],
    ret_value: Optional[Dict[str, Any]] = None,
):
  if ret_value:
    return ret_value
  return None


def mock_sync_after_cb_side_effect(
    tool: FunctionTool,
    args: Dict[str, Any],
    tool_context: ToolContext,
    tool_response: Dict[str, Any],
    ret_value: Optional[Dict[str, Any]] = None,
):
  if ret_value:
    return ret_value
  return None


CALLBACK_PARAMS = [
    pytest.param(
        [
            (None, CallbackType.SYNC),
            ({"test": "callback_2_response"}, CallbackType.ASYNC),
            ({"test": "callback_3_response"}, CallbackType.SYNC),
            (None, CallbackType.ASYNC),
        ],
        {"test": "callback_2_response"},
        [1, 1, 0, 0],
        id="middle_async_callback_returns",
    ),
    pytest.param(
        [
            (None, CallbackType.SYNC),
            (None, CallbackType.ASYNC),
            (None, CallbackType.SYNC),
            (None, CallbackType.ASYNC),
        ],
        {"initial": "response"},
        [1, 1, 1, 1],
        id="all_callbacks_return_none",
    ),
    pytest.param(
        [
            ({"test": "callback_1_response"}, CallbackType.SYNC),
            ({"test": "callback_2_response"}, CallbackType.ASYNC),
        ],
        {"test": "callback_1_response"},
        [1, 0],
        id="first_sync_callback_returns",
    ),
]


@pytest.mark.parametrize(
    "callbacks, expected_response, expected_calls",
    CALLBACK_PARAMS,
)
@pytest.mark.asyncio
async def test_before_tool_callbacks_chain(
    callbacks: List[tuple[Optional[Dict[str, Any]], int]],
    expected_response: Dict[str, Any],
    expected_calls: List[int],
):
  mock_before_cbs = []
  for response, callback_type in callbacks:
    if callback_type == CallbackType.ASYNC:
      mock_cb = mock.AsyncMock(
          side_effect=partial(
              mock_async_before_cb_side_effect, ret_value=response
          )
      )
    else:
      mock_cb = mock.Mock(
          side_effect=partial(
              mock_sync_before_cb_side_effect, ret_value=response
          )
      )
    mock_before_cbs.append(mock_cb)
  result_event = await invoke_tool_with_callbacks(before_cb=mock_before_cbs)
  assert result_event is not None
  part = result_event.content.parts[0]
  assert part.function_response.response == expected_response

  # Assert that the callbacks were called the expected number of times
  for i, mock_cb in enumerate(mock_before_cbs):
    expected_calls_count = expected_calls[i]
    if expected_calls_count == 1:
      if isinstance(mock_cb, mock.AsyncMock):
        mock_cb.assert_awaited_once()
      else:
        mock_cb.assert_called_once()
    elif expected_calls_count == 0:
      if isinstance(mock_cb, mock.AsyncMock):
        mock_cb.assert_not_awaited()
      else:
        mock_cb.assert_not_called()
    else:
      if isinstance(mock_cb, mock.AsyncMock):
        mock_cb.assert_awaited(expected_calls_count)
      else:
        mock_cb.assert_called(expected_calls_count)


@pytest.mark.parametrize(
    "callbacks, expected_response, expected_calls",
    CALLBACK_PARAMS,
)
@pytest.mark.asyncio
async def test_after_tool_callbacks_chain(
    callbacks: List[tuple[Optional[Dict[str, Any]], int]],
    expected_response: Dict[str, Any],
    expected_calls: List[int],
):
  mock_after_cbs = []
  for response, callback_type in callbacks:
    if callback_type == CallbackType.ASYNC:
      mock_cb = mock.AsyncMock(
          side_effect=partial(
              mock_async_after_cb_side_effect, ret_value=response
          )
      )
    else:
      mock_cb = mock.Mock(
          side_effect=partial(
              mock_sync_after_cb_side_effect, ret_value=response
          )
      )
    mock_after_cbs.append(mock_cb)
  result_event = await invoke_tool_with_callbacks(after_cb=mock_after_cbs)
  assert result_event is not None
  part = result_event.content.parts[0]
  assert part.function_response.response == expected_response

  # Assert that the callbacks were called the expected number of times
  for i, mock_cb in enumerate(mock_after_cbs):
    expected_calls_count = expected_calls[i]
    if expected_calls_count == 1:
      if isinstance(mock_cb, mock.AsyncMock):
        mock_cb.assert_awaited_once()
      else:
        mock_cb.assert_called_once()
    elif expected_calls_count == 0:
      if isinstance(mock_cb, mock.AsyncMock):
        mock_cb.assert_not_awaited()
      else:
        mock_cb.assert_not_called()
    else:
      if isinstance(mock_cb, mock.AsyncMock):
        mock_cb.assert_awaited(expected_calls_count)
      else:
        mock_cb.assert_called(expected_calls_count)

==== tests/unittests/flows/llm_flows/_test_examples.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# TODO: delete and rewrite unit tests
from google.adk.agents import Agent
from google.adk.examples import BaseExampleProvider
from google.adk.examples import Example
from google.adk.flows.llm_flows import examples
from google.adk.models.base_llm import LlmRequest
from google.genai import types
import pytest

from ... import utils


@pytest.mark.asyncio
async def test_no_examples():
  request = LlmRequest(
      model="gemini-1.5-flash",
      config=types.GenerateContentConfig(system_instruction=""),
  )
  agent = Agent(model="gemini-1.5-flash", name="agent", examples=[])
  invocation_context = await utils.create_invocation_context(
      agent=agent, user_content=""
  )

  async for _ in examples.request_processor.run_async(
      invocation_context,
      request,
  ):
    pass

  assert request.config.system_instruction == ""


@pytest.mark.asyncio
async def test_agent_examples():
  example_list = [
      Example(
          input=types.Content(
              role="user",
              parts=[types.Part.from_text(text="test1")],
          ),
          output=[
              types.Content(
                  role="model",
                  parts=[types.Part.from_text(text="response1")],
              ),
          ],
      )
  ]
  request = LlmRequest(
      model="gemini-1.5-flash",
      config=types.GenerateContentConfig(system_instruction=""),
  )
  agent = Agent(
      model="gemini-1.5-flash",
      name="agent",
      examples=example_list,
  )
  invocation_context = await utils.create_invocation_context(
      agent=agent, user_content="test"
  )

  async for _ in examples.request_processor.run_async(
      invocation_context,
      request,
  ):
    pass

  assert (
      request.config.system_instruction
      == "<EXAMPLES>\nBegin few-shot\nThe following are examples of user"
      " queries and model responses using the available tools.\n\nEXAMPLE"
      " 1:\nBegin example\n[user]\ntest1\n\n[model]\nresponse1\nEnd"
      " example\n\nEnd few-shot\nNow, try to follow these examples and"
      " complete the following conversation\n<EXAMPLES>"
  )


@pytest.mark.asyncio
async def test_agent_base_example_provider():
  class TestExampleProvider(BaseExampleProvider):

    def get_examples(self, query: str) -> list[Example]:
      if query == "test":
        return [
            Example(
                input=types.Content(
                    role="user",
                    parts=[types.Part.from_text(text="test")],
                ),
                output=[
                    types.Content(
                        role="model",
                        parts=[types.Part.from_text(text="response1")],
                    ),
                ],
            )
        ]
      else:
        return []

  provider = TestExampleProvider()
  request = LlmRequest(
      model="gemini-1.5-flash",
      config=types.GenerateContentConfig(system_instruction=""),
  )
  agent = Agent(
      model="gemini-1.5-flash",
      name="agent",
      examples=provider,
  )
  invocation_context = await utils.create_invocation_context(
      agent=agent, user_content="test"
  )

  async for _ in examples.request_processor.run_async(
      invocation_context,
      request,
  ):
    pass

  assert (
      request.config.system_instruction
      == "<EXAMPLES>\nBegin few-shot\nThe following are examples of user"
      " queries and model responses using the available tools.\n\nEXAMPLE"
      " 1:\nBegin example\n[user]\ntest\n\n[model]\nresponse1\nEnd"
      " example\n\nEnd few-shot\nNow, try to follow these examples and"
      " complete the following conversation\n<EXAMPLES>"
  )

==== tests/unittests/flows/llm_flows/test_functions_simple.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from typing import Any
from typing import AsyncGenerator
from typing import Callable

from google.adk.agents import Agent
from google.adk.tools import ToolContext
from google.adk.tools.function_tool import FunctionTool
from google.genai import types
import pytest

from ... import utils


def test_simple_function():
  function_call_1 = types.Part.from_function_call(
      name='increase_by_one', args={'x': 1}
  )
  function_respones_2 = types.Part.from_function_response(
      name='increase_by_one', response={'result': 2}
  )
  responses: list[types.Content] = [
      function_call_1,
      'response1',
      'response2',
      'response3',
      'response4',
  ]
  function_called = 0
  mock_model = utils.MockModel.create(responses=responses)

  def increase_by_one(x: int) -> int:
    nonlocal function_called
    function_called += 1
    return x + 1

  agent = Agent(name='root_agent', model=mock_model, tools=[increase_by_one])
  runner = utils.InMemoryRunner(agent)
  assert utils.simplify_events(runner.run('test')) == [
      ('root_agent', function_call_1),
      ('root_agent', function_respones_2),
      ('root_agent', 'response1'),
  ]

  # Asserts the requests.
  assert utils.simplify_contents(mock_model.requests[0].contents) == [
      ('user', 'test')
  ]
  assert utils.simplify_contents(mock_model.requests[1].contents) == [
      ('user', 'test'),
      ('model', function_call_1),
      ('user', function_respones_2),
  ]

  # Asserts the function calls.
  assert function_called == 1


@pytest.mark.asyncio
async def test_async_function():
  function_calls = [
      types.Part.from_function_call(name='increase_by_one', args={'x': 1}),
      types.Part.from_function_call(name='multiple_by_two', args={'x': 2}),
      types.Part.from_function_call(name='multiple_by_two_sync', args={'x': 3}),
  ]
  function_responses = [
      types.Part.from_function_response(
          name='increase_by_one', response={'result': 2}
      ),
      types.Part.from_function_response(
          name='multiple_by_two', response={'result': 4}
      ),
      types.Part.from_function_response(
          name='multiple_by_two_sync', response={'result': 6}
      ),
  ]

  responses: list[types.Content] = [
      function_calls,
      'response1',
      'response2',
      'response3',
      'response4',
  ]
  function_called = 0
  mock_model = utils.MockModel.create(responses=responses)

  async def increase_by_one(x: int) -> int:
    nonlocal function_called
    function_called += 1
    return x + 1

  async def multiple_by_two(x: int) -> int:
    nonlocal function_called
    function_called += 1
    return x * 2

  def multiple_by_two_sync(x: int) -> int:
    nonlocal function_called
    function_called += 1
    return x * 2

  agent = Agent(
      name='root_agent',
      model=mock_model,
      tools=[increase_by_one, multiple_by_two, multiple_by_two_sync],
  )
  runner = utils.TestInMemoryRunner(agent)
  events = await runner.run_async_with_new_session('test')
  assert utils.simplify_events(events) == [
      ('root_agent', function_calls),
      ('root_agent', function_responses),
      ('root_agent', 'response1'),
  ]

  # Asserts the requests.
  assert utils.simplify_contents(mock_model.requests[0].contents) == [
      ('user', 'test')
  ]
  assert utils.simplify_contents(mock_model.requests[1].contents) == [
      ('user', 'test'),
      ('model', function_calls),
      ('user', function_responses),
  ]

  # Asserts the function calls.
  assert function_called == 3


@pytest.mark.asyncio
async def test_function_tool():
  function_calls = [
      types.Part.from_function_call(name='increase_by_one', args={'x': 1}),
      types.Part.from_function_call(name='multiple_by_two', args={'x': 2}),
      types.Part.from_function_call(name='multiple_by_two_sync', args={'x': 3}),
  ]
  function_responses = [
      types.Part.from_function_response(
          name='increase_by_one', response={'result': 2}
      ),
      types.Part.from_function_response(
          name='multiple_by_two', response={'result': 4}
      ),
      types.Part.from_function_response(
          name='multiple_by_two_sync', response={'result': 6}
      ),
  ]

  responses: list[types.Content] = [
      function_calls,
      'response1',
      'response2',
      'response3',
      'response4',
  ]
  function_called = 0
  mock_model = utils.MockModel.create(responses=responses)

  async def increase_by_one(x: int) -> int:
    nonlocal function_called
    function_called += 1
    return x + 1

  async def multiple_by_two(x: int) -> int:
    nonlocal function_called
    function_called += 1
    return x * 2

  def multiple_by_two_sync(x: int) -> int:
    nonlocal function_called
    function_called += 1
    return x * 2

  class TestTool(FunctionTool):

    def __init__(self, func: Callable[..., Any]):
      super().__init__(func=func)

  wrapped_increase_by_one = TestTool(func=increase_by_one)
  agent = Agent(
      name='root_agent',
      model=mock_model,
      tools=[wrapped_increase_by_one, multiple_by_two, multiple_by_two_sync],
  )
  runner = utils.TestInMemoryRunner(agent)
  events = await runner.run_async_with_new_session('test')
  assert utils.simplify_events(events) == [
      ('root_agent', function_calls),
      ('root_agent', function_responses),
      ('root_agent', 'response1'),
  ]

  # Asserts the requests.
  assert utils.simplify_contents(mock_model.requests[0].contents) == [
      ('user', 'test')
  ]
  assert utils.simplify_contents(mock_model.requests[1].contents) == [
      ('user', 'test'),
      ('model', function_calls),
      ('user', function_responses),
  ]

  # Asserts the function calls.
  assert function_called == 3


def test_update_state():
  mock_model = utils.MockModel.create(
      responses=[
          types.Part.from_function_call(name='update_state', args={}),
          'response1',
      ]
  )

  def update_state(tool_context: ToolContext):
    tool_context.state['x'] = 1

  agent = Agent(name='root_agent', model=mock_model, tools=[update_state])
  runner = utils.InMemoryRunner(agent)
  runner.run('test')
  assert runner.session.state['x'] == 1


def test_function_call_id():
  responses = [
      types.Part.from_function_call(name='increase_by_one', args={'x': 1}),
      'response1',
  ]
  mock_model = utils.MockModel.create(responses=responses)

  def increase_by_one(x: int) -> int:
    return x + 1

  agent = Agent(name='root_agent', model=mock_model, tools=[increase_by_one])
  runner = utils.InMemoryRunner(agent)
  events = runner.run('test')
  for reqeust in mock_model.requests:
    for content in reqeust.contents:
      for part in content.parts:
        if part.function_call:
          assert part.function_call.id is None
        if part.function_response:
          assert part.function_response.id is None
  assert events[0].content.parts[0].function_call.id.startswith('adk-')
  assert events[1].content.parts[0].function_response.id.startswith('adk-')

==== tests/unittests/flows/llm_flows/test_functions_sequential.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from typing import Any

from google.adk.agents import Agent
from google.genai import types

from ... import utils


def function_call(args: dict[str, Any]) -> types.Part:
  return types.Part.from_function_call(name='increase_by_one', args=args)


def function_response(response: dict[str, Any]) -> types.Part:
  return types.Part.from_function_response(
      name='increase_by_one', response=response
  )


def test_sequential_calls():
  responses = [
      function_call({'x': 1}),
      function_call({'x': 2}),
      function_call({'x': 3}),
      'response1',
  ]
  mockModel = utils.MockModel.create(responses=responses)
  function_called = 0

  def increase_by_one(x: int) -> int:
    nonlocal function_called
    function_called += 1
    return x + 1

  agent = Agent(name='root_agent', model=mockModel, tools=[increase_by_one])
  runner = utils.InMemoryRunner(agent)
  result = utils.simplify_events(runner.run('test'))
  assert result == [
      ('root_agent', function_call({'x': 1})),
      ('root_agent', function_response({'result': 2})),
      ('root_agent', function_call({'x': 2})),
      ('root_agent', function_response({'result': 3})),
      ('root_agent', function_call({'x': 3})),
      ('root_agent', function_response({'result': 4})),
      ('root_agent', 'response1'),
  ]

  # Asserts the requests.
  assert len(mockModel.requests) == 4
  # 1 item: user content
  assert utils.simplify_contents(mockModel.requests[0].contents) == [
      ('user', 'test')
  ]
  # 3 items: user content, functaion call / response for the 1st call
  assert utils.simplify_contents(mockModel.requests[1].contents) == [
      ('user', 'test'),
      ('model', function_call({'x': 1})),
      ('user', function_response({'result': 2})),
  ]
  # 5 items: user content, functaion call / response for two calls
  assert utils.simplify_contents(mockModel.requests[2].contents) == [
      ('user', 'test'),
      ('model', function_call({'x': 1})),
      ('user', function_response({'result': 2})),
      ('model', function_call({'x': 2})),
      ('user', function_response({'result': 3})),
  ]
  # 7 items: user content, functaion call / response for three calls
  assert utils.simplify_contents(mockModel.requests[3].contents) == [
      ('user', 'test'),
      ('model', function_call({'x': 1})),
      ('user', function_response({'result': 2})),
      ('model', function_call({'x': 2})),
      ('user', function_response({'result': 3})),
      ('model', function_call({'x': 3})),
      ('user', function_response({'result': 4})),
  ]

  # Asserts the function calls.
  assert function_called == 3

==== tests/unittests/flows/llm_flows/test_other_configs.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.adk.agents import Agent
from google.adk.tools import ToolContext
from google.genai.types import Part
from pydantic import BaseModel

from ... import utils


def test_output_schema():
  class CustomOutput(BaseModel):
    custom_field: str

  response = [
      'response1',
  ]
  mockModel = utils.MockModel.create(responses=response)
  root_agent = Agent(
      name='root_agent',
      model=mockModel,
      output_schema=CustomOutput,
      disallow_transfer_to_parent=True,
      disallow_transfer_to_peers=True,
  )

  runner = utils.InMemoryRunner(root_agent)

  assert utils.simplify_events(runner.run('test1')) == [
      ('root_agent', 'response1'),
  ]
  assert len(mockModel.requests) == 1
  assert mockModel.requests[0].config.response_schema == CustomOutput
  assert mockModel.requests[0].config.response_mime_type == 'application/json'

==== tests/unittests/flows/llm_flows/test_model_callbacks.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from typing import Any
from typing import Optional

from google.adk.agents import Agent
from google.adk.agents.callback_context import CallbackContext
from google.adk.models import LlmRequest
from google.adk.models import LlmResponse
from google.genai import types
from pydantic import BaseModel
import pytest

from ... import utils


class MockBeforeModelCallback(BaseModel):
  mock_response: str

  def __call__(
      self,
      callback_context: CallbackContext,
      llm_request: LlmRequest,
  ) -> LlmResponse:
    return LlmResponse(
        content=utils.ModelContent(
            [types.Part.from_text(text=self.mock_response)]
        )
    )


class MockAfterModelCallback(BaseModel):
  mock_response: str

  def __call__(
      self,
      callback_context: CallbackContext,
      llm_response: LlmResponse,
  ) -> LlmResponse:
    return LlmResponse(
        content=utils.ModelContent(
            [types.Part.from_text(text=self.mock_response)]
        )
    )


def noop_callback(**kwargs) -> Optional[LlmResponse]:
  pass


def test_before_model_callback():
  responses = ['model_response']
  mock_model = utils.MockModel.create(responses=responses)
  agent = Agent(
      name='root_agent',
      model=mock_model,
      before_model_callback=MockBeforeModelCallback(
          mock_response='before_model_callback'
      ),
  )

  runner = utils.InMemoryRunner(agent)
  assert utils.simplify_events(runner.run('test')) == [
      ('root_agent', 'before_model_callback'),
  ]


def test_before_model_callback_noop():
  responses = ['model_response']
  mock_model = utils.MockModel.create(responses=responses)
  agent = Agent(
      name='root_agent',
      model=mock_model,
      before_model_callback=noop_callback,
  )

  runner = utils.InMemoryRunner(agent)
  assert utils.simplify_events(runner.run('test')) == [
      ('root_agent', 'model_response'),
  ]


def test_before_model_callback_end():
  responses = ['model_response']
  mock_model = utils.MockModel.create(responses=responses)
  agent = Agent(
      name='root_agent',
      model=mock_model,
      before_model_callback=MockBeforeModelCallback(
          mock_response='before_model_callback',
      ),
  )

  runner = utils.InMemoryRunner(agent)
  assert utils.simplify_events(runner.run('test')) == [
      ('root_agent', 'before_model_callback'),
  ]


def test_after_model_callback():
  responses = ['model_response']
  mock_model = utils.MockModel.create(responses=responses)
  agent = Agent(
      name='root_agent',
      model=mock_model,
      after_model_callback=MockAfterModelCallback(
          mock_response='after_model_callback'
      ),
  )

  runner = utils.InMemoryRunner(agent)
  assert utils.simplify_events(runner.run('test')) == [
      ('root_agent', 'after_model_callback'),
  ]


@pytest.mark.asyncio
async def test_after_model_callback_noop():
  responses = ['model_response']
  mock_model = utils.MockModel.create(responses=responses)
  agent = Agent(
      name='root_agent',
      model=mock_model,
      after_model_callback=noop_callback,
  )

  runner = utils.TestInMemoryRunner(agent)
  assert utils.simplify_events(
      await runner.run_async_with_new_session('test')
  ) == [('root_agent', 'model_response')]

==== tests/unittests/flows/llm_flows/test_functions_request_euc.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from typing import Any
from typing import Optional

from fastapi.openapi.models import OAuth2
from fastapi.openapi.models import OAuthFlowAuthorizationCode
from fastapi.openapi.models import OAuthFlows
from google.adk.agents import Agent
from google.adk.auth import AuthConfig
from google.adk.auth import AuthCredential
from google.adk.auth import AuthCredentialTypes
from google.adk.auth import OAuth2Auth
from google.adk.flows.llm_flows import functions
from google.adk.tools import AuthToolArguments
from google.adk.tools import ToolContext
from google.genai import types

from ... import utils


def function_call(function_call_id, name, args: dict[str, Any]) -> types.Part:
  part = types.Part.from_function_call(name=name, args=args)
  part.function_call.id = function_call_id
  return part


def test_function_request_euc():
  responses = [
      [
          types.Part.from_function_call(name='call_external_api1', args={}),
          types.Part.from_function_call(name='call_external_api2', args={}),
      ],
      [
          types.Part.from_text(text='response1'),
      ],
  ]

  auth_config1 = AuthConfig(
      auth_scheme=OAuth2(
          flows=OAuthFlows(
              authorizationCode=OAuthFlowAuthorizationCode(
                  authorizationUrl='https://accounts.google.com/o/oauth2/auth',
                  tokenUrl='https://oauth2.googleapis.com/token',
                  scopes={
                      'https://www.googleapis.com/auth/calendar': (
                          'See, edit, share, and permanently delete all the'
                          ' calendars you can access using Google Calendar'
                      )
                  },
              )
          )
      ),
      raw_auth_credential=AuthCredential(
          auth_type=AuthCredentialTypes.OAUTH2,
          oauth2=OAuth2Auth(
              client_id='oauth_client_id_1',
              client_secret='oauth_client_secret1',
          ),
      ),
  )
  auth_config2 = AuthConfig(
      auth_scheme=OAuth2(
          flows=OAuthFlows(
              authorizationCode=OAuthFlowAuthorizationCode(
                  authorizationUrl='https://accounts.google.com/o/oauth2/auth',
                  tokenUrl='https://oauth2.googleapis.com/token',
                  scopes={
                      'https://www.googleapis.com/auth/calendar': (
                          'See, edit, share, and permanently delete all the'
                          ' calendars you can access using Google Calendar'
                      )
                  },
              )
          )
      ),
      raw_auth_credential=AuthCredential(
          auth_type=AuthCredentialTypes.OAUTH2,
          oauth2=OAuth2Auth(
              client_id='oauth_client_id_2',
              client_secret='oauth_client_secret2',
          ),
      ),
  )

  mock_model = utils.MockModel.create(responses=responses)

  def call_external_api1(tool_context: ToolContext) -> Optional[int]:
    tool_context.request_credential(auth_config1)

  def call_external_api2(tool_context: ToolContext) -> Optional[int]:
    tool_context.request_credential(auth_config2)

  agent = Agent(
      name='root_agent',
      model=mock_model,
      tools=[call_external_api1, call_external_api2],
  )
  runner = utils.InMemoryRunner(agent)
  events = runner.run('test')
  assert events[0].content.parts[0].function_call is not None
  assert events[0].content.parts[1].function_call is not None
  auth_configs = list(events[2].actions.requested_auth_configs.values())
  exchanged_auth_config1 = auth_configs[0]
  exchanged_auth_config2 = auth_configs[1]
  assert exchanged_auth_config1.auth_scheme == auth_config1.auth_scheme
  assert (
      exchanged_auth_config1.raw_auth_credential
      == auth_config1.raw_auth_credential
  )
  assert (
      exchanged_auth_config1.exchanged_auth_credential.oauth2.auth_uri
      is not None
  )
  assert exchanged_auth_config2.auth_scheme == auth_config2.auth_scheme
  assert (
      exchanged_auth_config2.raw_auth_credential
      == auth_config2.raw_auth_credential
  )
  assert (
      exchanged_auth_config2.exchanged_auth_credential.oauth2.auth_uri
      is not None
  )
  function_call_ids = list(events[2].actions.requested_auth_configs.keys())

  for idx, part in enumerate(events[1].content.parts):
    reqeust_euc_function_call = part.function_call
    assert reqeust_euc_function_call is not None
    assert (
        reqeust_euc_function_call.name
        == functions.REQUEST_EUC_FUNCTION_CALL_NAME
    )
    args = AuthToolArguments.model_validate(reqeust_euc_function_call.args)

    assert args.function_call_id == function_call_ids[idx]
    args.auth_config.auth_scheme.model_extra.clear()
    assert args.auth_config.auth_scheme == auth_configs[idx].auth_scheme
    assert (
        args.auth_config.raw_auth_credential
        == auth_configs[idx].raw_auth_credential
    )


def test_function_get_auth_response():
  id_1 = 'id_1'
  id_2 = 'id_2'
  responses = [
      [
          function_call(id_1, 'call_external_api1', {}),
          function_call(id_2, 'call_external_api2', {}),
      ],
      [
          types.Part.from_text(text='response1'),
      ],
      [
          types.Part.from_text(text='response2'),
      ],
  ]

  mock_model = utils.MockModel.create(responses=responses)
  function_invoked = 0

  auth_config1 = AuthConfig(
      auth_scheme=OAuth2(
          flows=OAuthFlows(
              authorizationCode=OAuthFlowAuthorizationCode(
                  authorizationUrl='https://accounts.google.com/o/oauth2/auth',
                  tokenUrl='https://oauth2.googleapis.com/token',
                  scopes={
                      'https://www.googleapis.com/auth/calendar': (
                          'See, edit, share, and permanently delete all the'
                          ' calendars you can access using Google Calendar'
                      )
                  },
              )
          )
      ),
      raw_auth_credential=AuthCredential(
          auth_type=AuthCredentialTypes.OAUTH2,
          oauth2=OAuth2Auth(
              client_id='oauth_client_id_1',
              client_secret='oauth_client_secret1',
          ),
      ),
  )
  auth_config2 = AuthConfig(
      auth_scheme=OAuth2(
          flows=OAuthFlows(
              authorizationCode=OAuthFlowAuthorizationCode(
                  authorizationUrl='https://accounts.google.com/o/oauth2/auth',
                  tokenUrl='https://oauth2.googleapis.com/token',
                  scopes={
                      'https://www.googleapis.com/auth/calendar': (
                          'See, edit, share, and permanently delete all the'
                          ' calendars you can access using Google Calendar'
                      )
                  },
              )
          )
      ),
      raw_auth_credential=AuthCredential(
          auth_type=AuthCredentialTypes.OAUTH2,
          oauth2=OAuth2Auth(
              client_id='oauth_client_id_2',
              client_secret='oauth_client_secret2',
          ),
      ),
  )

  auth_response1 = AuthConfig(
      auth_scheme=OAuth2(
          flows=OAuthFlows(
              authorizationCode=OAuthFlowAuthorizationCode(
                  authorizationUrl='https://accounts.google.com/o/oauth2/auth',
                  tokenUrl='https://oauth2.googleapis.com/token',
                  scopes={
                      'https://www.googleapis.com/auth/calendar': (
                          'See, edit, share, and permanently delete all the'
                          ' calendars you can access using Google Calendar'
                      )
                  },
              )
          )
      ),
      raw_auth_credential=AuthCredential(
          auth_type=AuthCredentialTypes.OAUTH2,
          oauth2=OAuth2Auth(
              client_id='oauth_client_id_1',
              client_secret='oauth_client_secret1',
          ),
      ),
      exchanged_auth_credential=AuthCredential(
          auth_type=AuthCredentialTypes.OAUTH2,
          oauth2=OAuth2Auth(
              client_id='oauth_client_id_1',
              client_secret='oauth_client_secret1',
              access_token='token1',
          ),
      ),
  )
  auth_response2 = AuthConfig(
      auth_scheme=OAuth2(
          flows=OAuthFlows(
              authorizationCode=OAuthFlowAuthorizationCode(
                  authorizationUrl='https://accounts.google.com/o/oauth2/auth',
                  tokenUrl='https://oauth2.googleapis.com/token',
                  scopes={
                      'https://www.googleapis.com/auth/calendar': (
                          'See, edit, share, and permanently delete all the'
                          ' calendars you can access using Google Calendar'
                      )
                  },
              )
          )
      ),
      raw_auth_credential=AuthCredential(
          auth_type=AuthCredentialTypes.OAUTH2,
          oauth2=OAuth2Auth(
              client_id='oauth_client_id_2',
              client_secret='oauth_client_secret2',
          ),
      ),
      exchanged_auth_credential=AuthCredential(
          auth_type=AuthCredentialTypes.OAUTH2,
          oauth2=OAuth2Auth(
              client_id='oauth_client_id_2',
              client_secret='oauth_client_secret2',
              access_token='token2',
          ),
      ),
  )

  def call_external_api1(tool_context: ToolContext) -> int:
    nonlocal function_invoked
    function_invoked += 1
    auth_response = tool_context.get_auth_response(auth_config1)
    if not auth_response:
      tool_context.request_credential(auth_config1)
      return
    assert auth_response == auth_response1.exchanged_auth_credential
    return 1

  def call_external_api2(tool_context: ToolContext) -> int:
    nonlocal function_invoked
    function_invoked += 1
    auth_response = tool_context.get_auth_response(auth_config2)
    if not auth_response:
      tool_context.request_credential(auth_config2)
      return
    assert auth_response == auth_response2.exchanged_auth_credential
    return 2

  agent = Agent(
      name='root_agent',
      model=mock_model,
      tools=[call_external_api1, call_external_api2],
  )
  runner = utils.InMemoryRunner(agent)
  runner.run('test')
  request_euc_function_call_event = runner.session.events[-3]
  function_response1 = types.FunctionResponse(
      name=request_euc_function_call_event.content.parts[0].function_call.name,
      response=auth_response1.model_dump(),
  )
  function_response1.id = request_euc_function_call_event.content.parts[
      0
  ].function_call.id

  function_response2 = types.FunctionResponse(
      name=request_euc_function_call_event.content.parts[1].function_call.name,
      response=auth_response2.model_dump(),
  )
  function_response2.id = request_euc_function_call_event.content.parts[
      1
  ].function_call.id
  runner.run(
      new_message=types.Content(
          role='user',
          parts=[
              types.Part(function_response=function_response1),
              types.Part(function_response=function_response2),
          ],
      ),
  )

  assert function_invoked == 4
  reqeust = mock_model.requests[-1]
  content = reqeust.contents[-1]
  parts = content.parts
  assert len(parts) == 2
  assert parts[0].function_response.name == 'call_external_api1'
  assert parts[0].function_response.response == {'result': 1}
  assert parts[1].function_response.name == 'call_external_api2'
  assert parts[1].function_response.response == {'result': 2}

==== tests/unittests/flows/llm_flows/test_tool_callbacks.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from typing import Any

from google.adk.agents import Agent
from google.adk.tools import BaseTool
from google.adk.tools import ToolContext
from google.genai import types
from google.genai.types import Part
from pydantic import BaseModel

from ... import utils


def simple_function(input_str: str) -> str:
  return {'result': input_str}


class MockBeforeToolCallback(BaseModel):
  mock_response: dict[str, object]
  modify_tool_request: bool = False

  def __call__(
      self,
      tool: BaseTool,
      args: dict[str, Any],
      tool_context: ToolContext,
  ) -> dict[str, object]:
    if self.modify_tool_request:
      args['input_str'] = 'modified_input'
      return None
    return self.mock_response


class MockAfterToolCallback(BaseModel):
  mock_response: dict[str, object]
  modify_tool_request: bool = False
  modify_tool_response: bool = False

  def __call__(
      self,
      tool: BaseTool,
      args: dict[str, Any],
      tool_context: ToolContext,
      tool_response: dict[str, Any] = None,
  ) -> dict[str, object]:
    if self.modify_tool_request:
      args['input_str'] = 'modified_input'
      return None
    if self.modify_tool_response:
      tool_response['result'] = 'modified_output'
      return tool_response
    return self.mock_response


def noop_callback(
    **kwargs,
) -> dict[str, object]:
  pass


def test_before_tool_callback():
  responses = [
      types.Part.from_function_call(name='simple_function', args={}),
      'response1',
  ]
  mock_model = utils.MockModel.create(responses=responses)
  agent = Agent(
      name='root_agent',
      model=mock_model,
      before_tool_callback=MockBeforeToolCallback(
          mock_response={'test': 'before_tool_callback'}
      ),
      tools=[simple_function],
  )

  runner = utils.InMemoryRunner(agent)
  assert utils.simplify_events(runner.run('test')) == [
      ('root_agent', Part.from_function_call(name='simple_function', args={})),
      (
          'root_agent',
          Part.from_function_response(
              name='simple_function', response={'test': 'before_tool_callback'}
          ),
      ),
      ('root_agent', 'response1'),
  ]


def test_before_tool_callback_noop():
  responses = [
      types.Part.from_function_call(
          name='simple_function', args={'input_str': 'simple_function_call'}
      ),
      'response1',
  ]
  mock_model = utils.MockModel.create(responses=responses)
  agent = Agent(
      name='root_agent',
      model=mock_model,
      before_tool_callback=noop_callback,
      tools=[simple_function],
  )

  runner = utils.InMemoryRunner(agent)
  assert utils.simplify_events(runner.run('test')) == [
      (
          'root_agent',
          Part.from_function_call(
              name='simple_function', args={'input_str': 'simple_function_call'}
          ),
      ),
      (
          'root_agent',
          Part.from_function_response(
              name='simple_function',
              response={'result': 'simple_function_call'},
          ),
      ),
      ('root_agent', 'response1'),
  ]


def test_before_tool_callback_modify_tool_request():
  responses = [
      types.Part.from_function_call(name='simple_function', args={}),
      'response1',
  ]
  mock_model = utils.MockModel.create(responses=responses)
  agent = Agent(
      name='root_agent',
      model=mock_model,
      before_tool_callback=MockBeforeToolCallback(
          mock_response={'test': 'before_tool_callback'},
          modify_tool_request=True,
      ),
      tools=[simple_function],
  )

  runner = utils.InMemoryRunner(agent)
  assert utils.simplify_events(runner.run('test')) == [
      ('root_agent', Part.from_function_call(name='simple_function', args={})),
      (
          'root_agent',
          Part.from_function_response(
              name='simple_function',
              response={'result': 'modified_input'},
          ),
      ),
      ('root_agent', 'response1'),
  ]


def test_after_tool_callback():
  responses = [
      types.Part.from_function_call(
          name='simple_function', args={'input_str': 'simple_function_call'}
      ),
      'response1',
  ]
  mock_model = utils.MockModel.create(responses=responses)
  agent = Agent(
      name='root_agent',
      model=mock_model,
      after_tool_callback=MockAfterToolCallback(
          mock_response={'test': 'after_tool_callback'}
      ),
      tools=[simple_function],
  )

  runner = utils.InMemoryRunner(agent)
  assert utils.simplify_events(runner.run('test')) == [
      (
          'root_agent',
          Part.from_function_call(
              name='simple_function', args={'input_str': 'simple_function_call'}
          ),
      ),
      (
          'root_agent',
          Part.from_function_response(
              name='simple_function', response={'test': 'after_tool_callback'}
          ),
      ),
      ('root_agent', 'response1'),
  ]


def test_after_tool_callback_noop():
  responses = [
      types.Part.from_function_call(
          name='simple_function', args={'input_str': 'simple_function_call'}
      ),
      'response1',
  ]
  mock_model = utils.MockModel.create(responses=responses)
  agent = Agent(
      name='root_agent',
      model=mock_model,
      after_tool_callback=noop_callback,
      tools=[simple_function],
  )

  runner = utils.InMemoryRunner(agent)
  assert utils.simplify_events(runner.run('test')) == [
      (
          'root_agent',
          Part.from_function_call(
              name='simple_function', args={'input_str': 'simple_function_call'}
          ),
      ),
      (
          'root_agent',
          Part.from_function_response(
              name='simple_function',
              response={'result': 'simple_function_call'},
          ),
      ),
      ('root_agent', 'response1'),
  ]


def test_after_tool_callback_modify_tool_response():
  responses = [
      types.Part.from_function_call(
          name='simple_function', args={'input_str': 'simple_function_call'}
      ),
      'response1',
  ]
  mock_model = utils.MockModel.create(responses=responses)
  agent = Agent(
      name='root_agent',
      model=mock_model,
      after_tool_callback=MockAfterToolCallback(
          mock_response={'result': 'after_tool_callback'},
          modify_tool_response=True,
      ),
      tools=[simple_function],
  )

  runner = utils.InMemoryRunner(agent)
  assert utils.simplify_events(runner.run('test')) == [
      (
          'root_agent',
          Part.from_function_call(
              name='simple_function', args={'input_str': 'simple_function_call'}
          ),
      ),
      (
          'root_agent',
          Part.from_function_response(
              name='simple_function',
              response={'result': 'modified_output'},
          ),
      ),
      ('root_agent', 'response1'),
  ]

==== tests/unittests/flows/llm_flows/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

==== tests/unittests/flows/llm_flows/test_functions_long_running.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.adk.agents import Agent
from google.adk.tools import ToolContext
from google.adk.tools.long_running_tool import LongRunningFunctionTool
from google.genai.types import Part

from ... import utils


def test_async_function():
  responses = [
      Part.from_function_call(name='increase_by_one', args={'x': 1}),
      'response1',
      'response2',
      'response3',
      'response4',
  ]
  mockModel = utils.MockModel.create(responses=responses)
  function_called = 0

  def increase_by_one(x: int, tool_context: ToolContext) -> int:
    nonlocal function_called

    function_called += 1
    return {'status': 'pending'}

  # Calls the first time.
  agent = Agent(
      name='root_agent',
      model=mockModel,
      tools=[LongRunningFunctionTool(func=increase_by_one)],
  )
  runner = utils.InMemoryRunner(agent)
  events = runner.run('test1')

  # Asserts the requests.
  assert len(mockModel.requests) == 2
  # 1 item: user content
  assert mockModel.requests[0].contents == [
      utils.UserContent('test1'),
  ]
  increase_by_one_call = Part.from_function_call(
      name='increase_by_one', args={'x': 1}
  )
  pending_response = Part.from_function_response(
      name='increase_by_one', response={'status': 'pending'}
  )

  assert utils.simplify_contents(mockModel.requests[1].contents) == [
      ('user', 'test1'),
      ('model', increase_by_one_call),
      ('user', pending_response),
  ]

  # Asserts the function calls.
  assert function_called == 1

  # Asserts the responses.
  assert utils.simplify_events(events) == [
      (
          'root_agent',
          Part.from_function_call(name='increase_by_one', args={'x': 1}),
      ),
      (
          'root_agent',
          Part.from_function_response(
              name='increase_by_one', response={'status': 'pending'}
          ),
      ),
      ('root_agent', 'response1'),
  ]
  assert events[0].long_running_tool_ids

  # Updates with another pending progress.
  still_waiting_response = Part.from_function_response(
      name='increase_by_one', response={'status': 'still waiting'}
  )
  events = runner.run(utils.UserContent(still_waiting_response))
  # We have one new request.
  assert len(mockModel.requests) == 3
  assert utils.simplify_contents(mockModel.requests[2].contents) == [
      ('user', 'test1'),
      ('model', increase_by_one_call),
      ('user', still_waiting_response),
  ]

  assert utils.simplify_events(events) == [('root_agent', 'response2')]

  # Calls when the result is ready.
  result_response = Part.from_function_response(
      name='increase_by_one', response={'result': 2}
  )
  events = runner.run(utils.UserContent(result_response))
  # We have one new request.
  assert len(mockModel.requests) == 4
  assert utils.simplify_contents(mockModel.requests[3].contents) == [
      ('user', 'test1'),
      ('model', increase_by_one_call),
      ('user', result_response),
  ]
  assert utils.simplify_events(events) == [('root_agent', 'response3')]

  # Calls when the result is ready. Here we still accept the result and do
  # another summarization. Whether this is the right behavior is TBD.
  another_result_response = Part.from_function_response(
      name='increase_by_one', response={'result': 3}
  )
  events = runner.run(utils.UserContent(another_result_response))
  # We have one new request.
  assert len(mockModel.requests) == 5
  assert utils.simplify_contents(mockModel.requests[4].contents) == [
      ('user', 'test1'),
      ('model', increase_by_one_call),
      ('user', another_result_response),
  ]
  assert utils.simplify_events(events) == [('root_agent', 'response4')]

  # At the end, function_called should still be 1.
  assert function_called == 1


def test_async_function_with_none_response():
  responses = [
      Part.from_function_call(name='increase_by_one', args={'x': 1}),
      'response1',
      'response2',
      'response3',
      'response4',
  ]
  mockModel = utils.MockModel.create(responses=responses)
  function_called = 0

  def increase_by_one(x: int, tool_context: ToolContext) -> int:
    nonlocal function_called
    function_called += 1
    return 'pending'

  # Calls the first time.
  agent = Agent(
      name='root_agent',
      model=mockModel,
      tools=[LongRunningFunctionTool(func=increase_by_one)],
  )
  runner = utils.InMemoryRunner(agent)
  events = runner.run('test1')

  # Asserts the requests.
  assert len(mockModel.requests) == 2
  # 1 item: user content
  assert mockModel.requests[0].contents == [
      utils.UserContent('test1'),
  ]
  increase_by_one_call = Part.from_function_call(
      name='increase_by_one', args={'x': 1}
  )

  assert utils.simplify_contents(mockModel.requests[1].contents) == [
      ('user', 'test1'),
      ('model', increase_by_one_call),
      (
          'user',
          Part.from_function_response(
              name='increase_by_one', response={'result': 'pending'}
          ),
      ),
  ]

  # Asserts the function calls.
  assert function_called == 1

  # Asserts the responses.
  assert utils.simplify_events(events) == [
      (
          'root_agent',
          Part.from_function_call(name='increase_by_one', args={'x': 1}),
      ),
      (
          'root_agent',
          Part.from_function_response(
              name='increase_by_one', response={'result': 'pending'}
          ),
      ),
      ('root_agent', 'response1'),
  ]

  # Updates with another pending progress.
  still_waiting_response = Part.from_function_response(
      name='increase_by_one', response={'status': 'still waiting'}
  )
  events = runner.run(utils.UserContent(still_waiting_response))
  # We have one new request.
  assert len(mockModel.requests) == 3
  assert utils.simplify_contents(mockModel.requests[2].contents) == [
      ('user', 'test1'),
      ('model', increase_by_one_call),
      ('user', still_waiting_response),
  ]

  assert utils.simplify_events(events) == [('root_agent', 'response2')]

  # Calls when the result is ready.
  result_response = Part.from_function_response(
      name='increase_by_one', response={'result': 2}
  )
  events = runner.run(utils.UserContent(result_response))
  # We have one new request.
  assert len(mockModel.requests) == 4
  assert utils.simplify_contents(mockModel.requests[3].contents) == [
      ('user', 'test1'),
      ('model', increase_by_one_call),
      ('user', result_response),
  ]
  assert utils.simplify_events(events) == [('root_agent', 'response3')]

  # Calls when the result is ready. Here we still accept the result and do
  # another summarization. Whether this is the right behavior is TBD.
  another_result_response = Part.from_function_response(
      name='increase_by_one', response={'result': 3}
  )
  events = runner.run(utils.UserContent(another_result_response))
  # We have one new request.
  assert len(mockModel.requests) == 5
  assert utils.simplify_contents(mockModel.requests[4].contents) == [
      ('user', 'test1'),
      ('model', increase_by_one_call),
      ('user', another_result_response),
  ]
  assert utils.simplify_events(events) == [('root_agent', 'response4')]

  # At the end, function_called should still be 1.
  assert function_called == 1

==== tests/unittests/flows/llm_flows/test_identity.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.adk.agents import Agent
from google.adk.flows.llm_flows import identity
from google.adk.models import LlmRequest
from google.genai import types
import pytest

from ... import utils


@pytest.mark.asyncio
async def test_no_description():
  request = LlmRequest(
      model="gemini-1.5-flash",
      config=types.GenerateContentConfig(system_instruction=""),
  )
  agent = Agent(model="gemini-1.5-flash", name="agent")
  invocation_context = await utils.create_invocation_context(agent=agent)

  async for _ in identity.request_processor.run_async(
      invocation_context,
      request,
  ):
    pass

  assert request.config.system_instruction == (
      """You are an agent. Your internal name is "agent"."""
  )


@pytest.mark.asyncio
async def test_with_description():
  request = LlmRequest(
      model="gemini-1.5-flash",
      config=types.GenerateContentConfig(system_instruction=""),
  )
  agent = Agent(
      model="gemini-1.5-flash",
      name="agent",
      description="test description",
  )
  invocation_context = await utils.create_invocation_context(agent=agent)

  async for _ in identity.request_processor.run_async(
      invocation_context,
      request,
  ):
    pass

  assert request.config.system_instruction == "\n\n".join([
      'You are an agent. Your internal name is "agent".',
      ' The description about you is "test description"',
  ])

==== tests/unittests/flows/llm_flows/test_instructions.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.adk.agents import Agent
from google.adk.agents.readonly_context import ReadonlyContext
from google.adk.flows.llm_flows import instructions
from google.adk.models import LlmRequest
from google.adk.sessions import Session
from google.genai import types
import pytest

from ... import utils


@pytest.mark.asyncio
async def test_build_system_instruction():
  request = LlmRequest(
      model="gemini-1.5-flash",
      config=types.GenerateContentConfig(system_instruction=""),
  )
  agent = Agent(
      model="gemini-1.5-flash",
      name="agent",
      instruction=("""Use the echo_info tool to echo { customerId }, \
{{customer_int  }, {  non-identifier-float}}, \
{'key1': 'value1'} and {{'key2': 'value2'}}."""),
  )
  invocation_context = await utils.create_invocation_context(agent=agent)
  invocation_context.session = Session(
      app_name="test_app",
      user_id="test_user",
      id="test_id",
      state={"customerId": "1234567890", "customer_int": 30},
  )

  async for _ in instructions.request_processor.run_async(
      invocation_context,
      request,
  ):
    pass

  assert request.config.system_instruction == (
      """Use the echo_info tool to echo 1234567890, 30, \
{  non-identifier-float}}, {'key1': 'value1'} and {{'key2': 'value2'}}."""
  )


@pytest.mark.asyncio
async def test_function_system_instruction():
  def build_function_instruction(readonly_context: ReadonlyContext) -> str:
    return (
        "This is the function agent instruction for invocation:"
        " provider template intact { customerId }"
        " provider template intact { customer_int }"
        f" {readonly_context.invocation_id}."
    )

  request = LlmRequest(
      model="gemini-1.5-flash",
      config=types.GenerateContentConfig(system_instruction=""),
  )
  agent = Agent(
      model="gemini-1.5-flash",
      name="agent",
      instruction=build_function_instruction,
  )
  invocation_context = await utils.create_invocation_context(agent=agent)
  invocation_context.session = Session(
      app_name="test_app",
      user_id="test_user",
      id="test_id",
      state={"customerId": "1234567890", "customer_int": 30},
  )

  async for _ in instructions.request_processor.run_async(
      invocation_context,
      request,
  ):
    pass

  assert request.config.system_instruction == (
      "This is the function agent instruction for invocation:"
      " provider template intact { customerId }"
      " provider template intact { customer_int }"
      " test_id."
  )

@pytest.mark.asyncio
async def test_async_function_system_instruction():
  async def build_function_instruction(
      readonly_context: ReadonlyContext,
  ) -> str:
    return (
        "This is the function agent instruction for invocation:"
        " provider template intact { customerId }"
        " provider template intact { customer_int }"
        f" {readonly_context.invocation_id}."
    )

  request = LlmRequest(
      model="gemini-1.5-flash",
      config=types.GenerateContentConfig(system_instruction=""),
  )
  agent = Agent(
      model="gemini-1.5-flash",
      name="agent",
      instruction=build_function_instruction,
  )
  invocation_context = await utils.create_invocation_context(agent=agent)
  invocation_context.session = Session(
      app_name="test_app",
      user_id="test_user",
      id="test_id",
      state={"customerId": "1234567890", "customer_int": 30},
  )

  async for _ in instructions.request_processor.run_async(
      invocation_context,
      request,
  ):
    pass

  assert request.config.system_instruction == (
      "This is the function agent instruction for invocation:"
      " provider template intact { customerId }"
      " provider template intact { customer_int }"
      " test_id."
  )


@pytest.mark.asyncio
async def test_global_system_instruction():
  sub_agent = Agent(
      model="gemini-1.5-flash",
      name="sub_agent",
      instruction="This is the sub agent instruction.",
  )
  root_agent = Agent(
      model="gemini-1.5-flash",
      name="root_agent",
      global_instruction="This is the global instruction.",
      sub_agents=[sub_agent],
  )
  request = LlmRequest(
      model="gemini-1.5-flash",
      config=types.GenerateContentConfig(system_instruction=""),
  )
  invocation_context = await utils.create_invocation_context(agent=sub_agent)
  invocation_context.session = Session(
      app_name="test_app",
      user_id="test_user",
      id="test_id",
      state={"customerId": "1234567890", "customer_int": 30},
  )

  async for _ in instructions.request_processor.run_async(
      invocation_context,
      request,
  ):
    pass

  assert request.config.system_instruction == (
      "This is the global instruction.\n\nThis is the sub agent instruction."
  )


@pytest.mark.asyncio
async def test_function_global_system_instruction():
  def sub_agent_si(readonly_context: ReadonlyContext) -> str:
    return "This is the sub agent instruction."

  def root_agent_gi(readonly_context: ReadonlyContext) -> str:
    return "This is the global instruction."

  sub_agent = Agent(
      model="gemini-1.5-flash",
      name="sub_agent",
      instruction=sub_agent_si,
  )
  root_agent = Agent(
      model="gemini-1.5-flash",
      name="root_agent",
      global_instruction=root_agent_gi,
      sub_agents=[sub_agent],
  )
  request = LlmRequest(
      model="gemini-1.5-flash",
      config=types.GenerateContentConfig(system_instruction=""),
  )
  invocation_context = await utils.create_invocation_context(agent=sub_agent)
  invocation_context.session = Session(
      app_name="test_app",
      user_id="test_user",
      id="test_id",
      state={"customerId": "1234567890", "customer_int": 30},
  )

  async for _ in instructions.request_processor.run_async(
      invocation_context,
      request,
  ):
    pass

  assert request.config.system_instruction == (
      "This is the global instruction.\n\nThis is the sub agent instruction."
  )


@pytest.mark.asyncio
async def test_async_function_global_system_instruction():
  async def sub_agent_si(readonly_context: ReadonlyContext) -> str:
    return "This is the sub agent instruction."

  async def root_agent_gi(readonly_context: ReadonlyContext) -> str:
    return "This is the global instruction."

  sub_agent = Agent(
      model="gemini-1.5-flash",
      name="sub_agent",
      instruction=sub_agent_si,
  )
  root_agent = Agent(
      model="gemini-1.5-flash",
      name="root_agent",
      global_instruction=root_agent_gi,
      sub_agents=[sub_agent],
  )
  request = LlmRequest(
      model="gemini-1.5-flash",
      config=types.GenerateContentConfig(system_instruction=""),
  )
  invocation_context = await utils.create_invocation_context(agent=sub_agent)
  invocation_context.session = Session(
      app_name="test_app",
      user_id="test_user",
      id="test_id",
      state={"customerId": "1234567890", "customer_int": 30},
  )

  async for _ in instructions.request_processor.run_async(
      invocation_context,
      request,
  ):
    pass

  assert request.config.system_instruction == (
      "This is the global instruction.\n\nThis is the sub agent instruction."
  )


@pytest.mark.asyncio
async def test_build_system_instruction_with_namespace():
  request = LlmRequest(
      model="gemini-1.5-flash",
      config=types.GenerateContentConfig(system_instruction=""),
  )
  agent = Agent(
      model="gemini-1.5-flash",
      name="agent",
      instruction=(
          """Use the echo_info tool to echo { customerId }, {app:key}, {user:key}, {a:key}."""
      ),
  )
  invocation_context = await utils.create_invocation_context(agent=agent)
  invocation_context.session = Session(
      app_name="test_app",
      user_id="test_user",
      id="test_id",
      state={
          "customerId": "1234567890",
          "app:key": "app_value",
          "user:key": "user_value",
      },
  )

  async for _ in instructions.request_processor.run_async(
      invocation_context,
      request,
  ):
    pass

  assert request.config.system_instruction == (
      """Use the echo_info tool to echo 1234567890, app_value, user_value, {a:key}."""
  )

==== tests/unittests/flows/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

==== tests/unittests/conftest.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os

from pytest import fixture
from pytest import FixtureRequest
from pytest import hookimpl
from pytest import Metafunc

_ENV_VARS = {
    'GOOGLE_API_KEY': 'fake_google_api_key',
    'GOOGLE_CLOUD_PROJECT': 'fake_google_cloud_project',
    'GOOGLE_CLOUD_LOCATION': 'fake_google_cloud_location',
}

ENV_SETUPS = {
    'GOOGLE_AI': {
        'GOOGLE_GENAI_USE_VERTEXAI': '0',
        **_ENV_VARS,
    },
    'VERTEX': {
        'GOOGLE_GENAI_USE_VERTEXAI': '1',
        **_ENV_VARS,
    },
}


@fixture(autouse=True)
def env_variables(request: FixtureRequest):
  # Set up the environment
  env_name: str = request.param
  envs = ENV_SETUPS[env_name]
  original_env = {key: os.environ.get(key) for key in envs}
  os.environ.update(envs)

  yield  # Run the test

  # Restore the environment
  for key in envs:
    if (original_val := original_env.get(key)) is None:
      os.environ.pop(key, None)
    else:
      os.environ[key] = original_val


@hookimpl(tryfirst=True)
def pytest_generate_tests(metafunc: Metafunc):
  """Generate test cases for each environment setup."""
  if env_variables.__name__ in metafunc.fixturenames:
    if not _is_explicitly_marked(env_variables.__name__, metafunc):
      metafunc.parametrize(
          env_variables.__name__, ENV_SETUPS.keys(), indirect=True
      )


def _is_explicitly_marked(mark_name: str, metafunc: Metafunc) -> bool:
  if hasattr(metafunc.function, 'pytestmark'):
    for mark in metafunc.function.pytestmark:
      if mark.name == 'parametrize' and mark.args[0] == mark_name:
        return True
  return False

==== tests/unittests/tools/application_integration_tool/clients/test_integration_client.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import json
import re
from unittest import mock

from google.adk.tools.application_integration_tool.clients.connections_client import ConnectionsClient
from google.adk.tools.application_integration_tool.clients.integration_client import IntegrationClient
import google.auth
import google.auth.transport.requests
from google.auth.transport.requests import Request
from google.oauth2 import service_account
import pytest
import requests
from requests import exceptions


@pytest.fixture
def project():
  return "test-project"


@pytest.fixture
def location():
  return "us-central1"


@pytest.fixture
def integration_name():
  return "test-integration"


@pytest.fixture
def triggers():
  return ["test-trigger", "test-trigger2"]


@pytest.fixture
def connection_name():
  return "test-connection"


@pytest.fixture
def mock_credentials():
  creds = mock.create_autospec(google.auth.credentials.Credentials)
  creds.token = "test_token"
  return creds


@pytest.fixture
def mock_auth_request():
  return mock.create_autospec(Request)


@pytest.fixture
def mock_connections_client():
  with mock.patch(
      "google.adk.tools.application_integration_tool.clients.integration_client.ConnectionsClient"
  ) as mock_client:
    mock_instance = mock.create_autospec(ConnectionsClient)
    mock_client.return_value = mock_instance
    yield mock_client


class TestIntegrationClient:

  def test_initialization(
      self, project, location, integration_name, triggers, connection_name
  ):
    client = IntegrationClient(
        project=project,
        location=location,
        integration=integration_name,
        triggers=triggers,
        connection=connection_name,
        entity_operations={"entity": ["LIST"]},
        actions=["action1"],
        service_account_json=json.dumps({"email": "test@example.com"}),
    )
    assert client.project == project
    assert client.location == location
    assert client.integration == integration_name
    assert client.triggers == triggers
    assert client.connection == connection_name
    assert client.entity_operations == {"entity": ["LIST"]}
    assert client.actions == ["action1"]
    assert client.service_account_json == json.dumps(
        {"email": "test@example.com"}
    )
    assert client.credential_cache is None

  def test_get_openapi_spec_for_integration_success(
      self,
      project,
      location,
      integration_name,
      triggers,
      mock_credentials,
      mock_connections_client,
  ):
    expected_spec = {"openapi": "3.0.0", "info": {"title": "Test Integration"}}
    mock_response = mock.MagicMock()
    mock_response.status_code = 200
    mock_response.json.return_value = {"openApiSpec": json.dumps(expected_spec)}

    with (
        mock.patch.object(
            IntegrationClient,
            "_get_access_token",
            return_value=mock_credentials.token,
        ),
        mock.patch("requests.post", return_value=mock_response),
    ):
      client = IntegrationClient(
          project=project,
          location=location,
          integration=integration_name,
          triggers=triggers,
          connection=None,
          entity_operations=None,
          actions=None,
          service_account_json=None,
      )
      spec = client.get_openapi_spec_for_integration()
      assert spec == expected_spec
      requests.post.assert_called_once_with(
          f"https://{location}-integrations.googleapis.com/v1/projects/{project}/locations/{location}:generateOpenApiSpec",
          headers={
              "Content-Type": "application/json",
              "Authorization": f"Bearer {mock_credentials.token}",
          },
          json={
              "apiTriggerResources": [{
                  "integrationResource": integration_name,
                  "triggerId": triggers,
              }],
              "fileFormat": "JSON",
          },
      )

  def test_get_openapi_spec_for_integration_credential_error(
      self,
      project,
      location,
      integration_name,
      triggers,
      mock_connections_client,
  ):
    with mock.patch.object(
        IntegrationClient,
        "_get_access_token",
        side_effect=ValueError(
            "Please provide a service account that has the required permissions"
            " to access the connection."
        ),
    ):
      client = IntegrationClient(
          project=project,
          location=location,
          integration=integration_name,
          triggers=triggers,
          connection=None,
          entity_operations=None,
          actions=None,
          service_account_json=None,
      )
      with pytest.raises(
          Exception,
          match=(
              "An unexpected error occurred: Please provide a service account"
              " that has the required permissions to access the connection."
          ),
      ):
        client.get_openapi_spec_for_integration()

  @pytest.mark.parametrize(
      "status_code, response_text",
      [(404, "Not Found"), (400, "Bad Request"), (404, ""), (400, "")],
  )
  def test_get_openapi_spec_for_integration_request_error_not_found_or_bad_request(
      self,
      project,
      location,
      integration_name,
      triggers,
      mock_credentials,
      status_code,
      response_text,
      mock_connections_client,
  ):
    mock_response = mock.MagicMock()
    mock_response.status_code = status_code
    mock_response.raise_for_status.side_effect = exceptions.HTTPError(
        f"HTTP error {status_code}: {response_text}"
    )

    with (
        mock.patch.object(
            IntegrationClient,
            "_get_access_token",
            return_value=mock_credentials.token,
        ),
        mock.patch("requests.post", return_value=mock_response),
    ):
      client = IntegrationClient(
          project=project,
          location=location,
          integration=integration_name,
          triggers=triggers,
          connection=None,
          entity_operations=None,
          actions=None,
          service_account_json=None,
      )
      with pytest.raises(
          ValueError,
          match=(
              r"Invalid request\. Please check the provided values of"
              rf" project\({project}\), location\({location}\),"
              rf" integration\({integration_name}\)."
          ),
      ):
        client.get_openapi_spec_for_integration()

  def test_get_openapi_spec_for_integration_other_request_error(
      self,
      project,
      location,
      integration_name,
      triggers,
      mock_credentials,
      mock_connections_client,
  ):
    mock_response = mock.MagicMock()
    mock_response.status_code = 500
    mock_response.raise_for_status.side_effect = exceptions.HTTPError(
        "Internal Server Error"
    )

    with (
        mock.patch.object(
            IntegrationClient,
            "_get_access_token",
            return_value=mock_credentials.token,
        ),
        mock.patch("requests.post", return_value=mock_response),
    ):
      client = IntegrationClient(
          project=project,
          location=location,
          integration=integration_name,
          triggers=triggers,
          connection=None,
          entity_operations=None,
          actions=None,
          service_account_json=None,
      )
      with pytest.raises(ValueError, match="Request error: "):
        client.get_openapi_spec_for_integration()

  def test_get_openapi_spec_for_integration_unexpected_error(
      self,
      project,
      location,
      integration_name,
      triggers,
      mock_credentials,
      mock_connections_client,
  ):
    with (
        mock.patch.object(
            IntegrationClient,
            "_get_access_token",
            return_value=mock_credentials.token,
        ),
        mock.patch(
            "requests.post", side_effect=Exception("Something went wrong")
        ),
    ):
      client = IntegrationClient(
          project=project,
          location=location,
          integration=integration_name,
          triggers=triggers,
          connection=None,
          entity_operations=None,
          actions=None,
          service_account_json=None,
      )
      with pytest.raises(
          Exception, match="An unexpected error occurred: Something went wrong"
      ):
        client.get_openapi_spec_for_integration()

  def test_get_openapi_spec_for_connection_no_entity_operations_or_actions(
      self, project, location, connection_name, mock_connections_client
  ):
    client = IntegrationClient(
        project=project,
        location=location,
        integration=None,
        triggers=None,
        connection=connection_name,
        entity_operations=None,
        actions=None,
        service_account_json=None,
    )
    with pytest.raises(
        ValueError,
        match=(
            "No entity operations or actions provided. Please provide at least"
            " one of them."
        ),
    ):
      client.get_openapi_spec_for_connection()

  def test_get_openapi_spec_for_connection_with_entity_operations(
      self, project, location, connection_name, mock_connections_client
  ):
    entity_operations = {"entity1": ["LIST", "GET"]}

    mock_connections_client_instance = mock_connections_client.return_value
    mock_connections_client_instance.get_connector_base_spec.return_value = {
        "components": {"schemas": {}},
        "paths": {},
    }
    mock_connections_client_instance.get_entity_schema_and_operations.return_value = (
        {"type": "object", "properties": {"id": {"type": "string"}}},
        ["LIST", "GET"],
    )
    mock_connections_client_instance.connector_payload.return_value = {
        "type": "object"
    }
    mock_connections_client_instance.list_operation.return_value = {"get": {}}
    mock_connections_client_instance.list_operation_request.return_value = {
        "type": "object"
    }
    mock_connections_client_instance.get_operation.return_value = {"get": {}}
    mock_connections_client_instance.get_operation_request.return_value = {
        "type": "object"
    }

    client = IntegrationClient(
        project=project,
        location=location,
        integration=None,
        triggers=None,
        connection=connection_name,
        entity_operations=entity_operations,
        actions=None,
        service_account_json=None,
    )
    spec = client.get_openapi_spec_for_connection()
    assert "paths" in spec
    assert (
        f"/v2/projects/{project}/locations/{location}/integrations/ExecuteConnection:execute?triggerId=api_trigger/ExecuteConnection#list_entity1"
        in spec["paths"]
    )
    assert (
        f"/v2/projects/{project}/locations/{location}/integrations/ExecuteConnection:execute?triggerId=api_trigger/ExecuteConnection#get_entity1"
        in spec["paths"]
    )
    mock_connections_client.assert_called_once_with(
        project, location, connection_name, None
    )
    mock_connections_client_instance.get_connector_base_spec.assert_called_once()
    mock_connections_client_instance.get_entity_schema_and_operations.assert_any_call(
        "entity1"
    )
    mock_connections_client_instance.connector_payload.assert_any_call(
        {"type": "object", "properties": {"id": {"type": "string"}}}
    )
    mock_connections_client_instance.list_operation.assert_called_once()
    mock_connections_client_instance.get_operation.assert_called_once()

  def test_get_openapi_spec_for_connection_with_actions(
      self, project, location, connection_name, mock_connections_client
  ):
    actions = ["TestAction"]
    mock_connections_client_instance = (
        mock_connections_client.return_value
    )  # Corrected line
    mock_connections_client_instance.get_connector_base_spec.return_value = {
        "components": {"schemas": {}},
        "paths": {},
    }
    mock_connections_client_instance.get_action_schema.return_value = {
        "inputSchema": {
            "type": "object",
            "properties": {"input": {"type": "string"}},
        },
        "outputSchema": {
            "type": "object",
            "properties": {"output": {"type": "string"}},
        },
        "displayName": "TestAction",
    }
    mock_connections_client_instance.connector_payload.side_effect = [
        {"type": "object"},
        {"type": "object"},
    ]
    mock_connections_client_instance.action_request.return_value = {
        "type": "object"
    }
    mock_connections_client_instance.action_response.return_value = {
        "type": "object"
    }
    mock_connections_client_instance.get_action_operation.return_value = {
        "post": {}
    }

    client = IntegrationClient(
        project=project,
        location=location,
        integration=None,
        triggers=None,
        connection=connection_name,
        entity_operations=None,
        actions=actions,
        service_account_json=None,
    )
    spec = client.get_openapi_spec_for_connection()
    assert "paths" in spec
    assert (
        f"/v2/projects/{project}/locations/{location}/integrations/ExecuteConnection:execute?triggerId=api_trigger/ExecuteConnection#TestAction"
        in spec["paths"]
    )
    mock_connections_client.assert_called_once_with(
        project, location, connection_name, None
    )
    mock_connections_client_instance.get_connector_base_spec.assert_called_once()
    mock_connections_client_instance.get_action_schema.assert_called_once_with(
        "TestAction"
    )
    mock_connections_client_instance.connector_payload.assert_any_call(
        {"type": "object", "properties": {"input": {"type": "string"}}}
    )
    mock_connections_client_instance.connector_payload.assert_any_call(
        {"type": "object", "properties": {"output": {"type": "string"}}}
    )
    mock_connections_client_instance.action_request.assert_called_once_with(
        "TestAction"
    )
    mock_connections_client_instance.action_response.assert_called_once_with(
        "TestAction"
    )
    mock_connections_client_instance.get_action_operation.assert_called_once()

  def test_get_openapi_spec_for_connection_invalid_operation(
      self, project, location, connection_name, mock_connections_client
  ):
    entity_operations = {"entity1": ["INVALID"]}
    mock_connections_client_instance = mock_connections_client.return_value
    mock_connections_client_instance.get_connector_base_spec.return_value = {
        "components": {"schemas": {}},
        "paths": {},
    }
    mock_connections_client_instance.get_entity_schema_and_operations.return_value = (
        {"type": "object", "properties": {"id": {"type": "string"}}},
        ["LIST", "GET"],
    )

    client = IntegrationClient(
        project=project,
        location=location,
        integration=None,
        triggers=None,
        connection=connection_name,
        entity_operations=entity_operations,
        actions=None,
        service_account_json=None,
    )
    with pytest.raises(
        ValueError, match="Invalid operation: INVALID for entity: entity1"
    ):
      client.get_openapi_spec_for_connection()

  def test_get_access_token_with_service_account_json(
      self, project, location, integration_name, triggers, connection_name
  ):
    service_account_json = json.dumps({
        "client_email": "test@example.com",
        "private_key": "test_key",
    })
    mock_creds = mock.create_autospec(service_account.Credentials)
    mock_creds.token = "sa_token"
    mock_creds.expired = False

    with (
        mock.patch(
            "google.oauth2.service_account.Credentials.from_service_account_info",
            return_value=mock_creds,
        ),
        mock.patch.object(mock_creds, "refresh", return_value=None),
    ):
      client = IntegrationClient(
          project=project,
          location=location,
          integration=integration_name,
          triggers=triggers,
          connection=connection_name,
          entity_operations=None,
          actions=None,
          service_account_json=service_account_json,
      )
      token = client._get_access_token()
      assert token == "sa_token"
      service_account.Credentials.from_service_account_info.assert_called_once_with(
          json.loads(service_account_json),
          scopes=["https://www.googleapis.com/auth/cloud-platform"],
      )
      mock_creds.refresh.assert_called_once()

  def test_get_access_token_with_default_credentials(
      self,
      project,
      location,
      integration_name,
      triggers,
      connection_name,
      mock_credentials,
  ):
    mock_credentials.expired = False
    with (
        mock.patch(
            "google.adk.tools.application_integration_tool.clients.integration_client.default_service_credential",
            return_value=(mock_credentials, "test_project_id"),
        ),
        mock.patch.object(mock_credentials, "refresh", return_value=None),
    ):
      client = IntegrationClient(
          project=project,
          location=location,
          integration=integration_name,
          triggers=triggers,
          connection=connection_name,
          entity_operations=None,
          actions=None,
          service_account_json=None,
      )
      token = client._get_access_token()
      assert token == "test_token"

  def test_get_access_token_no_valid_credentials(
      self, project, location, integration_name, triggers, connection_name
  ):
    with (
        mock.patch(
            "google.adk.tools.application_integration_tool.clients.integration_client.default_service_credential",
            return_value=(None, None),
        ),
        mock.patch(
            "google.oauth2.service_account.Credentials.from_service_account_info",
            return_value=None,
        ),
    ):
      client = IntegrationClient(
          project=project,
          location=location,
          integration=integration_name,
          triggers=triggers,
          connection=connection_name,
          entity_operations=None,
          actions=None,
          service_account_json=None,
      )
      try:
        client._get_access_token()
        assert False, "ValueError was not raised"  # Explicitly fail if no error
      except ValueError as e:
        assert (
            "Please provide a service account that has the required permissions"
            " to access the connection."
            in str(e)
        )

  def test_get_access_token_uses_cached_token(
      self,
      project,
      location,
      integration_name,
      triggers,
      connection_name,
      mock_credentials,
  ):
    mock_credentials.token = "cached_token"
    mock_credentials.expired = False
    client = IntegrationClient(
        project=project,
        location=location,
        integration=integration_name,
        triggers=triggers,
        connection=connection_name,
        entity_operations=None,
        actions=None,
        service_account_json=None,
    )
    client.credential_cache = mock_credentials  # Simulate a cached credential
    with (
        mock.patch("google.auth.default") as mock_default,
        mock.patch(
            "google.oauth2.service_account.Credentials.from_service_account_info"
        ) as mock_sa,
    ):
      token = client._get_access_token()
      assert token == "cached_token"
      mock_default.assert_not_called()
      mock_sa.assert_not_called()

  def test_get_access_token_refreshes_expired_token(
      self,
      project,
      location,
      integration_name,
      triggers,
      connection_name,
      mock_credentials,
  ):
    mock_credentials = mock.create_autospec(google.auth.credentials.Credentials)
    mock_credentials.token = "old_token"
    mock_credentials.expired = True
    mock_credentials.refresh.return_value = None
    mock_credentials.token = "new_token"  # Simulate token refresh

    with mock.patch(
        "google.adk.tools.application_integration_tool.clients.integration_client.default_service_credential",
        return_value=(mock_credentials, "test_project_id"),
    ):
      client = IntegrationClient(
          project=project,
          location=location,
          integration=integration_name,
          triggers=triggers,
          connection=connection_name,
          entity_operations=None,
          actions=None,
          service_account_json=None,
      )
      client.credential_cache = mock_credentials
      token = client._get_access_token()
      assert token == "new_token"
      mock_credentials.refresh.assert_called_once()

==== tests/unittests/tools/application_integration_tool/clients/test_connections_client.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import json
from unittest import mock

from google.adk.tools.application_integration_tool.clients.connections_client import ConnectionsClient
import google.auth
import pytest
import requests
from requests import exceptions


@pytest.fixture
def project():
  return "test-project"


@pytest.fixture
def location():
  return "us-central1"


@pytest.fixture
def connection_name():
  return "test-connection"


@pytest.fixture
def mock_credentials():
  creds = mock.create_autospec(google.auth.credentials.Credentials)
  creds.token = "test_token"
  creds.expired = False
  return creds


@pytest.fixture
def mock_auth_request():
  return mock.create_autospec(google.auth.transport.requests.Request)


class TestConnectionsClient:

  def test_initialization(self, project, location, connection_name):
    credentials = {"email": "test@example.com"}
    client = ConnectionsClient(
        project, location, connection_name, json.dumps(credentials)
    )
    assert client.project == project
    assert client.location == location
    assert client.connection == connection_name
    assert client.connector_url == "https://connectors.googleapis.com"
    assert client.service_account_json == json.dumps(credentials)
    assert client.credential_cache is None

  def test_execute_api_call_success(
      self, project, location, connection_name, mock_credentials
  ):
    credentials = {"email": "test@example.com"}
    client = ConnectionsClient(project, location, connection_name, credentials)
    mock_response = mock.MagicMock()
    mock_response.status_code = 200
    mock_response.raise_for_status.return_value = None
    mock_response.json.return_value = {"data": "test"}

    with (
        mock.patch.object(
            client, "_get_access_token", return_value=mock_credentials.token
        ),
        mock.patch("requests.get", return_value=mock_response),
    ):
      response = client._execute_api_call("https://test.url")
      assert response.json() == {"data": "test"}
      requests.get.assert_called_once_with(
          "https://test.url",
          headers={
              "Content-Type": "application/json",
              "Authorization": f"Bearer {mock_credentials.token}",
          },
      )

  def test_execute_api_call_credential_error(
      self, project, location, connection_name
  ):
    credentials = {"email": "test@example.com"}
    client = ConnectionsClient(project, location, connection_name, credentials)
    with mock.patch.object(
        client,
        "_get_access_token",
        side_effect=google.auth.exceptions.DefaultCredentialsError("Test"),
    ):
      with pytest.raises(PermissionError, match="Credentials error: Test"):
        client._execute_api_call("https://test.url")

  @pytest.mark.parametrize(
      "status_code, response_text",
      [(404, "Not Found"), (400, "Bad Request")],
  )
  def test_execute_api_call_request_error_not_found_or_bad_request(
      self,
      project,
      location,
      connection_name,
      mock_credentials,
      status_code,
      response_text,
  ):
    credentials = {"email": "test@example.com"}
    client = ConnectionsClient(project, location, connection_name, credentials)
    mock_response = mock.MagicMock()
    mock_response.status_code = status_code
    mock_response.raise_for_status.side_effect = exceptions.HTTPError(
        f"HTTP error {status_code}: {response_text}"
    )

    with (
        mock.patch.object(
            client, "_get_access_token", return_value=mock_credentials.token
        ),
        mock.patch("requests.get", return_value=mock_response),
    ):
      with pytest.raises(
          ValueError, match="Invalid request. Please check the provided"
      ):
        client._execute_api_call("https://test.url")

  def test_execute_api_call_other_request_error(
      self, project, location, connection_name, mock_credentials
  ):
    credentials = {"email": "test@example.com"}
    client = ConnectionsClient(project, location, connection_name, credentials)
    mock_response = mock.MagicMock()
    mock_response.status_code = 500
    mock_response.raise_for_status.side_effect = exceptions.HTTPError(
        "Internal Server Error"
    )

    with (
        mock.patch.object(
            client, "_get_access_token", return_value=mock_credentials.token
        ),
        mock.patch("requests.get", return_value=mock_response),
    ):
      with pytest.raises(ValueError, match="Request error: "):
        client._execute_api_call("https://test.url")

  def test_execute_api_call_unexpected_error(
      self, project, location, connection_name, mock_credentials
  ):
    credentials = {"email": "test@example.com"}
    client = ConnectionsClient(project, location, connection_name, credentials)
    with (
        mock.patch.object(
            client, "_get_access_token", return_value=mock_credentials.token
        ),
        mock.patch(
            "requests.get", side_effect=Exception("Something went wrong")
        ),
    ):
      with pytest.raises(
          Exception, match="An unexpected error occurred: Something went wrong"
      ):
        client._execute_api_call("https://test.url")

  def test_get_connection_details_success_with_host(
      self, project, location, connection_name, mock_credentials
  ):
    credentials = {"email": "test@example.com"}
    client = ConnectionsClient(project, location, connection_name, credentials)
    mock_response = mock.MagicMock()
    mock_response.status_code = 200
    mock_response.json.return_value = {
        "serviceDirectory": "test_service",
        "host": "test.host",
        "tlsServiceDirectory": "tls_test_service",
        "authOverrideEnabled": True,
    }

    with mock.patch.object(
        client, "_execute_api_call", return_value=mock_response
    ):
      details = client.get_connection_details()
      assert details == {
          "serviceName": "tls_test_service",
          "host": "test.host",
          "authOverrideEnabled": True,
          "name": "",
      }

  def test_get_connection_details_success_without_host(
      self, project, location, connection_name, mock_credentials
  ):
    credentials = {"email": "test@example.com"}
    client = ConnectionsClient(project, location, connection_name, credentials)
    mock_response = mock.MagicMock()
    mock_response.status_code = 200
    mock_response.json.return_value = {
        "serviceDirectory": "test_service",
        "authOverrideEnabled": False,
    }

    with mock.patch.object(
        client, "_execute_api_call", return_value=mock_response
    ):
      details = client.get_connection_details()
      assert details == {
          "serviceName": "test_service",
          "host": "",
          "authOverrideEnabled": False,
          "name": "",
      }

  def test_get_connection_details_error(
      self, project, location, connection_name
  ):
    credentials = {"email": "test@example.com"}
    client = ConnectionsClient(project, location, connection_name, credentials)
    with mock.patch.object(
        client, "_execute_api_call", side_effect=ValueError("Request error")
    ):
      with pytest.raises(ValueError, match="Request error"):
        client.get_connection_details()

  def test_get_entity_schema_and_operations_success(
      self, project, location, connection_name, mock_credentials
  ):
    credentials = {"email": "test@example.com"}
    client = ConnectionsClient(project, location, connection_name, credentials)
    mock_execute_response_initial = mock.MagicMock()
    mock_execute_response_initial.status_code = 200
    mock_execute_response_initial.json.return_value = {
        "name": "operations/test_op"
    }

    mock_execute_response_poll_done = mock.MagicMock()
    mock_execute_response_poll_done.status_code = 200
    mock_execute_response_poll_done.json.return_value = {
        "done": True,
        "response": {
            "jsonSchema": {"type": "object"},
            "operations": ["LIST", "GET"],
        },
    }

    with mock.patch.object(
        client,
        "_execute_api_call",
        side_effect=[
            mock_execute_response_initial,
            mock_execute_response_poll_done,
        ],
    ):
      schema, operations = client.get_entity_schema_and_operations("entity1")
      assert schema == {"type": "object"}
      assert operations == ["LIST", "GET"]
      assert (
          mock.call(
              f"https://connectors.googleapis.com/v1/projects/{project}/locations/{location}/connections/{connection_name}/connectionSchemaMetadata:getEntityType?entityId=entity1"
          )
          in client._execute_api_call.mock_calls
      )
      assert (
          mock.call(f"https://connectors.googleapis.com/v1/operations/test_op")
          in client._execute_api_call.mock_calls
      )

  def test_get_entity_schema_and_operations_no_operation_id(
      self, project, location, connection_name, mock_credentials
  ):
    credentials = {"email": "test@example.com"}
    client = ConnectionsClient(project, location, connection_name, credentials)
    mock_execute_response = mock.MagicMock()
    mock_execute_response.status_code = 200
    mock_execute_response.json.return_value = {}

    with mock.patch.object(
        client, "_execute_api_call", return_value=mock_execute_response
    ):
      with pytest.raises(
          ValueError,
          match=(
              "Failed to get entity schema and operations for entity: entity1"
          ),
      ):
        client.get_entity_schema_and_operations("entity1")

  def test_get_entity_schema_and_operations_execute_api_call_error(
      self, project, location, connection_name
  ):
    credentials = {"email": "test@example.com"}
    client = ConnectionsClient(project, location, connection_name, credentials)
    with mock.patch.object(
        client, "_execute_api_call", side_effect=ValueError("Request error")
    ):
      with pytest.raises(ValueError, match="Request error"):
        client.get_entity_schema_and_operations("entity1")

  def test_get_action_schema_success(
      self, project, location, connection_name, mock_credentials
  ):
    credentials = {"email": "test@example.com"}
    client = ConnectionsClient(project, location, connection_name, credentials)
    mock_execute_response_initial = mock.MagicMock()
    mock_execute_response_initial.status_code = 200
    mock_execute_response_initial.json.return_value = {
        "name": "operations/test_op"
    }

    mock_execute_response_poll_done = mock.MagicMock()
    mock_execute_response_poll_done.status_code = 200
    mock_execute_response_poll_done.json.return_value = {
        "done": True,
        "response": {
            "inputJsonSchema": {
                "type": "object",
                "properties": {"input": {"type": "string"}},
            },
            "outputJsonSchema": {
                "type": "object",
                "properties": {"output": {"type": "string"}},
            },
            "description": "Test Action Description",
            "displayName": "TestAction",
        },
    }

    with mock.patch.object(
        client,
        "_execute_api_call",
        side_effect=[
            mock_execute_response_initial,
            mock_execute_response_poll_done,
        ],
    ):
      schema = client.get_action_schema("action1")
      assert schema == {
          "inputSchema": {
              "type": "object",
              "properties": {"input": {"type": "string"}},
          },
          "outputSchema": {
              "type": "object",
              "properties": {"output": {"type": "string"}},
          },
          "description": "Test Action Description",
          "displayName": "TestAction",
      }
      assert (
          mock.call(
              f"https://connectors.googleapis.com/v1/projects/{project}/locations/{location}/connections/{connection_name}/connectionSchemaMetadata:getAction?actionId=action1"
          )
          in client._execute_api_call.mock_calls
      )
      assert (
          mock.call(f"https://connectors.googleapis.com/v1/operations/test_op")
          in client._execute_api_call.mock_calls
      )

  def test_get_action_schema_no_operation_id(
      self, project, location, connection_name, mock_credentials
  ):
    credentials = {"email": "test@example.com"}
    client = ConnectionsClient(project, location, connection_name, credentials)
    mock_execute_response = mock.MagicMock()
    mock_execute_response.status_code = 200
    mock_execute_response.json.return_value = {}

    with mock.patch.object(
        client, "_execute_api_call", return_value=mock_execute_response
    ):
      with pytest.raises(
          ValueError, match="Failed to get action schema for action: action1"
      ):
        client.get_action_schema("action1")

  def test_get_action_schema_execute_api_call_error(
      self, project, location, connection_name
  ):
    credentials = {"email": "test@example.com"}
    client = ConnectionsClient(project, location, connection_name, credentials)
    with mock.patch.object(
        client, "_execute_api_call", side_effect=ValueError("Request error")
    ):
      with pytest.raises(ValueError, match="Request error"):
        client.get_action_schema("action1")

  def test_get_connector_base_spec(self):
    spec = ConnectionsClient.get_connector_base_spec()
    assert "openapi" in spec
    assert spec["info"]["title"] == "ExecuteConnection"
    assert "components" in spec
    assert "schemas" in spec["components"]
    assert "operation" in spec["components"]["schemas"]

  def test_get_action_operation(self):
    operation = ConnectionsClient.get_action_operation(
        "TestAction", "EXECUTE_ACTION", "TestActionDisplayName", "test_tool"
    )
    assert "post" in operation
    assert operation["post"]["summary"] == "TestActionDisplayName"
    assert "operationId" in operation["post"]
    assert operation["post"]["operationId"] == "test_tool_TestActionDisplayName"

  def test_list_operation(self):
    operation = ConnectionsClient.list_operation(
        "Entity1", '{"type": "object"}', "test_tool"
    )
    assert "post" in operation
    assert operation["post"]["summary"] == "List Entity1"
    assert "operationId" in operation["post"]
    assert operation["post"]["operationId"] == "test_tool_list_Entity1"

  def test_get_operation_static(self):
    operation = ConnectionsClient.get_operation(
        "Entity1", '{"type": "object"}', "test_tool"
    )
    assert "post" in operation
    assert operation["post"]["summary"] == "Get Entity1"
    assert "operationId" in operation["post"]
    assert operation["post"]["operationId"] == "test_tool_get_Entity1"

  def test_create_operation(self):
    operation = ConnectionsClient.create_operation("Entity1", "test_tool")
    assert "post" in operation
    assert operation["post"]["summary"] == "Creates a new Entity1"
    assert "operationId" in operation["post"]
    assert operation["post"]["operationId"] == "test_tool_create_Entity1"

  def test_update_operation(self):
    operation = ConnectionsClient.update_operation("Entity1", "test_tool")
    assert "post" in operation
    assert operation["post"]["summary"] == "Updates the Entity1"
    assert "operationId" in operation["post"]
    assert operation["post"]["operationId"] == "test_tool_update_Entity1"

  def test_delete_operation(self):
    operation = ConnectionsClient.delete_operation("Entity1", "test_tool")
    assert "post" in operation
    assert operation["post"]["summary"] == "Delete the Entity1"
    assert operation["post"]["operationId"] == "test_tool_delete_Entity1"

  def test_create_operation_request(self):
    schema = ConnectionsClient.create_operation_request("Entity1")
    assert "type" in schema
    assert schema["type"] == "object"
    assert "properties" in schema
    assert "connectorInputPayload" in schema["properties"]

  def test_update_operation_request(self):
    schema = ConnectionsClient.update_operation_request("Entity1")
    assert "type" in schema
    assert schema["type"] == "object"
    assert "properties" in schema
    assert "entityId" in schema["properties"]
    assert "filterClause" in schema["properties"]

  def test_get_operation_request_static(self):
    schema = ConnectionsClient.get_operation_request()
    assert "type" in schema
    assert schema["type"] == "object"
    assert "properties" in schema
    assert "entityId" in schema["properties"]

  def test_delete_operation_request(self):
    schema = ConnectionsClient.delete_operation_request()
    assert "type" in schema
    assert schema["type"] == "object"
    assert "properties" in schema
    assert "entityId" in schema["properties"]
    assert "filterClause" in schema["properties"]

  def test_list_operation_request(self):
    schema = ConnectionsClient.list_operation_request()
    assert "type" in schema
    assert schema["type"] == "object"
    assert "properties" in schema
    assert "filterClause" in schema["properties"]

  def test_action_request(self):
    schema = ConnectionsClient.action_request("TestAction")
    assert "type" in schema
    assert schema["type"] == "object"
    assert "properties" in schema
    assert "connectorInputPayload" in schema["properties"]

  def test_action_response(self):
    schema = ConnectionsClient.action_response("TestAction")
    assert "type" in schema
    assert schema["type"] == "object"
    assert "properties" in schema
    assert "connectorOutputPayload" in schema["properties"]

  def test_execute_custom_query_request(self):
    schema = ConnectionsClient.execute_custom_query_request()
    assert "type" in schema
    assert schema["type"] == "object"
    assert "properties" in schema
    assert "query" in schema["properties"]

  def test_connector_payload(self):
    client = ConnectionsClient("test-project", "us-central1", "test-connection")
    schema = client.connector_payload(
        json_schema={
            "type": "object",
            "properties": {
                "input": {
                    "type": ["null", "string"],
                    "description": "description",
                }
            },
        }
    )
    assert schema == {
        "type": "object",
        "properties": {
            "input": {
                "type": "string",
                "nullable": True,
                "description": "description",
            }
        },
    }

  def test_get_access_token_uses_cached_token(
      self, project, location, connection_name, mock_credentials
  ):
    credentials = {"email": "test@example.com"}
    client = ConnectionsClient(project, location, connection_name, credentials)
    client.credential_cache = mock_credentials
    token = client._get_access_token()
    assert token == "test_token"

  def test_get_access_token_with_service_account_credentials(
      self, project, location, connection_name
  ):
    service_account_json = json.dumps({
        "client_email": "test@example.com",
        "private_key": "test_key",
    })
    client = ConnectionsClient(
        project, location, connection_name, service_account_json
    )
    mock_creds = mock.create_autospec(google.oauth2.service_account.Credentials)
    mock_creds.token = "sa_token"
    mock_creds.expired = False

    with (
        mock.patch(
            "google.oauth2.service_account.Credentials.from_service_account_info",
            return_value=mock_creds,
        ),
        mock.patch.object(mock_creds, "refresh", return_value=None),
    ):
      token = client._get_access_token()
      assert token == "sa_token"
      google.oauth2.service_account.Credentials.from_service_account_info.assert_called_once_with(
          json.loads(service_account_json),
          scopes=["https://www.googleapis.com/auth/cloud-platform"],
      )
      mock_creds.refresh.assert_called_once()

  def test_get_access_token_with_default_credentials(
      self, project, location, connection_name, mock_credentials
  ):
    client = ConnectionsClient(project, location, connection_name, None)
    with (
        mock.patch(
            "google.adk.tools.application_integration_tool.clients.connections_client.default_service_credential",
            return_value=(mock_credentials, "test_project_id"),
        ),
        mock.patch.object(mock_credentials, "refresh", return_value=None),
    ):
      token = client._get_access_token()
      assert token == "test_token"

  def test_get_access_token_no_valid_credentials(
      self, project, location, connection_name
  ):
    client = ConnectionsClient(project, location, connection_name, None)
    with mock.patch(
        "google.adk.tools.application_integration_tool.clients.connections_client.default_service_credential",
        return_value=(None, None),
    ):
      with pytest.raises(
          ValueError,
          match=(
              "Please provide a service account that has the required"
              " permissions"
          ),
      ):
        client._get_access_token()

  def test_get_access_token_refreshes_expired_token(
      self, project, location, connection_name, mock_credentials
  ):
    client = ConnectionsClient(project, location, connection_name, None)
    mock_credentials.expired = True
    mock_credentials.token = "old_token"
    mock_credentials.refresh.return_value = None

    client.credential_cache = mock_credentials
    with mock.patch(
        "google.adk.tools.application_integration_tool.clients.connections_client.default_service_credential",
        return_value=(mock_credentials, "test_project_id"),
    ):
      # Mock the refresh method directly on the instance within the context
      with mock.patch.object(mock_credentials, "refresh") as mock_refresh:
        mock_credentials.token = "new_token"  # Set the expected new token
        token = client._get_access_token()
        assert token == "new_token"
        mock_refresh.assert_called_once()

==== tests/unittests/tools/application_integration_tool/test_application_integration_toolset.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import json
from unittest import mock

from fastapi.openapi.models import Operation
from google.adk.agents.readonly_context import ReadonlyContext
from google.adk.auth import AuthCredentialTypes
from google.adk.auth import OAuth2Auth
from google.adk.auth.auth_credential import AuthCredential
from google.adk.tools.application_integration_tool.application_integration_toolset import ApplicationIntegrationToolset
from google.adk.tools.application_integration_tool.integration_connector_tool import IntegrationConnectorTool
from google.adk.tools.openapi_tool.auth.auth_helpers import dict_to_auth_scheme
from google.adk.tools.openapi_tool.openapi_spec_parser import ParsedOperation
from google.adk.tools.openapi_tool.openapi_spec_parser import rest_api_tool
from google.adk.tools.openapi_tool.openapi_spec_parser.openapi_spec_parser import OperationEndpoint
import pytest


@pytest.fixture
def mock_integration_client():
  with mock.patch(
      "google.adk.tools.application_integration_tool.application_integration_toolset.IntegrationClient"
  ) as mock_client:
    yield mock_client


@pytest.fixture
def mock_connections_client():
  with mock.patch(
      "google.adk.tools.application_integration_tool.application_integration_toolset.ConnectionsClient"
  ) as mock_client:
    yield mock_client


@pytest.fixture
def mock_openapi_toolset():
  with mock.patch(
      "google.adk.tools.application_integration_tool.application_integration_toolset.OpenAPIToolset"
  ) as mock_toolset:
    mock_toolset_instance = mock.MagicMock()
    mock_rest_api_tool = mock.MagicMock(spec=rest_api_tool.RestApiTool)
    mock_rest_api_tool.name = "Test Tool"

    # Create an async mock for the get_tools method
    async def mock_get_tools(context: ReadonlyContext = None):
      return [mock_rest_api_tool]

    # Assign the async mock function to get_tools
    mock_toolset_instance.get_tools = mock_get_tools

    mock_toolset.return_value = mock_toolset_instance
    yield mock_toolset


@pytest.fixture
def mock_openapi_toolset_with_multiple_tools_and_no_tools():
  with mock.patch(
      "google.adk.tools.application_integration_tool.application_integration_toolset.OpenAPIToolset"
  ) as mock_toolset:
    mock_toolset_instance = mock.MagicMock()
    mock_rest_api_tool = mock.MagicMock(spec=rest_api_tool.RestApiTool)
    mock_rest_api_tool.name = "Test Tool"
    mock_rest_api_tool_2 = mock.MagicMock(spec=rest_api_tool.RestApiTool)
    mock_rest_api_tool_2.name = "Test Tool 2"

    # Create an async mock for the get_tools method
    async def mock_get_tools(context: ReadonlyContext = None):
      return [mock_rest_api_tool, mock_rest_api_tool_2]

    mock_toolset_instance.get_tools = mock_get_tools
    mock_toolset.return_value = mock_toolset_instance
    yield mock_toolset


def get_mocked_parsed_operation(operation_id, attributes):
  mock_openapi_spec_parser_instance = mock.MagicMock()
  mock_parsed_operation = mock.MagicMock(spec=ParsedOperation)
  mock_parsed_operation.name = "list_issues"
  mock_parsed_operation.description = "list_issues_description"
  mock_parsed_operation.endpoint = OperationEndpoint(
      base_url="http://localhost:8080",
      path="/v1/issues",
      method="GET",
  )
  mock_parsed_operation.auth_scheme = None
  mock_parsed_operation.auth_credential = None
  mock_parsed_operation.additional_context = {}
  mock_parsed_operation.parameters = []
  mock_operation = mock.MagicMock(spec=Operation)
  mock_operation.operationId = operation_id
  mock_operation.description = "list_issues_description"
  mock_operation.parameters = []
  mock_operation.requestBody = None
  mock_operation.responses = {}
  mock_operation.callbacks = {}
  for key, value in attributes.items():
    setattr(mock_operation, key, value)
  mock_parsed_operation.operation = mock_operation
  mock_openapi_spec_parser_instance.parse.return_value = [mock_parsed_operation]
  return mock_openapi_spec_parser_instance


@pytest.fixture
def mock_openapi_entity_spec_parser():
  with mock.patch(
      "google.adk.tools.application_integration_tool.application_integration_toolset.OpenApiSpecParser"
  ) as mock_spec_parser:
    mock_openapi_spec_parser_instance = get_mocked_parsed_operation(
        "list_issues", {"x-entity": "Issues", "x-operation": "LIST_ENTITIES"}
    )
    mock_spec_parser.return_value = mock_openapi_spec_parser_instance
    yield mock_spec_parser


@pytest.fixture
def mock_openapi_action_spec_parser():
  with mock.patch(
      "google.adk.tools.application_integration_tool.application_integration_toolset.OpenApiSpecParser"
  ) as mock_spec_parser:
    mock_openapi_action_spec_parser_instance = get_mocked_parsed_operation(
        "list_issues_operation",
        {"x-action": "CustomAction", "x-operation": "EXECUTE_ACTION"},
    )
    mock_spec_parser.return_value = mock_openapi_action_spec_parser_instance
    yield mock_spec_parser


@pytest.fixture
def project():
  return "test-project"


@pytest.fixture
def location():
  return "us-central1"


@pytest.fixture
def integration_spec():
  return {"openapi": "3.0.0", "info": {"title": "Integration API"}}


@pytest.fixture
def connection_spec():
  return {"openapi": "3.0.0", "info": {"title": "Connection API"}}


@pytest.fixture
def connection_details():
  return {
      "serviceName": "test-service",
      "host": "test.host",
      "name": "test-connection",
  }


@pytest.fixture
def connection_details_auth_override_enabled():
  return {
      "serviceName": "test-service",
      "host": "test.host",
      "name": "test-connection",
      "authOverrideEnabled": True,
  }


@pytest.mark.asyncio
async def test_initialization_with_integration_and_trigger(
    project,
    location,
    mock_integration_client,
    mock_connections_client,
    mock_openapi_toolset,
):
  integration_name = "test-integration"
  triggers = ["test-trigger"]
  toolset = ApplicationIntegrationToolset(
      project, location, integration=integration_name, triggers=triggers
  )
  mock_integration_client.assert_called_once_with(
      project, location, integration_name, triggers, None, None, None, None
  )
  mock_integration_client.return_value.get_openapi_spec_for_integration.assert_called_once()
  mock_connections_client.assert_not_called()
  mock_openapi_toolset.assert_called_once()
  tools = await toolset.get_tools()
  assert len(tools) == 1
  assert tools[0].name == "Test Tool"


@pytest.mark.asyncio
async def test_initialization_with_integration_and_list_of_triggers(
    project,
    location,
    mock_integration_client,
    mock_connections_client,
    mock_openapi_toolset_with_multiple_tools_and_no_tools,
):
  integration_name = "test-integration"
  triggers = ["test-trigger1", "test-trigger2"]
  toolset = ApplicationIntegrationToolset(
      project, location, integration=integration_name, triggers=triggers
  )
  mock_integration_client.assert_called_once_with(
      project,
      location,
      integration_name,
      triggers,
      None,
      None,
      None,
      None,
  )
  mock_integration_client.return_value.get_openapi_spec_for_integration.assert_called_once()
  mock_connections_client.assert_not_called()
  mock_openapi_toolset_with_multiple_tools_and_no_tools.assert_called_once()
  tools = await toolset.get_tools()
  assert len(tools) == 2
  assert tools[0].name == "Test Tool"
  assert tools[1].name == "Test Tool 2"


@pytest.mark.asyncio
async def test_initialization_with_integration_and_empty_trigger_list(
    project,
    location,
    mock_integration_client,
    mock_connections_client,
    mock_openapi_toolset_with_multiple_tools_and_no_tools,
):
  integration_name = "test-integration"
  toolset = ApplicationIntegrationToolset(
      project, location, integration=integration_name
  )
  mock_integration_client.assert_called_once_with(
      project, location, integration_name, None, None, None, None, None
  )
  mock_integration_client.return_value.get_openapi_spec_for_integration.assert_called_once()
  mock_connections_client.assert_not_called()
  mock_openapi_toolset_with_multiple_tools_and_no_tools.assert_called_once()
  tools = await toolset.get_tools()
  assert len(tools) == 2
  assert tools[0].name == "Test Tool"
  assert tools[1].name == "Test Tool 2"


@pytest.mark.asyncio
async def test_initialization_with_connection_and_entity_operations(
    project,
    location,
    mock_integration_client,
    mock_connections_client,
    mock_openapi_entity_spec_parser,
    connection_details,
):
  connection_name = "test-connection"
  entity_operations_list = ["list", "get"]
  tool_name = "My Connection Tool"
  tool_instructions = "Use this tool to manage entities."
  mock_connections_client.return_value.get_connection_details.return_value = (
      connection_details
  )
  toolset = ApplicationIntegrationToolset(
      project,
      location,
      connection=connection_name,
      entity_operations=entity_operations_list,
      tool_name_prefix=tool_name,
      tool_instructions=tool_instructions,
  )
  mock_integration_client.assert_called_once_with(
      project,
      location,
      None,
      None,
      connection_name,
      entity_operations_list,
      None,
      None,
  )
  mock_connections_client.assert_called_once_with(
      project, location, connection_name, None
  )
  mock_openapi_entity_spec_parser.return_value.parse.assert_called_once()
  mock_connections_client.return_value.get_connection_details.assert_called_once()
  mock_integration_client.return_value.get_openapi_spec_for_connection.assert_called_once_with(
      tool_name,
      tool_instructions,
  )

  tools = await toolset.get_tools()
  assert len(tools) == 1
  assert tools[0].name == "list_issues"
  assert isinstance(tools[0], IntegrationConnectorTool)
  assert tools[0]._entity == "Issues"
  assert tools[0]._operation == "LIST_ENTITIES"


@pytest.mark.asyncio
async def test_initialization_with_connection_and_actions(
    project,
    location,
    mock_integration_client,
    mock_connections_client,
    mock_openapi_action_spec_parser,
    connection_details,
):
  connection_name = "test-connection"
  actions_list = ["create", "delete"]
  tool_name = "My Actions Tool"
  tool_instructions = "Perform actions using this tool."
  mock_connections_client.return_value.get_connection_details.return_value = (
      connection_details
  )
  toolset = ApplicationIntegrationToolset(
      project,
      location,
      connection=connection_name,
      actions=actions_list,
      tool_name_prefix=tool_name,
      tool_instructions=tool_instructions,
  )
  mock_integration_client.assert_called_once_with(
      project, location, None, None, connection_name, None, actions_list, None
  )
  mock_connections_client.assert_called_once_with(
      project, location, connection_name, None
  )
  mock_connections_client.return_value.get_connection_details.assert_called_once()
  mock_integration_client.return_value.get_openapi_spec_for_connection.assert_called_once_with(
      tool_name, tool_instructions
  )
  mock_openapi_action_spec_parser.return_value.parse.assert_called_once()
  tools = await toolset.get_tools()
  assert len(tools) == 1
  assert tools[0].name == "list_issues_operation"
  assert isinstance(tools[0], IntegrationConnectorTool)
  assert tools[0]._action == "CustomAction"
  assert tools[0]._operation == "EXECUTE_ACTION"


def test_initialization_without_required_params(project, location):
  with pytest.raises(
      ValueError,
      match=(
          "Invalid request, Either integration or \\(connection and"
          " \\(entity_operations or actions\\)\\) should be provided."
      ),
  ):
    ApplicationIntegrationToolset(project, location)

  with pytest.raises(
      ValueError,
      match=(
          "Invalid request, Either integration or \\(connection and"
          " \\(entity_operations or actions\\)\\) should be provided."
      ),
  ):
    ApplicationIntegrationToolset(project, location, triggers=["test"])

  with pytest.raises(
      ValueError,
      match=(
          "Invalid request, Either integration or \\(connection and"
          " \\(entity_operations or actions\\)\\) should be provided."
      ),
  ):
    ApplicationIntegrationToolset(project, location, connection="test")


def test_initialization_with_service_account_credentials(
    project, location, mock_integration_client, mock_openapi_toolset
):
  service_account_json = json.dumps({
      "type": "service_account",
      "project_id": "dummy",
      "private_key_id": "dummy",
      "private_key": "dummy",
      "client_email": "test@example.com",
      "client_id": "131331543646416",
      "auth_uri": "https://accounts.google.com/o/oauth2/auth",
      "token_uri": "https://oauth2.googleapis.com/token",
      "auth_provider_x509_cert_url": (
          "https://www.googleapis.com/oauth2/v1/certs"
      ),
      "client_x509_cert_url": (
          "http://www.googleapis.com/robot/v1/metadata/x509/dummy%40dummy.com"
      ),
      "universe_domain": "googleapis.com",
  })
  integration_name = "test-integration"
  triggers = ["test-trigger"]
  toolset = ApplicationIntegrationToolset(
      project,
      location,
      integration=integration_name,
      triggers=triggers,
      service_account_json=service_account_json,
  )
  mock_integration_client.assert_called_once_with(
      project,
      location,
      integration_name,
      triggers,
      None,
      None,
      None,
      service_account_json,
  )
  mock_openapi_toolset.assert_called_once()
  _, kwargs = mock_openapi_toolset.call_args
  assert isinstance(kwargs["auth_credential"], AuthCredential)
  assert (
      kwargs[
          "auth_credential"
      ].service_account.service_account_credential.client_email
      == "test@example.com"
  )


def test_initialization_without_explicit_service_account_credentials(
    project, location, mock_integration_client, mock_openapi_toolset
):
  integration_name = "test-integration"
  triggers = "test-trigger"
  toolset = ApplicationIntegrationToolset(
      project, location, integration=integration_name, triggers=triggers
  )
  mock_integration_client.assert_called_once_with(
      project, location, integration_name, triggers, None, None, None, None
  )
  mock_openapi_toolset.assert_called_once()
  _, kwargs = mock_openapi_toolset.call_args
  assert isinstance(kwargs["auth_credential"], AuthCredential)
  assert kwargs["auth_credential"].service_account.use_default_credential


@pytest.mark.asyncio
async def test_get_tools(
    project, location, mock_integration_client, mock_openapi_toolset
):
  integration_name = "test-integration"
  triggers = ["test-trigger"]
  toolset = ApplicationIntegrationToolset(
      project, location, integration=integration_name, triggers=triggers
  )
  tools = await toolset.get_tools()
  assert len(tools) == 1
  assert isinstance(tools[0], rest_api_tool.RestApiTool)
  assert tools[0].name == "Test Tool"


def test_initialization_with_connection_details(
    project,
    location,
    mock_integration_client,
    mock_connections_client,
    mock_openapi_toolset,
):
  connection_name = "test-connection"
  entity_operations_list = ["list"]
  tool_name = "My Connection Tool"
  tool_instructions = "Use this tool."
  mock_connections_client.return_value.get_connection_details.return_value = {
      "serviceName": "custom-service",
      "host": "custom.host",
  }
  toolset = ApplicationIntegrationToolset(
      project,
      location,
      connection=connection_name,
      entity_operations=entity_operations_list,
      tool_name_prefix=tool_name,
      tool_instructions=tool_instructions,
  )
  mock_integration_client.return_value.get_openapi_spec_for_connection.assert_called_once_with(
      tool_name, tool_instructions
  )


@pytest.mark.asyncio
async def test_init_with_connection_and_custom_auth(
    mock_integration_client,
    mock_connections_client,
    mock_openapi_action_spec_parser,
    connection_details_auth_override_enabled,
):
  connection_name = "test-connection"
  actions_list = ["create", "delete"]
  tool_name = "My Actions Tool"
  tool_instructions = "Perform actions using this tool."
  mock_connections_client.return_value.get_connection_details.return_value = (
      connection_details_auth_override_enabled
  )

  oauth2_data_google_cloud = {
      "type": "oauth2",
      "flows": {
          "authorizationCode": {
              "authorizationUrl": "https://test-url/o/oauth2/auth",
              "tokenUrl": "https://test-url/token",
              "scopes": {
                  "https://test-url/auth/test-scope": "test scope",
                  "https://www.test-url.com/auth/test-scope2": "test scope 2",
              },
          }
      },
  }

  oauth2_scheme = dict_to_auth_scheme(oauth2_data_google_cloud)

  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.OAUTH2,
      oauth2=OAuth2Auth(
          client_id="test-client-id",
          client_secret="test-client-secret",
      ),
  )

  toolset = ApplicationIntegrationToolset(
      project,
      location,
      connection=connection_name,
      actions=actions_list,
      tool_name_prefix=tool_name,
      tool_instructions=tool_instructions,
      auth_scheme=oauth2_scheme,
      auth_credential=auth_credential,
  )
  mock_integration_client.assert_called_once_with(
      project, location, None, None, connection_name, None, actions_list, None
  )
  mock_connections_client.assert_called_once_with(
      project, location, connection_name, None
  )
  mock_connections_client.return_value.get_connection_details.assert_called_once()
  mock_integration_client.return_value.get_openapi_spec_for_connection.assert_called_once_with(
      tool_name, tool_instructions
  )
  mock_openapi_action_spec_parser.return_value.parse.assert_called_once()
  assert len(await toolset.get_tools()) == 1
  assert (await toolset.get_tools())[0].name == "list_issues_operation"
  assert isinstance((await toolset.get_tools())[0], IntegrationConnectorTool)
  assert (await toolset.get_tools())[0]._action == "CustomAction"
  assert (await toolset.get_tools())[0]._operation == "EXECUTE_ACTION"
  assert (await toolset.get_tools())[0]._auth_scheme == oauth2_scheme
  assert (await toolset.get_tools())[0]._auth_credential == auth_credential


@pytest.mark.asyncio
async def test_init_with_connection_with_auth_override_disabled_and_custom_auth(
    mock_integration_client,
    mock_connections_client,
    mock_openapi_action_spec_parser,
    connection_details,
):
  connection_name = "test-connection"
  actions_list = ["create", "delete"]
  tool_name = "My Actions Tool"
  tool_instructions = "Perform actions using this tool."
  mock_connections_client.return_value.get_connection_details.return_value = (
      connection_details
  )

  oauth2_data_google_cloud = {
      "type": "oauth2",
      "flows": {
          "authorizationCode": {
              "authorizationUrl": "https://test-url/o/oauth2/auth",
              "tokenUrl": "https://test-url/token",
              "scopes": {
                  "https://test-url/auth/test-scope": "test scope",
                  "https://www.test-url.com/auth/test-scope2": "test scope 2",
              },
          }
      },
  }

  oauth2_scheme = dict_to_auth_scheme(oauth2_data_google_cloud)

  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.OAUTH2,
      oauth2=OAuth2Auth(
          client_id="test-client-id",
          client_secret="test-client-secret",
      ),
  )

  toolset = ApplicationIntegrationToolset(
      project,
      location,
      connection=connection_name,
      actions=actions_list,
      tool_name_prefix=tool_name,
      tool_instructions=tool_instructions,
      auth_scheme=oauth2_scheme,
      auth_credential=auth_credential,
  )
  mock_integration_client.assert_called_once_with(
      project, location, None, None, connection_name, None, actions_list, None
  )
  mock_connections_client.assert_called_once_with(
      project, location, connection_name, None
  )
  mock_connections_client.return_value.get_connection_details.assert_called_once()
  mock_integration_client.return_value.get_openapi_spec_for_connection.assert_called_once_with(
      tool_name, tool_instructions
  )
  mock_openapi_action_spec_parser.return_value.parse.assert_called_once()
  assert len(await toolset.get_tools()) == 1
  assert (await toolset.get_tools())[0].name == "list_issues_operation"
  assert isinstance((await toolset.get_tools())[0], IntegrationConnectorTool)
  assert (await toolset.get_tools())[0]._action == "CustomAction"
  assert (await toolset.get_tools())[0]._operation == "EXECUTE_ACTION"
  assert not (await toolset.get_tools())[0]._auth_scheme
  assert not (await toolset.get_tools())[0]._auth_credential

==== tests/unittests/tools/application_integration_tool/test_integration_connector_tool.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from unittest import mock

from google.adk.auth import AuthCredential
from google.adk.auth import AuthCredentialTypes
from google.adk.auth.auth_credential import HttpAuth
from google.adk.auth.auth_credential import HttpCredentials
from google.adk.tools.application_integration_tool.integration_connector_tool import IntegrationConnectorTool
from google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool import RestApiTool
from google.genai.types import FunctionDeclaration
from google.genai.types import Schema
from google.genai.types import Type
import pytest


@pytest.fixture
def mock_rest_api_tool():
  """Fixture for a mocked RestApiTool."""
  mock_tool = mock.MagicMock(spec=RestApiTool)
  mock_tool.name = "mock_rest_tool"
  mock_tool.description = "Mock REST tool description."
  # Mock the internal parser needed for _get_declaration
  mock_parser = mock.MagicMock()
  mock_parser.get_json_schema.return_value = {
      "type": "object",
      "properties": {
          "user_id": {"type": "string", "description": "User ID"},
          "connection_name": {"type": "string"},
          "host": {"type": "string"},
          "service_name": {"type": "string"},
          "entity": {"type": "string"},
          "operation": {"type": "string"},
          "action": {"type": "string"},
          "page_size": {"type": "integer"},
          "filter": {"type": "string"},
      },
      "required": ["user_id", "page_size", "filter", "connection_name"],
  }
  mock_tool._operation_parser = mock_parser
  mock_tool.call.return_value = {"status": "success", "data": "mock_data"}
  return mock_tool


@pytest.fixture
def integration_tool(mock_rest_api_tool):
  """Fixture for an IntegrationConnectorTool instance."""
  return IntegrationConnectorTool(
      name="test_integration_tool",
      description="Test integration tool description.",
      connection_name="test-conn",
      connection_host="test.example.com",
      connection_service_name="test-service",
      entity="TestEntity",
      operation="LIST",
      action="TestAction",
      rest_api_tool=mock_rest_api_tool,
  )


@pytest.fixture
def integration_tool_with_auth(mock_rest_api_tool):
  """Fixture for an IntegrationConnectorTool instance."""
  return IntegrationConnectorTool(
      name="test_integration_tool",
      description="Test integration tool description.",
      connection_name="test-conn",
      connection_host="test.example.com",
      connection_service_name="test-service",
      entity="TestEntity",
      operation="LIST",
      action="TestAction",
      rest_api_tool=mock_rest_api_tool,
      auth_scheme=None,
      auth_credential=AuthCredential(
          auth_type=AuthCredentialTypes.HTTP,
          http=HttpAuth(
              scheme="bearer",
              credentials=HttpCredentials(token="mocked_token"),
          ),
      ),
  )


def test_get_declaration(integration_tool):
  """Tests the generation of the function declaration."""
  declaration = integration_tool._get_declaration()

  assert isinstance(declaration, FunctionDeclaration)
  assert declaration.name == "test_integration_tool"
  assert declaration.description == "Test integration tool description."

  # Check parameters schema
  params = declaration.parameters
  assert isinstance(params, Schema)
  print(f"params: {params}")
  assert params.type == Type.OBJECT

  # Check properties (excluded fields should not be present)
  assert "user_id" in params.properties
  assert "connection_name" not in params.properties
  assert "host" not in params.properties
  assert "service_name" not in params.properties
  assert "entity" not in params.properties
  assert "operation" not in params.properties
  assert "action" not in params.properties
  assert "page_size" in params.properties
  assert "filter" in params.properties

  # Check required fields (optional and excluded fields should not be required)
  assert "user_id" in params.required
  assert "page_size" not in params.required
  assert "filter" not in params.required
  assert "connection_name" not in params.required


@pytest.mark.asyncio
async def test_run_async(integration_tool, mock_rest_api_tool):
  """Tests the async execution delegates correctly to the RestApiTool."""
  input_args = {"user_id": "user123", "page_size": 10}
  expected_call_args = {
      "user_id": "user123",
      "page_size": 10,
      "connection_name": "test-conn",
      "host": "test.example.com",
      "service_name": "test-service",
      "entity": "TestEntity",
      "operation": "LIST",
      "action": "TestAction",
  }

  result = await integration_tool.run_async(args=input_args, tool_context=None)

  # Assert the underlying rest_api_tool.call was called correctly
  mock_rest_api_tool.call.assert_called_once_with(
      args=expected_call_args, tool_context=None
  )

  # Assert the result is what the mocked call returned
  assert result == {"status": "success", "data": "mock_data"}


@pytest.mark.asyncio
async def test_run_with_auth_async_none_token(
    integration_tool_with_auth, mock_rest_api_tool
):
  """Tests run_async when auth credential token is None."""
  input_args = {"user_id": "user456", "filter": "some_filter"}
  expected_call_args = {
      "user_id": "user456",
      "filter": "some_filter",
      "dynamic_auth_config": {"oauth2_auth_code_flow.access_token": {}},
      "connection_name": "test-conn",
      "service_name": "test-service",
      "host": "test.example.com",
      "entity": "TestEntity",
      "operation": "LIST",
      "action": "TestAction",
  }

  with mock.patch(
      "google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.ToolAuthHandler.from_tool_context"
  ) as mock_from_tool_context:
    mock_tool_auth_handler_instance = mock.MagicMock()
    mock_tool_auth_handler_instance.prepare_auth_credentials.return_value.state = (
        "done"
    )
    # Simulate an AuthCredential that would cause _prepare_dynamic_euc to return None
    mock_auth_credential_without_token = AuthCredential(
        auth_type=AuthCredentialTypes.HTTP,
        http=HttpAuth(
            scheme="bearer",
            credentials=HttpCredentials(token=None),  # Token is None
        ),
    )
    mock_tool_auth_handler_instance.prepare_auth_credentials.return_value.auth_credential = (
        mock_auth_credential_without_token
    )
    mock_from_tool_context.return_value = mock_tool_auth_handler_instance

    result = await integration_tool_with_auth.run_async(
        args=input_args, tool_context={}
    )

    mock_rest_api_tool.call.assert_called_once_with(
        args=expected_call_args, tool_context={}
    )
    assert result == {"status": "success", "data": "mock_data"}


@pytest.mark.asyncio
async def test_run_with_auth_async(
    integration_tool_with_auth, mock_rest_api_tool
):
  """Tests the async execution with auth delegates correctly to the RestApiTool."""
  input_args = {"user_id": "user123", "page_size": 10}
  expected_call_args = {
      "user_id": "user123",
      "page_size": 10,
      "dynamic_auth_config": {
          "oauth2_auth_code_flow.access_token": "mocked_token"
      },
      "connection_name": "test-conn",
      "service_name": "test-service",
      "host": "test.example.com",
      "entity": "TestEntity",
      "operation": "LIST",
      "action": "TestAction",
  }

  with mock.patch(
      "google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.ToolAuthHandler.from_tool_context"
  ) as mock_from_tool_context:
    mock_tool_auth_handler_instance = mock.MagicMock()
    mock_tool_auth_handler_instance.prepare_auth_credentials.return_value.state = (
        "done"
    )
    mock_tool_auth_handler_instance.prepare_auth_credentials.return_value.state = (
        "done"
    )
    mock_tool_auth_handler_instance.prepare_auth_credentials.return_value.auth_credential = AuthCredential(
        auth_type=AuthCredentialTypes.HTTP,
        http=HttpAuth(
            scheme="bearer",
            credentials=HttpCredentials(token="mocked_token"),
        ),
    )
    mock_from_tool_context.return_value = mock_tool_auth_handler_instance
    result = await integration_tool_with_auth.run_async(
        args=input_args, tool_context={}
    )
    mock_rest_api_tool.call.assert_called_once_with(
        args=expected_call_args, tool_context={}
    )
    assert result == {"status": "success", "data": "mock_data"}

==== tests/unittests/tools/test_agent_tool.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.adk.agents import Agent
from google.adk.agents.callback_context import CallbackContext
from google.adk.tools.agent_tool import AgentTool
from google.genai.types import Part
from pydantic import BaseModel
import pytest
from pytest import mark

from .. import utils

pytestmark = pytest.mark.skip(
    reason='Skipping until tool.func evaluations are fixed (async)'
)


function_call_custom = Part.from_function_call(
    name='tool_agent', args={'custom_input': 'test1'}
)

function_call_no_schema = Part.from_function_call(
    name='tool_agent', args={'request': 'test1'}
)

function_response_custom = Part.from_function_response(
    name='tool_agent', response={'custom_output': 'response1'}
)

function_response_no_schema = Part.from_function_response(
    name='tool_agent', response={'result': 'response1'}
)


def change_state_callback(callback_context: CallbackContext):
  callback_context.state['state_1'] = 'changed_value'
  print('change_state_callback: ', callback_context.state)


def test_no_schema():
  mock_model = utils.MockModel.create(
      responses=[
          function_call_no_schema,
          'response1',
          'response2',
      ]
  )

  tool_agent = Agent(
      name='tool_agent',
      model=mock_model,
  )

  root_agent = Agent(
      name='root_agent',
      model=mock_model,
      tools=[AgentTool(agent=tool_agent)],
  )

  runner = utils.InMemoryRunner(root_agent)

  assert utils.simplify_events(runner.run('test1')) == [
      ('root_agent', function_call_no_schema),
      ('root_agent', function_response_no_schema),
      ('root_agent', 'response2'),
  ]


def test_update_state():
  """The agent tool can read and change parent state."""

  mock_model = utils.MockModel.create(
      responses=[
          function_call_no_schema,
          '{"custom_output": "response1"}',
          'response2',
      ]
  )

  tool_agent = Agent(
      name='tool_agent',
      model=mock_model,
      instruction='input: {state_1}',
      before_agent_callback=change_state_callback,
  )

  root_agent = Agent(
      name='root_agent',
      model=mock_model,
      tools=[AgentTool(agent=tool_agent)],
  )

  runner = utils.InMemoryRunner(root_agent)
  runner.session.state['state_1'] = 'state1_value'

  runner.run('test1')
  assert (
      'input: changed_value' in mock_model.requests[1].config.system_instruction
  )
  assert runner.session.state['state_1'] == 'changed_value'


@mark.parametrize(
    'env_variables',
    [
        'GOOGLE_AI',
        # TODO(wanyif): re-enable after fix.
        # 'VERTEX',
    ],
    indirect=True,
)
def test_custom_schema():
  class CustomInput(BaseModel):
    custom_input: str

  class CustomOutput(BaseModel):
    custom_output: str

  mock_model = utils.MockModel.create(
      responses=[
          function_call_custom,
          '{"custom_output": "response1"}',
          'response2',
      ]
  )

  tool_agent = Agent(
      name='tool_agent',
      model=mock_model,
      input_schema=CustomInput,
      output_schema=CustomOutput,
      output_key='tool_output',
  )

  root_agent = Agent(
      name='root_agent',
      model=mock_model,
      tools=[AgentTool(agent=tool_agent)],
  )

  runner = utils.InMemoryRunner(root_agent)
  runner.session.state['state_1'] = 'state1_value'

  assert utils.simplify_events(runner.run('test1')) == [
      ('root_agent', function_call_custom),
      ('root_agent', function_response_custom),
      ('root_agent', 'response2'),
  ]

  assert runner.session.state['tool_output'] == {'custom_output': 'response1'}

  assert len(mock_model.requests) == 3
  # The second request is the tool agent request.
  assert mock_model.requests[1].config.response_schema == CustomOutput
  assert mock_model.requests[1].config.response_mime_type == 'application/json'

==== tests/unittests/tools/apihub_tool/test_apihub_toolset.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from unittest.mock import MagicMock

from google.adk.auth.auth_credential import AuthCredential
from google.adk.auth.auth_schemes import AuthScheme
from google.adk.tools.apihub_tool.apihub_toolset import APIHubToolset
from google.adk.tools.apihub_tool.clients.apihub_client import BaseAPIHubClient
import pytest
import yaml


class MockAPIHubClient(BaseAPIHubClient):

  def get_spec_content(self, _apihub_resource_name: str) -> str:
    return """
openapi: 3.0.0
info:
  version: 1.0.0
  title: Mock API
  description: Mock API Description
paths:
  /test:
    get:
      summary: Test GET endpoint
      operationId: testGet
      responses:
        '200':
          description: Successful response
    """


# Fixture for a basic APIHubToolset
@pytest.fixture
def basic_apihub_toolset():
  apihub_client = MockAPIHubClient()
  tool = APIHubToolset(
      apihub_resource_name='test_resource', apihub_client=apihub_client
  )
  return tool


# Fixture for an APIHubToolset with lazy loading
@pytest.fixture
def lazy_apihub_toolset():
  apihub_client = MockAPIHubClient()
  tool = APIHubToolset(
      apihub_resource_name='test_resource',
      apihub_client=apihub_client,
      lazy_load_spec=True,
  )
  return tool


# Fixture for auth scheme
@pytest.fixture
def mock_auth_scheme():
  return MagicMock(spec=AuthScheme)


# Fixture for auth credential
@pytest.fixture
def mock_auth_credential():
  return MagicMock(spec=AuthCredential)


# Test cases
@pytest.mark.asyncio
async def test_apihub_toolset_initialization(basic_apihub_toolset):
  assert basic_apihub_toolset.name == 'mock_api'
  assert basic_apihub_toolset.description == 'Mock API Description'
  assert basic_apihub_toolset._apihub_resource_name == 'test_resource'
  assert not basic_apihub_toolset._lazy_load_spec
  generated_tools = await basic_apihub_toolset.get_tools()
  assert len(generated_tools) == 1
  assert 'test_get' == generated_tools[0].name


@pytest.mark.asyncio
async def test_apihub_toolset_lazy_loading(lazy_apihub_toolset):
  assert lazy_apihub_toolset._lazy_load_spec
  generated_tools = await lazy_apihub_toolset.get_tools()
  assert generated_tools

  tools = await lazy_apihub_toolset.get_tools()
  assert len(tools) == 1
  'test_get' == tools[0].name


def test_apihub_toolset_no_title_in_spec(basic_apihub_toolset):
  spec = """
openapi: 3.0.0
info:
  version: 1.0.0
paths:
  /empty_desc_test:
    delete:
      summary: Test DELETE endpoint
      operationId: emptyDescTest
      responses:
        '200':
          description: Successful response
    """

  class MockAPIHubClientEmptySpec(BaseAPIHubClient):

    def get_spec_content(self, _apihub_resource_name: str) -> str:
      return spec

  apihub_client = MockAPIHubClientEmptySpec()
  toolset = APIHubToolset(
      apihub_resource_name='test_resource',
      apihub_client=apihub_client,
  )

  assert toolset.name == 'unnamed'


def test_apihub_toolset_empty_description_in_spec():
  spec = """
openapi: 3.0.0
info:
  version: 1.0.0
  title: Empty Description API
paths:
  /empty_desc_test:
    delete:
      summary: Test DELETE endpoint
      operationId: emptyDescTest
      responses:
        '200':
          description: Successful response
    """

  class MockAPIHubClientEmptySpec(BaseAPIHubClient):

    def get_spec_content(self, _apihub_resource_name: str) -> str:
      return spec

  apihub_client = MockAPIHubClientEmptySpec()
  toolset = APIHubToolset(
      apihub_resource_name='test_resource',
      apihub_client=apihub_client,
  )

  assert toolset.name == 'empty_description_api'
  assert toolset.description == ''


@pytest.mark.asyncio
async def test_get_tools_with_auth(mock_auth_scheme, mock_auth_credential):
  apihub_client = MockAPIHubClient()
  tool = APIHubToolset(
      apihub_resource_name='test_resource',
      apihub_client=apihub_client,
      auth_scheme=mock_auth_scheme,
      auth_credential=mock_auth_credential,
  )
  tools = await tool.get_tools()
  assert len(tools) == 1


@pytest.mark.asyncio
async def test_apihub_toolset_get_tools_lazy_load_empty_spec():

  class MockAPIHubClientEmptySpec(BaseAPIHubClient):

    def get_spec_content(self, _apihub_resource_name: str) -> str:
      return ''

  apihub_client = MockAPIHubClientEmptySpec()
  tool = APIHubToolset(
      apihub_resource_name='test_resource',
      apihub_client=apihub_client,
      lazy_load_spec=True,
  )
  tools = await tool.get_tools()
  assert not tools


@pytest.mark.asyncio
async def test_apihub_toolset_get_tools_invalid_yaml():

  class MockAPIHubClientInvalidYAML(BaseAPIHubClient):

    def get_spec_content(self, _apihub_resource_name: str) -> str:
      return '{invalid yaml'  # Return invalid YAML

  with pytest.raises(yaml.YAMLError):
    apihub_client = MockAPIHubClientInvalidYAML()
    tool = APIHubToolset(
        apihub_resource_name='test_resource',
        apihub_client=apihub_client,
    )
    await tool.get_tools()


if __name__ == '__main__':
  pytest.main([__file__])

==== tests/unittests/tools/apihub_tool/clients/test_apihub_client.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import base64
import json
from unittest.mock import MagicMock, patch
from google.adk.tools.apihub_tool.clients.apihub_client import APIHubClient
import pytest
from requests.exceptions import HTTPError

# Mock data for API responses
MOCK_API_LIST = {
    "apis": [
        {"name": "projects/test-project/locations/us-central1/apis/api1"},
        {"name": "projects/test-project/locations/us-central1/apis/api2"},
    ]
}
MOCK_API_DETAIL = {
    "name": "projects/test-project/locations/us-central1/apis/api1",
    "versions": [
        "projects/test-project/locations/us-central1/apis/api1/versions/v1"
    ],
}
MOCK_API_VERSION = {
    "name": "projects/test-project/locations/us-central1/apis/api1/versions/v1",
    "specs": [
        "projects/test-project/locations/us-central1/apis/api1/versions/v1/specs/spec1"
    ],
}
MOCK_SPEC_CONTENT = {"contents": base64.b64encode(b"spec content").decode()}


# Test cases
class TestAPIHubClient:

  @pytest.fixture
  def client(self):
    return APIHubClient(access_token="mocked_token")

  @pytest.fixture
  def service_account_config(self):
    return json.dumps({
        "type": "service_account",
        "project_id": "test",
        "token_uri": "test.com",
        "client_email": "test@example.com",
        "private_key": "1234",
    })

  @patch("requests.get")
  def test_list_apis(self, mock_get, client):
    mock_get.return_value.json.return_value = MOCK_API_LIST
    mock_get.return_value.status_code = 200

    apis = client.list_apis("test-project", "us-central1")
    assert apis == MOCK_API_LIST["apis"]
    mock_get.assert_called_once_with(
        "https://apihub.googleapis.com/v1/projects/test-project/locations/us-central1/apis",
        headers={
            "accept": "application/json, text/plain, */*",
            "Authorization": "Bearer mocked_token",
        },
    )

  @patch("requests.get")
  def test_list_apis_empty(self, mock_get, client):
    mock_get.return_value.json.return_value = {"apis": []}
    mock_get.return_value.status_code = 200

    apis = client.list_apis("test-project", "us-central1")
    assert apis == []

  @patch("requests.get")
  def test_list_apis_error(self, mock_get, client):
    mock_get.return_value.raise_for_status.side_effect = HTTPError

    with pytest.raises(HTTPError):
      client.list_apis("test-project", "us-central1")

  @patch("requests.get")
  def test_get_api(self, mock_get, client):
    mock_get.return_value.json.return_value = MOCK_API_DETAIL
    mock_get.return_value.status_code = 200
    api = client.get_api(
        "projects/test-project/locations/us-central1/apis/api1"
    )
    assert api == MOCK_API_DETAIL
    mock_get.assert_called_once_with(
        "https://apihub.googleapis.com/v1/projects/test-project/locations/us-central1/apis/api1",
        headers={
            "accept": "application/json, text/plain, */*",
            "Authorization": "Bearer mocked_token",
        },
    )

  @patch("requests.get")
  def test_get_api_error(self, mock_get, client):
    mock_get.return_value.raise_for_status.side_effect = HTTPError
    with pytest.raises(HTTPError):
      client.get_api("projects/test-project/locations/us-central1/apis/api1")

  @patch("requests.get")
  def test_get_api_version(self, mock_get, client):
    mock_get.return_value.json.return_value = MOCK_API_VERSION
    mock_get.return_value.status_code = 200
    api_version = client.get_api_version(
        "projects/test-project/locations/us-central1/apis/api1/versions/v1"
    )
    assert api_version == MOCK_API_VERSION
    mock_get.assert_called_once_with(
        "https://apihub.googleapis.com/v1/projects/test-project/locations/us-central1/apis/api1/versions/v1",
        headers={
            "accept": "application/json, text/plain, */*",
            "Authorization": "Bearer mocked_token",
        },
    )

  @patch("requests.get")
  def test_get_api_version_error(self, mock_get, client):
    mock_get.return_value.raise_for_status.side_effect = HTTPError
    with pytest.raises(HTTPError):
      client.get_api_version(
          "projects/test-project/locations/us-central1/apis/api1/versions/v1"
      )

  @patch("requests.get")
  def test_get_spec_content(self, mock_get, client):
    mock_get.return_value.json.return_value = MOCK_SPEC_CONTENT
    mock_get.return_value.status_code = 200
    spec_content = client.get_spec_content(
        "projects/test-project/locations/us-central1/apis/api1/versions/v1/specs/spec1"
    )
    assert spec_content == "spec content"
    mock_get.assert_called_once_with(
        "https://apihub.googleapis.com/v1/projects/test-project/locations/us-central1/apis/api1/versions/v1/specs/spec1:contents",
        headers={
            "accept": "application/json, text/plain, */*",
            "Authorization": "Bearer mocked_token",
        },
    )

  @patch("requests.get")
  def test_get_spec_content_empty(self, mock_get, client):
    mock_get.return_value.json.return_value = {"contents": ""}
    mock_get.return_value.status_code = 200
    spec_content = client.get_spec_content(
        "projects/test-project/locations/us-central1/apis/api1/versions/v1/specs/spec1"
    )
    assert spec_content == ""

  @patch("requests.get")
  def test_get_spec_content_error(self, mock_get, client):
    mock_get.return_value.raise_for_status.side_effect = HTTPError
    with pytest.raises(HTTPError):
      client.get_spec_content(
          "projects/test-project/locations/us-central1/apis/api1/versions/v1/specs/spec1"
      )

  @pytest.mark.parametrize(
      "url_or_path, expected",
      [
          (
              "projects/test-project/locations/us-central1/apis/api1",
              (
                  "projects/test-project/locations/us-central1/apis/api1",
                  None,
                  None,
              ),
          ),
          (
              "projects/test-project/locations/us-central1/apis/api1/versions/v1",
              (
                  "projects/test-project/locations/us-central1/apis/api1",
                  "projects/test-project/locations/us-central1/apis/api1/versions/v1",
                  None,
              ),
          ),
          (
              "projects/test-project/locations/us-central1/apis/api1/versions/v1/specs/spec1",
              (
                  "projects/test-project/locations/us-central1/apis/api1",
                  "projects/test-project/locations/us-central1/apis/api1/versions/v1",
                  "projects/test-project/locations/us-central1/apis/api1/versions/v1/specs/spec1",
              ),
          ),
          (
              "https://console.cloud.google.com/apigee/api-hub/projects/test-project/locations/us-central1/apis/api1/versions/v1?project=test-project",
              (
                  "projects/test-project/locations/us-central1/apis/api1",
                  "projects/test-project/locations/us-central1/apis/api1/versions/v1",
                  None,
              ),
          ),
          (
              "https://console.cloud.google.com/apigee/api-hub/projects/test-project/locations/us-central1/apis/api1/versions/v1/specs/spec1?project=test-project",
              (
                  "projects/test-project/locations/us-central1/apis/api1",
                  "projects/test-project/locations/us-central1/apis/api1/versions/v1",
                  "projects/test-project/locations/us-central1/apis/api1/versions/v1/specs/spec1",
              ),
          ),
          (
              "/projects/test-project/locations/us-central1/apis/api1/versions/v1",
              (
                  "projects/test-project/locations/us-central1/apis/api1",
                  "projects/test-project/locations/us-central1/apis/api1/versions/v1",
                  None,
              ),
          ),
          (  # Added trailing slashes
              "projects/test-project/locations/us-central1/apis/api1/",
              (
                  "projects/test-project/locations/us-central1/apis/api1",
                  None,
                  None,
              ),
          ),
          (  # case location name
              "projects/test-project/locations/LOCATION/apis/api1/",
              (
                  "projects/test-project/locations/LOCATION/apis/api1",
                  None,
                  None,
              ),
          ),
          (
              "projects/p1/locations/l1/apis/a1/versions/v1/specs/s1",
              (
                  "projects/p1/locations/l1/apis/a1",
                  "projects/p1/locations/l1/apis/a1/versions/v1",
                  "projects/p1/locations/l1/apis/a1/versions/v1/specs/s1",
              ),
          ),
      ],
  )
  def test_extract_resource_name(self, client, url_or_path, expected):
    result = client._extract_resource_name(url_or_path)
    assert result == expected

  @pytest.mark.parametrize(
      "url_or_path, expected_error_message",
      [
          (
              "invalid-path",
              "Project ID not found in URL or path in APIHubClient.",
          ),
          (
              "projects/test-project",
              "Location not found in URL or path in APIHubClient.",
          ),
          (
              "projects/test-project/locations/us-central1",
              "API id not found in URL or path in APIHubClient.",
          ),
      ],
  )
  def test_extract_resource_name_invalid(
      self, client, url_or_path, expected_error_message
  ):
    with pytest.raises(ValueError, match=expected_error_message):
      client._extract_resource_name(url_or_path)

  @patch(
      "google.adk.tools.apihub_tool.clients.apihub_client.default_service_credential"
  )
  @patch(
      "google.adk.tools.apihub_tool.clients.apihub_client.service_account.Credentials.from_service_account_info"
  )
  def test_get_access_token_use_default_credential(
      self,
      mock_from_service_account_info,
      mock_default_service_credential,
  ):
    mock_credential = MagicMock()
    mock_credential.token = "default_token"
    mock_default_service_credential.return_value = (
        mock_credential,
        "project_id",
    )
    mock_config_credential = MagicMock()
    mock_config_credential.token = "config_token"
    mock_from_service_account_info.return_value = mock_config_credential

    client = APIHubClient()
    token = client._get_access_token()
    assert token == "default_token"
    mock_credential.refresh.assert_called_once()
    assert client.credential_cache == mock_credential

  @patch(
      "google.adk.tools.apihub_tool.clients.apihub_client.default_service_credential"
  )
  @patch(
      "google.adk.tools.apihub_tool.clients.apihub_client.service_account.Credentials.from_service_account_info"
  )
  def test_get_access_token_use_configured_service_account(
      self,
      mock_from_service_account_info,
      mock_default_service_credential,
      service_account_config,
  ):
    mock_credential = MagicMock()
    mock_credential.token = "default_token"
    mock_default_service_credential.return_value = (
        mock_credential,
        "project_id",
    )
    mock_config_credential = MagicMock()
    mock_config_credential.token = "config_token"
    mock_from_service_account_info.return_value = mock_config_credential

    client = APIHubClient(service_account_json=service_account_config)
    token = client._get_access_token()

    assert token == "config_token"
    mock_from_service_account_info.assert_called_once_with(
        json.loads(service_account_config),
        scopes=["https://www.googleapis.com/auth/cloud-platform"],
    )
    mock_config_credential.refresh.assert_called_once()
    assert client.credential_cache == mock_config_credential

  @patch(
      "google.adk.tools.apihub_tool.clients.apihub_client.default_service_credential"
  )
  def test_get_access_token_not_expired_use_cached_token(
      self, mock_default_credential
  ):
    mock_credentials = MagicMock()
    mock_credentials.token = "default_service_account_token"
    mock_default_credential.return_value = (mock_credentials, "")

    client = APIHubClient()
    # Call #1: Setup cache
    token = client._get_access_token()
    assert token == "default_service_account_token"
    mock_default_credential.assert_called_once()

    # Call #2: Reuse cache
    mock_credentials.reset_mock()
    mock_credentials.expired = False
    token = client._get_access_token()
    assert token == "default_service_account_token"
    mock_credentials.refresh.assert_not_called()

  @patch(
      "google.adk.tools.apihub_tool.clients.apihub_client.default_service_credential"
  )
  def test_get_access_token_expired_refresh(self, mock_default_credential):
    mock_credentials = MagicMock()
    mock_credentials.token = "default_service_account_token"
    mock_default_credential.return_value = (mock_credentials, "")
    client = APIHubClient()

    # Call #1: Setup cache
    token = client._get_access_token()
    assert token == "default_service_account_token"
    mock_default_credential.assert_called_once()

    # Call #2: Cache expired
    mock_credentials.reset_mock()
    mock_credentials.expired = True
    token = client._get_access_token()
    mock_credentials.refresh.assert_called_once()
    assert token == "default_service_account_token"

  @patch(
      "google.adk.tools.apihub_tool.clients.apihub_client.default_service_credential"
  )
  def test_get_access_token_no_credentials(
      self, mock_default_service_credential
  ):
    mock_default_service_credential.return_value = (None, None)
    with pytest.raises(
        ValueError,
        match=(
            "Please provide a service account or an access token to API Hub"
            " client."
        ),
    ):
      # no service account client
      APIHubClient()._get_access_token()

  @patch("requests.get")
  def test_get_spec_content_api_level(self, mock_get, client):
    mock_get.side_effect = [
        MagicMock(status_code=200, json=lambda: MOCK_API_DETAIL),  # For get_api
        MagicMock(
            status_code=200, json=lambda: MOCK_API_VERSION
        ),  # For get_api_version
        MagicMock(
            status_code=200, json=lambda: MOCK_SPEC_CONTENT
        ),  # For get_spec_content
    ]

    content = client.get_spec_content(
        "projects/test-project/locations/us-central1/apis/api1"
    )
    assert content == "spec content"
    # Check calls - get_api, get_api_version, then get_spec_content
    assert mock_get.call_count == 3

  @patch("requests.get")
  def test_get_spec_content_version_level(self, mock_get, client):
    mock_get.side_effect = [
        MagicMock(
            status_code=200, json=lambda: MOCK_API_VERSION
        ),  # For get_api_version
        MagicMock(
            status_code=200, json=lambda: MOCK_SPEC_CONTENT
        ),  # For get_spec_content
    ]

    content = client.get_spec_content(
        "projects/test-project/locations/us-central1/apis/api1/versions/v1"
    )
    assert content == "spec content"
    assert mock_get.call_count == 2  # get_api_version and get_spec_content

  @patch("requests.get")
  def test_get_spec_content_spec_level(self, mock_get, client):
    mock_get.return_value.json.return_value = MOCK_SPEC_CONTENT
    mock_get.return_value.status_code = 200

    content = client.get_spec_content(
        "projects/test-project/locations/us-central1/apis/api1/versions/v1/specs/spec1"
    )
    assert content == "spec content"
    mock_get.assert_called_once()  # Only get_spec_content should be called

  @patch("requests.get")
  def test_get_spec_content_no_versions(self, mock_get, client):
    mock_get.return_value.json.return_value = {
        "name": "projects/test-project/locations/us-central1/apis/api1",
        "versions": [],
    }  # No versions
    mock_get.return_value.status_code = 200
    with pytest.raises(
        ValueError,
        match=(
            "No versions found in API Hub resource:"
            " projects/test-project/locations/us-central1/apis/api1"
        ),
    ):
      client.get_spec_content(
          "projects/test-project/locations/us-central1/apis/api1"
      )

  @patch("requests.get")
  def test_get_spec_content_no_specs(self, mock_get, client):
    mock_get.side_effect = [
        MagicMock(status_code=200, json=lambda: MOCK_API_DETAIL),
        MagicMock(
            status_code=200,
            json=lambda: {
                "name": (
                    "projects/test-project/locations/us-central1/apis/api1/versions/v1"
                ),
                "specs": [],
            },
        ),  # No specs
    ]

    with pytest.raises(
        ValueError,
        match=(
            "No specs found in API Hub version:"
            " projects/test-project/locations/us-central1/apis/api1/versions/v1"
        ),
    ):
      client.get_spec_content(
          "projects/test-project/locations/us-central1/apis/api1/versions/v1"
      )

  @patch("requests.get")
  def test_get_spec_content_invalid_path(self, mock_get, client):
    with pytest.raises(
        ValueError,
        match=(
            "Project ID not found in URL or path in APIHubClient. Input"
            " path is 'invalid-path'."
        ),
    ):
      client.get_spec_content("invalid-path")


if __name__ == "__main__":
  pytest.main([__file__])

==== tests/unittests/tools/retrieval/test_vertex_ai_rag_retrieval.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.adk.agents import Agent
from google.adk.tools.function_tool import FunctionTool
from google.adk.tools.retrieval.vertex_ai_rag_retrieval import VertexAiRagRetrieval
from google.genai import types

from ... import utils


def noop_tool(x: str) -> str:
  return x


def test_vertex_rag_retrieval_for_gemini_1_x():
  responses = [
      'response1',
  ]
  mockModel = utils.MockModel.create(responses=responses)
  mockModel.model = 'gemini-1.5-pro'

  # Calls the first time.
  agent = Agent(
      name='root_agent',
      model=mockModel,
      tools=[
          VertexAiRagRetrieval(
              name='rag_retrieval',
              description='rag_retrieval',
              rag_corpora=[
                  'projects/123456789/locations/us-central1/ragCorpora/1234567890'
              ],
          )
      ],
  )
  runner = utils.InMemoryRunner(agent)
  events = runner.run('test1')

  # Asserts the requests.
  assert len(mockModel.requests) == 1
  assert utils.simplify_contents(mockModel.requests[0].contents) == [
      ('user', 'test1'),
  ]
  assert len(mockModel.requests[0].config.tools) == 1
  assert (
      mockModel.requests[0].config.tools[0].function_declarations[0].name
      == 'rag_retrieval'
  )
  assert mockModel.requests[0].tools_dict['rag_retrieval'] is not None


def test_vertex_rag_retrieval_for_gemini_1_x_with_another_function_tool():
  responses = [
      'response1',
  ]
  mockModel = utils.MockModel.create(responses=responses)
  mockModel.model = 'gemini-1.5-pro'

  # Calls the first time.
  agent = Agent(
      name='root_agent',
      model=mockModel,
      tools=[
          VertexAiRagRetrieval(
              name='rag_retrieval',
              description='rag_retrieval',
              rag_corpora=[
                  'projects/123456789/locations/us-central1/ragCorpora/1234567890'
              ],
          ),
          FunctionTool(func=noop_tool),
      ],
  )
  runner = utils.InMemoryRunner(agent)
  events = runner.run('test1')

  # Asserts the requests.
  assert len(mockModel.requests) == 1
  assert utils.simplify_contents(mockModel.requests[0].contents) == [
      ('user', 'test1'),
  ]
  assert len(mockModel.requests[0].config.tools[0].function_declarations) == 2
  assert (
      mockModel.requests[0].config.tools[0].function_declarations[0].name
      == 'rag_retrieval'
  )
  assert (
      mockModel.requests[0].config.tools[0].function_declarations[1].name
      == 'noop_tool'
  )
  assert mockModel.requests[0].tools_dict['rag_retrieval'] is not None


def test_vertex_rag_retrieval_for_gemini_2_x():
  responses = [
      'response1',
  ]
  mockModel = utils.MockModel.create(responses=responses)
  mockModel.model = 'gemini-2.0-flash'

  # Calls the first time.
  agent = Agent(
      name='root_agent',
      model=mockModel,
      tools=[
          VertexAiRagRetrieval(
              name='rag_retrieval',
              description='rag_retrieval',
              rag_corpora=[
                  'projects/123456789/locations/us-central1/ragCorpora/1234567890'
              ],
          )
      ],
  )
  runner = utils.InMemoryRunner(agent)
  events = runner.run('test1')

  # Asserts the requests.
  assert len(mockModel.requests) == 1
  assert utils.simplify_contents(mockModel.requests[0].contents) == [
      ('user', 'test1'),
  ]
  assert len(mockModel.requests[0].config.tools) == 1
  assert mockModel.requests[0].config.tools == [
      types.Tool(
          retrieval=types.Retrieval(
              vertex_rag_store=types.VertexRagStore(
                  rag_corpora=[
                      'projects/123456789/locations/us-central1/ragCorpora/1234567890'
                  ]
              )
          )
      )
  ]
  assert 'rag_retrieval' not in mockModel.requests[0].tools_dict

==== tests/unittests/tools/retrieval/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

==== tests/unittests/tools/google_api_tool/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

==== tests/unittests/tools/google_api_tool/test_googleapi_to_openapi_converter.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from unittest.mock import MagicMock

from google.adk.tools.google_api_tool.googleapi_to_openapi_converter import GoogleApiToOpenApiConverter
# Import the converter class
from googleapiclient.errors import HttpError
import pytest


@pytest.fixture
def calendar_api_spec():
  """Fixture that provides a mock Google Calendar API spec for testing."""
  return {
      "kind": "discovery#restDescription",
      "id": "calendar:v3",
      "name": "calendar",
      "version": "v3",
      "title": "Google Calendar API",
      "description": "Accesses the Google Calendar API",
      "documentationLink": "https://developers.google.com/calendar/",
      "protocol": "rest",
      "rootUrl": "https://www.googleapis.com/",
      "servicePath": "calendar/v3/",
      "auth": {
          "oauth2": {
              "scopes": {
                  "https://www.googleapis.com/auth/calendar": {
                      "description": "Full access to Google Calendar"
                  },
                  "https://www.googleapis.com/auth/calendar.readonly": {
                      "description": "Read-only access to Google Calendar"
                  },
              }
          }
      },
      "schemas": {
          "Calendar": {
              "type": "object",
              "description": "A calendar resource",
              "properties": {
                  "id": {
                      "type": "string",
                      "description": "Calendar identifier",
                  },
                  "summary": {
                      "type": "string",
                      "description": "Calendar summary",
                      "required": True,
                  },
                  "timeZone": {
                      "type": "string",
                      "description": "Calendar timezone",
                  },
              },
          },
          "Event": {
              "type": "object",
              "description": "An event resource",
              "properties": {
                  "id": {"type": "string", "description": "Event identifier"},
                  "summary": {"type": "string", "description": "Event summary"},
                  "start": {"$ref": "EventDateTime"},
                  "end": {"$ref": "EventDateTime"},
                  "attendees": {
                      "type": "array",
                      "description": "Event attendees",
                      "items": {"$ref": "EventAttendee"},
                  },
              },
          },
          "EventDateTime": {
              "type": "object",
              "description": "Date/time for an event",
              "properties": {
                  "dateTime": {
                      "type": "string",
                      "format": "date-time",
                      "description": "Date/time in RFC3339 format",
                  },
                  "timeZone": {
                      "type": "string",
                      "description": "Timezone for the date/time",
                  },
              },
          },
          "EventAttendee": {
              "type": "object",
              "description": "An attendee of an event",
              "properties": {
                  "email": {"type": "string", "description": "Attendee email"},
                  "responseStatus": {
                      "type": "string",
                      "description": "Response status",
                      "enum": [
                          "needsAction",
                          "declined",
                          "tentative",
                          "accepted",
                      ],
                  },
              },
          },
      },
      "resources": {
          "calendars": {
              "methods": {
                  "get": {
                      "id": "calendar.calendars.get",
                      "flatPath": "calendars/{calendarId}",
                      "httpMethod": "GET",
                      "description": "Returns metadata for a calendar.",
                      "parameters": {
                          "calendarId": {
                              "type": "string",
                              "description": "Calendar identifier",
                              "required": True,
                              "location": "path",
                          }
                      },
                      "response": {"$ref": "Calendar"},
                      "scopes": [
                          "https://www.googleapis.com/auth/calendar",
                          "https://www.googleapis.com/auth/calendar.readonly",
                      ],
                  },
                  "insert": {
                      "id": "calendar.calendars.insert",
                      "path": "calendars",
                      "httpMethod": "POST",
                      "description": "Creates a secondary calendar.",
                      "request": {"$ref": "Calendar"},
                      "response": {"$ref": "Calendar"},
                      "scopes": ["https://www.googleapis.com/auth/calendar"],
                  },
              },
              "resources": {
                  "events": {
                      "methods": {
                          "list": {
                              "id": "calendar.events.list",
                              "flatPath": "calendars/{calendarId}/events",
                              "httpMethod": "GET",
                              "description": (
                                  "Returns events on the specified calendar."
                              ),
                              "parameters": {
                                  "calendarId": {
                                      "type": "string",
                                      "description": "Calendar identifier",
                                      "required": True,
                                      "location": "path",
                                  },
                                  "maxResults": {
                                      "type": "integer",
                                      "description": (
                                          "Maximum number of events returned"
                                      ),
                                      "format": "int32",
                                      "minimum": "1",
                                      "maximum": "2500",
                                      "default": "250",
                                      "location": "query",
                                  },
                                  "orderBy": {
                                      "type": "string",
                                      "description": (
                                          "Order of the events returned"
                                      ),
                                      "enum": ["startTime", "updated"],
                                      "location": "query",
                                  },
                              },
                              "response": {"$ref": "Events"},
                              "scopes": [
                                  "https://www.googleapis.com/auth/calendar",
                                  "https://www.googleapis.com/auth/calendar.readonly",
                              ],
                          }
                      }
                  }
              },
          }
      },
  }


@pytest.fixture
def converter():
  """Fixture that provides a basic converter instance."""
  return GoogleApiToOpenApiConverter("calendar", "v3")


@pytest.fixture
def mock_api_resource(calendar_api_spec):
  """Fixture that provides a mock API resource with the test spec."""
  mock_resource = MagicMock()
  mock_resource._rootDesc = calendar_api_spec
  return mock_resource


@pytest.fixture
def prepared_converter(converter, calendar_api_spec):
  """Fixture that provides a converter with the API spec already set."""
  converter._google_api_spec = calendar_api_spec
  return converter


@pytest.fixture
def converter_with_patched_build(monkeypatch, mock_api_resource):
  """Fixture that provides a converter with the build function patched.

  This simulates a successful API spec fetch.
  """
  # Create a mock for the build function
  mock_build = MagicMock(return_value=mock_api_resource)

  # Patch the build function in the target module
  monkeypatch.setattr(
      "google.adk.tools.google_api_tool.googleapi_to_openapi_converter.build",
      mock_build,
  )

  # Create and return a converter instance
  return GoogleApiToOpenApiConverter("calendar", "v3")


class TestGoogleApiToOpenApiConverter:
  """Test suite for the GoogleApiToOpenApiConverter class."""

  def test_init(self, converter):
    """Test converter initialization."""
    assert converter._api_name == "calendar"
    assert converter._api_version == "v3"
    assert converter._google_api_resource is None
    assert converter._google_api_spec is None
    assert converter._openapi_spec["openapi"] == "3.0.0"
    assert "info" in converter._openapi_spec
    assert "paths" in converter._openapi_spec
    assert "components" in converter._openapi_spec

  def test_fetch_google_api_spec(
      self, converter_with_patched_build, calendar_api_spec
  ):
    """Test fetching Google API specification."""
    # Call the method
    converter_with_patched_build.fetch_google_api_spec()

    # Verify the results
    assert converter_with_patched_build._google_api_spec == calendar_api_spec

  def test_fetch_google_api_spec_error(self, monkeypatch, converter):
    """Test error handling when fetching Google API specification."""
    # Create a mock that raises an error
    mock_build = MagicMock(
        side_effect=HttpError(resp=MagicMock(status=404), content=b"Not Found")
    )
    monkeypatch.setattr(
        "google.adk.tools.google_api_tool.googleapi_to_openapi_converter.build",
        mock_build,
    )

    # Verify exception is raised
    with pytest.raises(HttpError):
      converter.fetch_google_api_spec()

  def test_convert_info(self, prepared_converter):
    """Test conversion of basic API information."""
    # Call the method
    prepared_converter._convert_info()

    # Verify the results
    info = prepared_converter._openapi_spec["info"]
    assert info["title"] == "Google Calendar API"
    assert info["description"] == "Accesses the Google Calendar API"
    assert info["version"] == "v3"
    assert info["termsOfService"] == "https://developers.google.com/calendar/"

    # Check external docs
    external_docs = prepared_converter._openapi_spec["externalDocs"]
    assert external_docs["url"] == "https://developers.google.com/calendar/"

  def test_convert_servers(self, prepared_converter):
    """Test conversion of server information."""
    # Call the method
    prepared_converter._convert_servers()

    # Verify the results
    servers = prepared_converter._openapi_spec["servers"]
    assert len(servers) == 1
    assert servers[0]["url"] == "https://www.googleapis.com/calendar/v3"
    assert servers[0]["description"] == "calendar v3 API"

  def test_convert_security_schemes(self, prepared_converter):
    """Test conversion of security schemes."""
    # Call the method
    prepared_converter._convert_security_schemes()

    # Verify the results
    security_schemes = prepared_converter._openapi_spec["components"][
        "securitySchemes"
    ]

    # Check OAuth2 configuration
    assert "oauth2" in security_schemes
    oauth2 = security_schemes["oauth2"]
    assert oauth2["type"] == "oauth2"

    # Check OAuth2 scopes
    scopes = oauth2["flows"]["authorizationCode"]["scopes"]
    assert "https://www.googleapis.com/auth/calendar" in scopes
    assert "https://www.googleapis.com/auth/calendar.readonly" in scopes

    # Check API key configuration
    assert "apiKey" in security_schemes
    assert security_schemes["apiKey"]["type"] == "apiKey"
    assert security_schemes["apiKey"]["in"] == "query"
    assert security_schemes["apiKey"]["name"] == "key"

  def test_convert_schemas(self, prepared_converter):
    """Test conversion of schema definitions."""
    # Call the method
    prepared_converter._convert_schemas()

    # Verify the results
    schemas = prepared_converter._openapi_spec["components"]["schemas"]

    # Check Calendar schema
    assert "Calendar" in schemas
    calendar_schema = schemas["Calendar"]
    assert calendar_schema["type"] == "object"
    assert calendar_schema["description"] == "A calendar resource"

    # Check required properties
    assert "required" in calendar_schema
    assert "summary" in calendar_schema["required"]

    # Check Event schema references
    assert "Event" in schemas
    event_schema = schemas["Event"]
    assert (
        event_schema["properties"]["start"]["$ref"]
        == "#/components/schemas/EventDateTime"
    )

    # Check array type with references
    attendees_schema = event_schema["properties"]["attendees"]
    assert attendees_schema["type"] == "array"
    assert (
        attendees_schema["items"]["$ref"]
        == "#/components/schemas/EventAttendee"
    )

    # Check enum values
    attendee_schema = schemas["EventAttendee"]
    response_status = attendee_schema["properties"]["responseStatus"]
    assert "enum" in response_status
    assert "accepted" in response_status["enum"]

  @pytest.mark.parametrize(
      "schema_def, expected_type, expected_attrs",
      [
          # Test object type
          (
              {
                  "type": "object",
                  "description": "Test object",
                  "properties": {
                      "id": {"type": "string", "required": True},
                      "name": {"type": "string"},
                  },
              },
              "object",
              {"description": "Test object", "required": ["id"]},
          ),
          # Test array type
          (
              {
                  "type": "array",
                  "description": "Test array",
                  "items": {"type": "string"},
              },
              "array",
              {"description": "Test array", "items": {"type": "string"}},
          ),
          # Test reference conversion
          (
              {"$ref": "Calendar"},
              None,  # No type for references
              {"$ref": "#/components/schemas/Calendar"},
          ),
          # Test enum conversion
          (
              {"type": "string", "enum": ["value1", "value2"]},
              "string",
              {"enum": ["value1", "value2"]},
          ),
      ],
  )
  def test_convert_schema_object(
      self, converter, schema_def, expected_type, expected_attrs
  ):
    """Test conversion of individual schema objects with different input variations."""
    converted = converter._convert_schema_object(schema_def)

    # Check type if expected
    if expected_type:
      assert converted["type"] == expected_type

    # Check other expected attributes
    for key, value in expected_attrs.items():
      assert converted[key] == value

  @pytest.mark.parametrize(
      "path, expected_params",
      [
          # Path with parameters
          (
              "/calendars/{calendarId}/events/{eventId}",
              ["calendarId", "eventId"],
          ),
          # Path without parameters
          ("/calendars/events", []),
          # Mixed path
          ("/users/{userId}/calendars/default", ["userId"]),
      ],
  )
  def test_extract_path_parameters(self, converter, path, expected_params):
    """Test extraction of path parameters from URL path with various inputs."""
    params = converter._extract_path_parameters(path)
    assert set(params) == set(expected_params)
    assert len(params) == len(expected_params)

  @pytest.mark.parametrize(
      "param_data, expected_result",
      [
          # String parameter
          (
              {
                  "type": "string",
                  "description": "String parameter",
                  "pattern": "^[a-z]+$",
              },
              {"type": "string", "pattern": "^[a-z]+$"},
          ),
          # Integer parameter with format
          (
              {"type": "integer", "format": "int32", "default": "10"},
              {"type": "integer", "format": "int32", "default": "10"},
          ),
          # Enum parameter
          (
              {"type": "string", "enum": ["option1", "option2"]},
              {"type": "string", "enum": ["option1", "option2"]},
          ),
      ],
  )
  def test_convert_parameter_schema(
      self, converter, param_data, expected_result
  ):
    """Test conversion of parameter definitions to OpenAPI schemas."""
    converted = converter._convert_parameter_schema(param_data)

    # Check all expected attributes
    for key, value in expected_result.items():
      assert converted[key] == value

  def test_convert(self, converter_with_patched_build):
    """Test the complete conversion process."""
    # Call the method
    result = converter_with_patched_build.convert()

    # Verify basic structure
    assert result["openapi"] == "3.0.0"
    assert "info" in result
    assert "servers" in result
    assert "paths" in result
    assert "components" in result

    # Verify paths
    paths = result["paths"]
    assert "/calendars/{calendarId}" in paths
    assert "get" in paths["/calendars/{calendarId}"]

    # Verify nested resources
    assert "/calendars/{calendarId}/events" in paths

    # Verify method details
    get_calendar = paths["/calendars/{calendarId}"]["get"]
    assert get_calendar["operationId"] == "calendar.calendars.get"
    assert "parameters" in get_calendar

    # Verify request body
    insert_calendar = paths["/calendars"]["post"]
    assert "requestBody" in insert_calendar
    request_schema = insert_calendar["requestBody"]["content"][
        "application/json"
    ]["schema"]
    assert request_schema["$ref"] == "#/components/schemas/Calendar"

    # Verify response body
    assert "responses" in get_calendar
    response_schema = get_calendar["responses"]["200"]["content"][
        "application/json"
    ]["schema"]
    assert response_schema["$ref"] == "#/components/schemas/Calendar"

  def test_convert_methods(self, prepared_converter, calendar_api_spec):
    """Test conversion of API methods."""
    # Convert methods
    methods = calendar_api_spec["resources"]["calendars"]["methods"]
    prepared_converter._convert_methods(methods, "/calendars")

    # Verify the results
    paths = prepared_converter._openapi_spec["paths"]

    # Check GET method
    assert "/calendars/{calendarId}" in paths
    get_method = paths["/calendars/{calendarId}"]["get"]
    assert get_method["operationId"] == "calendar.calendars.get"

    # Check parameters
    params = get_method["parameters"]
    param_names = [p["name"] for p in params]
    assert "calendarId" in param_names

    # Check POST method
    assert "/calendars" in paths
    post_method = paths["/calendars"]["post"]
    assert post_method["operationId"] == "calendar.calendars.insert"

    # Check request body
    assert "requestBody" in post_method
    assert (
        post_method["requestBody"]["content"]["application/json"]["schema"][
            "$ref"
        ]
        == "#/components/schemas/Calendar"
    )

    # Check response
    assert (
        post_method["responses"]["200"]["content"]["application/json"][
            "schema"
        ]["$ref"]
        == "#/components/schemas/Calendar"
    )

  def test_convert_resources(self, prepared_converter, calendar_api_spec):
    """Test conversion of nested resources."""
    # Convert resources
    resources = calendar_api_spec["resources"]
    prepared_converter._convert_resources(resources)

    # Verify the results
    paths = prepared_converter._openapi_spec["paths"]

    # Check top-level resource methods
    assert "/calendars/{calendarId}" in paths

    # Check nested resource methods
    assert "/calendars/{calendarId}/events" in paths
    events_method = paths["/calendars/{calendarId}/events"]["get"]
    assert events_method["operationId"] == "calendar.events.list"

    # Check parameters in nested resource
    params = events_method["parameters"]
    param_names = [p["name"] for p in params]
    assert "calendarId" in param_names
    assert "maxResults" in param_names
    assert "orderBy" in param_names

  def test_integration_calendar_api(self, converter_with_patched_build):
    """Integration test using Calendar API specification."""
    # Create and run the converter
    openapi_spec = converter_with_patched_build.convert()

    # Verify conversion results
    assert openapi_spec["info"]["title"] == "Google Calendar API"
    assert (
        openapi_spec["servers"][0]["url"]
        == "https://www.googleapis.com/calendar/v3"
    )

    # Check security schemes
    security_schemes = openapi_spec["components"]["securitySchemes"]
    assert "oauth2" in security_schemes
    assert "apiKey" in security_schemes

    # Check schemas
    schemas = openapi_spec["components"]["schemas"]
    assert "Calendar" in schemas
    assert "Event" in schemas
    assert "EventDateTime" in schemas

    # Check paths
    paths = openapi_spec["paths"]
    assert "/calendars/{calendarId}" in paths
    assert "/calendars" in paths
    assert "/calendars/{calendarId}/events" in paths

    # Check method details
    get_events = paths["/calendars/{calendarId}/events"]["get"]
    assert get_events["operationId"] == "calendar.events.list"

    # Check parameter details
    param_dict = {p["name"]: p for p in get_events["parameters"]}
    assert "maxResults" in param_dict
    max_results = param_dict["maxResults"]
    assert max_results["in"] == "query"
    assert max_results["schema"]["type"] == "integer"
    assert max_results["schema"]["default"] == "250"


@pytest.fixture
def conftest_content():
  """Returns content for a conftest.py file to help with testing."""
  return """
import pytest
from unittest.mock import MagicMock

# This file contains fixtures that can be shared across multiple test modules

@pytest.fixture
def mock_google_response():
    \"\"\"Fixture that provides a mock response from Google's API.\"\"\"
    return {"key": "value", "items": [{"id": 1}, {"id": 2}]}

@pytest.fixture
def mock_http_error():
    \"\"\"Fixture that provides a mock HTTP error.\"\"\"
    mock_resp = MagicMock()
    mock_resp.status = 404
    return HttpError(resp=mock_resp, content=b'Not Found')
"""


def test_generate_conftest_example(conftest_content):
  """This is a meta-test that demonstrates how to generate a conftest.py file.

  In a real project, you would create a separate conftest.py file.
  """
  # In a real scenario, you would write this to a file named conftest.py
  # This test just verifies the conftest content is not empty
  assert len(conftest_content) > 0

==== tests/unittests/tools/openapi_tool/auth/credential_exchangers/test_auto_auth_credential_exchanger.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Unit tests for AutoAuthCredentialExchanger."""

from typing import Dict
from typing import Optional
from typing import Type
from unittest.mock import MagicMock

from google.adk.auth.auth_credential import AuthCredential
from google.adk.auth.auth_credential import AuthCredentialTypes
from google.adk.auth.auth_schemes import AuthScheme
from google.adk.tools.openapi_tool.auth.credential_exchangers.auto_auth_credential_exchanger import AutoAuthCredentialExchanger
from google.adk.tools.openapi_tool.auth.credential_exchangers.base_credential_exchanger import BaseAuthCredentialExchanger
from google.adk.tools.openapi_tool.auth.credential_exchangers.oauth2_exchanger import OAuth2CredentialExchanger
from google.adk.tools.openapi_tool.auth.credential_exchangers.service_account_exchanger import ServiceAccountCredentialExchanger
import pytest


class MockCredentialExchanger(BaseAuthCredentialExchanger):
  """Mock credential exchanger for testing."""

  def exchange_credential(
      self,
      auth_scheme: AuthScheme,
      auth_credential: Optional[AuthCredential] = None,
  ) -> AuthCredential:
    """Mock exchange credential method."""
    return auth_credential


@pytest.fixture
def auto_exchanger():
  """Fixture for creating an AutoAuthCredentialExchanger instance."""
  return AutoAuthCredentialExchanger()


@pytest.fixture
def auth_scheme():
  """Fixture for creating a mock AuthScheme instance."""
  scheme = MagicMock(spec=AuthScheme)
  return scheme


def test_init_with_custom_exchangers():
  """Test initialization with custom exchangers."""
  custom_exchangers: Dict[str, Type[BaseAuthCredentialExchanger]] = {
      AuthCredentialTypes.API_KEY: MockCredentialExchanger
  }

  auto_exchanger = AutoAuthCredentialExchanger(
      custom_exchangers=custom_exchangers
  )

  assert (
      auto_exchanger.exchangers[AuthCredentialTypes.API_KEY]
      == MockCredentialExchanger
  )
  assert (
      auto_exchanger.exchangers[AuthCredentialTypes.OPEN_ID_CONNECT]
      == OAuth2CredentialExchanger
  )


def test_exchange_credential_no_auth_credential(auto_exchanger, auth_scheme):
  """Test exchange_credential with no auth_credential."""

  assert auto_exchanger.exchange_credential(auth_scheme, None) is None


def test_exchange_credential_no_exchange(auto_exchanger, auth_scheme):
  """Test exchange_credential with NoExchangeCredentialExchanger."""
  auth_credential = AuthCredential(auth_type=AuthCredentialTypes.API_KEY)

  result = auto_exchanger.exchange_credential(auth_scheme, auth_credential)

  assert result == auth_credential


def test_exchange_credential_open_id_connect(auto_exchanger, auth_scheme):
  """Test exchange_credential with OpenID Connect scheme."""
  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.OPEN_ID_CONNECT
  )
  mock_exchanger = MagicMock(spec=OAuth2CredentialExchanger)
  mock_exchanger.exchange_credential.return_value = "exchanged_credential"
  auto_exchanger.exchangers[AuthCredentialTypes.OPEN_ID_CONNECT] = (
      lambda: mock_exchanger
  )

  result = auto_exchanger.exchange_credential(auth_scheme, auth_credential)

  assert result == "exchanged_credential"
  mock_exchanger.exchange_credential.assert_called_once_with(
      auth_scheme, auth_credential
  )


def test_exchange_credential_service_account(auto_exchanger, auth_scheme):
  """Test exchange_credential with Service Account scheme."""
  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.SERVICE_ACCOUNT
  )
  mock_exchanger = MagicMock(spec=ServiceAccountCredentialExchanger)
  mock_exchanger.exchange_credential.return_value = "exchanged_credential_sa"
  auto_exchanger.exchangers[AuthCredentialTypes.SERVICE_ACCOUNT] = (
      lambda: mock_exchanger
  )

  result = auto_exchanger.exchange_credential(auth_scheme, auth_credential)

  assert result == "exchanged_credential_sa"
  mock_exchanger.exchange_credential.assert_called_once_with(
      auth_scheme, auth_credential
  )


def test_exchange_credential_custom_exchanger(auto_exchanger, auth_scheme):
  """Test that exchange_credential calls the correct (custom) exchanger."""
  # Use a custom exchanger via the initialization
  mock_exchanger = MagicMock(spec=MockCredentialExchanger)
  mock_exchanger.exchange_credential.return_value = "custom_credential"
  auto_exchanger.exchangers[AuthCredentialTypes.API_KEY] = (
      lambda: mock_exchanger
  )
  auth_credential = AuthCredential(auth_type=AuthCredentialTypes.API_KEY)

  result = auto_exchanger.exchange_credential(auth_scheme, auth_credential)

  assert result == "custom_credential"
  mock_exchanger.exchange_credential.assert_called_once_with(
      auth_scheme, auth_credential
  )

==== tests/unittests/tools/openapi_tool/auth/credential_exchangers/test_oauth2_exchanger.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Tests for OAuth2CredentialExchanger."""

import copy
from unittest.mock import MagicMock

from google.adk.auth.auth_credential import AuthCredential
from google.adk.auth.auth_credential import AuthCredentialTypes
from google.adk.auth.auth_credential import OAuth2Auth
from google.adk.auth.auth_schemes import AuthSchemeType
from google.adk.auth.auth_schemes import OpenIdConnectWithConfig
from google.adk.tools.openapi_tool.auth.credential_exchangers import OAuth2CredentialExchanger
from google.adk.tools.openapi_tool.auth.credential_exchangers.base_credential_exchanger import AuthCredentialMissingError
import pytest


@pytest.fixture
def oauth2_exchanger():
  return OAuth2CredentialExchanger()


@pytest.fixture
def auth_scheme():
  openid_config = OpenIdConnectWithConfig(
      type_=AuthSchemeType.openIdConnect,
      authorization_endpoint="https://example.com/auth",
      token_endpoint="https://example.com/token",
      scopes=["openid", "profile"],
  )
  return openid_config


def test_check_scheme_credential_type_success(oauth2_exchanger, auth_scheme):
  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.OAUTH2,
      oauth2=OAuth2Auth(
          client_id="test_client",
          client_secret="test_secret",
          redirect_uri="http://localhost:8080",
      ),
  )
  # Check that the method does not raise an exception
  oauth2_exchanger._check_scheme_credential_type(auth_scheme, auth_credential)


def test_check_scheme_credential_type_missing_credential(
    oauth2_exchanger, auth_scheme
):
  # Test case: auth_credential is None
  with pytest.raises(ValueError) as exc_info:
    oauth2_exchanger._check_scheme_credential_type(auth_scheme, None)
  assert "auth_credential is empty" in str(exc_info.value)


def test_check_scheme_credential_type_invalid_scheme_type(
    oauth2_exchanger, auth_scheme: OpenIdConnectWithConfig
):
  """Test case: Invalid AuthSchemeType."""
  # Test case: Invalid AuthSchemeType
  invalid_scheme = copy.deepcopy(auth_scheme)
  invalid_scheme.type_ = AuthSchemeType.apiKey
  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.OAUTH2,
      oauth2=OAuth2Auth(
          client_id="test_client",
          client_secret="test_secret",
          redirect_uri="http://localhost:8080",
      ),
  )
  with pytest.raises(ValueError) as exc_info:
    oauth2_exchanger._check_scheme_credential_type(
        invalid_scheme, auth_credential
    )
  assert "Invalid security scheme" in str(exc_info.value)


def test_check_scheme_credential_type_missing_openid_connect(
    oauth2_exchanger, auth_scheme
):
  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.OAUTH2,
  )
  with pytest.raises(ValueError) as exc_info:
    oauth2_exchanger._check_scheme_credential_type(auth_scheme, auth_credential)
  assert "auth_credential is not configured with oauth2" in str(exc_info.value)


def test_generate_auth_token_success(
    oauth2_exchanger, auth_scheme, monkeypatch
):
  """Test case: Successful generation of access token."""
  # Test case: Successful generation of access token
  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.OAUTH2,
      oauth2=OAuth2Auth(
          client_id="test_client",
          client_secret="test_secret",
          redirect_uri="http://localhost:8080",
          auth_response_uri="https://example.com/callback?code=test_code",
          access_token="test_access_token",
      ),
  )
  updated_credential = oauth2_exchanger.generate_auth_token(auth_credential)

  assert updated_credential.auth_type == AuthCredentialTypes.HTTP
  assert updated_credential.http.scheme == "bearer"
  assert updated_credential.http.credentials.token == "test_access_token"


def test_exchange_credential_generate_auth_token(
    oauth2_exchanger, auth_scheme, monkeypatch
):
  """Test exchange_credential when auth_response_uri is present."""
  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.OAUTH2,
      oauth2=OAuth2Auth(
          client_id="test_client",
          client_secret="test_secret",
          redirect_uri="http://localhost:8080",
          auth_response_uri="https://example.com/callback?code=test_code",
          access_token="test_access_token",
      ),
  )

  updated_credential = oauth2_exchanger.exchange_credential(
      auth_scheme, auth_credential
  )

  assert updated_credential.auth_type == AuthCredentialTypes.HTTP
  assert updated_credential.http.scheme == "bearer"
  assert updated_credential.http.credentials.token == "test_access_token"


def test_exchange_credential_auth_missing(oauth2_exchanger, auth_scheme):
  """Test exchange_credential when auth_credential is missing."""
  with pytest.raises(ValueError) as exc_info:
    oauth2_exchanger.exchange_credential(auth_scheme, None)
  assert "auth_credential is empty. Please create AuthCredential using" in str(
      exc_info.value
  )

==== tests/unittests/tools/openapi_tool/auth/credential_exchangers/test_base_auth_credential_exchanger.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Tests for the BaseAuthCredentialExchanger class."""

from typing import Optional
from unittest.mock import MagicMock

from google.adk.auth.auth_credential import AuthCredential
from google.adk.auth.auth_credential import AuthCredentialTypes
from google.adk.auth.auth_schemes import AuthScheme
from google.adk.tools.openapi_tool.auth.credential_exchangers.base_credential_exchanger import AuthCredentialMissingError
from google.adk.tools.openapi_tool.auth.credential_exchangers.base_credential_exchanger import BaseAuthCredentialExchanger
import pytest


class MockAuthCredentialExchanger(BaseAuthCredentialExchanger):

  def exchange_credential(
      self,
      auth_scheme: AuthScheme,
      auth_credential: Optional[AuthCredential] = None,
  ) -> AuthCredential:
    return AuthCredential(token="some-token")


class TestBaseAuthCredentialExchanger:
  """Tests for the BaseAuthCredentialExchanger class."""

  @pytest.fixture
  def base_exchanger(self):
    return BaseAuthCredentialExchanger()

  @pytest.fixture
  def auth_scheme(self):
    scheme = MagicMock(spec=AuthScheme)
    scheme.type = "apiKey"
    scheme.name = "x-api-key"
    return scheme

  def test_exchange_credential_not_implemented(
      self, base_exchanger, auth_scheme
  ):
    auth_credential = AuthCredential(
        auth_type=AuthCredentialTypes.API_KEY, token="some-token"
    )
    with pytest.raises(NotImplementedError) as exc_info:
      base_exchanger.exchange_credential(auth_scheme, auth_credential)
    assert "Subclasses must implement exchange_credential." in str(
        exc_info.value
    )

  def test_auth_credential_missing_error(self):
    error_message = "Test missing credential"
    error = AuthCredentialMissingError(error_message)
    # assert error.message == error_message
    assert str(error) == error_message

==== tests/unittests/tools/openapi_tool/auth/credential_exchangers/test_service_account_exchanger.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Unit tests for the service account credential exchanger."""

from unittest.mock import MagicMock

from google.adk.auth.auth_credential import AuthCredential
from google.adk.auth.auth_credential import AuthCredentialTypes
from google.adk.auth.auth_credential import ServiceAccount
from google.adk.auth.auth_credential import ServiceAccountCredential
from google.adk.auth.auth_schemes import AuthScheme
from google.adk.auth.auth_schemes import AuthSchemeType
from google.adk.tools.openapi_tool.auth.credential_exchangers.base_credential_exchanger import AuthCredentialMissingError
from google.adk.tools.openapi_tool.auth.credential_exchangers.service_account_exchanger import ServiceAccountCredentialExchanger
import google.auth
import pytest


@pytest.fixture
def service_account_exchanger():
  return ServiceAccountCredentialExchanger()


@pytest.fixture
def auth_scheme():
  scheme = MagicMock(spec=AuthScheme)
  scheme.type_ = AuthSchemeType.oauth2
  scheme.description = "Google Service Account"
  return scheme


def test_exchange_credential_success(
    service_account_exchanger, auth_scheme, monkeypatch
):
  """Test successful exchange of service account credentials."""
  mock_credentials = MagicMock()
  mock_credentials.token = "mock_access_token"

  # Mock the from_service_account_info method
  mock_from_service_account_info = MagicMock(return_value=mock_credentials)
  target_path = (
      "google.adk.tools.openapi_tool.auth.credential_exchangers."
      "service_account_exchanger.service_account.Credentials."
      "from_service_account_info"
  )
  monkeypatch.setattr(
      target_path,
      mock_from_service_account_info,
  )

  # Mock the refresh method
  mock_credentials.refresh = MagicMock()

  # Create a valid AuthCredential with service account info
  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.SERVICE_ACCOUNT,
      service_account=ServiceAccount(
          service_account_credential=ServiceAccountCredential(
              type_="service_account",
              project_id="your_project_id",
              private_key_id="your_private_key_id",
              private_key="-----BEGIN PRIVATE KEY-----...",
              client_email="...@....iam.gserviceaccount.com",
              client_id="your_client_id",
              auth_uri="https://accounts.google.com/o/oauth2/auth",
              token_uri="https://oauth2.googleapis.com/token",
              auth_provider_x509_cert_url=(
                  "https://www.googleapis.com/oauth2/v1/certs"
              ),
              client_x509_cert_url=(
                  "https://www.googleapis.com/robot/v1/metadata/x509/..."
              ),
              universe_domain="googleapis.com",
          ),
          scopes=["https://www.googleapis.com/auth/cloud-platform"],
      ),
  )

  result = service_account_exchanger.exchange_credential(
      auth_scheme, auth_credential
  )

  assert result.auth_type == AuthCredentialTypes.HTTP
  assert result.http.scheme == "bearer"
  assert result.http.credentials.token == "mock_access_token"
  mock_from_service_account_info.assert_called_once()
  mock_credentials.refresh.assert_called_once()


def test_exchange_credential_use_default_credential_success(
    service_account_exchanger, auth_scheme, monkeypatch
):
  """Test successful exchange of service account credentials using default credential."""
  mock_credentials = MagicMock()
  mock_credentials.token = "mock_access_token"
  mock_google_auth_default = MagicMock(
      return_value=(mock_credentials, "test_project")
  )
  monkeypatch.setattr(google.auth, "default", mock_google_auth_default)

  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.SERVICE_ACCOUNT,
      service_account=ServiceAccount(
          use_default_credential=True,
          scopes=["https://www.googleapis.com/auth/cloud-platform"],
      ),
  )

  result = service_account_exchanger.exchange_credential(
      auth_scheme, auth_credential
  )

  assert result.auth_type == AuthCredentialTypes.HTTP
  assert result.http.scheme == "bearer"
  assert result.http.credentials.token == "mock_access_token"
  mock_google_auth_default.assert_called_once()
  mock_credentials.refresh.assert_called_once()


def test_exchange_credential_missing_auth_credential(
    service_account_exchanger, auth_scheme
):
  """Test missing auth credential during exchange."""
  with pytest.raises(AuthCredentialMissingError) as exc_info:
    service_account_exchanger.exchange_credential(auth_scheme, None)
  assert "Service account credentials are missing" in str(exc_info.value)


def test_exchange_credential_missing_service_account_info(
    service_account_exchanger, auth_scheme
):
  """Test missing service account info during exchange."""
  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.SERVICE_ACCOUNT,
  )
  with pytest.raises(AuthCredentialMissingError) as exc_info:
    service_account_exchanger.exchange_credential(auth_scheme, auth_credential)
  assert "Service account credentials are missing" in str(exc_info.value)


def test_exchange_credential_exchange_failure(
    service_account_exchanger, auth_scheme, monkeypatch
):
  """Test failure during service account token exchange."""
  mock_from_service_account_info = MagicMock(
      side_effect=Exception("Failed to load credentials")
  )
  target_path = (
      "google.adk.tools.openapi_tool.auth.credential_exchangers."
      "service_account_exchanger.service_account.Credentials."
      "from_service_account_info"
  )
  monkeypatch.setattr(
      target_path,
      mock_from_service_account_info,
  )

  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.SERVICE_ACCOUNT,
      service_account=ServiceAccount(
          service_account_credential=ServiceAccountCredential(
              type_="service_account",
              project_id="your_project_id",
              private_key_id="your_private_key_id",
              private_key="-----BEGIN PRIVATE KEY-----...",
              client_email="...@....iam.gserviceaccount.com",
              client_id="your_client_id",
              auth_uri="https://accounts.google.com/o/oauth2/auth",
              token_uri="https://oauth2.googleapis.com/token",
              auth_provider_x509_cert_url=(
                  "https://www.googleapis.com/oauth2/v1/certs"
              ),
              client_x509_cert_url=(
                  "https://www.googleapis.com/robot/v1/metadata/x509/..."
              ),
              universe_domain="googleapis.com",
          ),
          scopes=["https://www.googleapis.com/auth/cloud-platform"],
      ),
  )
  with pytest.raises(AuthCredentialMissingError) as exc_info:
    service_account_exchanger.exchange_credential(auth_scheme, auth_credential)
  assert "Failed to exchange service account token" in str(exc_info.value)
  mock_from_service_account_info.assert_called_once()

==== tests/unittests/tools/openapi_tool/auth/test_auth_helper.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from unittest.mock import patch

from fastapi.openapi.models import APIKey
from fastapi.openapi.models import APIKeyIn
from fastapi.openapi.models import HTTPBase
from fastapi.openapi.models import HTTPBearer
from fastapi.openapi.models import OAuth2
from fastapi.openapi.models import OpenIdConnect
from google.adk.auth.auth_credential import AuthCredential
from google.adk.auth.auth_credential import AuthCredentialTypes
from google.adk.auth.auth_credential import HttpAuth
from google.adk.auth.auth_credential import HttpCredentials
from google.adk.auth.auth_credential import ServiceAccount
from google.adk.auth.auth_credential import ServiceAccountCredential
from google.adk.auth.auth_schemes import AuthSchemeType
from google.adk.auth.auth_schemes import OpenIdConnectWithConfig
from google.adk.tools.openapi_tool.auth.auth_helpers import credential_to_param
from google.adk.tools.openapi_tool.auth.auth_helpers import dict_to_auth_scheme
from google.adk.tools.openapi_tool.auth.auth_helpers import INTERNAL_AUTH_PREFIX
from google.adk.tools.openapi_tool.auth.auth_helpers import openid_dict_to_scheme_credential
from google.adk.tools.openapi_tool.auth.auth_helpers import openid_url_to_scheme_credential
from google.adk.tools.openapi_tool.auth.auth_helpers import service_account_dict_to_scheme_credential
from google.adk.tools.openapi_tool.auth.auth_helpers import service_account_scheme_credential
from google.adk.tools.openapi_tool.auth.auth_helpers import token_to_scheme_credential
import pytest
import requests


def test_token_to_scheme_credential_api_key_header():
  scheme, credential = token_to_scheme_credential(
      "apikey", "header", "X-API-Key", "test_key"
  )

  assert isinstance(scheme, APIKey)
  assert scheme.type_ == AuthSchemeType.apiKey
  assert scheme.in_ == APIKeyIn.header
  assert scheme.name == "X-API-Key"
  assert credential == AuthCredential(
      auth_type=AuthCredentialTypes.API_KEY, api_key="test_key"
  )


def test_token_to_scheme_credential_api_key_query():
  scheme, credential = token_to_scheme_credential(
      "apikey", "query", "api_key", "test_key"
  )

  assert isinstance(scheme, APIKey)
  assert scheme.type_ == AuthSchemeType.apiKey
  assert scheme.in_ == APIKeyIn.query
  assert scheme.name == "api_key"
  assert credential == AuthCredential(
      auth_type=AuthCredentialTypes.API_KEY, api_key="test_key"
  )


def test_token_to_scheme_credential_api_key_cookie():
  scheme, credential = token_to_scheme_credential(
      "apikey", "cookie", "session_id", "test_key"
  )

  assert isinstance(scheme, APIKey)
  assert scheme.type_ == AuthSchemeType.apiKey
  assert scheme.in_ == APIKeyIn.cookie
  assert scheme.name == "session_id"
  assert credential == AuthCredential(
      auth_type=AuthCredentialTypes.API_KEY, api_key="test_key"
  )


def test_token_to_scheme_credential_api_key_no_credential():
  scheme, credential = token_to_scheme_credential(
      "apikey", "cookie", "session_id"
  )

  assert isinstance(scheme, APIKey)
  assert credential is None


def test_token_to_scheme_credential_oauth2_token():
  scheme, credential = token_to_scheme_credential(
      "oauth2Token", "header", "Authorization", "test_token"
  )

  assert isinstance(scheme, HTTPBearer)
  assert scheme.bearerFormat == "JWT"
  assert credential == AuthCredential(
      auth_type=AuthCredentialTypes.HTTP,
      http=HttpAuth(
          scheme="bearer", credentials=HttpCredentials(token="test_token")
      ),
  )


def test_token_to_scheme_credential_oauth2_no_credential():
  scheme, credential = token_to_scheme_credential(
      "oauth2Token", "header", "Authorization"
  )

  assert isinstance(scheme, HTTPBearer)
  assert credential is None


def test_service_account_dict_to_scheme_credential():
  config = {
      "type": "service_account",
      "project_id": "project_id",
      "private_key_id": "private_key_id",
      "private_key": "private_key",
      "client_email": "client_email",
      "client_id": "client_id",
      "auth_uri": "auth_uri",
      "token_uri": "token_uri",
      "auth_provider_x509_cert_url": "auth_provider_x509_cert_url",
      "client_x509_cert_url": "client_x509_cert_url",
      "universe_domain": "universe_domain",
  }
  scopes = ["scope1", "scope2"]

  scheme, credential = service_account_dict_to_scheme_credential(config, scopes)

  assert isinstance(scheme, HTTPBearer)
  assert scheme.bearerFormat == "JWT"
  assert credential.auth_type == AuthCredentialTypes.SERVICE_ACCOUNT
  assert credential.service_account.scopes == scopes
  assert (
      credential.service_account.service_account_credential.project_id
      == "project_id"
  )


def test_service_account_scheme_credential():
  config = ServiceAccount(
      service_account_credential=ServiceAccountCredential(
          type="service_account",
          project_id="project_id",
          private_key_id="private_key_id",
          private_key="private_key",
          client_email="client_email",
          client_id="client_id",
          auth_uri="auth_uri",
          token_uri="token_uri",
          auth_provider_x509_cert_url="auth_provider_x509_cert_url",
          client_x509_cert_url="client_x509_cert_url",
          universe_domain="universe_domain",
      ),
      scopes=["scope1", "scope2"],
  )

  scheme, credential = service_account_scheme_credential(config)

  assert isinstance(scheme, HTTPBearer)
  assert scheme.bearerFormat == "JWT"
  assert credential.auth_type == AuthCredentialTypes.SERVICE_ACCOUNT
  assert credential.service_account == config


def test_openid_dict_to_scheme_credential():
  config_dict = {
      "authorization_endpoint": "auth_url",
      "token_endpoint": "token_url",
      "openIdConnectUrl": "openid_url",
  }
  credential_dict = {
      "client_id": "client_id",
      "client_secret": "client_secret",
      "redirect_uri": "redirect_uri",
  }
  scopes = ["scope1", "scope2"]

  scheme, credential = openid_dict_to_scheme_credential(
      config_dict, scopes, credential_dict
  )

  assert isinstance(scheme, OpenIdConnectWithConfig)
  assert scheme.authorization_endpoint == "auth_url"
  assert scheme.token_endpoint == "token_url"
  assert scheme.scopes == scopes
  assert credential.auth_type == AuthCredentialTypes.OPEN_ID_CONNECT
  assert credential.oauth2.client_id == "client_id"
  assert credential.oauth2.client_secret == "client_secret"
  assert credential.oauth2.redirect_uri == "redirect_uri"


def test_openid_dict_to_scheme_credential_no_openid_url():
  config_dict = {
      "authorization_endpoint": "auth_url",
      "token_endpoint": "token_url",
  }
  credential_dict = {
      "client_id": "client_id",
      "client_secret": "client_secret",
      "redirect_uri": "redirect_uri",
  }
  scopes = ["scope1", "scope2"]

  scheme, credential = openid_dict_to_scheme_credential(
      config_dict, scopes, credential_dict
  )

  assert scheme.openIdConnectUrl == ""


def test_openid_dict_to_scheme_credential_google_oauth_credential():
  config_dict = {
      "authorization_endpoint": "auth_url",
      "token_endpoint": "token_url",
      "openIdConnectUrl": "openid_url",
  }
  credential_dict = {
      "web": {
          "client_id": "client_id",
          "client_secret": "client_secret",
          "redirect_uri": "redirect_uri",
      }
  }
  scopes = ["scope1", "scope2"]

  scheme, credential = openid_dict_to_scheme_credential(
      config_dict, scopes, credential_dict
  )

  assert isinstance(scheme, OpenIdConnectWithConfig)
  assert credential.auth_type == AuthCredentialTypes.OPEN_ID_CONNECT
  assert credential.oauth2.client_id == "client_id"
  assert credential.oauth2.client_secret == "client_secret"
  assert credential.oauth2.redirect_uri == "redirect_uri"


def test_openid_dict_to_scheme_credential_invalid_config():
  config_dict = {
      "invalid_field": "value",
  }
  credential_dict = {
      "client_id": "client_id",
      "client_secret": "client_secret",
  }
  scopes = ["scope1", "scope2"]

  with pytest.raises(ValueError, match="Invalid OpenID Connect configuration"):
    openid_dict_to_scheme_credential(config_dict, scopes, credential_dict)


def test_openid_dict_to_scheme_credential_missing_credential_fields():
  config_dict = {
      "authorization_endpoint": "auth_url",
      "token_endpoint": "token_url",
  }
  credential_dict = {
      "client_id": "client_id",
  }
  scopes = ["scope1", "scope2"]

  with pytest.raises(
      ValueError,
      match="Missing required fields in credential_dict: client_secret",
  ):
    openid_dict_to_scheme_credential(config_dict, scopes, credential_dict)


@patch("requests.get")
def test_openid_url_to_scheme_credential(mock_get):
  mock_response = {
      "authorization_endpoint": "auth_url",
      "token_endpoint": "token_url",
      "userinfo_endpoint": "userinfo_url",
  }
  mock_get.return_value.json.return_value = mock_response
  mock_get.return_value.raise_for_status.return_value = None
  credential_dict = {
      "client_id": "client_id",
      "client_secret": "client_secret",
      "redirect_uri": "redirect_uri",
  }
  scopes = ["scope1", "scope2"]

  scheme, credential = openid_url_to_scheme_credential(
      "openid_url", scopes, credential_dict
  )

  assert isinstance(scheme, OpenIdConnectWithConfig)
  assert scheme.authorization_endpoint == "auth_url"
  assert scheme.token_endpoint == "token_url"
  assert scheme.scopes == scopes
  assert credential.auth_type == AuthCredentialTypes.OPEN_ID_CONNECT
  assert credential.oauth2.client_id == "client_id"
  assert credential.oauth2.client_secret == "client_secret"
  assert credential.oauth2.redirect_uri == "redirect_uri"
  mock_get.assert_called_once_with("openid_url", timeout=10)


@patch("requests.get")
def test_openid_url_to_scheme_credential_no_openid_url(mock_get):
  mock_response = {
      "authorization_endpoint": "auth_url",
      "token_endpoint": "token_url",
      "userinfo_endpoint": "userinfo_url",
  }
  mock_get.return_value.json.return_value = mock_response
  mock_get.return_value.raise_for_status.return_value = None
  credential_dict = {
      "client_id": "client_id",
      "client_secret": "client_secret",
      "redirect_uri": "redirect_uri",
  }
  scopes = ["scope1", "scope2"]

  scheme, credential = openid_url_to_scheme_credential(
      "openid_url", scopes, credential_dict
  )

  assert scheme.openIdConnectUrl == "openid_url"


@patch("requests.get")
def test_openid_url_to_scheme_credential_request_exception(mock_get):
  mock_get.side_effect = requests.exceptions.RequestException("Test Error")
  credential_dict = {"client_id": "client_id", "client_secret": "client_secret"}

  with pytest.raises(
      ValueError, match="Failed to fetch OpenID configuration from openid_url"
  ):
    openid_url_to_scheme_credential("openid_url", [], credential_dict)


@patch("requests.get")
def test_openid_url_to_scheme_credential_invalid_json(mock_get):
  mock_get.return_value.json.side_effect = ValueError("Invalid JSON")
  mock_get.return_value.raise_for_status.return_value = None
  credential_dict = {"client_id": "client_id", "client_secret": "client_secret"}

  with pytest.raises(
      ValueError,
      match=(
          "Invalid JSON response from OpenID configuration endpoint openid_url"
      ),
  ):
    openid_url_to_scheme_credential("openid_url", [], credential_dict)


def test_credential_to_param_api_key_header():
  auth_scheme = APIKey(
      **{"type": "apiKey", "in": "header", "name": "X-API-Key"}
  )
  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.API_KEY, api_key="test_key"
  )

  param, kwargs = credential_to_param(auth_scheme, auth_credential)

  assert param.original_name == "X-API-Key"
  assert param.param_location == "header"
  assert kwargs == {INTERNAL_AUTH_PREFIX + "X-API-Key": "test_key"}


def test_credential_to_param_api_key_query():
  auth_scheme = APIKey(**{"type": "apiKey", "in": "query", "name": "api_key"})
  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.API_KEY, api_key="test_key"
  )

  param, kwargs = credential_to_param(auth_scheme, auth_credential)

  assert param.original_name == "api_key"
  assert param.param_location == "query"
  assert kwargs == {INTERNAL_AUTH_PREFIX + "api_key": "test_key"}


def test_credential_to_param_api_key_cookie():
  auth_scheme = APIKey(
      **{"type": "apiKey", "in": "cookie", "name": "session_id"}
  )
  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.API_KEY, api_key="test_key"
  )

  param, kwargs = credential_to_param(auth_scheme, auth_credential)

  assert param.original_name == "session_id"
  assert param.param_location == "cookie"
  assert kwargs == {INTERNAL_AUTH_PREFIX + "session_id": "test_key"}


def test_credential_to_param_http_bearer():
  auth_scheme = HTTPBearer(bearerFormat="JWT")
  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.HTTP,
      http=HttpAuth(
          scheme="bearer", credentials=HttpCredentials(token="test_token")
      ),
  )

  param, kwargs = credential_to_param(auth_scheme, auth_credential)

  assert param.original_name == "Authorization"
  assert param.param_location == "header"
  assert kwargs == {INTERNAL_AUTH_PREFIX + "Authorization": "Bearer test_token"}


def test_credential_to_param_http_basic_not_supported():
  auth_scheme = HTTPBase(scheme="basic")
  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.HTTP,
      http=HttpAuth(
          scheme="basic",
          credentials=HttpCredentials(username="user", password="password"),
      ),
  )

  with pytest.raises(
      NotImplementedError, match="Basic Authentication is not supported."
  ):
    credential_to_param(auth_scheme, auth_credential)


def test_credential_to_param_http_invalid_credentials_no_http():
  auth_scheme = HTTPBase(scheme="basic")
  auth_credential = AuthCredential(auth_type=AuthCredentialTypes.HTTP)

  with pytest.raises(ValueError, match="Invalid HTTP auth credentials"):
    credential_to_param(auth_scheme, auth_credential)


def test_credential_to_param_oauth2():
  auth_scheme = OAuth2(flows={})
  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.HTTP,
      http=HttpAuth(
          scheme="bearer", credentials=HttpCredentials(token="test_token")
      ),
  )

  param, kwargs = credential_to_param(auth_scheme, auth_credential)

  assert param.original_name == "Authorization"
  assert param.param_location == "header"
  assert kwargs == {INTERNAL_AUTH_PREFIX + "Authorization": "Bearer test_token"}


def test_credential_to_param_openid_connect():
  auth_scheme = OpenIdConnect(openIdConnectUrl="openid_url")
  auth_credential = AuthCredential(
      auth_type=AuthCredentialTypes.HTTP,
      http=HttpAuth(
          scheme="bearer", credentials=HttpCredentials(token="test_token")
      ),
  )

  param, kwargs = credential_to_param(auth_scheme, auth_credential)

  assert param.original_name == "Authorization"
  assert param.param_location == "header"
  assert kwargs == {INTERNAL_AUTH_PREFIX + "Authorization": "Bearer test_token"}


def test_credential_to_param_openid_no_credential():
  auth_scheme = OpenIdConnect(openIdConnectUrl="openid_url")

  param, kwargs = credential_to_param(auth_scheme, None)

  assert param == None
  assert kwargs == None


def test_credential_to_param_oauth2_no_credential():
  auth_scheme = OAuth2(flows={})

  param, kwargs = credential_to_param(auth_scheme, None)

  assert param == None
  assert kwargs == None


def test_dict_to_auth_scheme_api_key():
  data = {"type": "apiKey", "in": "header", "name": "X-API-Key"}

  scheme = dict_to_auth_scheme(data)

  assert isinstance(scheme, APIKey)
  assert scheme.type_ == AuthSchemeType.apiKey
  assert scheme.in_ == APIKeyIn.header
  assert scheme.name == "X-API-Key"


def test_dict_to_auth_scheme_http_bearer():
  data = {"type": "http", "scheme": "bearer", "bearerFormat": "JWT"}

  scheme = dict_to_auth_scheme(data)

  assert isinstance(scheme, HTTPBearer)
  assert scheme.scheme == "bearer"
  assert scheme.bearerFormat == "JWT"


def test_dict_to_auth_scheme_http_base():
  data = {"type": "http", "scheme": "basic"}

  scheme = dict_to_auth_scheme(data)

  assert isinstance(scheme, HTTPBase)
  assert scheme.scheme == "basic"


def test_dict_to_auth_scheme_oauth2():
  data = {
      "type": "oauth2",
      "flows": {
          "authorizationCode": {
              "authorizationUrl": "https://example.com/auth",
              "tokenUrl": "https://example.com/token",
          }
      },
  }

  scheme = dict_to_auth_scheme(data)

  assert isinstance(scheme, OAuth2)
  assert hasattr(scheme.flows, "authorizationCode")


def test_dict_to_auth_scheme_openid_connect():
  data = {
      "type": "openIdConnect",
      "openIdConnectUrl": (
          "https://example.com/.well-known/openid-configuration"
      ),
  }

  scheme = dict_to_auth_scheme(data)

  assert isinstance(scheme, OpenIdConnect)
  assert (
      scheme.openIdConnectUrl
      == "https://example.com/.well-known/openid-configuration"
  )


def test_dict_to_auth_scheme_missing_type():
  data = {"in": "header", "name": "X-API-Key"}
  with pytest.raises(
      ValueError, match="Missing 'type' field in security scheme dictionary."
  ):
    dict_to_auth_scheme(data)


def test_dict_to_auth_scheme_invalid_type():
  data = {"type": "invalid", "in": "header", "name": "X-API-Key"}
  with pytest.raises(ValueError, match="Invalid security scheme type: invalid"):
    dict_to_auth_scheme(data)


def test_dict_to_auth_scheme_invalid_data():
  data = {"type": "apiKey", "in": "header"}  # Missing 'name'
  with pytest.raises(ValueError, match="Invalid security scheme data"):
    dict_to_auth_scheme(data)


if __name__ == "__main__":
  pytest.main([__file__])

==== tests/unittests/tools/openapi_tool/openapi_spec_parser/test.yaml ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

openapi: 3.0.0
servers:
  - url: https://www.googleapis.com/calendar/v3
info:
  contact:
    name: Google
    url: https://google.com
    x-twitter: youtube
  description: Manipulates events and other calendar data.
  license:
    name: Creative Commons Attribution 3.0
    url: http://creativecommons.org/licenses/by/3.0/
  termsOfService: https://developers.google.com/terms/
  title: Calendar API
  version: v3
  x-apiClientRegistration:
    url: https://console.developers.google.com
  x-apisguru-categories:
    - analytics
    - media
  x-logo:
    url: https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_272x92dp.png
  x-origin:
    - format: google
      url: https://calendar-json.googleapis.com/$discovery/rest?version=v3
      version: v1
  x-providerName: googleapis.com
  x-serviceName: calendar
externalDocs:
  url: https://developers.google.com/google-apps/calendar/firstapp
tags:
  - name: acl
  - name: calendarList
  - name: calendars
  - name: channels
  - name: colors
  - name: events
  - name: freebusy
  - name: settings
paths:
  /calendars:
    parameters:
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/userIp"
    post:
      description: Creates a secondary calendar.
      operationId: calendar.calendars.insert
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Calendar"
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Calendar"
          description: Successful response
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/calendar
          Oauth2c:
            - https://www.googleapis.com/auth/calendar
      tags:
        - calendars
  /calendars/{calendarId}:
    delete:
      description: Deletes a secondary calendar. Use calendars.clear for clearing all events on primary calendars.
      operationId: calendar.calendars.delete
      parameters:
        - description: Calendar identifier. To retrieve calendar IDs call the calendarList.list method. If you want to access the primary calendar of the currently logged in user, use the "primary" keyword.
          in: path
          name: calendarId
          required: true
          schema:
            type: string
      responses:
        "200":
          description: Successful response
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/calendar
          Oauth2c:
            - https://www.googleapis.com/auth/calendar
      tags:
        - calendars
    get:
      description: Returns metadata for a calendar.
      operationId: calendar.calendars.get
      parameters:
        - description: Calendar identifier. To retrieve calendar IDs call the calendarList.list method. If you want to access the primary calendar of the currently logged in user, use the "primary" keyword.
          in: path
          name: calendarId
          required: true
          schema:
            type: string
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Calendar"
          description: Successful response
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/calendar
          Oauth2c:
            - https://www.googleapis.com/auth/calendar
        - Oauth2:
            - https://www.googleapis.com/auth/calendar.readonly
          Oauth2c:
            - https://www.googleapis.com/auth/calendar.readonly
      tags:
        - calendars
    parameters:
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/userIp"
    patch:
      description: Updates metadata for a calendar. This method supports patch semantics.
      operationId: calendar.calendars.patch
      parameters:
        - description: Calendar identifier. To retrieve calendar IDs call the calendarList.list method. If you want to access the primary calendar of the currently logged in user, use the "primary" keyword.
          in: path
          name: calendarId
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Calendar"
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Calendar"
          description: Successful response
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/calendar
          Oauth2c:
            - https://www.googleapis.com/auth/calendar
      tags:
        - calendars
    put:
      description: Updates metadata for a calendar.
      operationId: calendar.calendars.update
      parameters:
        - description: Calendar identifier. To retrieve calendar IDs call the calendarList.list method. If you want to access the primary calendar of the currently logged in user, use the "primary" keyword.
          in: path
          name: calendarId
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Calendar"
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Calendar"
          description: Successful response
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/calendar
          Oauth2c:
            - https://www.googleapis.com/auth/calendar
      tags:
        - calendars
components:
  parameters:
    alt:
      description: Data format for the response.
      in: query
      name: alt
      schema:
        enum:
          - json
        type: string
    fields:
      description: Selector specifying which fields to include in a partial response.
      in: query
      name: fields
      schema:
        type: string
    key:
      description: API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.
      in: query
      name: key
      schema:
        type: string
    oauth_token:
      description: OAuth 2.0 token for the current user.
      in: query
      name: oauth_token
      schema:
        type: string
    prettyPrint:
      description: Returns response with indentations and line breaks.
      in: query
      name: prettyPrint
      schema:
        type: boolean
    quotaUser:
      description: An opaque string that represents a user for quota purposes. Must not exceed 40 characters.
      in: query
      name: quotaUser
      schema:
        type: string
    userIp:
      description: Deprecated. Please use quotaUser instead.
      in: query
      name: userIp
      schema:
        type: string
  schemas:
    Acl:
      properties:
        etag:
          description: ETag of the collection.
          type: string
        items:
          description: List of rules on the access control list.
          items:
            $ref: "#/components/schemas/AclRule"
          type: array
        kind:
          default: calendar#acl
          description: Type of the collection ("calendar#acl").
          type: string
        nextPageToken:
          description: Token used to access the next page of this result. Omitted if no further results are available, in which case nextSyncToken is provided.
          type: string
        nextSyncToken:
          description: Token used at a later point in time to retrieve only the entries that have changed since this result was returned. Omitted if further results are available, in which case nextPageToken is provided.
          type: string
      type: object
    AclRule:
      properties:
        etag:
          description: ETag of the resource.
          type: string
        id:
          description: Identifier of the Access Control List (ACL) rule. See Sharing calendars.
          type: string
        kind:
          default: calendar#aclRule
          description: Type of the resource ("calendar#aclRule").
          type: string
        role:
          description: |-
            The role assigned to the scope. Possible values are:
            - "none" - Provides no access.
            - "freeBusyReader" - Provides read access to free/busy information.
            - "reader" - Provides read access to the calendar. Private events will appear to users with reader access, but event details will be hidden.
            - "writer" - Provides read and write access to the calendar. Private events will appear to users with writer access, and event details will be visible.
            - "owner" - Provides ownership of the calendar. This role has all of the permissions of the writer role with the additional ability to see and manipulate ACLs.
          type: string
        scope:
          description: The extent to which calendar access is granted by this ACL rule.
          properties:
            type:
              description: |-
                The type of the scope. Possible values are:
                - "default" - The public scope. This is the default value.
                - "user" - Limits the scope to a single user.
                - "group" - Limits the scope to a group.
                - "domain" - Limits the scope to a domain.  Note: The permissions granted to the "default", or public, scope apply to any user, authenticated or not.
              type: string
            value:
              description: The email address of a user or group, or the name of a domain, depending on the scope type. Omitted for type "default".
              type: string
          type: object
      type: object
    Calendar:
      properties:
        conferenceProperties:
          $ref: "#/components/schemas/ConferenceProperties"
          description: Conferencing properties for this calendar, for example what types of conferences are allowed.
        description:
          description: Description of the calendar. Optional.
          type: string
        etag:
          description: ETag of the resource.
          type: string
        id:
          description: Identifier of the calendar. To retrieve IDs call the calendarList.list() method.
          type: string
        kind:
          default: calendar#calendar
          description: Type of the resource ("calendar#calendar").
          type: string
        location:
          description: Geographic location of the calendar as free-form text. Optional.
          type: string
        summary:
          description: Title of the calendar.
          type: string
        timeZone:
          description: The time zone of the calendar. (Formatted as an IANA Time Zone Database name, e.g. "Europe/Zurich".) Optional.
          type: string
      type: object
    CalendarList:
      properties:
        etag:
          description: ETag of the collection.
          type: string
        items:
          description: Calendars that are present on the user's calendar list.
          items:
            $ref: "#/components/schemas/CalendarListEntry"
          type: array
        kind:
          default: calendar#calendarList
          description: Type of the collection ("calendar#calendarList").
          type: string
        nextPageToken:
          description: Token used to access the next page of this result. Omitted if no further results are available, in which case nextSyncToken is provided.
          type: string
        nextSyncToken:
          description: Token used at a later point in time to retrieve only the entries that have changed since this result was returned. Omitted if further results are available, in which case nextPageToken is provided.
          type: string
      type: object
    CalendarListEntry:
      properties:
        accessRole:
          description: |-
            The effective access role that the authenticated user has on the calendar. Read-only. Possible values are:
            - "freeBusyReader" - Provides read access to free/busy information.
            - "reader" - Provides read access to the calendar. Private events will appear to users with reader access, but event details will be hidden.
            - "writer" - Provides read and write access to the calendar. Private events will appear to users with writer access, and event details will be visible.
            - "owner" - Provides ownership of the calendar. This role has all of the permissions of the writer role with the additional ability to see and manipulate ACLs.
          type: string
        backgroundColor:
          description: The main color of the calendar in the hexadecimal format "#0088aa". This property supersedes the index-based colorId property. To set or change this property, you need to specify colorRgbFormat=true in the parameters of the insert, update and patch methods. Optional.
          type: string
        colorId:
          description: The color of the calendar. This is an ID referring to an entry in the calendar section of the colors definition (see the colors endpoint). This property is superseded by the backgroundColor and foregroundColor properties and can be ignored when using these properties. Optional.
          type: string
        conferenceProperties:
          $ref: "#/components/schemas/ConferenceProperties"
          description: Conferencing properties for this calendar, for example what types of conferences are allowed.
        defaultReminders:
          description: The default reminders that the authenticated user has for this calendar.
          items:
            $ref: "#/components/schemas/EventReminder"
          type: array
        deleted:
          default: false
          description: Whether this calendar list entry has been deleted from the calendar list. Read-only. Optional. The default is False.
          type: boolean
        description:
          description: Description of the calendar. Optional. Read-only.
          type: string
        etag:
          description: ETag of the resource.
          type: string
        foregroundColor:
          description: The foreground color of the calendar in the hexadecimal format "#ffffff". This property supersedes the index-based colorId property. To set or change this property, you need to specify colorRgbFormat=true in the parameters of the insert, update and patch methods. Optional.
          type: string
        hidden:
          default: false
          description: Whether the calendar has been hidden from the list. Optional. The attribute is only returned when the calendar is hidden, in which case the value is true.
          type: boolean
        id:
          description: Identifier of the calendar.
          type: string
        kind:
          default: calendar#calendarListEntry
          description: Type of the resource ("calendar#calendarListEntry").
          type: string
        location:
          description: Geographic location of the calendar as free-form text. Optional. Read-only.
          type: string
        notificationSettings:
          description: The notifications that the authenticated user is receiving for this calendar.
          properties:
            notifications:
              description: The list of notifications set for this calendar.
              items:
                $ref: "#/components/schemas/CalendarNotification"
              type: array
          type: object
        primary:
          default: false
          description: Whether the calendar is the primary calendar of the authenticated user. Read-only. Optional. The default is False.
          type: boolean
        selected:
          default: false
          description: Whether the calendar content shows up in the calendar UI. Optional. The default is False.
          type: boolean
        summary:
          description: Title of the calendar. Read-only.
          type: string
        summaryOverride:
          description: The summary that the authenticated user has set for this calendar. Optional.
          type: string
        timeZone:
          description: The time zone of the calendar. Optional. Read-only.
          type: string
      type: object
    CalendarNotification:
      properties:
        method:
          description: |-
            The method used to deliver the notification. The possible value is:
            - "email" - Notifications are sent via email.
            Required when adding a notification.
          type: string
        type:
          description: |-
            The type of notification. Possible values are:
            - "eventCreation" - Notification sent when a new event is put on the calendar.
            - "eventChange" - Notification sent when an event is changed.
            - "eventCancellation" - Notification sent when an event is cancelled.
            - "eventResponse" - Notification sent when an attendee responds to the event invitation.
            - "agenda" - An agenda with the events of the day (sent out in the morning).
            Required when adding a notification.
          type: string
      type: object
    Channel:
      properties:
        address:
          description: The address where notifications are delivered for this channel.
          type: string
        expiration:
          description: Date and time of notification channel expiration, expressed as a Unix timestamp, in milliseconds. Optional.
          format: int64
          type: string
        id:
          description: A UUID or similar unique string that identifies this channel.
          type: string
        kind:
          default: api#channel
          description: Identifies this as a notification channel used to watch for changes to a resource, which is "api#channel".
          type: string
        params:
          additionalProperties:
            description: Declares a new parameter by name.
            type: string
          description: Additional parameters controlling delivery channel behavior. Optional.
          type: object
        payload:
          description: A Boolean value to indicate whether payload is wanted. Optional.
          type: boolean
        resourceId:
          description: An opaque ID that identifies the resource being watched on this channel. Stable across different API versions.
          type: string
        resourceUri:
          description: A version-specific identifier for the watched resource.
          type: string
        token:
          description: An arbitrary string delivered to the target address with each notification delivered over this channel. Optional.
          type: string
        type:
          description: The type of delivery mechanism used for this channel. Valid values are "web_hook" (or "webhook"). Both values refer to a channel where Http requests are used to deliver messages.
          type: string
      type: object
    ColorDefinition:
      properties:
        background:
          description: The background color associated with this color definition.
          type: string
        foreground:
          description: The foreground color that can be used to write on top of a background with 'background' color.
          type: string
      type: object
    Colors:
      properties:
        calendar:
          additionalProperties:
            $ref: "#/components/schemas/ColorDefinition"
            description: A calendar color definition.
          description: A global palette of calendar colors, mapping from the color ID to its definition. A calendarListEntry resource refers to one of these color IDs in its colorId field. Read-only.
          type: object
        event:
          additionalProperties:
            $ref: "#/components/schemas/ColorDefinition"
            description: An event color definition.
          description: A global palette of event colors, mapping from the color ID to its definition. An event resource may refer to one of these color IDs in its colorId field. Read-only.
          type: object
        kind:
          default: calendar#colors
          description: Type of the resource ("calendar#colors").
          type: string
        updated:
          description: Last modification time of the color palette (as a RFC3339 timestamp). Read-only.
          format: date-time
          type: string
      type: object
    ConferenceData:
      properties:
        conferenceId:
          description: |-
            The ID of the conference.
            Can be used by developers to keep track of conferences, should not be displayed to users.
            The ID value is formed differently for each conference solution type:
            - eventHangout: ID is not set. (This conference type is deprecated.)
            - eventNamedHangout: ID is the name of the Hangout. (This conference type is deprecated.)
            - hangoutsMeet: ID is the 10-letter meeting code, for example aaa-bbbb-ccc.
            - addOn: ID is defined by the third-party provider.  Optional.
          type: string
        conferenceSolution:
          $ref: "#/components/schemas/ConferenceSolution"
          description: |-
            The conference solution, such as Google Meet.
            Unset for a conference with a failed create request.
            Either conferenceSolution and at least one entryPoint, or createRequest is required.
        createRequest:
          $ref: "#/components/schemas/CreateConferenceRequest"
          description: |-
            A request to generate a new conference and attach it to the event. The data is generated asynchronously. To see whether the data is present check the status field.
            Either conferenceSolution and at least one entryPoint, or createRequest is required.
        entryPoints:
          description: |-
            Information about individual conference entry points, such as URLs or phone numbers.
            All of them must belong to the same conference.
            Either conferenceSolution and at least one entryPoint, or createRequest is required.
          items:
            $ref: "#/components/schemas/EntryPoint"
          type: array
        notes:
          description: Additional notes (such as instructions from the domain administrator, legal notices) to display to the user. Can contain HTML. The maximum length is 2048 characters. Optional.
          type: string
        parameters:
          $ref: "#/components/schemas/ConferenceParameters"
          description: Additional properties related to a conference. An example would be a solution-specific setting for enabling video streaming.
        signature:
          description: |-
            The signature of the conference data.
            Generated on server side.
            Unset for a conference with a failed create request.
            Optional for a conference with a pending create request.
          type: string
      type: object
    ConferenceParameters:
      properties:
        addOnParameters:
          $ref: "#/components/schemas/ConferenceParametersAddOnParameters"
          description: Additional add-on specific data.
      type: object
    ConferenceParametersAddOnParameters:
      properties:
        parameters:
          additionalProperties:
            type: string
          type: object
      type: object
    ConferenceProperties:
      properties:
        allowedConferenceSolutionTypes:
          description: |-
            The types of conference solutions that are supported for this calendar.
            The possible values are:
            - "eventHangout"
            - "eventNamedHangout"
            - "hangoutsMeet"  Optional.
          items:
            type: string
          type: array
      type: object
    ConferenceRequestStatus:
      properties:
        statusCode:
          description: |-
            The current status of the conference create request. Read-only.
            The possible values are:
            - "pending": the conference create request is still being processed.
            - "success": the conference create request succeeded, the entry points are populated.
            - "failure": the conference create request failed, there are no entry points.
          type: string
      type: object
    ConferenceSolution:
      properties:
        iconUri:
          description: The user-visible icon for this solution.
          type: string
        key:
          $ref: "#/components/schemas/ConferenceSolutionKey"
          description: The key which can uniquely identify the conference solution for this event.
        name:
          description: The user-visible name of this solution. Not localized.
          type: string
      type: object
    ConferenceSolutionKey:
      properties:
        type:
          description: |-
            The conference solution type.
            If a client encounters an unfamiliar or empty type, it should still be able to display the entry points. However, it should disallow modifications.
            The possible values are:
            - "eventHangout" for Hangouts for consumers (deprecated; existing events may show this conference solution type but new conferences cannot be created)
            - "eventNamedHangout" for classic Hangouts for Google Workspace users (deprecated; existing events may show this conference solution type but new conferences cannot be created)
            - "hangoutsMeet" for Google Meet (http://meet.google.com)
            - "addOn" for 3P conference providers
          type: string
      type: object
    CreateConferenceRequest:
      properties:
        conferenceSolutionKey:
          $ref: "#/components/schemas/ConferenceSolutionKey"
          description: The conference solution, such as Hangouts or Google Meet.
        requestId:
          description: |-
            The client-generated unique ID for this request.
            Clients should regenerate this ID for every new request. If an ID provided is the same as for the previous request, the request is ignored.
          type: string
        status:
          $ref: "#/components/schemas/ConferenceRequestStatus"
          description: The status of the conference create request.
      type: object
    EntryPoint:
      properties:
        accessCode:
          description: |-
            The access code to access the conference. The maximum length is 128 characters.
            When creating new conference data, populate only the subset of {meetingCode, accessCode, passcode, password, pin} fields that match the terminology that the conference provider uses. Only the populated fields should be displayed.
            Optional.
          type: string
        entryPointFeatures:
          description: Features of the entry point, such as being toll or toll-free. One entry point can have multiple features. However, toll and toll-free cannot be both set on the same entry point.
          items:
            type: string
          type: array
        entryPointType:
          description: |-
            The type of the conference entry point.
            Possible values are:
            - "video" - joining a conference over HTTP. A conference can have zero or one video entry point.
            - "phone" - joining a conference by dialing a phone number. A conference can have zero or more phone entry points.
            - "sip" - joining a conference over SIP. A conference can have zero or one sip entry point.
            - "more" - further conference joining instructions, for example additional phone numbers. A conference can have zero or one more entry point. A conference with only a more entry point is not a valid conference.
          type: string
        label:
          description: |-
            The label for the URI. Visible to end users. Not localized. The maximum length is 512 characters.
            Examples:
            - for video: meet.google.com/aaa-bbbb-ccc
            - for phone: +1 123 268 2601
            - for sip: 12345678@altostrat.com
            - for more: should not be filled
            Optional.
          type: string
        meetingCode:
          description: |-
            The meeting code to access the conference. The maximum length is 128 characters.
            When creating new conference data, populate only the subset of {meetingCode, accessCode, passcode, password, pin} fields that match the terminology that the conference provider uses. Only the populated fields should be displayed.
            Optional.
          type: string
        passcode:
          description: |-
            The passcode to access the conference. The maximum length is 128 characters.
            When creating new conference data, populate only the subset of {meetingCode, accessCode, passcode, password, pin} fields that match the terminology that the conference provider uses. Only the populated fields should be displayed.
          type: string
        password:
          description: |-
            The password to access the conference. The maximum length is 128 characters.
            When creating new conference data, populate only the subset of {meetingCode, accessCode, passcode, password, pin} fields that match the terminology that the conference provider uses. Only the populated fields should be displayed.
            Optional.
          type: string
        pin:
          description: |-
            The PIN to access the conference. The maximum length is 128 characters.
            When creating new conference data, populate only the subset of {meetingCode, accessCode, passcode, password, pin} fields that match the terminology that the conference provider uses. Only the populated fields should be displayed.
            Optional.
          type: string
        regionCode:
          description: |-
            The CLDR/ISO 3166 region code for the country associated with this phone access. Example: "SE" for Sweden.
            Calendar backend will populate this field only for EntryPointType.PHONE.
          type: string
        uri:
          description: |-
            The URI of the entry point. The maximum length is 1300 characters.
            Format:
            - for video, http: or https: schema is required.
            - for phone, tel: schema is required. The URI should include the entire dial sequence (e.g., tel:+12345678900,,,123456789;1234).
            - for sip, sip: schema is required, e.g., sip:12345678@myprovider.com.
            - for more, http: or https: schema is required.
          type: string
      type: object
    Error:
      properties:
        domain:
          description: Domain, or broad category, of the error.
          type: string
        reason:
          description: |-
            Specific reason for the error. Some of the possible values are:
            - "groupTooBig" - The group of users requested is too large for a single query.
            - "tooManyCalendarsRequested" - The number of calendars requested is too large for a single query.
            - "notFound" - The requested resource was not found.
            - "internalError" - The API service has encountered an internal error.  Additional error types may be added in the future, so clients should gracefully handle additional error statuses not included in this list.
          type: string
      type: object
    Event:
      properties:
        anyoneCanAddSelf:
          default: false
          description: Whether anyone can invite themselves to the event (deprecated). Optional. The default is False.
          type: boolean
        attachments:
          description: |-
            File attachments for the event.
            In order to modify attachments the supportsAttachments request parameter should be set to true.
            There can be at most 25 attachments per event,
          items:
            $ref: "#/components/schemas/EventAttachment"
          type: array
        attendees:
          description: The attendees of the event. See the Events with attendees guide for more information on scheduling events with other calendar users. Service accounts need to use domain-wide delegation of authority to populate the attendee list.
          items:
            $ref: "#/components/schemas/EventAttendee"
          type: array
        attendeesOmitted:
          default: false
          description: Whether attendees may have been omitted from the event's representation. When retrieving an event, this may be due to a restriction specified by the maxAttendee query parameter. When updating an event, this can be used to only update the participant's response. Optional. The default is False.
          type: boolean
        colorId:
          description: The color of the event. This is an ID referring to an entry in the event section of the colors definition (see the  colors endpoint). Optional.
          type: string
        conferenceData:
          $ref: "#/components/schemas/ConferenceData"
          description: The conference-related information, such as details of a Google Meet conference. To create new conference details use the createRequest field. To persist your changes, remember to set the conferenceDataVersion request parameter to 1 for all event modification requests.
        created:
          description: Creation time of the event (as a RFC3339 timestamp). Read-only.
          format: date-time
          type: string
        creator:
          description: The creator of the event. Read-only.
          properties:
            displayName:
              description: The creator's name, if available.
              type: string
            email:
              description: The creator's email address, if available.
              type: string
            id:
              description: The creator's Profile ID, if available.
              type: string
            self:
              default: false
              description: Whether the creator corresponds to the calendar on which this copy of the event appears. Read-only. The default is False.
              type: boolean
          type: object
        description:
          description: Description of the event. Can contain HTML. Optional.
          type: string
        end:
          $ref: "#/components/schemas/EventDateTime"
          description: The (exclusive) end time of the event. For a recurring event, this is the end time of the first instance.
        endTimeUnspecified:
          default: false
          description: Whether the end time is actually unspecified. An end time is still provided for compatibility reasons, even if this attribute is set to True. The default is False.
          type: boolean
        etag:
          description: ETag of the resource.
          type: string
        eventType:
          default: default
          description: |-
            Specific type of the event. This cannot be modified after the event is created. Possible values are:
            - "default" - A regular event or not further specified.
            - "outOfOffice" - An out-of-office event.
            - "focusTime" - A focus-time event.
            - "workingLocation" - A working location event.  Currently, only "default " and "workingLocation" events can be created using the API. Extended support for other event types will be made available in later releases.
          type: string
        extendedProperties:
          description: Extended properties of the event.
          properties:
            private:
              additionalProperties:
                description: The name of the private property and the corresponding value.
                type: string
              description: Properties that are private to the copy of the event that appears on this calendar.
              type: object
            shared:
              additionalProperties:
                description: The name of the shared property and the corresponding value.
                type: string
              description: Properties that are shared between copies of the event on other attendees' calendars.
              type: object
          type: object
        focusTimeProperties:
          $ref: "#/components/schemas/EventFocusTimeProperties"
          description: Focus Time event data. Used if eventType is focusTime.
        gadget:
          description: A gadget that extends this event. Gadgets are deprecated; this structure is instead only used for returning birthday calendar metadata.
          properties:
            display:
              description: |-
                The gadget's display mode. Deprecated. Possible values are:
                - "icon" - The gadget displays next to the event's title in the calendar view.
                - "chip" - The gadget displays when the event is clicked.
              type: string
            height:
              description: The gadget's height in pixels. The height must be an integer greater than 0. Optional. Deprecated.
              format: int32
              type: integer
            iconLink:
              description: The gadget's icon URL. The URL scheme must be HTTPS. Deprecated.
              type: string
            link:
              description: The gadget's URL. The URL scheme must be HTTPS. Deprecated.
              type: string
            preferences:
              additionalProperties:
                description: The preference name and corresponding value.
                type: string
              description: Preferences.
              type: object
            title:
              description: The gadget's title. Deprecated.
              type: string
            type:
              description: The gadget's type. Deprecated.
              type: string
            width:
              description: The gadget's width in pixels. The width must be an integer greater than 0. Optional. Deprecated.
              format: int32
              type: integer
          type: object
        guestsCanInviteOthers:
          default: true
          description: Whether attendees other than the organizer can invite others to the event. Optional. The default is True.
          type: boolean
        guestsCanModify:
          default: false
          description: Whether attendees other than the organizer can modify the event. Optional. The default is False.
          type: boolean
        guestsCanSeeOtherGuests:
          default: true
          description: Whether attendees other than the organizer can see who the event's attendees are. Optional. The default is True.
          type: boolean
        hangoutLink:
          description: An absolute link to the Google Hangout associated with this event. Read-only.
          type: string
        htmlLink:
          description: An absolute link to this event in the Google Calendar Web UI. Read-only.
          type: string
        iCalUID:
          description: |-
            Event unique identifier as defined in RFC5545. It is used to uniquely identify events accross calendaring systems and must be supplied when importing events via the import method.
            Note that the iCalUID and the id are not identical and only one of them should be supplied at event creation time. One difference in their semantics is that in recurring events, all occurrences of one event have different ids while they all share the same iCalUIDs. To retrieve an event using its iCalUID, call the events.list method using the iCalUID parameter. To retrieve an event using its id, call the events.get method.
          type: string
        id:
          description: |-
            Opaque identifier of the event. When creating new single or recurring events, you can specify their IDs. Provided IDs must follow these rules:
            - characters allowed in the ID are those used in base32hex encoding, i.e. lowercase letters a-v and digits 0-9, see section 3.1.2 in RFC2938
            - the length of the ID must be between 5 and 1024 characters
            - the ID must be unique per calendar  Due to the globally distributed nature of the system, we cannot guarantee that ID collisions will be detected at event creation time. To minimize the risk of collisions we recommend using an established UUID algorithm such as one described in RFC4122.
            If you do not specify an ID, it will be automatically generated by the server.
            Note that the icalUID and the id are not identical and only one of them should be supplied at event creation time. One difference in their semantics is that in recurring events, all occurrences of one event have different ids while they all share the same icalUIDs.
          type: string
        kind:
          default: calendar#event
          description: Type of the resource ("calendar#event").
          type: string
        location:
          description: Geographic location of the event as free-form text. Optional.
          type: string
        locked:
          default: false
          description: Whether this is a locked event copy where no changes can be made to the main event fields "summary", "description", "location", "start", "end" or "recurrence". The default is False. Read-Only.
          type: boolean
        organizer:
          description: The organizer of the event. If the organizer is also an attendee, this is indicated with a separate entry in attendees with the organizer field set to True. To change the organizer, use the move operation. Read-only, except when importing an event.
          properties:
            displayName:
              description: The organizer's name, if available.
              type: string
            email:
              description: The organizer's email address, if available. It must be a valid email address as per RFC5322.
              type: string
            id:
              description: The organizer's Profile ID, if available.
              type: string
            self:
              default: false
              description: Whether the organizer corresponds to the calendar on which this copy of the event appears. Read-only. The default is False.
              type: boolean
          type: object
        originalStartTime:
          $ref: "#/components/schemas/EventDateTime"
          description: For an instance of a recurring event, this is the time at which this event would start according to the recurrence data in the recurring event identified by recurringEventId. It uniquely identifies the instance within the recurring event series even if the instance was moved to a different time. Immutable.
        outOfOfficeProperties:
          $ref: "#/components/schemas/EventOutOfOfficeProperties"
          description: Out of office event data. Used if eventType is outOfOffice.
        privateCopy:
          default: false
          description: If set to True, Event propagation is disabled. Note that it is not the same thing as Private event properties. Optional. Immutable. The default is False.
          type: boolean
        recurrence:
          description: List of RRULE, EXRULE, RDATE and EXDATE lines for a recurring event, as specified in RFC5545. Note that DTSTART and DTEND lines are not allowed in this field; event start and end times are specified in the start and end fields. This field is omitted for single events or instances of recurring events.
          items:
            type: string
          type: array
        recurringEventId:
          description: For an instance of a recurring event, this is the id of the recurring event to which this instance belongs. Immutable.
          type: string
        reminders:
          description: Information about the event's reminders for the authenticated user.
          properties:
            overrides:
              description: If the event doesn't use the default reminders, this lists the reminders specific to the event, or, if not set, indicates that no reminders are set for this event. The maximum number of override reminders is 5.
              items:
                $ref: "#/components/schemas/EventReminder"
              type: array
            useDefault:
              description: Whether the default reminders of the calendar apply to the event.
              type: boolean
          type: object
        sequence:
          description: Sequence number as per iCalendar.
          format: int32
          type: integer
        source:
          description: Source from which the event was created. For example, a web page, an email message or any document identifiable by an URL with HTTP or HTTPS scheme. Can only be seen or modified by the creator of the event.
          properties:
            title:
              description: Title of the source; for example a title of a web page or an email subject.
              type: string
            url:
              description: URL of the source pointing to a resource. The URL scheme must be HTTP or HTTPS.
              type: string
          type: object
        start:
          $ref: "#/components/schemas/EventDateTime"
          description: The (inclusive) start time of the event. For a recurring event, this is the start time of the first instance.
        status:
          description: |-
            Status of the event. Optional. Possible values are:
            - "confirmed" - The event is confirmed. This is the default status.
            - "tentative" - The event is tentatively confirmed.
            - "cancelled" - The event is cancelled (deleted). The list method returns cancelled events only on incremental sync (when syncToken or updatedMin are specified) or if the showDeleted flag is set to true. The get method always returns them.
            A cancelled status represents two different states depending on the event type:
            - Cancelled exceptions of an uncancelled recurring event indicate that this instance should no longer be presented to the user. Clients should store these events for the lifetime of the parent recurring event.
            Cancelled exceptions are only guaranteed to have values for the id, recurringEventId and originalStartTime fields populated. The other fields might be empty.
            - All other cancelled events represent deleted events. Clients should remove their locally synced copies. Such cancelled events will eventually disappear, so do not rely on them being available indefinitely.
            Deleted events are only guaranteed to have the id field populated.   On the organizer's calendar, cancelled events continue to expose event details (summary, location, etc.) so that they can be restored (undeleted). Similarly, the events to which the user was invited and that they manually removed continue to provide details. However, incremental sync requests with showDeleted set to false will not return these details.
            If an event changes its organizer (for example via the move operation) and the original organizer is not on the attendee list, it will leave behind a cancelled event where only the id field is guaranteed to be populated.
          type: string
        summary:
          description: Title of the event.
          type: string
        transparency:
          default: opaque
          description: |-
            Whether the event blocks time on the calendar. Optional. Possible values are:
            - "opaque" - Default value. The event does block time on the calendar. This is equivalent to setting Show me as to Busy in the Calendar UI.
            - "transparent" - The event does not block time on the calendar. This is equivalent to setting Show me as to Available in the Calendar UI.
          type: string
        updated:
          description: Last modification time of the event (as a RFC3339 timestamp). Read-only.
          format: date-time
          type: string
        visibility:
          default: default
          description: |-
            Visibility of the event. Optional. Possible values are:
            - "default" - Uses the default visibility for events on the calendar. This is the default value.
            - "public" - The event is public and event details are visible to all readers of the calendar.
            - "private" - The event is private and only event attendees may view event details.
            - "confidential" - The event is private. This value is provided for compatibility reasons.
          type: string
        workingLocationProperties:
          $ref: "#/components/schemas/EventWorkingLocationProperties"
          description: Working location event data.
      type: object
    EventAttachment:
      properties:
        fileId:
          description: |-
            ID of the attached file. Read-only.
            For Google Drive files, this is the ID of the corresponding Files resource entry in the Drive API.
          type: string
        fileUrl:
          description: |-
            URL link to the attachment.
            For adding Google Drive file attachments use the same format as in alternateLink property of the Files resource in the Drive API.
            Required when adding an attachment.
          type: string
        iconLink:
          description: URL link to the attachment's icon. This field can only be modified for custom third-party attachments.
          type: string
        mimeType:
          description: Internet media type (MIME type) of the attachment.
          type: string
        title:
          description: Attachment title.
          type: string
      type: object
    EventAttendee:
      properties:
        additionalGuests:
          default: 0
          description: Number of additional guests. Optional. The default is 0.
          format: int32
          type: integer
        comment:
          description: The attendee's response comment. Optional.
          type: string
        displayName:
          description: The attendee's name, if available. Optional.
          type: string
        email:
          description: |-
            The attendee's email address, if available. This field must be present when adding an attendee. It must be a valid email address as per RFC5322.
            Required when adding an attendee.
          type: string
        id:
          description: The attendee's Profile ID, if available.
          type: string
        optional:
          default: false
          description: Whether this is an optional attendee. Optional. The default is False.
          type: boolean
        organizer:
          description: Whether the attendee is the organizer of the event. Read-only. The default is False.
          type: boolean
        resource:
          default: false
          description: Whether the attendee is a resource. Can only be set when the attendee is added to the event for the first time. Subsequent modifications are ignored. Optional. The default is False.
          type: boolean
        responseStatus:
          description: |-
            The attendee's response status. Possible values are:
            - "needsAction" - The attendee has not responded to the invitation (recommended for new events).
            - "declined" - The attendee has declined the invitation.
            - "tentative" - The attendee has tentatively accepted the invitation.
            - "accepted" - The attendee has accepted the invitation.  Warning: If you add an event using the values declined, tentative, or accepted, attendees with the "Add invitations to my calendar" setting set to "When I respond to invitation in email" won't see an event on their calendar unless they choose to change their invitation response in the event invitation email.
          type: string
        self:
          default: false
          description: Whether this entry represents the calendar on which this copy of the event appears. Read-only. The default is False.
          type: boolean
      type: object
    EventDateTime:
      properties:
        date:
          description: The date, in the format "yyyy-mm-dd", if this is an all-day event.
          format: date
          type: string
        dateTime:
          description: The time, as a combined date-time value (formatted according to RFC3339). A time zone offset is required unless a time zone is explicitly specified in timeZone.
          format: date-time
          type: string
        timeZone:
          description: The time zone in which the time is specified. (Formatted as an IANA Time Zone Database name, e.g. "Europe/Zurich".) For recurring events this field is required and specifies the time zone in which the recurrence is expanded. For single events this field is optional and indicates a custom time zone for the event start/end.
          type: string
      type: object
    EventFocusTimeProperties:
      properties:
        autoDeclineMode:
          description: Whether to decline meeting invitations which overlap Focus Time events. Valid values are declineNone, meaning that no meeting invitations are declined; declineAllConflictingInvitations, meaning that all conflicting meeting invitations that conflict with the event are declined; and declineOnlyNewConflictingInvitations, meaning that only new conflicting meeting invitations which arrive while the Focus Time event is present are to be declined.
          type: string
        chatStatus:
          description: The status to mark the user in Chat and related products. This can be available or doNotDisturb.
          type: string
        declineMessage:
          description: Response message to set if an existing event or new invitation is automatically declined by Calendar.
          type: string
      type: object
    EventOutOfOfficeProperties:
      properties:
        autoDeclineMode:
          description: Whether to decline meeting invitations which overlap Out of office events. Valid values are declineNone, meaning that no meeting invitations are declined; declineAllConflictingInvitations, meaning that all conflicting meeting invitations that conflict with the event are declined; and declineOnlyNewConflictingInvitations, meaning that only new conflicting meeting invitations which arrive while the Out of office event is present are to be declined.
          type: string
        declineMessage:
          description: Response message to set if an existing event or new invitation is automatically declined by Calendar.
          type: string
      type: object
    EventReminder:
      properties:
        method:
          description: |-
            The method used by this reminder. Possible values are:
            - "email" - Reminders are sent via email.
            - "popup" - Reminders are sent via a UI popup.
            Required when adding a reminder.
          type: string
        minutes:
          description: |-
            Number of minutes before the start of the event when the reminder should trigger. Valid values are between 0 and 40320 (4 weeks in minutes).
            Required when adding a reminder.
          format: int32
          type: integer
      type: object
    EventWorkingLocationProperties:
      properties:
        customLocation:
          description: If present, specifies that the user is working from a custom location.
          properties:
            label:
              description: An optional extra label for additional information.
              type: string
          type: object
        homeOffice:
          description: If present, specifies that the user is working at home.
        officeLocation:
          description: If present, specifies that the user is working from an office.
          properties:
            buildingId:
              description: An optional building identifier. This should reference a building ID in the organization's Resources database.
              type: string
            deskId:
              description: An optional desk identifier.
              type: string
            floorId:
              description: An optional floor identifier.
              type: string
            floorSectionId:
              description: An optional floor section identifier.
              type: string
            label:
              description: The office name that's displayed in Calendar Web and Mobile clients. We recommend you reference a building name in the organization's Resources database.
              type: string
          type: object
        type:
          description: |-
            Type of the working location. Possible values are:
            - "homeOffice" - The user is working at home.
            - "officeLocation" - The user is working from an office.
            - "customLocation" - The user is working from a custom location.  Any details are specified in a sub-field of the specified name, but this field may be missing if empty. Any other fields are ignored.
            Required when adding working location properties.
          type: string
      type: object
    Events:
      properties:
        accessRole:
          description: |-
            The user's access role for this calendar. Read-only. Possible values are:
            - "none" - The user has no access.
            - "freeBusyReader" - The user has read access to free/busy information.
            - "reader" - The user has read access to the calendar. Private events will appear to users with reader access, but event details will be hidden.
            - "writer" - The user has read and write access to the calendar. Private events will appear to users with writer access, and event details will be visible.
            - "owner" - The user has ownership of the calendar. This role has all of the permissions of the writer role with the additional ability to see and manipulate ACLs.
          type: string
        defaultReminders:
          description: The default reminders on the calendar for the authenticated user. These reminders apply to all events on this calendar that do not explicitly override them (i.e. do not have reminders.useDefault set to True).
          items:
            $ref: "#/components/schemas/EventReminder"
          type: array
        description:
          description: Description of the calendar. Read-only.
          type: string
        etag:
          description: ETag of the collection.
          type: string
        items:
          description: List of events on the calendar.
          items:
            $ref: "#/components/schemas/Event"
          type: array
        kind:
          default: calendar#events
          description: Type of the collection ("calendar#events").
          type: string
        nextPageToken:
          description: Token used to access the next page of this result. Omitted if no further results are available, in which case nextSyncToken is provided.
          type: string
        nextSyncToken:
          description: Token used at a later point in time to retrieve only the entries that have changed since this result was returned. Omitted if further results are available, in which case nextPageToken is provided.
          type: string
        summary:
          description: Title of the calendar. Read-only.
          type: string
        timeZone:
          description: The time zone of the calendar. Read-only.
          type: string
        updated:
          description: Last modification time of the calendar (as a RFC3339 timestamp). Read-only.
          format: date-time
          type: string
      type: object
    FreeBusyCalendar:
      properties:
        busy:
          description: List of time ranges during which this calendar should be regarded as busy.
          items:
            $ref: "#/components/schemas/TimePeriod"
          type: array
        errors:
          description: Optional error(s) (if computation for the calendar failed).
          items:
            $ref: "#/components/schemas/Error"
          type: array
      type: object
    FreeBusyGroup:
      properties:
        calendars:
          description: List of calendars' identifiers within a group.
          items:
            type: string
          type: array
        errors:
          description: Optional error(s) (if computation for the group failed).
          items:
            $ref: "#/components/schemas/Error"
          type: array
      type: object
    FreeBusyRequest:
      properties:
        calendarExpansionMax:
          description: Maximal number of calendars for which FreeBusy information is to be provided. Optional. Maximum value is 50.
          format: int32
          type: integer
        groupExpansionMax:
          description: Maximal number of calendar identifiers to be provided for a single group. Optional. An error is returned for a group with more members than this value. Maximum value is 100.
          format: int32
          type: integer
        items:
          description: List of calendars and/or groups to query.
          items:
            $ref: "#/components/schemas/FreeBusyRequestItem"
          type: array
        timeMax:
          description: The end of the interval for the query formatted as per RFC3339.
          format: date-time
          type: string
        timeMin:
          description: The start of the interval for the query formatted as per RFC3339.
          format: date-time
          type: string
        timeZone:
          default: UTC
          description: Time zone used in the response. Optional. The default is UTC.
          type: string
      type: object
    FreeBusyRequestItem:
      properties:
        id:
          description: The identifier of a calendar or a group.
          type: string
      type: object
    FreeBusyResponse:
      properties:
        calendars:
          additionalProperties:
            $ref: "#/components/schemas/FreeBusyCalendar"
            description: Free/busy expansions for a single calendar.
          description: List of free/busy information for calendars.
          type: object
        groups:
          additionalProperties:
            $ref: "#/components/schemas/FreeBusyGroup"
            description: List of calendars that are members of this group.
          description: Expansion of groups.
          type: object
        kind:
          default: calendar#freeBusy
          description: Type of the resource ("calendar#freeBusy").
          type: string
        timeMax:
          description: The end of the interval.
          format: date-time
          type: string
        timeMin:
          description: The start of the interval.
          format: date-time
          type: string
      type: object
    Setting:
      properties:
        etag:
          description: ETag of the resource.
          type: string
        id:
          description: The id of the user setting.
          type: string
        kind:
          default: calendar#setting
          description: Type of the resource ("calendar#setting").
          type: string
        value:
          description: Value of the user setting. The format of the value depends on the ID of the setting. It must always be a UTF-8 string of length up to 1024 characters.
          type: string
      type: object
    Settings:
      properties:
        etag:
          description: Etag of the collection.
          type: string
        items:
          description: List of user settings.
          items:
            $ref: "#/components/schemas/Setting"
          type: array
        kind:
          default: calendar#settings
          description: Type of the collection ("calendar#settings").
          type: string
        nextPageToken:
          description: Token used to access the next page of this result. Omitted if no further results are available, in which case nextSyncToken is provided.
          type: string
        nextSyncToken:
          description: Token used at a later point in time to retrieve only the entries that have changed since this result was returned. Omitted if further results are available, in which case nextPageToken is provided.
          type: string
      type: object
    TimePeriod:
      properties:
        end:
          description: The (exclusive) end of the time period.
          format: date-time
          type: string
        start:
          description: The (inclusive) start of the time period.
          format: date-time
          type: string
      type: object
  securitySchemes:
    Oauth2:
      description: Oauth 2.0 implicit authentication
      flows:
        implicit:
          authorizationUrl: https://accounts.google.com/o/oauth2/auth
          scopes:
            https://www.googleapis.com/auth/calendar: See, edit, share, and permanently delete all the calendars you can access using Google Calendar
            https://www.googleapis.com/auth/calendar.events: View and edit events on all your calendars
            https://www.googleapis.com/auth/calendar.events.readonly: View events on all your calendars
            https://www.googleapis.com/auth/calendar.readonly: See and download any calendar you can access using your Google Calendar
            https://www.googleapis.com/auth/calendar.settings.readonly: View your Calendar settings
      type: oauth2
    Oauth2c:
      description: Oauth 2.0 authorizationCode authentication
      flows:
        authorizationCode:
          authorizationUrl: https://accounts.google.com/o/oauth2/auth
          scopes:
            https://www.googleapis.com/auth/calendar: See, edit, share, and permanently delete all the calendars you can access using Google Calendar
            https://www.googleapis.com/auth/calendar.events: View and edit events on all your calendars
            https://www.googleapis.com/auth/calendar.events.readonly: View events on all your calendars
            https://www.googleapis.com/auth/calendar.readonly: See and download any calendar you can access using your Google Calendar
            https://www.googleapis.com/auth/calendar.settings.readonly: View your Calendar settings
          tokenUrl: https://accounts.google.com/o/oauth2/token
      type: oauth2

==== tests/unittests/tools/openapi_tool/openapi_spec_parser/test_openapi_toolset.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
from typing import Dict

from fastapi.openapi.models import APIKey
from fastapi.openapi.models import APIKeyIn
from fastapi.openapi.models import MediaType
from fastapi.openapi.models import OAuth2
from fastapi.openapi.models import ParameterInType
from fastapi.openapi.models import SecuritySchemeType
from google.adk.auth.auth_credential import AuthCredential
from google.adk.auth.auth_credential import AuthCredentialTypes
from google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset import OpenAPIToolset
from google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool import RestApiTool
import pytest
import yaml


def load_spec(file_path: str) -> Dict:
  """Loads the OpenAPI specification from a YAML file."""
  with open(file_path, "r", encoding="utf-8") as f:
    return yaml.safe_load(f)


@pytest.fixture
def openapi_spec() -> Dict:
  """Fixture to load the OpenAPI specification."""
  current_dir = os.path.dirname(os.path.abspath(__file__))
  # Join the directory path with the filename
  yaml_path = os.path.join(current_dir, "test.yaml")
  return load_spec(yaml_path)


def test_openapi_toolset_initialization_from_dict(openapi_spec: Dict):
  """Test initialization of OpenAPIToolset with a dictionary."""
  toolset = OpenAPIToolset(spec_dict=openapi_spec)
  assert isinstance(toolset._tools, list)
  assert len(toolset._tools) == 5
  assert all(isinstance(tool, RestApiTool) for tool in toolset._tools)


def test_openapi_toolset_initialization_from_yaml_string(openapi_spec: Dict):
  """Test initialization of OpenAPIToolset with a YAML string."""
  spec_str = yaml.dump(openapi_spec)
  toolset = OpenAPIToolset(spec_str=spec_str, spec_str_type="yaml")
  assert isinstance(toolset._tools, list)
  assert len(toolset._tools) == 5
  assert all(isinstance(tool, RestApiTool) for tool in toolset._tools)


def test_openapi_toolset_tool_existing(openapi_spec: Dict):
  """Test the tool() method for an existing tool."""
  toolset = OpenAPIToolset(spec_dict=openapi_spec)
  tool_name = "calendar_calendars_insert"  # Example operationId from the spec
  tool = toolset.get_tool(tool_name)
  assert isinstance(tool, RestApiTool)
  assert tool.name == tool_name
  assert tool.description == "Creates a secondary calendar."
  assert tool.endpoint.method == "post"
  assert tool.endpoint.base_url == "https://www.googleapis.com/calendar/v3"
  assert tool.endpoint.path == "/calendars"
  assert tool.is_long_running is False
  assert tool.operation.operationId == "calendar.calendars.insert"
  assert tool.operation.description == "Creates a secondary calendar."
  assert isinstance(
      tool.operation.requestBody.content["application/json"], MediaType
  )
  assert len(tool.operation.responses) == 1
  response = tool.operation.responses["200"]
  assert response.description == "Successful response"
  assert isinstance(response.content["application/json"], MediaType)
  assert isinstance(tool.auth_scheme, OAuth2)

  tool_name = "calendar_calendars_get"
  tool = toolset.get_tool(tool_name)
  assert isinstance(tool, RestApiTool)
  assert tool.name == tool_name
  assert tool.description == "Returns metadata for a calendar."
  assert tool.endpoint.method == "get"
  assert tool.endpoint.base_url == "https://www.googleapis.com/calendar/v3"
  assert tool.endpoint.path == "/calendars/{calendarId}"
  assert tool.is_long_running is False
  assert tool.operation.operationId == "calendar.calendars.get"
  assert tool.operation.description == "Returns metadata for a calendar."
  assert len(tool.operation.parameters) == 1
  assert tool.operation.parameters[0].name == "calendarId"
  assert tool.operation.parameters[0].in_ == ParameterInType.path
  assert tool.operation.parameters[0].required is True
  assert tool.operation.parameters[0].schema_.type == "string"
  assert (
      tool.operation.parameters[0].description
      == "Calendar identifier. To retrieve calendar IDs call the"
      " calendarList.list method. If you want to access the primary calendar"
      ' of the currently logged in user, use the "primary" keyword.'
  )
  assert isinstance(tool.auth_scheme, OAuth2)

  assert isinstance(toolset.get_tool("calendar_calendars_update"), RestApiTool)
  assert isinstance(toolset.get_tool("calendar_calendars_delete"), RestApiTool)
  assert isinstance(toolset.get_tool("calendar_calendars_patch"), RestApiTool)


def test_openapi_toolset_tool_non_existing(openapi_spec: Dict):
  """Test the tool() method for a non-existing tool."""
  toolset = OpenAPIToolset(spec_dict=openapi_spec)
  tool = toolset.get_tool("non_existent_tool")
  assert tool is None


def test_openapi_toolset_configure_auth_on_init(openapi_spec: Dict):
  """Test configuring auth during initialization."""

  auth_scheme = APIKey(**{
      "in": APIKeyIn.header,  # Use alias name in dict
      "name": "api_key",
      "type": SecuritySchemeType.http,
  })
  auth_credential = AuthCredential(auth_type=AuthCredentialTypes.API_KEY)
  toolset = OpenAPIToolset(
      spec_dict=openapi_spec,
      auth_scheme=auth_scheme,
      auth_credential=auth_credential,
  )
  for tool in toolset._tools:
    assert tool.auth_scheme == auth_scheme
    assert tool.auth_credential == auth_credential

==== tests/unittests/tools/openapi_tool/openapi_spec_parser/test_tool_auth_handler.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from typing import Optional
from unittest.mock import MagicMock

from google.adk.agents.invocation_context import InvocationContext
from google.adk.agents.llm_agent import LlmAgent
from google.adk.auth.auth_credential import AuthCredential
from google.adk.auth.auth_credential import AuthCredentialTypes
from google.adk.auth.auth_credential import HttpAuth
from google.adk.auth.auth_credential import HttpCredentials
from google.adk.auth.auth_credential import OAuth2Auth
from google.adk.auth.auth_schemes import AuthScheme
from google.adk.sessions.in_memory_session_service import InMemorySessionService
from google.adk.sessions.session import Session
from google.adk.tools.openapi_tool.auth.auth_helpers import openid_dict_to_scheme_credential
from google.adk.tools.openapi_tool.auth.auth_helpers import token_to_scheme_credential
from google.adk.tools.openapi_tool.auth.credential_exchangers.auto_auth_credential_exchanger import OAuth2CredentialExchanger
from google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler import ToolAuthHandler
from google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler import ToolContextCredentialStore
from google.adk.tools.tool_context import ToolContext
import pytest


# Helper function to create a mock ToolContext
def create_mock_tool_context():
  return ToolContext(
      function_call_id='test-fc-id',
      invocation_context=InvocationContext(
          agent=LlmAgent(name='test'),
          session=Session(app_name='test', user_id='123', id='123'),
          invocation_id='123',
          session_service=InMemorySessionService(),
      ),
  )


# Test cases for OpenID Connect
class MockOpenIdConnectCredentialExchanger(OAuth2CredentialExchanger):

  def __init__(
      self, expected_scheme, expected_credential, expected_access_token
  ):
    self.expected_scheme = expected_scheme
    self.expected_credential = expected_credential
    self.expected_access_token = expected_access_token

  def exchange_credential(
      self,
      auth_scheme: AuthScheme,
      auth_credential: Optional[AuthCredential] = None,
  ) -> AuthCredential:
    if auth_credential.oauth2 and (
        auth_credential.oauth2.auth_response_uri
        or auth_credential.oauth2.auth_code
    ):
      auth_code = (
          auth_credential.oauth2.auth_response_uri
          if auth_credential.oauth2.auth_response_uri
          else auth_credential.oauth2.auth_code
      )
      # Simulate the token exchange
      updated_credential = AuthCredential(
          auth_type=AuthCredentialTypes.HTTP,  # Store as a bearer token
          http=HttpAuth(
              scheme='bearer',
              credentials=HttpCredentials(
                  token=auth_code + self.expected_access_token
              ),
          ),
      )
      return updated_credential

    # simulate the case of getting auth_uri
    return None


def get_mock_openid_scheme_credential():
  config_dict = {
      'authorization_endpoint': 'test.com',
      'token_endpoint': 'test.com',
  }
  scopes = ['test_scope']
  credential_dict = {
      'client_id': '123',
      'client_secret': '456',
      'redirect_uri': 'test.com',
  }
  return openid_dict_to_scheme_credential(config_dict, scopes, credential_dict)


# Fixture for the OpenID Connect security scheme
@pytest.fixture
def openid_connect_scheme():
  scheme, _ = get_mock_openid_scheme_credential()
  return scheme


# Fixture for a base OpenID Connect credential
@pytest.fixture
def openid_connect_credential():
  _, credential = get_mock_openid_scheme_credential()
  return credential


def test_openid_connect_no_auth_response(
    openid_connect_scheme, openid_connect_credential
):
  # Setup Mock exchanger
  mock_exchanger = MockOpenIdConnectCredentialExchanger(
      openid_connect_scheme, openid_connect_credential, None
  )
  tool_context = create_mock_tool_context()
  credential_store = ToolContextCredentialStore(tool_context=tool_context)
  handler = ToolAuthHandler(
      tool_context,
      openid_connect_scheme,
      openid_connect_credential,
      credential_exchanger=mock_exchanger,
      credential_store=credential_store,
  )
  result = handler.prepare_auth_credentials()
  assert result.state == 'pending'
  assert result.auth_credential == openid_connect_credential


def test_openid_connect_with_auth_response(
    openid_connect_scheme, openid_connect_credential, monkeypatch
):
  mock_exchanger = MockOpenIdConnectCredentialExchanger(
      openid_connect_scheme,
      openid_connect_credential,
      'test_access_token',
  )
  tool_context = create_mock_tool_context()

  mock_auth_handler = MagicMock()
  mock_auth_handler.get_auth_response.return_value = AuthCredential(
      auth_type=AuthCredentialTypes.OPEN_ID_CONNECT,
      oauth2=OAuth2Auth(auth_response_uri='test_auth_response_uri'),
  )
  mock_auth_handler_path = 'google.adk.tools.tool_context.AuthHandler'
  monkeypatch.setattr(
      mock_auth_handler_path, lambda *args, **kwargs: mock_auth_handler
  )

  credential_store = ToolContextCredentialStore(tool_context=tool_context)
  handler = ToolAuthHandler(
      tool_context,
      openid_connect_scheme,
      openid_connect_credential,
      credential_exchanger=mock_exchanger,
      credential_store=credential_store,
  )
  result = handler.prepare_auth_credentials()
  assert result.state == 'done'
  assert result.auth_credential.auth_type == AuthCredentialTypes.HTTP
  assert 'test_access_token' in result.auth_credential.http.credentials.token
  # Verify that the credential was stored:
  stored_credential = credential_store.get_credential(
      openid_connect_scheme, openid_connect_credential
  )
  assert stored_credential == result.auth_credential
  mock_auth_handler.get_auth_response.assert_called_once()


def test_openid_connect_existing_token(
    openid_connect_scheme, openid_connect_credential
):
  _, existing_credential = token_to_scheme_credential(
      'oauth2Token', 'header', 'bearer', '123123123'
  )
  tool_context = create_mock_tool_context()
  # Store the credential to simulate existing credential
  credential_store = ToolContextCredentialStore(tool_context=tool_context)
  key = credential_store.get_credential_key(
      openid_connect_scheme, openid_connect_credential
  )
  credential_store.store_credential(key, existing_credential)

  handler = ToolAuthHandler(
      tool_context,
      openid_connect_scheme,
      openid_connect_credential,
      credential_store=credential_store,
  )
  result = handler.prepare_auth_credentials()
  assert result.state == 'done'
  assert result.auth_credential == existing_credential

==== tests/unittests/tools/openapi_tool/openapi_spec_parser/test_rest_api_tool.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import json
from unittest.mock import MagicMock, patch

from fastapi.openapi.models import MediaType, Operation
from fastapi.openapi.models import Parameter as OpenAPIParameter
from fastapi.openapi.models import RequestBody
from fastapi.openapi.models import Schema as OpenAPISchema
from google.adk.sessions.state import State
from google.adk.tools.openapi_tool.auth.auth_helpers import token_to_scheme_credential
from google.adk.tools.openapi_tool.common.common import ApiParameter
from google.adk.tools.openapi_tool.openapi_spec_parser.openapi_spec_parser import OperationEndpoint
from google.adk.tools.openapi_tool.openapi_spec_parser.operation_parser import OperationParser
from google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool import (
    RestApiTool,
    snake_to_lower_camel,
    to_gemini_schema,
)
from google.adk.tools.tool_context import ToolContext
from google.genai.types import FunctionDeclaration, Schema, Type
import pytest


class TestRestApiTool:

  @pytest.fixture
  def mock_tool_context(self):
    """Fixture for a mock OperationParser."""
    mock_context = MagicMock(spec=ToolContext)
    mock_context.state = State({}, {})
    mock_context.get_auth_response.return_value = {}
    mock_context.request_credential.return_value = {}
    return mock_context

  @pytest.fixture
  def mock_operation_parser(self):
    """Fixture for a mock OperationParser."""
    mock_parser = MagicMock(spec=OperationParser)
    mock_parser.get_function_name.return_value = "mock_function_name"
    mock_parser.get_json_schema.return_value = {}
    mock_parser.get_parameters.return_value = []
    mock_parser.get_return_type_hint.return_value = "str"
    mock_parser.get_pydoc_string.return_value = "Mock docstring"
    mock_parser.get_signature_parameters.return_value = []
    mock_parser.get_return_type_value.return_value = str
    mock_parser.get_annotations.return_value = {}
    return mock_parser

  @pytest.fixture
  def sample_endpoint(self):
    return OperationEndpoint(
        base_url="https://example.com", path="/test", method="GET"
    )

  @pytest.fixture
  def sample_operation(self):
    return Operation(
        operationId="testOperation",
        description="Test operation",
        parameters=[],
        requestBody=RequestBody(
            content={
                "application/json": MediaType(
                    schema=OpenAPISchema(
                        type="object",
                        properties={
                            "testBodyParam": OpenAPISchema(type="string")
                        },
                    )
                )
            }
        ),
    )

  @pytest.fixture
  def sample_api_parameters(self):
    return [
        ApiParameter(
            original_name="test_param",
            py_name="test_param",
            param_location="query",
            param_schema=OpenAPISchema(type="string"),
            is_required=True,
        ),
        ApiParameter(
            original_name="",
            py_name="test_body_param",
            param_location="body",
            param_schema=OpenAPISchema(type="string"),
            is_required=True,
        ),
    ]

  @pytest.fixture
  def sample_return_parameter(self):
    return ApiParameter(
        original_name="test_param",
        py_name="test_param",
        param_location="query",
        param_schema=OpenAPISchema(type="string"),
        is_required=True,
    )

  @pytest.fixture
  def sample_auth_scheme(self):
    scheme, _ = token_to_scheme_credential(
        "apikey", "header", "", "sample_auth_credential_internal_test"
    )
    return scheme

  @pytest.fixture
  def sample_auth_credential(self):
    _, credential = token_to_scheme_credential(
        "apikey", "header", "", "sample_auth_credential_internal_test"
    )
    return credential

  def test_init(
      self,
      sample_endpoint,
      sample_operation,
      sample_auth_scheme,
      sample_auth_credential,
  ):
    tool = RestApiTool(
        name="test_tool",
        description="Test Tool",
        endpoint=sample_endpoint,
        operation=sample_operation,
        auth_scheme=sample_auth_scheme,
        auth_credential=sample_auth_credential,
    )
    assert tool.name == "test_tool"
    assert tool.description == "Test Tool"
    assert tool.endpoint == sample_endpoint
    assert tool.operation == sample_operation
    assert tool.auth_credential == sample_auth_credential
    assert tool.auth_scheme == sample_auth_scheme
    assert tool.credential_exchanger is not None

  def test_from_parsed_operation_str(
      self,
      sample_endpoint,
      sample_api_parameters,
      sample_return_parameter,
      sample_operation,
  ):
    parsed_operation_str = json.dumps({
        "name": "test_operation",
        "description": "Test Description",
        "endpoint": sample_endpoint.model_dump(),
        "operation": sample_operation.model_dump(),
        "auth_scheme": None,
        "auth_credential": None,
        "parameters": [p.model_dump() for p in sample_api_parameters],
        "return_value": sample_return_parameter.model_dump(),
    })

    tool = RestApiTool.from_parsed_operation_str(parsed_operation_str)
    assert tool.name == "test_operation"

  def test_get_declaration(
      self, sample_endpoint, sample_operation, mock_operation_parser
  ):
    tool = RestApiTool(
        name="test_tool",
        description="Test description",
        endpoint=sample_endpoint,
        operation=sample_operation,
        should_parse_operation=False,
    )
    tool._operation_parser = mock_operation_parser

    declaration = tool._get_declaration()
    assert isinstance(declaration, FunctionDeclaration)
    assert declaration.name == "test_tool"
    assert declaration.description == "Test description"
    assert isinstance(declaration.parameters, Schema)

  @patch(
      "google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.requests.request"
  )
  def test_call_success(
      self,
      mock_request,
      mock_tool_context,
      sample_endpoint,
      sample_operation,
      sample_auth_scheme,
      sample_auth_credential,
  ):
    mock_response = MagicMock()
    mock_response.json.return_value = {"result": "success"}
    mock_request.return_value = mock_response

    tool = RestApiTool(
        name="test_tool",
        description="Test Tool",
        endpoint=sample_endpoint,
        operation=sample_operation,
        auth_scheme=sample_auth_scheme,
        auth_credential=sample_auth_credential,
    )

    # Call the method
    result = tool.call(args={}, tool_context=mock_tool_context)

    # Check the result
    assert result == {"result": "success"}

  @patch(
      "google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.requests.request"
  )
  def test_call_auth_pending(
      self,
      mock_request,
      sample_endpoint,
      sample_operation,
      sample_auth_scheme,
      sample_auth_credential,
  ):

    tool = RestApiTool(
        name="test_tool",
        description="Test Tool",
        endpoint=sample_endpoint,
        operation=sample_operation,
        auth_scheme=sample_auth_scheme,
        auth_credential=sample_auth_credential,
    )
    with patch(
        "google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.ToolAuthHandler.from_tool_context"
    ) as mock_from_tool_context:
      mock_tool_auth_handler_instance = MagicMock()
      mock_tool_auth_handler_instance.prepare_auth_credentials.return_value.state = (
          "pending"
      )
      mock_from_tool_context.return_value = mock_tool_auth_handler_instance

      response = tool.call(args={}, tool_context=None)
      assert response == {
          "pending": True,
          "message": "Needs your authorization to access your data.",
      }

  def test_prepare_request_params_query_body(
      self, sample_endpoint, sample_auth_credential, sample_auth_scheme
  ):
    # Create a mock Operation object
    mock_operation = Operation(
        operationId="test_op",
        parameters=[
            OpenAPIParameter(**{
                "name": "testQueryParam",
                "in": "query",
                "schema": OpenAPISchema(type="string"),
            })
        ],
        requestBody=RequestBody(
            content={
                "application/json": MediaType(
                    schema=OpenAPISchema(
                        type="object",
                        properties={
                            "param1": OpenAPISchema(type="string"),
                            "param2": OpenAPISchema(type="integer"),
                        },
                    )
                )
            }
        ),
    )

    tool = RestApiTool(
        name="test_tool",
        description="test",
        endpoint=sample_endpoint,
        operation=mock_operation,
        auth_credential=sample_auth_credential,
        auth_scheme=sample_auth_scheme,
    )

    params = [
        ApiParameter(
            original_name="param1",
            py_name="param1",
            param_location="body",
            param_schema=OpenAPISchema(type="string"),
        ),
        ApiParameter(
            original_name="param2",
            py_name="param2",
            param_location="body",
            param_schema=OpenAPISchema(type="integer"),
        ),
        ApiParameter(
            original_name="testQueryParam",
            py_name="test_query_param",
            param_location="query",
            param_schema=OpenAPISchema(type="string"),
        ),
    ]
    kwargs = {
        "param1": "value1",
        "param2": 123,
        "test_query_param": "query_value",
    }

    request_params = tool._prepare_request_params(params, kwargs)
    assert request_params["method"] == "get"
    assert request_params["url"] == "https://example.com/test"
    assert request_params["json"] == {"param1": "value1", "param2": 123}
    assert request_params["params"] == {"testQueryParam": "query_value"}

  def test_prepare_request_params_array(
      self, sample_endpoint, sample_auth_scheme, sample_auth_credential
  ):
    mock_operation = Operation(
        operationId="test_op",
        requestBody=RequestBody(
            content={
                "application/json": MediaType(
                    schema=OpenAPISchema(
                        type="array", items=OpenAPISchema(type="string")
                    )
                )
            }
        ),
    )

    tool = RestApiTool(
        name="test_tool",
        description="test",
        endpoint=sample_endpoint,
        operation=mock_operation,
        auth_credential=sample_auth_credential,
        auth_scheme=sample_auth_scheme,
    )
    params = [
        ApiParameter(
            original_name="array",  # Match the parameter name
            py_name="array",
            param_location="body",
            param_schema=OpenAPISchema(
                type="array", items=OpenAPISchema(type="string")
            ),
        )
    ]
    kwargs = {"array": ["item1", "item2"]}

    request_params = tool._prepare_request_params(params, kwargs)

    assert request_params["json"] == ["item1", "item2"]

  def test_prepare_request_params_string(
      self, sample_endpoint, sample_auth_credential, sample_auth_scheme
  ):
    mock_operation = Operation(
        operationId="test_op",
        requestBody=RequestBody(
            content={
                "text/plain": MediaType(schema=OpenAPISchema(type="string"))
            }
        ),
    )
    tool = RestApiTool(
        name="test_tool",
        description="Test Tool",
        endpoint=sample_endpoint,
        operation=mock_operation,
        auth_credential=sample_auth_credential,
        auth_scheme=sample_auth_scheme,
    )
    params = [
        ApiParameter(
            original_name="",
            py_name="input_string",
            param_location="body",
            param_schema=OpenAPISchema(type="string"),
        )
    ]
    kwargs = {"input_string": "test_value"}

    request_params = tool._prepare_request_params(params, kwargs)

    assert request_params["data"] == "test_value"
    assert request_params["headers"]["Content-Type"] == "text/plain"

  def test_prepare_request_params_form_data(
      self, sample_endpoint, sample_auth_scheme, sample_auth_credential
  ):
    mock_operation = Operation(
        operationId="test_op",
        requestBody=RequestBody(
            content={
                "application/x-www-form-urlencoded": MediaType(
                    schema=OpenAPISchema(
                        type="object",
                        properties={"key1": OpenAPISchema(type="string")},
                    )
                )
            }
        ),
    )
    tool = RestApiTool(
        name="test_tool",
        description="test",
        endpoint=sample_endpoint,
        operation=mock_operation,
        auth_credential=sample_auth_credential,
        auth_scheme=sample_auth_scheme,
    )
    params = [
        ApiParameter(
            original_name="key1",
            py_name="key1",
            param_location="body",
            param_schema=OpenAPISchema(type="string"),
        )
    ]
    kwargs = {"key1": "value1"}

    request_params = tool._prepare_request_params(params, kwargs)

    assert request_params["data"] == {"key1": "value1"}
    assert (
        request_params["headers"]["Content-Type"]
        == "application/x-www-form-urlencoded"
    )

  def test_prepare_request_params_multipart(
      self, sample_endpoint, sample_auth_credential, sample_auth_scheme
  ):
    mock_operation = Operation(
        operationId="test_op",
        requestBody=RequestBody(
            content={
                "multipart/form-data": MediaType(
                    schema=OpenAPISchema(
                        type="object",
                        properties={
                            "file1": OpenAPISchema(
                                type="string", format="binary"
                            )
                        },
                    )
                )
            }
        ),
    )
    tool = RestApiTool(
        name="test_tool",
        description="test",
        endpoint=sample_endpoint,
        operation=mock_operation,
        auth_credential=sample_auth_credential,
        auth_scheme=sample_auth_scheme,
    )
    params = [
        ApiParameter(
            original_name="file1",
            py_name="file1",
            param_location="body",
            param_schema=OpenAPISchema(type="string", format="binary"),
        )
    ]
    kwargs = {"file1": b"file_content"}

    request_params = tool._prepare_request_params(params, kwargs)

    assert request_params["files"] == {"file1": b"file_content"}
    assert request_params["headers"]["Content-Type"] == "multipart/form-data"

  def test_prepare_request_params_octet_stream(
      self, sample_endpoint, sample_auth_scheme, sample_auth_credential
  ):
    mock_operation = Operation(
        operationId="test_op",
        requestBody=RequestBody(
            content={
                "application/octet-stream": MediaType(
                    schema=OpenAPISchema(type="string", format="binary")
                )
            }
        ),
    )
    tool = RestApiTool(
        name="test_tool",
        description="test",
        endpoint=sample_endpoint,
        operation=mock_operation,
        auth_credential=sample_auth_credential,
        auth_scheme=sample_auth_scheme,
    )
    params = [
        ApiParameter(
            original_name="",
            py_name="data",
            param_location="body",
            param_schema=OpenAPISchema(type="string", format="binary"),
        )
    ]
    kwargs = {"data": b"binary_data"}

    request_params = tool._prepare_request_params(params, kwargs)

    assert request_params["data"] == b"binary_data"
    assert (
        request_params["headers"]["Content-Type"] == "application/octet-stream"
    )

  def test_prepare_request_params_path_param(
      self, sample_endpoint, sample_auth_credential, sample_auth_scheme
  ):
    mock_operation = Operation(operationId="test_op")
    tool = RestApiTool(
        name="test_tool",
        description="Test Tool",
        endpoint=sample_endpoint,
        operation=mock_operation,
        auth_credential=sample_auth_credential,
        auth_scheme=sample_auth_scheme,
    )
    params = [
        ApiParameter(
            original_name="user_id",
            py_name="user_id",
            param_location="path",
            param_schema=OpenAPISchema(type="string"),
        )
    ]
    kwargs = {"user_id": "123"}
    endpoint_with_path = OperationEndpoint(
        base_url="https://example.com", path="/test/{user_id}", method="get"
    )
    tool.endpoint = endpoint_with_path

    request_params = tool._prepare_request_params(params, kwargs)

    assert (
        request_params["url"] == "https://example.com/test/123"
    )  # Path param replaced

  def test_prepare_request_params_header_param(
      self,
      sample_endpoint,
      sample_auth_credential,
      sample_auth_scheme,
      sample_operation,
  ):
    tool = RestApiTool(
        name="test_tool",
        description="Test Tool",
        endpoint=sample_endpoint,
        operation=sample_operation,
        auth_credential=sample_auth_credential,
        auth_scheme=sample_auth_scheme,
    )
    params = [
        ApiParameter(
            original_name="X-Custom-Header",
            py_name="x_custom_header",
            param_location="header",
            param_schema=OpenAPISchema(type="string"),
        )
    ]
    kwargs = {"x_custom_header": "header_value"}

    request_params = tool._prepare_request_params(params, kwargs)

    assert request_params["headers"]["X-Custom-Header"] == "header_value"

  def test_prepare_request_params_cookie_param(
      self,
      sample_endpoint,
      sample_auth_credential,
      sample_auth_scheme,
      sample_operation,
  ):
    tool = RestApiTool(
        name="test_tool",
        description="Test Tool",
        endpoint=sample_endpoint,
        operation=sample_operation,
        auth_credential=sample_auth_credential,
        auth_scheme=sample_auth_scheme,
    )
    params = [
        ApiParameter(
            original_name="session_id",
            py_name="session_id",
            param_location="cookie",
            param_schema=OpenAPISchema(type="string"),
        )
    ]
    kwargs = {"session_id": "cookie_value"}

    request_params = tool._prepare_request_params(params, kwargs)

    assert request_params["cookies"]["session_id"] == "cookie_value"

  def test_prepare_request_params_multiple_mime_types(
      self, sample_endpoint, sample_auth_credential, sample_auth_scheme
  ):
    # Test what happens when multiple mime types are specified. It should take
    # the first one.
    mock_operation = Operation(
        operationId="test_op",
        requestBody=RequestBody(
            content={
                "application/json": MediaType(
                    schema=OpenAPISchema(type="string")
                ),
                "text/plain": MediaType(schema=OpenAPISchema(type="string")),
            }
        ),
    )
    tool = RestApiTool(
        name="test_tool",
        description="Test Tool",
        endpoint=sample_endpoint,
        operation=mock_operation,
        auth_credential=sample_auth_credential,
        auth_scheme=sample_auth_scheme,
    )
    params = [
        ApiParameter(
            original_name="",
            py_name="input",
            param_location="body",
            param_schema=OpenAPISchema(type="string"),
        )
    ]
    kwargs = {"input": "some_value"}

    request_params = tool._prepare_request_params(params, kwargs)

    assert request_params["headers"]["Content-Type"] == "application/json"

  def test_prepare_request_params_unknown_parameter(
      self,
      sample_endpoint,
      sample_auth_credential,
      sample_auth_scheme,
      sample_operation,
  ):
    tool = RestApiTool(
        name="test_tool",
        description="Test Tool",
        endpoint=sample_endpoint,
        operation=sample_operation,
        auth_credential=sample_auth_credential,
        auth_scheme=sample_auth_scheme,
    )
    params = [
        ApiParameter(
            original_name="known_param",
            py_name="known_param",
            param_location="query",
            param_schema=OpenAPISchema(type="string"),
        )
    ]
    kwargs = {"known_param": "value", "unknown_param": "unknown"}

    request_params = tool._prepare_request_params(params, kwargs)

    # Make sure unknown parameters are ignored and do not raise errors.
    assert "unknown_param" not in request_params["params"]

  def test_prepare_request_params_base_url_handling(
      self, sample_auth_credential, sample_auth_scheme, sample_operation
  ):
    # No base_url provided, should use path as is
    tool_no_base = RestApiTool(
        name="test_tool_no_base",
        description="Test Tool",
        endpoint=OperationEndpoint(base_url="", path="/no_base", method="get"),
        operation=sample_operation,
        auth_credential=sample_auth_credential,
        auth_scheme=sample_auth_scheme,
    )
    params = []
    kwargs = {}

    request_params_no_base = tool_no_base._prepare_request_params(
        params, kwargs
    )
    assert request_params_no_base["url"] == "/no_base"

    tool_trailing_slash = RestApiTool(
        name="test_tool",
        description="Test Tool",
        endpoint=OperationEndpoint(
            base_url="https://example.com/", path="/trailing", method="get"
        ),
        operation=sample_operation,
        auth_credential=sample_auth_credential,
        auth_scheme=sample_auth_scheme,
    )

    request_params_trailing = tool_trailing_slash._prepare_request_params(
        params, kwargs
    )
    assert request_params_trailing["url"] == "https://example.com/trailing"

  def test_prepare_request_params_no_unrecognized_query_parameter(
      self,
      sample_endpoint,
      sample_auth_credential,
      sample_auth_scheme,
      sample_operation,
  ):
    tool = RestApiTool(
        name="test_tool",
        description="Test Tool",
        endpoint=sample_endpoint,
        operation=sample_operation,
        auth_credential=sample_auth_credential,
        auth_scheme=sample_auth_scheme,
    )
    params = [
        ApiParameter(
            original_name="unrecognized_param",
            py_name="unrecognized_param",
            param_location="query",
            param_schema=OpenAPISchema(type="string"),
        )
    ]
    kwargs = {"unrecognized_param": None}  # Explicitly passing None
    request_params = tool._prepare_request_params(params, kwargs)

    # Query param not in sample_operation. It should be ignored.
    assert "unrecognized_param" not in request_params["params"]

  def test_prepare_request_params_no_credential(
      self,
      sample_endpoint,
      sample_operation,
  ):
    tool = RestApiTool(
        name="test_tool",
        description="Test Tool",
        endpoint=sample_endpoint,
        operation=sample_operation,
        auth_credential=None,
        auth_scheme=None,
    )
    params = [
        ApiParameter(
            original_name="param_name",
            py_name="param_name",
            param_location="query",
            param_schema=OpenAPISchema(type="string"),
        )
    ]
    kwargs = {"param_name": "aaa", "empty_param": ""}

    request_params = tool._prepare_request_params(params, kwargs)

    assert "param_name" in request_params["params"]
    assert "empty_param" not in request_params["params"]


class TestToGeminiSchema:

  def test_to_gemini_schema_none(self):
    assert to_gemini_schema(None) is None

  def test_to_gemini_schema_not_dict(self):
    with pytest.raises(TypeError, match="openapi_schema must be a dictionary"):
      to_gemini_schema("not a dict")

  def test_to_gemini_schema_empty_dict(self):
    result = to_gemini_schema({})
    assert isinstance(result, Schema)
    assert result.type == Type.OBJECT
    assert result.properties is None

  def test_to_gemini_schema_dict_with_only_object_type(self):
    result = to_gemini_schema({"type": "object"})
    assert isinstance(result, Schema)
    assert result.type == Type.OBJECT
    assert result.properties is None

  def test_to_gemini_schema_basic_types(self):
    openapi_schema = {
        "type": "object",
        "properties": {
            "name": {"type": "string"},
            "age": {"type": "integer"},
            "is_active": {"type": "boolean"},
        },
    }
    gemini_schema = to_gemini_schema(openapi_schema)
    assert isinstance(gemini_schema, Schema)
    assert gemini_schema.type == Type.OBJECT
    assert gemini_schema.properties["name"].type == Type.STRING
    assert gemini_schema.properties["age"].type == Type.INTEGER
    assert gemini_schema.properties["is_active"].type == Type.BOOLEAN

  def test_to_gemini_schema_array_string_types(self):
    openapi_schema = {
        "type": "object",
        "properties": {
            "boolean_field": {"type": "boolean"},
            "nonnullable_string": {"type": ["string"]},
            "nullable_string": {"type": ["string", "null"]},
            "nullable_number": {"type": ["null", "integer"]},
            "object_nullable": {"type": "null"},
            "multi_types_nullable": {"type": ["string", "null", "integer"]},
            "empty_default_object": {},
        },
    }
    gemini_schema = to_gemini_schema(openapi_schema)
    assert isinstance(gemini_schema, Schema)
    assert gemini_schema.type == Type.OBJECT
    assert gemini_schema.properties["boolean_field"].type == Type.BOOLEAN

    assert gemini_schema.properties["nonnullable_string"].type == Type.STRING
    assert not gemini_schema.properties["nonnullable_string"].nullable

    assert gemini_schema.properties["nullable_string"].type == Type.STRING
    assert gemini_schema.properties["nullable_string"].nullable

    assert gemini_schema.properties["nullable_number"].type == Type.INTEGER
    assert gemini_schema.properties["nullable_number"].nullable

    assert gemini_schema.properties["object_nullable"].type == Type.OBJECT
    assert gemini_schema.properties["object_nullable"].nullable

    assert gemini_schema.properties["multi_types_nullable"].type == Type.STRING
    assert gemini_schema.properties["multi_types_nullable"].nullable

    assert gemini_schema.properties["empty_default_object"].type == Type.OBJECT
    assert not gemini_schema.properties["empty_default_object"].nullable

  def test_to_gemini_schema_nested_objects(self):
    openapi_schema = {
        "type": "object",
        "properties": {
            "address": {
                "type": "object",
                "properties": {
                    "street": {"type": "string"},
                    "city": {"type": "string"},
                },
            }
        },
    }
    gemini_schema = to_gemini_schema(openapi_schema)
    assert gemini_schema.properties["address"].type == Type.OBJECT
    assert (
        gemini_schema.properties["address"].properties["street"].type
        == Type.STRING
    )
    assert (
        gemini_schema.properties["address"].properties["city"].type
        == Type.STRING
    )

  def test_to_gemini_schema_array(self):
    openapi_schema = {
        "type": "array",
        "items": {"type": "string"},
    }
    gemini_schema = to_gemini_schema(openapi_schema)
    assert gemini_schema.type == Type.ARRAY
    assert gemini_schema.items.type == Type.STRING

  def test_to_gemini_schema_nested_array(self):
    openapi_schema = {
        "type": "array",
        "items": {
            "type": "object",
            "properties": {"name": {"type": "string"}},
        },
    }
    gemini_schema = to_gemini_schema(openapi_schema)
    assert gemini_schema.items.properties["name"].type == Type.STRING

  def test_to_gemini_schema_any_of(self):
    openapi_schema = {
        "anyOf": [{"type": "string"}, {"type": "integer"}],
    }
    gemini_schema = to_gemini_schema(openapi_schema)
    assert len(gemini_schema.any_of) == 2
    assert gemini_schema.any_of[0].type == Type.STRING
    assert gemini_schema.any_of[1].type == Type.INTEGER

  def test_to_gemini_schema_general_list(self):
    openapi_schema = {
        "type": "array",
        "properties": {
            "list_field": {"type": "array", "items": {"type": "string"}},
        },
    }
    gemini_schema = to_gemini_schema(openapi_schema)
    assert gemini_schema.properties["list_field"].type == Type.ARRAY
    assert gemini_schema.properties["list_field"].items.type == Type.STRING

  def test_to_gemini_schema_enum(self):
    openapi_schema = {"type": "string", "enum": ["a", "b", "c"]}
    gemini_schema = to_gemini_schema(openapi_schema)
    assert gemini_schema.enum == ["a", "b", "c"]

  def test_to_gemini_schema_required(self):
    openapi_schema = {
        "type": "object",
        "required": ["name"],
        "properties": {"name": {"type": "string"}},
    }
    gemini_schema = to_gemini_schema(openapi_schema)
    assert gemini_schema.required == ["name"]

  def test_to_gemini_schema_nested_dict(self):
    openapi_schema = {
        "type": "object",
        "properties": {
            "metadata": {
                "type": "object",
                "properties": {
                    "key1": {"type": "object"},
                    "key2": {"type": "string"},
                },
            }
        },
    }
    gemini_schema = to_gemini_schema(openapi_schema)
    # Since metadata is not properties nor item, it will call to_gemini_schema recursively.
    assert isinstance(gemini_schema.properties["metadata"], Schema)
    assert (
        gemini_schema.properties["metadata"].type == Type.OBJECT
    )  # add object type by default
    assert len(gemini_schema.properties["metadata"].properties) == 2
    assert (
        gemini_schema.properties["metadata"].properties["key1"].type
        == Type.OBJECT
    )
    assert (
        gemini_schema.properties["metadata"].properties["key2"].type
        == Type.STRING
    )

  def test_to_gemini_schema_ignore_title_default_format(self):
    openapi_schema = {
        "type": "string",
        "title": "Test Title",
        "default": "default_value",
        "format": "date",
    }
    gemini_schema = to_gemini_schema(openapi_schema)

    assert gemini_schema.title is None
    assert gemini_schema.default is None
    assert gemini_schema.format is None

  def test_to_gemini_schema_property_ordering(self):
    openapi_schema = {
        "type": "object",
        "propertyOrdering": ["name", "age"],
        "properties": {
            "name": {"type": "string"},
            "age": {"type": "integer"},
        },
    }

    gemini_schema = to_gemini_schema(openapi_schema)
    assert gemini_schema.property_ordering == ["name", "age"]

  def test_to_gemini_schema_converts_property_dict(self):
    openapi_schema = {
        "properties": {
            "name": {"type": "string", "description": "The property key"},
            "value": {"type": "string", "description": "The property value"},
        },
        "type": "object",
        "description": "A single property entry in the Properties message.",
    }
    gemini_schema = to_gemini_schema(openapi_schema)
    assert gemini_schema.type == Type.OBJECT
    assert gemini_schema.properties["name"].type == Type.STRING
    assert gemini_schema.properties["value"].type == Type.STRING

  def test_to_gemini_schema_remove_unrecognized_fields(self):
    openapi_schema = {
        "type": "string",
        "description": "A single date string.",
        "format": "date",
    }
    gemini_schema = to_gemini_schema(openapi_schema)
    assert gemini_schema.type == Type.STRING
    assert not gemini_schema.format


def test_snake_to_lower_camel():
  assert snake_to_lower_camel("single") == "single"
  assert snake_to_lower_camel("two_words") == "twoWords"
  assert snake_to_lower_camel("three_word_example") == "threeWordExample"
  assert not snake_to_lower_camel("")
  assert snake_to_lower_camel("alreadyCamelCase") == "alreadyCamelCase"

==== tests/unittests/tools/openapi_tool/openapi_spec_parser/test_openapi_spec_parser.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from typing import Any
from typing import Dict

from google.adk.tools.openapi_tool.openapi_spec_parser.openapi_spec_parser import OpenApiSpecParser
import pytest


def create_minimal_openapi_spec() -> Dict[str, Any]:
  """Creates a minimal valid OpenAPI spec."""
  return {
      "openapi": "3.1.0",
      "info": {"title": "Minimal API", "version": "1.0.0"},
      "paths": {
          "/test": {
              "get": {
                  "summary": "Test GET endpoint",
                  "operationId": "testGet",
                  "responses": {
                      "200": {
                          "description": "Successful response",
                          "content": {
                              "application/json": {"schema": {"type": "string"}}
                          },
                      }
                  },
              }
          }
      },
  }


@pytest.fixture
def openapi_spec_generator():
  """Fixture for creating an OperationGenerator instance."""
  return OpenApiSpecParser()


def test_parse_minimal_spec(openapi_spec_generator):
  """Test parsing a minimal OpenAPI specification."""
  openapi_spec = create_minimal_openapi_spec()

  parsed_operations = openapi_spec_generator.parse(openapi_spec)
  op = parsed_operations[0]

  assert len(parsed_operations) == 1
  assert op.name == "test_get"
  assert op.endpoint.path == "/test"
  assert op.endpoint.method == "get"
  assert op.return_value.type_value == str


def test_parse_spec_with_no_operation_id(openapi_spec_generator):
  """Test parsing a spec where operationId is missing (auto-generation)."""
  openapi_spec = create_minimal_openapi_spec()
  del openapi_spec["paths"]["/test"]["get"]["operationId"]  # Remove operationId

  parsed_operations = openapi_spec_generator.parse(openapi_spec)

  assert len(parsed_operations) == 1
  # Check if operationId is auto generated based on path and method.
  assert parsed_operations[0].name == "test_get"


def test_parse_spec_with_multiple_methods(openapi_spec_generator):
  """Test parsing a spec with multiple HTTP methods for the same path."""
  openapi_spec = create_minimal_openapi_spec()
  openapi_spec["paths"]["/test"]["post"] = {
      "summary": "Test POST endpoint",
      "operationId": "testPost",
      "responses": {"200": {"description": "Successful response"}},
  }

  parsed_operations = openapi_spec_generator.parse(openapi_spec)
  operation_names = {op.name for op in parsed_operations}

  assert len(parsed_operations) == 2
  assert "test_get" in operation_names
  assert "test_post" in operation_names


def test_parse_spec_with_parameters(openapi_spec_generator):
  openapi_spec = create_minimal_openapi_spec()
  openapi_spec["paths"]["/test"]["get"]["parameters"] = [
      {"name": "param1", "in": "query", "schema": {"type": "string"}},
      {"name": "param2", "in": "header", "schema": {"type": "integer"}},
  ]

  parsed_operations = openapi_spec_generator.parse(openapi_spec)

  assert len(parsed_operations[0].parameters) == 2
  assert parsed_operations[0].parameters[0].original_name == "param1"
  assert parsed_operations[0].parameters[0].param_location == "query"
  assert parsed_operations[0].parameters[1].original_name == "param2"
  assert parsed_operations[0].parameters[1].param_location == "header"


def test_parse_spec_with_request_body(openapi_spec_generator):
  openapi_spec = create_minimal_openapi_spec()
  openapi_spec["paths"]["/test"]["post"] = {
      "summary": "Endpoint with request body",
      "operationId": "testPostWithBody",
      "requestBody": {
          "content": {
              "application/json": {
                  "schema": {
                      "type": "object",
                      "properties": {"name": {"type": "string"}},
                  }
              }
          }
      },
      "responses": {"200": {"description": "OK"}},
  }

  parsed_operations = openapi_spec_generator.parse(openapi_spec)
  post_operations = [
      op for op in parsed_operations if op.endpoint.method == "post"
  ]
  op = post_operations[0]

  assert len(post_operations) == 1
  assert op.name == "test_post_with_body"
  assert len(op.parameters) == 1
  assert op.parameters[0].original_name == "name"
  assert op.parameters[0].type_value == str


def test_parse_spec_with_reference(openapi_spec_generator):
  """Test parsing a specification with $ref."""
  openapi_spec = {
      "openapi": "3.1.0",
      "info": {"title": "API with Refs", "version": "1.0.0"},
      "paths": {
          "/test_ref": {
              "get": {
                  "summary": "Endpoint with ref",
                  "operationId": "testGetRef",
                  "responses": {
                      "200": {
                          "description": "Success",
                          "content": {
                              "application/json": {
                                  "schema": {
                                      "$ref": "#/components/schemas/MySchema"
                                  }
                              }
                          },
                      }
                  },
              }
          }
      },
      "components": {
          "schemas": {
              "MySchema": {
                  "type": "object",
                  "properties": {"name": {"type": "string"}},
              }
          }
      },
  }
  parsed_operations = openapi_spec_generator.parse(openapi_spec)
  op = parsed_operations[0]

  assert len(parsed_operations) == 1
  assert op.return_value.type_value.__origin__ is dict


def test_parse_spec_with_circular_reference(openapi_spec_generator):
  """Test correct handling of circular $ref (important!)."""
  openapi_spec = {
      "openapi": "3.1.0",
      "info": {"title": "Circular Ref API", "version": "1.0.0"},
      "paths": {
          "/circular": {
              "get": {
                  "responses": {
                      "200": {
                          "description": "OK",
                          "content": {
                              "application/json": {
                                  "schema": {"$ref": "#/components/schemas/A"}
                              }
                          },
                      }
                  }
              }
          }
      },
      "components": {
          "schemas": {
              "A": {
                  "type": "object",
                  "properties": {"b": {"$ref": "#/components/schemas/B"}},
              },
              "B": {
                  "type": "object",
                  "properties": {"a": {"$ref": "#/components/schemas/A"}},
              },
          }
      },
  }

  parsed_operations = openapi_spec_generator.parse(openapi_spec)
  assert len(parsed_operations) == 1

  op = parsed_operations[0]
  assert op.return_value.type_value.__origin__ is dict
  assert op.return_value.type_hint == "Dict[str, Any]"


def test_parse_no_paths(openapi_spec_generator):
  """Test with a spec that has no paths defined."""
  openapi_spec = {
      "openapi": "3.1.0",
      "info": {"title": "No Paths API", "version": "1.0.0"},
  }
  parsed_operations = openapi_spec_generator.parse(openapi_spec)
  assert len(parsed_operations) == 0  # Should be empty


def test_parse_empty_path_item(openapi_spec_generator):
  """Test a path item that is present but empty."""
  openapi_spec = {
      "openapi": "3.1.0",
      "info": {"title": "Empty Path Item API", "version": "1.0.0"},
      "paths": {"/empty": None},
  }

  parsed_operations = openapi_spec_generator.parse(openapi_spec)

  assert len(parsed_operations) == 0


def test_parse_spec_with_global_auth_scheme(openapi_spec_generator):
  """Test parsing with a global security scheme."""
  openapi_spec = create_minimal_openapi_spec()
  openapi_spec["security"] = [{"api_key": []}]
  openapi_spec["components"] = {
      "securitySchemes": {
          "api_key": {"type": "apiKey", "in": "header", "name": "X-API-Key"}
      }
  }

  parsed_operations = openapi_spec_generator.parse(openapi_spec)
  op = parsed_operations[0]

  assert len(parsed_operations) == 1
  assert op.auth_scheme is not None
  assert op.auth_scheme.type_.value == "apiKey"


def test_parse_spec_with_local_auth_scheme(openapi_spec_generator):
  """Test parsing with a local (operation-level) security scheme."""
  openapi_spec = create_minimal_openapi_spec()
  openapi_spec["paths"]["/test"]["get"]["security"] = [{"local_auth": []}]
  openapi_spec["components"] = {
      "securitySchemes": {"local_auth": {"type": "http", "scheme": "bearer"}}
  }

  parsed_operations = openapi_spec_generator.parse(openapi_spec)
  op = parsed_operations[0]

  assert op.auth_scheme is not None
  assert op.auth_scheme.type_.value == "http"
  assert op.auth_scheme.scheme == "bearer"


def test_parse_spec_with_servers(openapi_spec_generator):
  """Test parsing with server URLs."""
  openapi_spec = create_minimal_openapi_spec()
  openapi_spec["servers"] = [
      {"url": "https://api.example.com"},
      {"url": "http://localhost:8000"},
  ]

  parsed_operations = openapi_spec_generator.parse(openapi_spec)

  assert len(parsed_operations) == 1
  assert parsed_operations[0].endpoint.base_url == "https://api.example.com"


def test_parse_spec_with_no_servers(openapi_spec_generator):
  """Test with no servers defined (should default to empty string)."""
  openapi_spec = create_minimal_openapi_spec()
  if "servers" in openapi_spec:
    del openapi_spec["servers"]

  parsed_operations = openapi_spec_generator.parse(openapi_spec)

  assert len(parsed_operations) == 1
  assert parsed_operations[0].endpoint.base_url == ""


def test_parse_spec_with_description(openapi_spec_generator):
  openapi_spec = create_minimal_openapi_spec()
  expected_description = "This is a test description."
  openapi_spec["paths"]["/test"]["get"]["description"] = expected_description

  parsed_operations = openapi_spec_generator.parse(openapi_spec)

  assert len(parsed_operations) == 1
  assert parsed_operations[0].description == expected_description


def test_parse_spec_with_empty_description(openapi_spec_generator):
  openapi_spec = create_minimal_openapi_spec()
  openapi_spec["paths"]["/test"]["get"]["description"] = ""
  openapi_spec["paths"]["/test"]["get"]["summary"] = ""

  parsed_operations = openapi_spec_generator.parse(openapi_spec)

  assert len(parsed_operations) == 1
  assert parsed_operations[0].description == ""


def test_parse_spec_with_no_description(openapi_spec_generator):
  openapi_spec = create_minimal_openapi_spec()

  # delete description
  if "description" in openapi_spec["paths"]["/test"]["get"]:
    del openapi_spec["paths"]["/test"]["get"]["description"]
  if "summary" in openapi_spec["paths"]["/test"]["get"]:
    del openapi_spec["paths"]["/test"]["get"]["summary"]

  parsed_operations = openapi_spec_generator.parse(openapi_spec)

  assert len(parsed_operations) == 1
  assert (
      parsed_operations[0].description == ""
  )  # it should be initialized with empty string


def test_parse_invalid_openapi_spec_type(openapi_spec_generator):
  """Test that passing a non-dict object to parse raises TypeError"""
  with pytest.raises(AttributeError):
    openapi_spec_generator.parse(123)  # type: ignore

  with pytest.raises(AttributeError):
    openapi_spec_generator.parse("openapi_spec")  # type: ignore

  with pytest.raises(AttributeError):
    openapi_spec_generator.parse([])  # type: ignore


def test_parse_external_ref_raises_error(openapi_spec_generator):
  """Check that external references (not starting with #) raise ValueError."""
  openapi_spec = {
      "openapi": "3.1.0",
      "info": {"title": "External Ref API", "version": "1.0.0"},
      "paths": {
          "/external": {
              "get": {
                  "responses": {
                      "200": {
                          "description": "OK",
                          "content": {
                              "application/json": {
                                  "schema": {
                                      "$ref": (
                                          "external_file.json#/components/schemas/ExternalSchema"
                                      )
                                  }
                              }
                          },
                      }
                  }
              }
          }
      },
  }
  with pytest.raises(ValueError):
    openapi_spec_generator.parse(openapi_spec)


def test_parse_spec_with_multiple_paths_deep_refs(openapi_spec_generator):
  """Test specs with multiple paths, request/response bodies using deep refs."""
  openapi_spec = {
      "openapi": "3.1.0",
      "info": {"title": "Multiple Paths Deep Refs API", "version": "1.0.0"},
      "paths": {
          "/path1": {
              "post": {
                  "operationId": "postPath1",
                  "requestBody": {
                      "content": {
                          "application/json": {
                              "schema": {
                                  "$ref": "#/components/schemas/Request1"
                              }
                          }
                      }
                  },
                  "responses": {
                      "200": {
                          "description": "OK",
                          "content": {
                              "application/json": {
                                  "schema": {
                                      "$ref": "#/components/schemas/Response1"
                                  }
                              }
                          },
                      }
                  },
              }
          },
          "/path2": {
              "put": {
                  "operationId": "putPath2",
                  "requestBody": {
                      "content": {
                          "application/json": {
                              "schema": {
                                  "$ref": "#/components/schemas/Request2"
                              }
                          }
                      }
                  },
                  "responses": {
                      "200": {
                          "description": "OK",
                          "content": {
                              "application/json": {
                                  "schema": {
                                      "$ref": "#/components/schemas/Response2"
                                  }
                              }
                          },
                      }
                  },
              },
              "get": {
                  "operationId": "getPath2",
                  "responses": {
                      "200": {
                          "description": "OK",
                          "content": {
                              "application/json": {
                                  "schema": {
                                      "$ref": "#/components/schemas/Response2"
                                  }
                              }
                          },
                      }
                  },
              },
          },
      },
      "components": {
          "schemas": {
              "Request1": {
                  "type": "object",
                  "properties": {
                      "req1_prop1": {"$ref": "#/components/schemas/Level1_1"}
                  },
              },
              "Response1": {
                  "type": "object",
                  "properties": {
                      "res1_prop1": {"$ref": "#/components/schemas/Level1_2"}
                  },
              },
              "Request2": {
                  "type": "object",
                  "properties": {
                      "req2_prop1": {"$ref": "#/components/schemas/Level1_1"}
                  },
              },
              "Response2": {
                  "type": "object",
                  "properties": {
                      "res2_prop1": {"$ref": "#/components/schemas/Level1_2"}
                  },
              },
              "Level1_1": {
                  "type": "object",
                  "properties": {
                      "level1_1_prop1": {
                          "$ref": "#/components/schemas/Level2_1"
                      }
                  },
              },
              "Level1_2": {
                  "type": "object",
                  "properties": {
                      "level1_2_prop1": {
                          "$ref": "#/components/schemas/Level2_2"
                      }
                  },
              },
              "Level2_1": {
                  "type": "object",
                  "properties": {
                      "level2_1_prop1": {"$ref": "#/components/schemas/Level3"}
                  },
              },
              "Level2_2": {
                  "type": "object",
                  "properties": {"level2_2_prop1": {"type": "string"}},
              },
              "Level3": {"type": "integer"},
          }
      },
  }

  parsed_operations = openapi_spec_generator.parse(openapi_spec)
  assert len(parsed_operations) == 3

  # Verify Path 1
  path1_ops = [op for op in parsed_operations if op.endpoint.path == "/path1"]
  assert len(path1_ops) == 1
  path1_op = path1_ops[0]
  assert path1_op.name == "post_path1"

  assert len(path1_op.parameters) == 1
  assert path1_op.parameters[0].original_name == "req1_prop1"
  assert (
      path1_op.parameters[0]
      .param_schema.properties["level1_1_prop1"]
      .properties["level2_1_prop1"]
      .type
      == "integer"
  )
  assert (
      path1_op.return_value.param_schema.properties["res1_prop1"]
      .properties["level1_2_prop1"]
      .properties["level2_2_prop1"]
      .type
      == "string"
  )

  # Verify Path 2
  path2_ops = [
      op
      for op in parsed_operations
      if op.endpoint.path == "/path2" and op.name == "put_path2"
  ]
  path2_op = path2_ops[0]
  assert path2_op is not None
  assert len(path2_op.parameters) == 1
  assert path2_op.parameters[0].original_name == "req2_prop1"
  assert (
      path2_op.parameters[0]
      .param_schema.properties["level1_1_prop1"]
      .properties["level2_1_prop1"]
      .type
      == "integer"
  )
  assert (
      path2_op.return_value.param_schema.properties["res2_prop1"]
      .properties["level1_2_prop1"]
      .properties["level2_2_prop1"]
      .type
      == "string"
  )


def test_parse_spec_with_duplicate_parameter_names(openapi_spec_generator):
  """Test handling of duplicate parameter names (one in query, one in body).

  The expected behavior is that both parameters should be captured but with
  different suffix, and
  their `original_name` attributes should reflect their origin (query or body).
  """
  openapi_spec = {
      "openapi": "3.1.0",
      "info": {"title": "Duplicate Parameter Names API", "version": "1.0.0"},
      "paths": {
          "/duplicate": {
              "post": {
                  "operationId": "createWithDuplicate",
                  "parameters": [{
                      "name": "name",
                      "in": "query",
                      "schema": {"type": "string"},
                  }],
                  "requestBody": {
                      "content": {
                          "application/json": {
                              "schema": {
                                  "type": "object",
                                  "properties": {"name": {"type": "integer"}},
                              }
                          }
                      }
                  },
                  "responses": {"200": {"description": "OK"}},
              }
          }
      },
  }

  parsed_operations = openapi_spec_generator.parse(openapi_spec)
  assert len(parsed_operations) == 1
  op = parsed_operations[0]
  assert op.name == "create_with_duplicate"
  assert len(op.parameters) == 2

  query_param = None
  body_param = None
  for param in op.parameters:
    if param.param_location == "query" and param.original_name == "name":
      query_param = param
    elif param.param_location == "body" and param.original_name == "name":
      body_param = param

  assert query_param is not None
  assert query_param.original_name == "name"
  assert query_param.py_name == "name"

  assert body_param is not None
  assert body_param.original_name == "name"
  assert body_param.py_name == "name_0"

==== tests/unittests/tools/openapi_tool/openapi_spec_parser/test_operation_parser.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from fastapi.openapi.models import MediaType
from fastapi.openapi.models import Operation
from fastapi.openapi.models import Parameter
from fastapi.openapi.models import RequestBody
from fastapi.openapi.models import Response
from fastapi.openapi.models import Schema
from google.adk.tools.openapi_tool.common.common import ApiParameter
from google.adk.tools.openapi_tool.openapi_spec_parser.operation_parser import OperationParser
import pytest


@pytest.fixture
def sample_operation() -> Operation:
  """Fixture to provide a sample OpenAPI Operation object."""
  return Operation(
      operationId='test_operation',
      summary='Test Summary',
      description='Test Description',
      parameters=[
          Parameter(**{
              'name': 'param1',
              'in': 'query',
              'schema': Schema(type='string'),
              'description': 'Parameter 1',
          }),
          Parameter(**{
              'name': 'param2',
              'in': 'header',
              'schema': Schema(type='string'),
              'description': 'Parameter 2',
          }),
      ],
      requestBody=RequestBody(
          content={
              'application/json': MediaType(
                  schema=Schema(
                      type='object',
                      properties={
                          'prop1': Schema(
                              type='string', description='Property 1'
                          ),
                          'prop2': Schema(
                              type='integer', description='Property 2'
                          ),
                      },
                  )
              )
          },
          description='Request body description',
      ),
      responses={
          '200': Response(
              description='Success',
              content={
                  'application/json': MediaType(schema=Schema(type='string'))
              },
          ),
          '400': Response(description='Client Error'),
      },
      security=[{'oauth2': ['resource: read', 'resource: write']}],
  )


def test_operation_parser_initialization(sample_operation):
  """Test initialization of OperationParser."""
  parser = OperationParser(sample_operation)
  assert parser._operation == sample_operation
  assert len(parser._params) == 4  # 2 params + 2 request body props
  assert parser._return_value is not None


def test_process_operation_parameters(sample_operation):
  """Test _process_operation_parameters method."""
  parser = OperationParser(sample_operation, should_parse=False)
  parser._process_operation_parameters()
  assert len(parser._params) == 2
  assert parser._params[0].original_name == 'param1'
  assert parser._params[0].param_location == 'query'
  assert parser._params[1].original_name == 'param2'
  assert parser._params[1].param_location == 'header'


def test_process_request_body(sample_operation):
  """Test _process_request_body method."""
  parser = OperationParser(sample_operation, should_parse=False)
  parser._process_request_body()
  assert len(parser._params) == 2  # 2 properties in request body
  assert parser._params[0].original_name == 'prop1'
  assert parser._params[0].param_location == 'body'
  assert parser._params[1].original_name == 'prop2'
  assert parser._params[1].param_location == 'body'


def test_process_request_body_array():
  """Test _process_request_body method with array schema."""
  operation = Operation(
      requestBody=RequestBody(
          content={
              'application/json': MediaType(
                  schema=Schema(
                      type='array',
                      items=Schema(
                          type='object',
                          properties={
                              'item_prop1': Schema(
                                  type='string', description='Item Property 1'
                              ),
                              'item_prop2': Schema(
                                  type='integer', description='Item Property 2'
                              ),
                          },
                      ),
                  )
              )
          }
      )
  )

  parser = OperationParser(operation, should_parse=False)
  parser._process_request_body()
  assert len(parser._params) == 1
  assert parser._params[0].original_name == 'array'
  assert parser._params[0].param_location == 'body'
  # Check that schema is correctly propagated and is a dictionary
  assert parser._params[0].param_schema.type == 'array'
  assert parser._params[0].param_schema.items.type == 'object'
  assert 'item_prop1' in parser._params[0].param_schema.items.properties
  assert 'item_prop2' in parser._params[0].param_schema.items.properties
  assert (
      parser._params[0].param_schema.items.properties['item_prop1'].description
      == 'Item Property 1'
  )
  assert (
      parser._params[0].param_schema.items.properties['item_prop2'].description
      == 'Item Property 2'
  )


def test_process_request_body_no_name():
  """Test _process_request_body with a schema that has no properties (unnamed)"""
  operation = Operation(
      requestBody=RequestBody(
          content={'application/json': MediaType(schema=Schema(type='string'))}
      )
  )
  parser = OperationParser(operation, should_parse=False)
  parser._process_request_body()
  assert len(parser._params) == 1
  assert parser._params[0].original_name == ''  # No name
  assert parser._params[0].param_location == 'body'


def test_process_request_body_empty_object():
  """Test _process_request_body with a schema that is of type object but with no properties."""
  operation = Operation(
      requestBody=RequestBody(
          content={'application/json': MediaType(schema=Schema(type='object'))}
      )
  )
  parser = OperationParser(operation, should_parse=False)
  parser._process_request_body()
  assert len(parser._params) == 0


def test_dedupe_param_names(sample_operation):
  """Test _dedupe_param_names method."""
  parser = OperationParser(sample_operation, should_parse=False)
  # Add duplicate named parameters.
  parser._params = [
      ApiParameter(original_name='test', param_location='', param_schema={}),
      ApiParameter(original_name='test', param_location='', param_schema={}),
      ApiParameter(original_name='test', param_location='', param_schema={}),
  ]
  parser._dedupe_param_names()
  assert parser._params[0].py_name == 'test'
  assert parser._params[1].py_name == 'test_0'
  assert parser._params[2].py_name == 'test_1'


def test_process_return_value(sample_operation):
  """Test _process_return_value method."""
  parser = OperationParser(sample_operation, should_parse=False)
  parser._process_return_value()
  assert parser._return_value is not None
  assert parser._return_value.type_hint == 'str'


def test_process_return_value_no_2xx(sample_operation):
  """Tests _process_return_value when no 2xx response exists."""
  operation_no_2xx = Operation(
      responses={'400': Response(description='Client Error')}
  )
  parser = OperationParser(operation_no_2xx, should_parse=False)
  parser._process_return_value()
  assert parser._return_value is not None
  assert parser._return_value.type_hint == 'Any'


def test_process_return_value_multiple_2xx(sample_operation):
  """Tests _process_return_value when multiple 2xx responses exist."""
  operation_multi_2xx = Operation(
      responses={
          '201': Response(
              description='Success',
              content={
                  'application/json': MediaType(schema=Schema(type='integer'))
              },
          ),
          '202': Response(
              description='Success',
              content={'text/plain': MediaType(schema=Schema(type='string'))},
          ),
          '200': Response(
              description='Success',
              content={
                  'application/pdf': MediaType(schema=Schema(type='boolean'))
              },
          ),
          '400': Response(
              description='Failure',
              content={
                  'application/xml': MediaType(schema=Schema(type='object'))
              },
          ),
      }
  )

  parser = OperationParser(operation_multi_2xx, should_parse=False)
  parser._process_return_value()

  assert parser._return_value is not None
  # Take the content type of the 200 response since it's the smallest response
  # code
  assert parser._return_value.param_schema.type == 'boolean'


def test_process_return_value_no_content(sample_operation):
  """Test when 2xx response has no content"""
  operation_no_content = Operation(
      responses={'200': Response(description='Success', content={})}
  )
  parser = OperationParser(operation_no_content, should_parse=False)
  parser._process_return_value()
  assert parser._return_value.type_hint == 'Any'


def test_process_return_value_no_schema(sample_operation):
  """Tests when the 2xx response's content has no schema."""
  operation_no_schema = Operation(
      responses={
          '200': Response(
              description='Success',
              content={'application/json': MediaType(schema=None)},
          )
      }
  )
  parser = OperationParser(operation_no_schema, should_parse=False)
  parser._process_return_value()
  assert parser._return_value.type_hint == 'Any'


def test_get_function_name(sample_operation):
  """Test get_function_name method."""
  parser = OperationParser(sample_operation)
  assert parser.get_function_name() == 'test_operation'


def test_get_function_name_missing_id():
  """Tests get_function_name when operationId is missing"""
  operation = Operation()  # No ID
  parser = OperationParser(operation)
  with pytest.raises(ValueError, match='Operation ID is missing'):
    parser.get_function_name()


def test_get_return_type_hint(sample_operation):
  """Test get_return_type_hint method."""
  parser = OperationParser(sample_operation)
  assert parser.get_return_type_hint() == 'str'


def test_get_return_type_value(sample_operation):
  """Test get_return_type_value method."""
  parser = OperationParser(sample_operation)
  assert parser.get_return_type_value() == str


def test_get_parameters(sample_operation):
  """Test get_parameters method."""
  parser = OperationParser(sample_operation)
  params = parser.get_parameters()
  assert len(params) == 4  # Correct count after processing
  assert all(isinstance(p, ApiParameter) for p in params)


def test_get_return_value(sample_operation):
  """Test get_return_value method."""
  parser = OperationParser(sample_operation)
  return_value = parser.get_return_value()
  assert isinstance(return_value, ApiParameter)


def test_get_auth_scheme_name(sample_operation):
  """Test get_auth_scheme_name method."""
  parser = OperationParser(sample_operation)
  assert parser.get_auth_scheme_name() == 'oauth2'


def test_get_auth_scheme_name_no_security():
  """Test get_auth_scheme_name when no security is present."""
  operation = Operation(responses={})
  parser = OperationParser(operation)
  assert parser.get_auth_scheme_name() == ''


def test_get_pydoc_string(sample_operation):
  """Test get_pydoc_string method."""
  parser = OperationParser(sample_operation)
  pydoc_string = parser.get_pydoc_string()
  assert 'Test Summary' in pydoc_string
  assert 'Args:' in pydoc_string
  assert 'param1 (str): Parameter 1' in pydoc_string
  assert 'prop1 (str): Property 1' in pydoc_string
  assert 'Returns (str):' in pydoc_string
  assert 'Success' in pydoc_string


def test_get_json_schema(sample_operation):
  """Test get_json_schema method."""
  parser = OperationParser(sample_operation)
  json_schema = parser.get_json_schema()
  assert json_schema['title'] == 'test_operation_Arguments'
  assert json_schema['type'] == 'object'
  assert 'param1' in json_schema['properties']
  assert 'prop1' in json_schema['properties']
  # By default nothing is required unless explicitly stated
  assert 'required' not in json_schema or json_schema['required'] == []


def test_get_signature_parameters(sample_operation):
  """Test get_signature_parameters method."""
  parser = OperationParser(sample_operation)
  signature_params = parser.get_signature_parameters()
  assert len(signature_params) == 4
  assert signature_params[0].name == 'param1'
  assert signature_params[0].annotation == str
  assert signature_params[2].name == 'prop1'
  assert signature_params[2].annotation == str


def test_get_annotations(sample_operation):
  """Test get_annotations method."""
  parser = OperationParser(sample_operation)
  annotations = parser.get_annotations()
  assert len(annotations) == 5  # 4 parameters + return
  assert annotations['param1'] == str
  assert annotations['prop1'] == str
  assert annotations['return'] == str


def test_load():
  """Test the load classmethod."""
  operation = Operation(operationId='my_op')  # Minimal operation
  params = [
      ApiParameter(
          original_name='p1',
          param_location='',
          param_schema={'type': 'integer'},
      )
  ]
  return_value = ApiParameter(
      original_name='', param_location='', param_schema={'type': 'string'}
  )

  parser = OperationParser.load(operation, params, return_value)

  assert isinstance(parser, OperationParser)
  assert parser._operation == operation
  assert parser._params == params
  assert parser._return_value == return_value
  assert (
      parser.get_function_name() == 'my_op'
  )  # Check that the operation is loaded


def test_operation_parser_with_dict():
  """Test initialization of OperationParser with a dictionary."""
  operation_dict = {
      'operationId': 'test_dict_operation',
      'parameters': [
          {'name': 'dict_param', 'in': 'query', 'schema': {'type': 'string'}}
      ],
      'responses': {
          '200': {
              'description': 'Dict Success',
              'content': {'application/json': {'schema': {'type': 'string'}}},
          }
      },
  }
  parser = OperationParser(operation_dict)
  assert parser._operation.operationId == 'test_dict_operation'
  assert len(parser._params) == 1
  assert parser._params[0].original_name == 'dict_param'
  assert parser._return_value.type_hint == 'str'

==== tests/unittests/tools/openapi_tool/common/test_common.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from typing import Any
from typing import Dict
from typing import List

from fastapi.openapi.models import Response, Schema
from google.adk.tools.openapi_tool.common.common import ApiParameter
from google.adk.tools.openapi_tool.common.common import PydocHelper
from google.adk.tools.openapi_tool.common.common import rename_python_keywords
from google.adk.tools.openapi_tool.common.common import to_snake_case
from google.adk.tools.openapi_tool.common.common import TypeHintHelper
import pytest


def dict_to_responses(input: Dict[str, Any]) -> Dict[str, Response]:
  return {k: Response.model_validate(input[k]) for k in input}


class TestToSnakeCase:

  @pytest.mark.parametrize(
      'input_str, expected_output',
      [
          ('lowerCamelCase', 'lower_camel_case'),
          ('UpperCamelCase', 'upper_camel_case'),
          ('space separated', 'space_separated'),
          ('REST API', 'rest_api'),
          ('Mixed_CASE with_Spaces', 'mixed_case_with_spaces'),
          ('__init__', 'init'),
          ('APIKey', 'api_key'),
          ('SomeLongURL', 'some_long_url'),
          ('CONSTANT_CASE', 'constant_case'),
          ('already_snake_case', 'already_snake_case'),
          ('single', 'single'),
          ('', ''),
          ('  spaced  ', 'spaced'),
          ('with123numbers', 'with123numbers'),
          ('With_Mixed_123_and_SPACES', 'with_mixed_123_and_spaces'),
          ('HTMLParser', 'html_parser'),
          ('HTTPResponseCode', 'http_response_code'),
          ('a_b_c', 'a_b_c'),
          ('A_B_C', 'a_b_c'),
          ('fromAtoB', 'from_ato_b'),
          ('XMLHTTPRequest', 'xmlhttp_request'),
          ('_leading', 'leading'),
          ('trailing_', 'trailing'),
          ('  leading_and_trailing_  ', 'leading_and_trailing'),
          ('Multiple___Underscores', 'multiple_underscores'),
          ('  spaces_and___underscores  ', 'spaces_and_underscores'),
          ('  _mixed_Case  ', 'mixed_case'),
          ('123Start', '123_start'),
          ('End123', 'end123'),
          ('Mid123dle', 'mid123dle'),
      ],
  )
  def test_to_snake_case(self, input_str, expected_output):
    assert to_snake_case(input_str) == expected_output


class TestRenamePythonKeywords:

  @pytest.mark.parametrize(
      'input_str, expected_output',
      [
          ('in', 'param_in'),
          ('for', 'param_for'),
          ('class', 'param_class'),
          ('normal', 'normal'),
          ('param_if', 'param_if'),
          ('', ''),
      ],
  )
  def test_rename_python_keywords(self, input_str, expected_output):
    assert rename_python_keywords(input_str) == expected_output


class TestApiParameter:

  def test_api_parameter_initialization(self):
    schema = Schema(type='string', description='A string parameter')
    param = ApiParameter(
        original_name='testParam',
        description='A string description',
        param_location='query',
        param_schema=schema,
    )
    assert param.original_name == 'testParam'
    assert param.param_location == 'query'
    assert param.param_schema.type == 'string'
    assert param.param_schema.description == 'A string parameter'
    assert param.py_name == 'test_param'
    assert param.type_hint == 'str'
    assert param.type_value == str
    assert param.description == 'A string description'

  def test_api_parameter_keyword_rename(self):
    schema = Schema(type='string')
    param = ApiParameter(
        original_name='in',
        param_location='query',
        param_schema=schema,
    )
    assert param.py_name == 'param_in'

  def test_api_parameter_custom_py_name(self):
    schema = Schema(type='integer')
    param = ApiParameter(
        original_name='testParam',
        param_location='query',
        param_schema=schema,
        py_name='custom_name',
    )
    assert param.py_name == 'custom_name'

  def test_api_parameter_str_representation(self):
    schema = Schema(type='number')
    param = ApiParameter(
        original_name='testParam',
        param_location='query',
        param_schema=schema,
    )
    assert str(param) == 'test_param: float'

  def test_api_parameter_to_arg_string(self):
    schema = Schema(type='boolean')
    param = ApiParameter(
        original_name='testParam',
        param_location='query',
        param_schema=schema,
    )
    assert param.to_arg_string() == 'test_param=test_param'

  def test_api_parameter_to_dict_property(self):
    schema = Schema(type='string')
    param = ApiParameter(
        original_name='testParam',
        param_location='path',
        param_schema=schema,
    )
    assert param.to_dict_property() == '"test_param": test_param'

  def test_api_parameter_model_serializer(self):
    schema = Schema(type='string', description='test description')
    param = ApiParameter(
        original_name='TestParam',
        param_location='path',
        param_schema=schema,
        py_name='test_param_custom',
        description='test description',
    )

    serialized_param = param.model_dump(mode='json', exclude_none=True)

    assert serialized_param == {
        'original_name': 'TestParam',
        'param_location': 'path',
        'param_schema': {'type': 'string', 'description': 'test description'},
        'description': 'test description',
        'py_name': 'test_param_custom',
    }

  @pytest.mark.parametrize(
      'schema, expected_type_value, expected_type_hint',
      [
          ({'type': 'integer'}, int, 'int'),
          ({'type': 'number'}, float, 'float'),
          ({'type': 'boolean'}, bool, 'bool'),
          ({'type': 'string'}, str, 'str'),
          (
              {'type': 'string', 'format': 'date'},
              str,
              'str',
          ),
          (
              {'type': 'string', 'format': 'date-time'},
              str,
              'str',
          ),
          (
              {'type': 'array', 'items': {'type': 'integer'}},
              List[int],
              'List[int]',
          ),
          (
              {'type': 'array', 'items': {'type': 'string'}},
              List[str],
              'List[str]',
          ),
          (
              {
                  'type': 'array',
                  'items': {'type': 'object'},
              },
              List[Dict[str, Any]],
              'List[Dict[str, Any]]',
          ),
          ({'type': 'object'}, Dict[str, Any], 'Dict[str, Any]'),
          ({'type': 'unknown'}, Any, 'Any'),
          ({}, Any, 'Any'),
      ],
  )
  def test_api_parameter_type_hint_helper(
      self, schema, expected_type_value, expected_type_hint
  ):
    param = ApiParameter(
        original_name='test', param_location='query', param_schema=schema
    )
    assert param.type_value == expected_type_value
    assert param.type_hint == expected_type_hint
    assert (
        TypeHintHelper.get_type_hint(param.param_schema) == expected_type_hint
    )
    assert (
        TypeHintHelper.get_type_value(param.param_schema) == expected_type_value
    )

  def test_api_parameter_description(self):
    schema = Schema(type='string')
    param = ApiParameter(
        original_name='param1',
        param_location='query',
        param_schema=schema,
        description='The description',
    )
    assert param.description == 'The description'

  def test_api_parameter_description_use_schema_fallback(self):
    schema = Schema(type='string', description='The description')
    param = ApiParameter(
        original_name='param1',
        param_location='query',
        param_schema=schema,
    )
    assert param.description == 'The description'


class TestTypeHintHelper:

  @pytest.mark.parametrize(
      'schema, expected_type_value, expected_type_hint',
      [
          ({'type': 'integer'}, int, 'int'),
          ({'type': 'number'}, float, 'float'),
          ({'type': 'string'}, str, 'str'),
          (
              {
                  'type': 'array',
                  'items': {'type': 'string'},
              },
              List[str],
              'List[str]',
          ),
      ],
  )
  def test_get_type_value_and_hint(
      self, schema, expected_type_value, expected_type_hint
  ):

    param = ApiParameter(
        original_name='test_param',
        param_location='query',
        param_schema=schema,
        description='Test parameter',
    )
    assert (
        TypeHintHelper.get_type_value(param.param_schema) == expected_type_value
    )
    assert (
        TypeHintHelper.get_type_hint(param.param_schema) == expected_type_hint
    )


class TestPydocHelper:

  def test_generate_param_doc_simple(self):
    schema = Schema(type='string')
    param = ApiParameter(
        original_name='test_param',
        param_location='query',
        param_schema=schema,
        description='Test description',
    )

    expected_doc = 'test_param (str): Test description'
    assert PydocHelper.generate_param_doc(param) == expected_doc

  def test_generate_param_doc_no_description(self):
    schema = Schema(type='integer')
    param = ApiParameter(
        original_name='test_param',
        param_location='query',
        param_schema=schema,
    )
    expected_doc = 'test_param (int): '
    assert PydocHelper.generate_param_doc(param) == expected_doc

  def test_generate_param_doc_object(self):
    schema = Schema(
        type='object',
        properties={
            'prop1': {'type': 'string', 'description': 'Prop1 desc'},
            'prop2': {'type': 'integer'},
        },
    )
    param = ApiParameter(
        original_name='test_param',
        param_location='query',
        param_schema=schema,
        description='Test object parameter',
    )
    expected_doc = (
        'test_param (Dict[str, Any]): Test object parameter Object'
        ' properties:\n       prop1 (str): Prop1 desc\n       prop2'
        ' (int): \n'
    )
    assert PydocHelper.generate_param_doc(param) == expected_doc

  def test_generate_param_doc_object_no_properties(self):
    schema = Schema(type='object', description='A test schema')
    param = ApiParameter(
        original_name='test_param',
        param_location='query',
        param_schema=schema,
        description='The description.',
    )
    expected_doc = 'test_param (Dict[str, Any]): The description.'
    assert PydocHelper.generate_param_doc(param) == expected_doc

  def test_generate_return_doc_simple(self):
    responses = {
        '200': {
            'description': 'Successful response',
            'content': {'application/json': {'schema': {'type': 'string'}}},
        }
    }
    expected_doc = 'Returns (str): Successful response'
    assert (
        PydocHelper.generate_return_doc(dict_to_responses(responses))
        == expected_doc
    )

  def test_generate_return_doc_no_content(self):
    responses = {'204': {'description': 'No content'}}
    assert not PydocHelper.generate_return_doc(dict_to_responses(responses))

  def test_generate_return_doc_object(self):
    responses = {
        '200': {
            'description': 'Successful object response',
            'content': {
                'application/json': {
                    'schema': {
                        'type': 'object',
                        'properties': {
                            'prop1': {
                                'type': 'string',
                                'description': 'Prop1 desc',
                            },
                            'prop2': {'type': 'integer'},
                        },
                    }
                }
            },
        }
    }

    return_doc = PydocHelper.generate_return_doc(dict_to_responses(responses))

    assert 'Returns (Dict[str, Any]): Successful object response' in return_doc
    assert 'prop1 (str): Prop1 desc' in return_doc
    assert 'prop2 (int):' in return_doc

  def test_generate_return_doc_multiple_success(self):
    responses = {
        '200': {
            'description': 'Successful response',
            'content': {'application/json': {'schema': {'type': 'string'}}},
        },
        '400': {'description': 'Bad request'},
    }
    expected_doc = 'Returns (str): Successful response'
    assert (
        PydocHelper.generate_return_doc(dict_to_responses(responses))
        == expected_doc
    )

  def test_generate_return_doc_2xx_smallest_status_code_response(self):
    responses = {
        '201': {
            'description': '201 response',
            'content': {'application/json': {'schema': {'type': 'integer'}}},
        },
        '200': {
            'description': '200 response',
            'content': {'application/json': {'schema': {'type': 'string'}}},
        },
        '400': {'description': 'Bad request'},
    }

    expected_doc = 'Returns (str): 200 response'
    assert (
        PydocHelper.generate_return_doc(dict_to_responses(responses))
        == expected_doc
    )

  def test_generate_return_doc_contentful_response(self):
    responses = {
        '200': {'description': 'No content response'},
        '201': {
            'description': '201 response',
            'content': {'application/json': {'schema': {'type': 'string'}}},
        },
        '400': {'description': 'Bad request'},
    }
    expected_doc = 'Returns (str): 201 response'
    assert (
        PydocHelper.generate_return_doc(dict_to_responses(responses))
        == expected_doc
    )


if __name__ == '__main__':
  pytest.main([__file__])

==== tests/unittests/tools/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

==== tests/unittests/tools/test_function_tool.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from unittest.mock import MagicMock

from google.adk.tools.function_tool import FunctionTool
import pytest


def function_for_testing_with_no_args():
  """Function for testing with no args."""
  pass


async def async_function_for_testing_with_1_arg_and_tool_context(
    arg1, tool_context
):
  """Async function for testing with 1 arge and tool context."""
  assert arg1
  assert tool_context
  return arg1


async def async_function_for_testing_with_2_arg_and_no_tool_context(arg1, arg2):
  """Async function for testing with 2 arge and no tool context."""
  assert arg1
  assert arg2
  return arg1


class AsyncCallableWith2ArgsAndNoToolContext:

  async def __call__(self, arg1, arg2):
    assert arg1
    assert arg2
    return arg1


def function_for_testing_with_1_arg_and_tool_context(arg1, tool_context):
  """Function for testing with 1 arge and tool context."""
  assert arg1
  assert tool_context
  return arg1


class AsyncCallableWith1ArgAndToolContext:

  async def __call__(self, arg1, tool_context):
    assert arg1
    assert tool_context
    return arg1


def function_for_testing_with_2_arg_and_no_tool_context(arg1, arg2):
  """Function for testing with 2 arge and no tool context."""
  assert arg1
  assert arg2
  return arg1


async def async_function_for_testing_with_4_arg_and_no_tool_context(
    arg1, arg2, arg3, arg4
):
  """Async function for testing with 4 args."""
  pass


def function_for_testing_with_4_arg_and_no_tool_context(arg1, arg2, arg3, arg4):
  """Function for testing with 4 args."""
  pass


def test_init():
  """Test that the FunctionTool is initialized correctly."""
  tool = FunctionTool(function_for_testing_with_no_args)
  assert tool.name == "function_for_testing_with_no_args"
  assert tool.description == "Function for testing with no args."
  assert tool.func == function_for_testing_with_no_args


@pytest.mark.asyncio
async def test_run_async_with_tool_context_async_func():
  """Test that run_async calls the function with tool_context when tool_context is in signature (async function)."""

  tool = FunctionTool(async_function_for_testing_with_1_arg_and_tool_context)
  args = {"arg1": "test_value_1"}
  result = await tool.run_async(args=args, tool_context=MagicMock())
  assert result == "test_value_1"


@pytest.mark.asyncio
async def test_run_async_with_tool_context_async_callable():
  """Test that run_async calls the callable with tool_context when tool_context is in signature (async callable)."""

  tool = FunctionTool(AsyncCallableWith1ArgAndToolContext())
  args = {"arg1": "test_value_1"}
  result = await tool.run_async(args=args, tool_context=MagicMock())
  assert result == "test_value_1"


@pytest.mark.asyncio
async def test_run_async_without_tool_context_async_func():
  """Test that run_async calls the function without tool_context when tool_context is not in signature (async function)."""
  tool = FunctionTool(async_function_for_testing_with_2_arg_and_no_tool_context)
  args = {"arg1": "test_value_1", "arg2": "test_value_2"}
  result = await tool.run_async(args=args, tool_context=MagicMock())
  assert result == "test_value_1"


@pytest.mark.asyncio
async def test_run_async_without_tool_context_async_callable():
  """Test that run_async calls the callable without tool_context when tool_context is not in signature (async callable)."""
  tool = FunctionTool(AsyncCallableWith2ArgsAndNoToolContext())
  args = {"arg1": "test_value_1", "arg2": "test_value_2"}
  result = await tool.run_async(args=args, tool_context=MagicMock())
  assert result == "test_value_1"


@pytest.mark.asyncio
async def test_run_async_with_tool_context_sync_func():
  """Test that run_async calls the function with tool_context when tool_context is in signature (synchronous function)."""
  tool = FunctionTool(function_for_testing_with_1_arg_and_tool_context)
  args = {"arg1": "test_value_1"}
  result = await tool.run_async(args=args, tool_context=MagicMock())
  assert result == "test_value_1"


@pytest.mark.asyncio
async def test_run_async_without_tool_context_sync_func():
  """Test that run_async calls the function without tool_context when tool_context is not in signature (synchronous function)."""
  tool = FunctionTool(function_for_testing_with_2_arg_and_no_tool_context)
  args = {"arg1": "test_value_1", "arg2": "test_value_2"}
  result = await tool.run_async(args=args, tool_context=MagicMock())
  assert result == "test_value_1"


@pytest.mark.asyncio
async def test_run_async_1_missing_arg_sync_func():
  """Test that run_async calls the function with 1 missing arg in signature (synchronous function)."""
  tool = FunctionTool(function_for_testing_with_2_arg_and_no_tool_context)
  args = {"arg1": "test_value_1"}
  result = await tool.run_async(args=args, tool_context=MagicMock())
  assert result == {
      "error": (
          """Invoking `function_for_testing_with_2_arg_and_no_tool_context()` failed as the following mandatory input parameters are not present:
arg2
You could retry calling this tool, but it is IMPORTANT for you to provide all the mandatory parameters."""
      )
  }


@pytest.mark.asyncio
async def test_run_async_1_missing_arg_async_func():
  """Test that run_async calls the function with 1 missing arg in signature (async function)."""
  tool = FunctionTool(async_function_for_testing_with_2_arg_and_no_tool_context)
  args = {"arg2": "test_value_1"}
  result = await tool.run_async(args=args, tool_context=MagicMock())
  assert result == {
      "error": (
          """Invoking `async_function_for_testing_with_2_arg_and_no_tool_context()` failed as the following mandatory input parameters are not present:
arg1
You could retry calling this tool, but it is IMPORTANT for you to provide all the mandatory parameters."""
      )
  }


@pytest.mark.asyncio
async def test_run_async_3_missing_arg_sync_func():
  """Test that run_async calls the function with 3 missing args in signature (synchronous function)."""
  tool = FunctionTool(function_for_testing_with_4_arg_and_no_tool_context)
  args = {"arg2": "test_value_1"}
  result = await tool.run_async(args=args, tool_context=MagicMock())
  assert result == {
      "error": (
          """Invoking `function_for_testing_with_4_arg_and_no_tool_context()` failed as the following mandatory input parameters are not present:
arg1
arg3
arg4
You could retry calling this tool, but it is IMPORTANT for you to provide all the mandatory parameters."""
      )
  }


@pytest.mark.asyncio
async def test_run_async_3_missing_arg_async_func():
  """Test that run_async calls the function with 3 missing args in signature (async function)."""
  tool = FunctionTool(async_function_for_testing_with_4_arg_and_no_tool_context)
  args = {"arg3": "test_value_1"}
  result = await tool.run_async(args=args, tool_context=MagicMock())
  assert result == {
      "error": (
          """Invoking `async_function_for_testing_with_4_arg_and_no_tool_context()` failed as the following mandatory input parameters are not present:
arg1
arg2
arg4
You could retry calling this tool, but it is IMPORTANT for you to provide all the mandatory parameters."""
      )
  }


@pytest.mark.asyncio
async def test_run_async_missing_all_arg_sync_func():
  """Test that run_async calls the function with all missing args in signature (synchronous function)."""
  tool = FunctionTool(function_for_testing_with_4_arg_and_no_tool_context)
  args = {}
  result = await tool.run_async(args=args, tool_context=MagicMock())
  assert result == {
      "error": (
          """Invoking `function_for_testing_with_4_arg_and_no_tool_context()` failed as the following mandatory input parameters are not present:
arg1
arg2
arg3
arg4
You could retry calling this tool, but it is IMPORTANT for you to provide all the mandatory parameters."""
      )
  }


@pytest.mark.asyncio
async def test_run_async_missing_all_arg_async_func():
  """Test that run_async calls the function with all missing args in signature (async function)."""
  tool = FunctionTool(async_function_for_testing_with_4_arg_and_no_tool_context)
  args = {}
  result = await tool.run_async(args=args, tool_context=MagicMock())
  assert result == {
      "error": (
          """Invoking `async_function_for_testing_with_4_arg_and_no_tool_context()` failed as the following mandatory input parameters are not present:
arg1
arg2
arg3
arg4
You could retry calling this tool, but it is IMPORTANT for you to provide all the mandatory parameters."""
      )
  }


@pytest.mark.asyncio
async def test_run_async_with_optional_args_not_set_sync_func():
  """Test that run_async calls the function for sync funciton with optional args not set."""

  def func_with_optional_args(arg1, arg2=None, *, arg3, arg4=None, **kwargs):
    return f"{arg1},{arg3}"

  tool = FunctionTool(func_with_optional_args)
  args = {"arg1": "test_value_1", "arg3": "test_value_3"}
  result = await tool.run_async(args=args, tool_context=MagicMock())
  assert result == "test_value_1,test_value_3"


@pytest.mark.asyncio
async def test_run_async_with_optional_args_not_set_async_func():
  """Test that run_async calls the function for async funciton with optional args not set."""

  async def async_func_with_optional_args(
      arg1, arg2=None, *, arg3, arg4=None, **kwargs
  ):
    return f"{arg1},{arg3}"

  tool = FunctionTool(async_func_with_optional_args)
  args = {"arg1": "test_value_1", "arg3": "test_value_3"}
  result = await tool.run_async(args=args, tool_context=MagicMock())
  assert result == "test_value_1,test_value_3"

==== tests/unittests/tools/test_build_function_declaration.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from typing import Dict
from typing import List

from google.adk.tools import _automatic_function_calling_util
from google.adk.tools.agent_tool import ToolContext
from google.adk.tools.langchain_tool import LangchainTool
# TODO: crewai requires python 3.10 as minimum
# from crewai_tools import FileReadTool
from langchain_community.tools import ShellTool
from pydantic import BaseModel
import pytest


def test_unsupported_variant():
  def simple_function(input_str: str) -> str:
    return {'result': input_str}

  with pytest.raises(ValueError):
    _automatic_function_calling_util.build_function_declaration(
        func=simple_function, variant='Unsupported'
    )


def test_string_input():
  def simple_function(input_str: str) -> str:
    return {'result': input_str}

  function_decl = _automatic_function_calling_util.build_function_declaration(
      func=simple_function
  )

  assert function_decl.name == 'simple_function'
  assert function_decl.parameters.type == 'OBJECT'
  assert function_decl.parameters.properties['input_str'].type == 'STRING'


def test_int_input():
  def simple_function(input_str: int) -> str:
    return {'result': input_str}

  function_decl = _automatic_function_calling_util.build_function_declaration(
      func=simple_function
  )

  assert function_decl.name == 'simple_function'
  assert function_decl.parameters.type == 'OBJECT'
  assert function_decl.parameters.properties['input_str'].type == 'INTEGER'


def test_float_input():
  def simple_function(input_str: float) -> str:
    return {'result': input_str}

  function_decl = _automatic_function_calling_util.build_function_declaration(
      func=simple_function
  )

  assert function_decl.name == 'simple_function'
  assert function_decl.parameters.type == 'OBJECT'
  assert function_decl.parameters.properties['input_str'].type == 'NUMBER'


def test_bool_input():
  def simple_function(input_str: bool) -> str:
    return {'result': input_str}

  function_decl = _automatic_function_calling_util.build_function_declaration(
      func=simple_function
  )

  assert function_decl.name == 'simple_function'
  assert function_decl.parameters.type == 'OBJECT'
  assert function_decl.parameters.properties['input_str'].type == 'BOOLEAN'


def test_array_input():
  def simple_function(input_str: List[str]) -> str:
    return {'result': input_str}

  function_decl = _automatic_function_calling_util.build_function_declaration(
      func=simple_function
  )

  assert function_decl.name == 'simple_function'
  assert function_decl.parameters.type == 'OBJECT'
  assert function_decl.parameters.properties['input_str'].type == 'ARRAY'


def test_dict_input():
  def simple_function(input_str: Dict[str, str]) -> str:
    return {'result': input_str}

  function_decl = _automatic_function_calling_util.build_function_declaration(
      func=simple_function
  )

  assert function_decl.name == 'simple_function'
  assert function_decl.parameters.type == 'OBJECT'
  assert function_decl.parameters.properties['input_str'].type == 'OBJECT'


def test_basemodel_input():
  class CustomInput(BaseModel):
    input_str: str

  def simple_function(input: CustomInput) -> str:
    return {'result': input}

  function_decl = _automatic_function_calling_util.build_function_declaration(
      func=simple_function
  )

  assert function_decl.name == 'simple_function'
  assert function_decl.parameters.type == 'OBJECT'
  assert function_decl.parameters.properties['input'].type == 'OBJECT'
  assert (
      function_decl.parameters.properties['input'].properties['input_str'].type
      == 'STRING'
  )


def test_toolcontext_ignored():
  def simple_function(input_str: str, tool_context: ToolContext) -> str:
    return {'result': input_str}

  function_decl = _automatic_function_calling_util.build_function_declaration(
      func=simple_function, ignore_params=['tool_context']
  )

  assert function_decl.name == 'simple_function'
  assert function_decl.parameters.type == 'OBJECT'
  assert function_decl.parameters.properties['input_str'].type == 'STRING'
  assert 'tool_context' not in function_decl.parameters.properties


def test_basemodel():
  class SimpleFunction(BaseModel):
    input_str: str
    custom_input: int

  function_decl = _automatic_function_calling_util.build_function_declaration(
      func=SimpleFunction, ignore_params=['custom_input']
  )

  assert function_decl.name == 'SimpleFunction'
  assert function_decl.parameters.type == 'OBJECT'
  assert function_decl.parameters.properties['input_str'].type == 'STRING'
  assert 'custom_input' not in function_decl.parameters.properties


def test_nested_basemodel_input():
  class ChildInput(BaseModel):
    input_str: str

  class CustomInput(BaseModel):
    child: ChildInput

  def simple_function(input: CustomInput) -> str:
    return {'result': input}

  function_decl = _automatic_function_calling_util.build_function_declaration(
      func=simple_function
  )

  assert function_decl.name == 'simple_function'
  assert function_decl.parameters.type == 'OBJECT'
  assert function_decl.parameters.properties['input'].type == 'OBJECT'
  assert (
      function_decl.parameters.properties['input'].properties['child'].type
      == 'OBJECT'
  )
  assert (
      function_decl.parameters.properties['input']
      .properties['child']
      .properties['input_str']
      .type
      == 'STRING'
  )


def test_basemodel_with_nested_basemodel():
  class ChildInput(BaseModel):
    input_str: str

  class CustomInput(BaseModel):
    child: ChildInput

  function_decl = _automatic_function_calling_util.build_function_declaration(
      func=CustomInput, ignore_params=['custom_input']
  )

  assert function_decl.name == 'CustomInput'
  assert function_decl.parameters.type == 'OBJECT'
  assert function_decl.parameters.properties['child'].type == 'OBJECT'
  assert (
      function_decl.parameters.properties['child'].properties['input_str'].type
      == 'STRING'
  )
  assert 'custom_input' not in function_decl.parameters.properties


def test_list():
  def simple_function(
      input_str: List[str], input_dir: List[Dict[str, str]]
  ) -> str:
    return {'result': input_str}

  function_decl = _automatic_function_calling_util.build_function_declaration(
      func=simple_function
  )

  assert function_decl.name == 'simple_function'
  assert function_decl.parameters.type == 'OBJECT'
  assert function_decl.parameters.properties['input_str'].type == 'ARRAY'
  assert function_decl.parameters.properties['input_str'].items.type == 'STRING'
  assert function_decl.parameters.properties['input_dir'].type == 'ARRAY'
  assert function_decl.parameters.properties['input_dir'].items.type == 'OBJECT'


def test_basemodel_list():
  class ChildInput(BaseModel):
    input_str: str

  class CustomInput(BaseModel):
    child: ChildInput

  def simple_function(input_str: List[CustomInput]) -> str:
    return {'result': input_str}

  function_decl = _automatic_function_calling_util.build_function_declaration(
      func=simple_function
  )

  assert function_decl.name == 'simple_function'
  assert function_decl.parameters.type == 'OBJECT'
  assert function_decl.parameters.properties['input_str'].type == 'ARRAY'
  assert function_decl.parameters.properties['input_str'].items.type == 'OBJECT'
  assert (
      function_decl.parameters.properties['input_str']
      .items.properties['child']
      .type
      == 'OBJECT'
  )
  assert (
      function_decl.parameters.properties['input_str']
      .items.properties['child']
      .properties['input_str']
      .type
      == 'STRING'
  )


# TODO: comment out this test for now as crewai requires python 3.10 as minimum
# def test_crewai_tool():
#   docs_tool = CrewaiTool(
#       name='directory_read_tool',
#       description='use this to find files for you.',
#       tool=FileReadTool(),
#   )
#   function_decl = docs_tool.get_declaration()
#   assert function_decl.name == 'directory_read_tool'
#   assert function_decl.parameters.type == 'OBJECT'
#   assert function_decl.parameters.properties['file_path'].type == 'STRING'

==== tests/unittests/tools/test_base_tool.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from typing import Optional

from google.adk.agents.invocation_context import InvocationContext
from google.adk.agents.sequential_agent import SequentialAgent
from google.adk.models.llm_request import LlmRequest
from google.adk.sessions.in_memory_session_service import InMemorySessionService
from google.adk.tools.base_tool import BaseTool
from google.adk.tools.tool_context import ToolContext
from google.genai import types
import pytest


class _TestingTool(BaseTool):

  def __init__(
      self,
      declaration: Optional[types.FunctionDeclaration] = None,
  ):
    super().__init__(name='test_tool', description='test_description')
    self.declaration = declaration

  def _get_declaration(self) -> Optional[types.FunctionDeclaration]:
    return self.declaration


async def _create_tool_context() -> ToolContext:
  session_service = InMemorySessionService()
  session = await session_service.create_session(
      app_name='test_app', user_id='test_user'
  )
  agent = SequentialAgent(name='test_agent')
  invocation_context = InvocationContext(
      invocation_id='invocation_id',
      agent=agent,
      session=session,
      session_service=session_service,
  )
  return ToolContext(invocation_context)


@pytest.mark.asyncio
async def test_process_llm_request_no_declaration():
  tool = _TestingTool()
  tool_context = await _create_tool_context()
  llm_request = LlmRequest()

  await tool.process_llm_request(
      tool_context=tool_context, llm_request=llm_request
  )

  assert llm_request.config is None


@pytest.mark.asyncio
async def test_process_llm_request_with_declaration():
  declaration = types.FunctionDeclaration(
      name='test_tool',
      description='test_description',
      parameters=types.Schema(
          type=types.Type.STRING,
          title='param_1',
      ),
  )
  tool = _TestingTool(declaration)
  llm_request = LlmRequest()
  tool_context = await _create_tool_context()

  await tool.process_llm_request(
      tool_context=tool_context, llm_request=llm_request
  )

  assert llm_request.config.tools[0].function_declarations == [declaration]


@pytest.mark.asyncio
async def test_process_llm_request_with_builtin_tool():
  declaration = types.FunctionDeclaration(
      name='test_tool',
      description='test_description',
      parameters=types.Schema(
          type=types.Type.STRING,
          title='param_1',
      ),
  )
  tool = _TestingTool(declaration)
  llm_request = LlmRequest(
      config=types.GenerateContentConfig(
          tools=[types.Tool(google_search=types.GoogleSearch())]
      )
  )
  tool_context = await _create_tool_context()

  await tool.process_llm_request(
      tool_context=tool_context, llm_request=llm_request
  )

  # function_declaration is added to another types.Tool without builtin tool.
  assert llm_request.config.tools[1].function_declarations == [declaration]


@pytest.mark.asyncio
async def test_process_llm_request_with_builtin_tool_and_another_declaration():
  declaration = types.FunctionDeclaration(
      name='test_tool',
      description='test_description',
      parameters=types.Schema(
          type=types.Type.STRING,
          title='param_1',
      ),
  )
  tool = _TestingTool(declaration)
  llm_request = LlmRequest(
      config=types.GenerateContentConfig(
          tools=[
              types.Tool(google_search=types.GoogleSearch()),
              types.Tool(function_declarations=[types.FunctionDeclaration()]),
          ]
      )
  )
  tool_context = await _create_tool_context()

  await tool.process_llm_request(
      tool_context=tool_context, llm_request=llm_request
  )

  # function_declaration is added to existing types.Tool with function_declaration.
  assert llm_request.config.tools[1].function_declarations[1] == declaration

==== tests/unittests/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

==== tests/unittests/evaluation/test_trajectory_evaluator.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Testings for the Trajectory Evaluator."""

import math
from google.adk.evaluation.trajectory_evaluator import TrajectoryEvaluator
import pytest

# Define reusable tool call structures
TOOL_ROLL_DICE_16 = {"tool_name": "roll_die", "tool_input": {"sides": 16}}
TOOL_ROLL_DICE_6 = {"tool_name": "roll_die", "tool_input": {"sides": 6}}
TOOL_GET_WEATHER = {
    "tool_name": "get_weather",
    "tool_input": {"location": "Paris"},
}
TOOL_GET_WEATHER_SF = {
    "tool_name": "get_weather",
    "tool_input": {"location": "SF"},
}

# Sample data for turns
TURN_MATCH = {
    "query": "Q1",
    "response": "R1",
    "actual_tool_use": [TOOL_ROLL_DICE_16],
    "expected_tool_use": [TOOL_ROLL_DICE_16],
}
TURN_MISMATCH_INPUT = {
    "query": "Q2",
    "response": "R2",
    "actual_tool_use": [TOOL_ROLL_DICE_6],
    "expected_tool_use": [TOOL_ROLL_DICE_16],
}
TURN_MISMATCH_NAME = {
    "query": "Q3",
    "response": "R3",
    "actual_tool_use": [TOOL_GET_WEATHER],
    "expected_tool_use": [TOOL_ROLL_DICE_16],
}
TURN_MATCH_MULTIPLE = {
    "query": "Q4",
    "response": "R4",
    "actual_tool_use": [TOOL_GET_WEATHER, TOOL_ROLL_DICE_6],
    "expected_tool_use": [TOOL_GET_WEATHER, TOOL_ROLL_DICE_6],
}
TURN_MISMATCH_ORDER = {
    "query": "Q5",
    "response": "R5",
    "actual_tool_use": [TOOL_ROLL_DICE_6, TOOL_GET_WEATHER],
    "expected_tool_use": [TOOL_GET_WEATHER, TOOL_ROLL_DICE_6],
}
TURN_MISMATCH_LENGTH_ACTUAL_LONGER = {
    "query": "Q6",
    "response": "R6",
    "actual_tool_use": [TOOL_GET_WEATHER, TOOL_ROLL_DICE_6],
    "expected_tool_use": [TOOL_GET_WEATHER],
}
TURN_MISMATCH_LENGTH_EXPECTED_LONGER = {
    "query": "Q7",
    "response": "R7",
    "actual_tool_use": [TOOL_GET_WEATHER],
    "expected_tool_use": [TOOL_GET_WEATHER, TOOL_ROLL_DICE_6],
}
TURN_MATCH_WITH_MOCK_OUTPUT = {
    "query": "Q8",
    "response": "R8",
    "actual_tool_use": [TOOL_GET_WEATHER_SF],
    "expected_tool_use": [
        {**TOOL_GET_WEATHER_SF, "mock_tool_output": "Sunny"}
    ],  # Add mock output to expected
}
TURN_MATCH_EMPTY_TOOLS = {
    "query": "Q9",
    "response": "R9",
    "actual_tool_use": [],
    "expected_tool_use": [],
}
TURN_MISMATCH_EMPTY_VS_NONEMPTY = {
    "query": "Q10",
    "response": "R10",
    "actual_tool_use": [],
    "expected_tool_use": [TOOL_GET_WEATHER],
}


def test_evaluate_none_dataset_raises_value_error():
  """Tests evaluate function raises ValueError for an empty list."""
  with pytest.raises(ValueError, match="The evaluation dataset is empty."):
    TrajectoryEvaluator.evaluate(None)


def test_evaluate_empty_dataset_raises_value_error():
  """Tests evaluate function raises ValueError for an empty list."""
  with pytest.raises(ValueError, match="The evaluation dataset is empty."):
    TrajectoryEvaluator.evaluate([])


def test_evaluate_single_turn_match():
  """Tests evaluate function with one conversation, one turn, perfect match."""
  eval_dataset = [[TURN_MATCH]]
  assert TrajectoryEvaluator.evaluate(eval_dataset) == 1.0


def test_evaluate_single_turn_mismatch():
  """Tests evaluate function with one conversation, one turn, mismatch."""
  eval_dataset = [[TURN_MISMATCH_INPUT]]
  assert TrajectoryEvaluator.evaluate(eval_dataset) == 0.0


def test_evaluate_multiple_turns_all_match():
  """Tests evaluate function with one conversation, multiple turns, all match."""
  eval_dataset = [[TURN_MATCH, TURN_MATCH_MULTIPLE, TURN_MATCH_EMPTY_TOOLS]]
  assert TrajectoryEvaluator.evaluate(eval_dataset) == 1.0


def test_evaluate_multiple_turns_mixed():
  """Tests evaluate function with one conversation, mixed match/mismatch turns."""
  eval_dataset = [
      [TURN_MATCH, TURN_MISMATCH_NAME, TURN_MATCH_MULTIPLE, TURN_MISMATCH_ORDER]
  ]
  # Expected: (1.0 + 0.0 + 1.0 + 0.0) / 4 = 0.5
  assert TrajectoryEvaluator.evaluate(eval_dataset) == 0.5


def test_evaluate_multiple_conversations_mixed():
  """Tests evaluate function with multiple conversations, mixed turns."""
  eval_dataset = [
      [TURN_MATCH, TURN_MISMATCH_INPUT],  # Conv 1: 1.0, 0.0 -> Avg 0.5
      [TURN_MATCH_MULTIPLE],  # Conv 2: 1.0 -> Avg 1.0
      [
          TURN_MISMATCH_ORDER,
          TURN_MISMATCH_LENGTH_ACTUAL_LONGER,
          TURN_MATCH,
      ],  # Conv 3: 0.0, 0.0, 1.0 -> Avg 1/3
  ]
  # Expected: (1.0 + 0.0 + 1.0 + 0.0 + 0.0 + 1.0) / 6 = 3.0 / 6 = 0.5
  assert TrajectoryEvaluator.evaluate(eval_dataset) == 0.5


def test_evaluate_ignores_mock_tool_output_in_expected():
  """Tests evaluate function correctly compares even if expected has mock_tool_output."""
  eval_dataset = [[TURN_MATCH_WITH_MOCK_OUTPUT]]
  assert TrajectoryEvaluator.evaluate(eval_dataset) == 1.0


def test_evaluate_match_empty_tool_lists():
  """Tests evaluate function correctly matches empty tool lists."""
  eval_dataset = [[TURN_MATCH_EMPTY_TOOLS]]
  assert TrajectoryEvaluator.evaluate(eval_dataset) == 1.0


def test_evaluate_mismatch_empty_vs_nonempty():
  """Tests evaluate function correctly mismatches empty vs non-empty tool lists."""
  eval_dataset = [[TURN_MISMATCH_EMPTY_VS_NONEMPTY]]
  assert TrajectoryEvaluator.evaluate(eval_dataset) == 0.0
  eval_dataset_rev = [[{
      **TURN_MISMATCH_EMPTY_VS_NONEMPTY,  # Swap actual/expected
      "actual_tool_use": [TOOL_GET_WEATHER],
      "expected_tool_use": [],
  }]]
  assert TrajectoryEvaluator.evaluate(eval_dataset_rev) == 0.0


def test_evaluate_dataset_with_empty_conversation():
  """Tests evaluate function handles dataset containing an empty conversation list."""
  eval_dataset = [[TURN_MATCH], []]  # One valid conversation, one empty
  # Should only evaluate the first conversation -> 1.0 / 1 turn = 1.0
  assert TrajectoryEvaluator.evaluate(eval_dataset) == 1.0


def test_evaluate_dataset_only_empty_conversation():
  """Tests evaluate function handles dataset with only an empty conversation."""
  eval_dataset = [[]]
  # No rows evaluated, mean of empty series is NaN
  # Depending on desired behavior, this could be 0.0 or NaN. The code returns
  # NaN.
  assert math.isnan(TrajectoryEvaluator.evaluate(eval_dataset))


def test_evaluate_print_detailed_results(capsys):
  """Tests evaluate function runs with print_detailed_results=True and prints something."""
  eval_dataset = [[TURN_MATCH, TURN_MISMATCH_INPUT]]
  TrajectoryEvaluator.evaluate(eval_dataset, print_detailed_results=True)
  captured = capsys.readouterr()
  assert "query" in captured.out  # Check if the results table header is printed
  assert "R1" in captured.out  # Check if some data is printed
  assert "Failures:" in captured.out  # Check if failures header is printed
  assert "Q2" in captured.out  # Check if the failing query is printed


def test_evaluate_no_failures_print(capsys):
  """Tests evaluate function does not print Failures section when all turns match."""
  eval_dataset = [[TURN_MATCH]]
  TrajectoryEvaluator.evaluate(eval_dataset, print_detailed_results=True)
  captured = capsys.readouterr()
  assert "query" in captured.out  # Results table should still print
  assert "Failures:" not in captured.out  # Failures section should NOT print


def test_are_tools_equal_identical():
  """Tests are_tools_equal function with identical lists."""
  list_a = [TOOL_GET_WEATHER, TOOL_ROLL_DICE_6]
  list_b = [TOOL_GET_WEATHER, TOOL_ROLL_DICE_6]
  assert TrajectoryEvaluator.are_tools_equal(list_a, list_b)


def test_are_tools_equal_empty():
  """Tests are_tools_equal function with empty lists."""
  assert TrajectoryEvaluator.are_tools_equal([], [])


def test_are_tools_equal_different_order():
  """Tests are_tools_equal function with same tools, different order."""
  list_a = [TOOL_ROLL_DICE_6, TOOL_GET_WEATHER]
  list_b = [TOOL_GET_WEATHER, TOOL_ROLL_DICE_6]
  assert not TrajectoryEvaluator.are_tools_equal(list_a, list_b)


def test_are_tools_equal_different_length():
  """Tests are_tools_equal function with lists of different lengths."""
  list_a = [TOOL_GET_WEATHER, TOOL_ROLL_DICE_6]
  list_b = [TOOL_GET_WEATHER]
  assert not TrajectoryEvaluator.are_tools_equal(list_a, list_b)


def test_are_tools_equal_different_input_values():
  """Tests are_tools_equal function with different input values."""
  list_a = [TOOL_ROLL_DICE_16]
  list_b = [TOOL_ROLL_DICE_6]
  assert not TrajectoryEvaluator.are_tools_equal(list_a, list_b)


def test_are_tools_equal_different_tool_names():
  """Tests are_tools_equal function with different tool names."""
  list_a = [TOOL_ROLL_DICE_16]
  list_b = [TOOL_GET_WEATHER]
  assert not TrajectoryEvaluator.are_tools_equal(list_a, list_b)


def test_are_tools_equal_ignores_extra_keys():
  """Tests are_tools_equal function ignores keys other than tool_name/tool_input."""
  list_a = [{
      "tool_name": "get_weather",
      "tool_input": {"location": "Paris"},
      "extra_key": "abc",
  }]
  list_b = [{
      "tool_name": "get_weather",
      "tool_input": {"location": "Paris"},
      "other_key": 123,
  }]
  assert TrajectoryEvaluator.are_tools_equal(list_a, list_b)


def test_are_tools_equal_one_empty_one_not():
  """Tests are_tools_equal function with one empty list and one non-empty list."""
  list_a = []
  list_b = [TOOL_GET_WEATHER]
  assert not TrajectoryEvaluator.are_tools_equal(list_a, list_b)

==== tests/unittests/evaluation/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

==== tests/unittests/evaluation/test_response_evaluator.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Tests for the Response Evaluator."""
from unittest.mock import MagicMock
from unittest.mock import patch

from google.adk.evaluation.response_evaluator import ResponseEvaluator
import pandas as pd
import pytest
from vertexai.preview.evaluation import MetricPromptTemplateExamples

# Mock object for the result normally returned by _perform_eval
MOCK_EVAL_RESULT = MagicMock()
MOCK_EVAL_RESULT.summary_metrics = {"mock_metric": 0.75, "another_mock": 3.5}
# Add a metrics_table for testing _print_results interaction
MOCK_EVAL_RESULT.metrics_table = pd.DataFrame({
    "prompt": ["mock_query1"],
    "response": ["mock_resp1"],
    "mock_metric": [0.75],
})

SAMPLE_TURN_1_ALL_KEYS = {
    "query": "query1",
    "response": "response1",
    "actual_tool_use": [{"tool_name": "tool_a", "tool_input": {}}],
    "expected_tool_use": [{"tool_name": "tool_a", "tool_input": {}}],
    "reference": "reference1",
}
SAMPLE_TURN_2_MISSING_REF = {
    "query": "query2",
    "response": "response2",
    "actual_tool_use": [],
    "expected_tool_use": [],
    # "reference": "reference2" # Missing
}
SAMPLE_TURN_3_MISSING_EXP_TOOLS = {
    "query": "query3",
    "response": "response3",
    "actual_tool_use": [{"tool_name": "tool_b", "tool_input": {}}],
    # "expected_tool_use": [], # Missing
    "reference": "reference3",
}
SAMPLE_TURN_4_MINIMAL = {
    "query": "query4",
    "response": "response4",
    # Minimal keys, others missing
}


@patch(
    "google.adk.evaluation.response_evaluator.ResponseEvaluator._perform_eval"
)
class TestResponseEvaluator:
  """A class to help organize "patch" that are applicabple to all tests."""

  def test_evaluate_none_dataset_raises_value_error(self, mock_perform_eval):
    """Test evaluate function raises ValueError for an empty list."""
    with pytest.raises(ValueError, match="The evaluation dataset is empty."):
      ResponseEvaluator.evaluate(None, ["response_evaluation_score"])
    mock_perform_eval.assert_not_called()  # Ensure _perform_eval was not called

  def test_evaluate_empty_dataset_raises_value_error(self, mock_perform_eval):
    """Test evaluate function raises ValueError for an empty list."""
    with pytest.raises(ValueError, match="The evaluation dataset is empty."):
      ResponseEvaluator.evaluate([], ["response_evaluation_score"])
    mock_perform_eval.assert_not_called()  # Ensure _perform_eval was not called

  def test_evaluate_determines_metrics_correctly_for_perform_eval(
      self, mock_perform_eval
  ):
    """Test that the correct metrics list is passed to _perform_eval based on criteria/keys."""
    mock_perform_eval.return_value = MOCK_EVAL_RESULT

    # Test case 1: Only Coherence
    raw_data_1 = [[SAMPLE_TURN_1_ALL_KEYS]]
    criteria_1 = ["response_evaluation_score"]
    ResponseEvaluator.evaluate(raw_data_1, criteria_1)
    _, kwargs = mock_perform_eval.call_args
    assert kwargs["metrics"] == [
        MetricPromptTemplateExamples.Pointwise.COHERENCE
    ]
    mock_perform_eval.reset_mock()  # Reset mock for next call

    # Test case 2: Only Rouge
    raw_data_2 = [[SAMPLE_TURN_1_ALL_KEYS]]
    criteria_2 = ["response_match_score"]
    ResponseEvaluator.evaluate(raw_data_2, criteria_2)
    _, kwargs = mock_perform_eval.call_args
    assert kwargs["metrics"] == ["rouge_1"]
    mock_perform_eval.reset_mock()

    # Test case 3: No metrics if keys missing in first turn
    raw_data_3 = [[SAMPLE_TURN_4_MINIMAL, SAMPLE_TURN_1_ALL_KEYS]]
    criteria_3 = ["response_evaluation_score", "response_match_score"]
    ResponseEvaluator.evaluate(raw_data_3, criteria_3)
    _, kwargs = mock_perform_eval.call_args
    assert kwargs["metrics"] == []
    mock_perform_eval.reset_mock()

    # Test case 4: No metrics if criteria empty
    raw_data_4 = [[SAMPLE_TURN_1_ALL_KEYS]]
    criteria_4 = []
    ResponseEvaluator.evaluate(raw_data_4, criteria_4)
    _, kwargs = mock_perform_eval.call_args
    assert kwargs["metrics"] == []
    mock_perform_eval.reset_mock()

  def test_evaluate_calls_perform_eval_correctly_all_metrics(
      self, mock_perform_eval
  ):
    """Test evaluate function calls _perform_eval with expected args when all criteria/keys are present."""
    # Arrange
    mock_perform_eval.return_value = (
        MOCK_EVAL_RESULT  # Configure the mock return value
    )

    raw_data = [[SAMPLE_TURN_1_ALL_KEYS]]
    criteria = ["response_evaluation_score", "response_match_score"]

    # Act
    summary = ResponseEvaluator.evaluate(raw_data, criteria)

    # Assert
    # 1. Check metrics determined by _get_metrics (passed to _perform_eval)
    expected_metrics_list = [
        MetricPromptTemplateExamples.Pointwise.COHERENCE,
        "rouge_1",
    ]
    # 2. Check DataFrame prepared (passed to _perform_eval)
    expected_df_data = [{
        "prompt": "query1",
        "response": "response1",
        "actual_tool_use": [{"tool_name": "tool_a", "tool_input": {}}],
        "reference_trajectory": [{"tool_name": "tool_a", "tool_input": {}}],
        "reference": "reference1",
    }]
    expected_df = pd.DataFrame(expected_df_data)

    # Assert _perform_eval was called once
    mock_perform_eval.assert_called_once()
    # Get the arguments passed to the mocked _perform_eval
    _, kwargs = mock_perform_eval.call_args
    # Check the 'dataset' keyword argument
    pd.testing.assert_frame_equal(kwargs["dataset"], expected_df)
    # Check the 'metrics' keyword argument
    assert kwargs["metrics"] == expected_metrics_list

    # 3. Check the correct summary metrics are returned
    # (from mock_perform_eval's return value)
    assert summary == MOCK_EVAL_RESULT.summary_metrics

  def test_evaluate_prepares_dataframe_correctly_for_perform_eval(
      self, mock_perform_eval
  ):
    """Test that the DataFrame is correctly flattened and renamed before passing to _perform_eval."""
    mock_perform_eval.return_value = MOCK_EVAL_RESULT

    raw_data = [
        [SAMPLE_TURN_1_ALL_KEYS],  # Conversation 1
        [
            SAMPLE_TURN_2_MISSING_REF,
            SAMPLE_TURN_3_MISSING_EXP_TOOLS,
        ],  # Conversation 2
    ]
    criteria = [
        "response_match_score"
    ]  # Doesn't affect the DataFrame structure

    ResponseEvaluator.evaluate(raw_data, criteria)

    # Expected flattened and renamed data
    expected_df_data = [
        # Turn 1 (from SAMPLE_TURN_1_ALL_KEYS)
        {
            "prompt": "query1",
            "response": "response1",
            "actual_tool_use": [{"tool_name": "tool_a", "tool_input": {}}],
            "reference_trajectory": [{"tool_name": "tool_a", "tool_input": {}}],
            "reference": "reference1",
        },
        # Turn 2 (from SAMPLE_TURN_2_MISSING_REF)
        {
            "prompt": "query2",
            "response": "response2",
            "actual_tool_use": [],
            "reference_trajectory": [],
            # "reference": None # Missing key results in NaN in DataFrame
            # usually
        },
        # Turn 3 (from SAMPLE_TURN_3_MISSING_EXP_TOOLS)
        {
            "prompt": "query3",
            "response": "response3",
            "actual_tool_use": [{"tool_name": "tool_b", "tool_input": {}}],
            # "reference_trajectory": None, # Missing key results in NaN
            "reference": "reference3",
        },
    ]
    # Need to be careful with missing keys -> NaN when creating DataFrame
    # Pandas handles this automatically when creating from list of dicts
    expected_df = pd.DataFrame(expected_df_data)

    mock_perform_eval.assert_called_once()
    _, kwargs = mock_perform_eval.call_args
    # Compare the DataFrame passed to the mock
    pd.testing.assert_frame_equal(kwargs["dataset"], expected_df)

  @patch(
      "google.adk.evaluation.response_evaluator.ResponseEvaluator._print_results"
  )  # Mock the private print method
  def test_evaluate_print_detailed_results(
      self, mock_print_results, mock_perform_eval
  ):
    """Test _print_results function is called when print_detailed_results=True."""
    mock_perform_eval.return_value = (
        MOCK_EVAL_RESULT  # Ensure _perform_eval returns our mock result
    )

    raw_data = [[SAMPLE_TURN_1_ALL_KEYS]]
    criteria = ["response_match_score"]

    ResponseEvaluator.evaluate(raw_data, criteria, print_detailed_results=True)

    # Assert _perform_eval was called
    mock_perform_eval.assert_called_once()
    # Assert _print_results was called once with the result object
    # from _perform_eval
    mock_print_results.assert_called_once_with(MOCK_EVAL_RESULT)

  @patch(
      "google.adk.evaluation.response_evaluator.ResponseEvaluator._print_results"
  )
  def test_evaluate_no_print_detailed_results(
      self, mock_print_results, mock_perform_eval
  ):
    """Test _print_results function is NOT called when print_detailed_results=False (default)."""
    mock_perform_eval.return_value = MOCK_EVAL_RESULT

    raw_data = [[SAMPLE_TURN_1_ALL_KEYS]]
    criteria = ["response_match_score"]

    ResponseEvaluator.evaluate(raw_data, criteria, print_detailed_results=False)

    # Assert _perform_eval was called
    mock_perform_eval.assert_called_once()
    # Assert _print_results was NOT called
    mock_print_results.assert_not_called()

==== tests/unittests/cli/utils/test_cli_create.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Tests for utilities in cli_create."""


from __future__ import annotations

import click
import os
import pytest
import subprocess

import google.adk.cli.cli_create as cli_create

from pathlib import Path
from typing import Any, Dict, List, Tuple

# Helpers
class _Recorder:
    """A callable object that records every invocation."""

    def __init__(self) -> None:
        self.calls: List[Tuple[Tuple[Any, ...], Dict[str, Any]]] = []

    def __call__(self, *args: Any, **kwargs: Any) -> None:  # noqa: D401
        self.calls.append((args, kwargs))


# Fixtures
@pytest.fixture(autouse=True)
def _mute_click(monkeypatch: pytest.MonkeyPatch) -> None:
    """Silence click output in every test."""
    monkeypatch.setattr(click, "echo", lambda *a, **k: None)
    monkeypatch.setattr(click, "secho", lambda *a, **k: None)


@pytest.fixture()
def agent_folder(tmp_path: Path) -> Path:
    """Return a temporary path that will hold generated agent sources."""
    return tmp_path / "agent"


# _generate_files
def test_generate_files_with_api_key(agent_folder: Path) -> None:
    """Files should be created with the API-key backend and correct .env flags."""
    cli_create._generate_files(
        str(agent_folder),
        google_api_key="dummy-key",
        model="gemini-2.0-flash-001",
    )

    env_content = (agent_folder / ".env").read_text()
    assert "GOOGLE_API_KEY=dummy-key" in env_content
    assert "GOOGLE_GENAI_USE_VERTEXAI=0" in env_content
    assert (agent_folder / "agent.py").exists()
    assert (agent_folder / "__init__.py").exists()


def test_generate_files_with_gcp(agent_folder: Path) -> None:
    """Files should be created with Vertex AI backend and correct .env flags."""
    cli_create._generate_files(
        str(agent_folder),
        google_cloud_project="proj",
        google_cloud_region="us-central1",
        model="gemini-2.0-flash-001",
    )

    env_content = (agent_folder / ".env").read_text()
    assert "GOOGLE_CLOUD_PROJECT=proj" in env_content
    assert "GOOGLE_CLOUD_LOCATION=us-central1" in env_content
    assert "GOOGLE_GENAI_USE_VERTEXAI=1" in env_content


def test_generate_files_overwrite(agent_folder: Path) -> None:
    """Existing files should be overwritten when generating again."""
    agent_folder.mkdir(parents=True, exist_ok=True)
    (agent_folder / ".env").write_text("OLD")

    cli_create._generate_files(
        str(agent_folder),
        google_api_key="new-key",
        model="gemini-2.0-flash-001",
    )

    assert "GOOGLE_API_KEY=new-key" in (agent_folder / ".env").read_text()


def test_generate_files_permission_error(monkeypatch: pytest.MonkeyPatch, agent_folder: Path) -> None:
    """PermissionError raised by os.makedirs should propagate."""
    monkeypatch.setattr(os, "makedirs", lambda *a, **k: (_ for _ in ()).throw(PermissionError()))
    with pytest.raises(PermissionError):
        cli_create._generate_files(str(agent_folder), model="gemini-2.0-flash-001")


def test_generate_files_no_params(agent_folder: Path) -> None:
    """No backend parameters  minimal .env file is generated."""
    cli_create._generate_files(str(agent_folder), model="gemini-2.0-flash-001")

    env_content = (agent_folder / ".env").read_text()
    for key in ("GOOGLE_API_KEY", "GOOGLE_CLOUD_PROJECT", "GOOGLE_CLOUD_LOCATION", "GOOGLE_GENAI_USE_VERTEXAI"):
        assert key not in env_content


# run_cmd
def test_run_cmd_overwrite_reject(monkeypatch: pytest.MonkeyPatch, tmp_path: Path) -> None:
    """User rejecting overwrite should trigger click.Abort."""
    agent_name = "agent"
    agent_dir = tmp_path / agent_name
    agent_dir.mkdir()
    (agent_dir / "dummy.txt").write_text("dummy")

    monkeypatch.setattr(os, "getcwd", lambda: str(tmp_path))
    monkeypatch.setattr(os.path, "exists", lambda _p: True)
    monkeypatch.setattr(os, "listdir", lambda _p: ["dummy.txt"])
    monkeypatch.setattr(click, "confirm", lambda *a, **k: False)

    with pytest.raises(click.Abort):
        cli_create.run_cmd(
            agent_name,
            model="gemini-2.0-flash-001",
            google_api_key=None,
            google_cloud_project=None,
            google_cloud_region=None,
        )


# Prompt helpers
def test_prompt_for_google_cloud(monkeypatch: pytest.MonkeyPatch) -> None:
    """Prompt should return the project input."""
    monkeypatch.setattr(click, "prompt", lambda *a, **k: "test-proj")
    assert cli_create._prompt_for_google_cloud(None) == "test-proj"


def test_prompt_for_google_cloud_region(monkeypatch: pytest.MonkeyPatch) -> None:
    """Prompt should return the region input."""
    monkeypatch.setattr(click, "prompt", lambda *a, **k: "asia-northeast1")
    assert cli_create._prompt_for_google_cloud_region(None) == "asia-northeast1"


def test_prompt_for_google_api_key(monkeypatch: pytest.MonkeyPatch) -> None:
    """Prompt should return the API-key input."""
    monkeypatch.setattr(click, "prompt", lambda *a, **k: "api-key")
    assert cli_create._prompt_for_google_api_key(None) == "api-key"


def test_prompt_for_model_gemini(monkeypatch: pytest.MonkeyPatch) -> None:
    """Selecting option '1' should return the default Gemini model string."""
    monkeypatch.setattr(click, "prompt", lambda *a, **k: "1")
    assert cli_create._prompt_for_model() == "gemini-2.0-flash-001"


def test_prompt_for_model_other(monkeypatch: pytest.MonkeyPatch) -> None:
    """Selecting option '2' should return placeholder and call secho."""
    called: Dict[str, bool] = {}

    monkeypatch.setattr(click, "prompt", lambda *a, **k: "2")

    def _fake_secho(*_a: Any, **_k: Any) -> None:
        called["secho"] = True

    monkeypatch.setattr(click, "secho", _fake_secho)
    assert cli_create._prompt_for_model() == "<FILL_IN_MODEL>"
    assert called.get("secho") is True



# Backend selection helper
def test_prompt_to_choose_backend_api(monkeypatch: pytest.MonkeyPatch) -> None:
    """Choosing API-key backend returns (api_key, None, None)."""
    monkeypatch.setattr(click, "prompt", lambda *a, **k: "1")
    monkeypatch.setattr(cli_create, "_prompt_for_google_api_key", lambda _v: "api-key")

    api_key, proj, region = cli_create._prompt_to_choose_backend(None, None, None)
    assert api_key == "api-key"
    assert proj is None and region is None


def test_prompt_to_choose_backend_vertex(monkeypatch: pytest.MonkeyPatch) -> None:
    """Choosing Vertex backend returns (None, project, region)."""
    monkeypatch.setattr(click, "prompt", lambda *a, **k: "2")
    monkeypatch.setattr(cli_create, "_prompt_for_google_cloud", lambda _v: "proj")
    monkeypatch.setattr(cli_create, "_prompt_for_google_cloud_region", lambda _v: "region")

    api_key, proj, region = cli_create._prompt_to_choose_backend(None, None, None)
    assert api_key is None
    assert proj == "proj"
    assert region == "region"



# prompt_str
def test_prompt_str_non_empty(monkeypatch: pytest.MonkeyPatch) -> None:
    """_prompt_str should retry until a non-blank string is provided."""
    responses = iter(["", " ", "valid"])
    monkeypatch.setattr(click, "prompt", lambda *_a, **_k: next(responses))
    assert cli_create._prompt_str("dummy") == "valid"



# gcloud fallback helpers
def test_get_gcp_project_from_gcloud_fail(monkeypatch: pytest.MonkeyPatch) -> None:
    """Failure of gcloud project lookup should return empty string."""
    monkeypatch.setattr(
        subprocess,
        "run",
        lambda *_a, **_k: (_ for _ in ()).throw(FileNotFoundError()),
    )
    assert cli_create._get_gcp_project_from_gcloud() == ""


def test_get_gcp_region_from_gcloud_fail(monkeypatch: pytest.MonkeyPatch) -> None:
    """CalledProcessError should result in empty region string."""
    monkeypatch.setattr(
        subprocess,
        "run",
        lambda *_a, **_k: (_ for _ in ()).throw(subprocess.CalledProcessError(1, "gcloud")),
    )
    assert cli_create._get_gcp_region_from_gcloud() == ""

==== tests/unittests/cli/utils/test_cli_deploy.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Tests for utilities in cli_deploy."""


from __future__ import annotations

import click
import shutil
import pytest
import subprocess
import tempfile
import types

import google.adk.cli.cli_deploy as cli_deploy

from pathlib import Path
from typing import Any, Callable, Dict, List, Tuple
from unittest import mock

# Helpers
class _Recorder:
    """A callable object that records every invocation."""

    def __init__(self) -> None:
        self.calls: List[Tuple[Tuple[Any, ...], Dict[str, Any]]] = []

    def __call__(self, *args: Any, **kwargs: Any) -> None:
        self.calls.append((args, kwargs))


# Fixtures
@pytest.fixture(autouse=True)
def _mute_click(monkeypatch: pytest.MonkeyPatch) -> None:
    """Suppress click.echo to keep test output clean."""
    monkeypatch.setattr(click, "echo", lambda *a, **k: None)


@pytest.fixture()
def agent_dir(tmp_path: Path) -> Callable[[bool], Path]:
    """Return a factory that creates a dummy agent directory tree."""

    def _factory(include_requirements: bool) -> Path:
        base = tmp_path / "agent"
        base.mkdir()
        (base / "agent.py").write_text("# dummy agent")
        (base / "__init__.py").touch()
        if include_requirements:
            (base / "requirements.txt").write_text("pytest\n")
        return base

    return _factory


# _resolve_project
def test_resolve_project_with_option() -> None:
    """It should return the explicit project value untouched."""
    assert cli_deploy._resolve_project("my-project") == "my-project"


def test_resolve_project_from_gcloud(monkeypatch: pytest.MonkeyPatch) -> None:
    """It should fall back to `gcloud config get-value project` when no value supplied."""
    monkeypatch.setattr(
        subprocess,
        "run",
        lambda *a, **k: types.SimpleNamespace(stdout="gcp-proj\n"),
    )

    with mock.patch("click.echo") as mocked_echo:
        assert cli_deploy._resolve_project(None) == "gcp-proj"
        mocked_echo.assert_called_once()


# to_cloud_run
@pytest.mark.parametrize("include_requirements", [True, False])
def test_to_cloud_run_happy_path(
    monkeypatch: pytest.MonkeyPatch,
    agent_dir: Callable[[bool], Path],
    include_requirements: bool,
) -> None:
    """
    End-to-end execution test for `to_cloud_run` covering both presence and
    absence of *requirements.txt*.
    """
    tmp_dir = Path(tempfile.mkdtemp())
    src_dir = agent_dir(include_requirements)

    copy_recorder = _Recorder()
    run_recorder = _Recorder()

    # Cache the ORIGINAL copytree before patching
    original_copytree = cli_deploy.shutil.copytree

    def _recording_copytree(*args: Any, **kwargs: Any):
        copy_recorder(*args, **kwargs)
        return original_copytree(*args, **kwargs)

    monkeypatch.setattr(cli_deploy.shutil, "copytree", _recording_copytree)
    # Skip actual cleanup so that we can inspect generated files later.
    monkeypatch.setattr(cli_deploy.shutil, "rmtree", lambda *_a, **_k: None)
    monkeypatch.setattr(subprocess, "run", run_recorder)

    cli_deploy.to_cloud_run(
        agent_folder=str(src_dir),
        project="proj",
        region="asia-northeast1",
        service_name="svc",
        app_name="app",
        temp_folder=str(tmp_dir),
        port=8080,
        trace_to_cloud=True,
        with_ui=True,
        verbosity="info",
        session_db_url="sqlite://",
        adk_version="0.0.5",
    )

    # Assertions
    assert len(copy_recorder.calls) == 1, "Agent sources must be copied exactly once."
    assert run_recorder.calls, "gcloud command should be executed at least once."
    assert (tmp_dir / "Dockerfile").exists(), "Dockerfile must be generated."

    # Manual cleanup because we disabled rmtree in the monkeypatch.
    shutil.rmtree(tmp_dir, ignore_errors=True)


def test_to_cloud_run_cleans_temp_dir(
    monkeypatch: pytest.MonkeyPatch,
    agent_dir: Callable[[bool], Path],
) -> None:
    """`to_cloud_run` should always delete the temporary folder on exit."""
    tmp_dir = Path(tempfile.mkdtemp())
    src_dir = agent_dir(False)

    deleted: Dict[str, Path] = {}

    def _fake_rmtree(path: str | Path, *a: Any, **k: Any) -> None:
        deleted["path"] = Path(path)

    monkeypatch.setattr(cli_deploy.shutil, "rmtree", _fake_rmtree)
    monkeypatch.setattr(subprocess, "run", _Recorder())

    cli_deploy.to_cloud_run(
        agent_folder=str(src_dir),
        project="proj",
        region=None,
        service_name="svc",
        app_name="app",
        temp_folder=str(tmp_dir),
        port=8080,
        trace_to_cloud=False,
        with_ui=False,
        verbosity="info",
        session_db_url=None,
        adk_version="0.0.5",
    )

    assert deleted["path"] == tmp_dir

==== tests/unittests/cli/utils/test_evals.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Tests for utilities in eval."""


from google.adk.cli.utils.evals import convert_session_to_eval_format
from google.adk.events.event import Event
from google.adk.sessions.session import Session
from google.genai import types


def build_event(author: str, parts_content: list[dict]) -> Event:
  """Builds an Event object with specified parts."""
  parts = []
  for p_data in parts_content:
    part_args = {}
    if "text" in p_data:
      part_args["text"] = p_data["text"]
    if "func_name" in p_data:
      part_args["function_call"] = types.FunctionCall(
          name=p_data.get("func_name"), args=p_data.get("func_args")
      )
    # Add other part types here if needed for future tests
    parts.append(types.Part(**part_args))
  return Event(author=author, content=types.Content(parts=parts))


def test_convert_empty_session():
  """Test conversion function with empty events list in Session."""
  # Pydantic models require mandatory fields for instantiation
  session_empty_events = Session(
      id="s1", app_name="app", user_id="u1", events=[]
  )
  assert not convert_session_to_eval_format(session_empty_events)


def test_convert_none_session():
  """Test conversion function with None Session."""
  assert not convert_session_to_eval_format(None)


def test_convert_session_skips_initial_non_user_events():
  """Test conversion function with only user events."""
  events = [
      build_event("model", [{"text": "Hello"}]),
      build_event("user", [{"text": "How are you?"}]),
  ]
  session = Session(id="s1", app_name="app", user_id="u1", events=events)
  expected = [
      {
          "query": "How are you?",
          "expected_tool_use": [],
          "expected_intermediate_agent_responses": [],
          "reference": "",
      },
  ]
  assert convert_session_to_eval_format(session) == expected


def test_convert_single_turn_text_only():
  """Test a single user query followed by a single agent text response."""
  events = [
      build_event("user", [{"text": "What is the time?"}]),
      build_event("root_agent", [{"text": "It is 3 PM."}]),
  ]
  session = Session(id="s1", app_name="app", user_id="u1", events=events)
  expected = [{
      "query": "What is the time?",
      "expected_tool_use": [],
      "expected_intermediate_agent_responses": [],
      "reference": "It is 3 PM.",
  }]
  assert convert_session_to_eval_format(session) == expected


def test_convert_single_turn_tool_only():
  """Test a single user query followed by a single agent tool call."""
  events = [
      build_event("user", [{"text": "Get weather for Seattle"}]),
      build_event(
          "root_agent",
          [{"func_name": "get_weather", "func_args": {"city": "Seattle"}}],
      ),
  ]
  session = Session(id="s1", app_name="app", user_id="u1", events=events)
  expected = [{
      "query": "Get weather for Seattle",
      "expected_tool_use": [
          {"tool_name": "get_weather", "tool_input": {"city": "Seattle"}}
      ],
      "expected_intermediate_agent_responses": [],
      "reference": "",
  }]
  assert convert_session_to_eval_format(session) == expected


def test_convert_single_turn_multiple_tools_and_texts():
  """Test a turn with multiple agent responses (tools and text)."""
  events = [
      build_event("user", [{"text": "Do task A then task B"}]),
      build_event(
          "root_agent", [{"text": "Okay, starting task A."}]
      ),  # Intermediate Text 1
      build_event(
          "root_agent", [{"func_name": "task_A", "func_args": {"param": 1}}]
      ),  # Tool 1
      build_event(
          "root_agent", [{"text": "Task A done. Now starting task B."}]
      ),  # Intermediate Text 2
      build_event(
          "another_agent", [{"func_name": "task_B", "func_args": {}}]
      ),  # Tool 2
      build_event(
          "root_agent", [{"text": "All tasks completed."}]
      ),  # Final Text (Reference)
  ]
  session = Session(id="s1", app_name="app", user_id="u1", events=events)
  expected = [{
      "query": "Do task A then task B",
      "expected_tool_use": [
          {"tool_name": "task_A", "tool_input": {"param": 1}},
          {"tool_name": "task_B", "tool_input": {}},
      ],
      "expected_intermediate_agent_responses": [
          {"author": "root_agent", "text": "Okay, starting task A."},
          {
              "author": "root_agent",
              "text": "Task A done. Now starting task B.",
          },
      ],
      "reference": "All tasks completed.",
  }]
  assert convert_session_to_eval_format(session) == expected


def test_convert_multi_turn_session():
  """Test a session with multiple user/agent turns."""
  events = [
      build_event("user", [{"text": "Query 1"}]),
      build_event("agent", [{"text": "Response 1"}]),
      build_event("user", [{"text": "Query 2"}]),
      build_event("agent", [{"func_name": "tool_X", "func_args": {}}]),
      build_event("agent", [{"text": "Response 2"}]),
  ]
  session = Session(id="s1", app_name="app", user_id="u1", events=events)
  expected = [
      {  # Turn 1
          "query": "Query 1",
          "expected_tool_use": [],
          "expected_intermediate_agent_responses": [],
          "reference": "Response 1",
      },
      {  # Turn 2
          "query": "Query 2",
          "expected_tool_use": [{"tool_name": "tool_X", "tool_input": {}}],
          "expected_intermediate_agent_responses": [],
          "reference": "Response 2",
      },
  ]
  assert convert_session_to_eval_format(session) == expected


def test_convert_agent_event_multiple_parts():
  """Test an agent event with both text and tool call parts."""
  events = [
      build_event("user", [{"text": "Do something complex"}]),
      # Build event with multiple dicts in parts_content list
      build_event(
          "agent",
          [
              {"text": "Okay, doing it."},
              {"func_name": "complex_tool", "func_args": {"value": True}},
          ],
      ),
      build_event("agent", [{"text": "Finished."}]),
  ]
  session = Session(id="s1", app_name="app", user_id="u1", events=events)
  expected = [{
      "query": "Do something complex",
      "expected_tool_use": [
          {"tool_name": "complex_tool", "tool_input": {"value": True}}
      ],
      "expected_intermediate_agent_responses": [{
          "author": "agent",
          "text": "Okay, doing it.",
      }],  # Text from first part of agent event
      "reference": "Finished.",  # Text from second agent event
  }]
  assert convert_session_to_eval_format(session) == expected


def test_convert_handles_missing_content_or_parts():
  """Test that events missing content or parts are skipped gracefully."""
  events = [
      build_event("user", [{"text": "Query 1"}]),
      Event(author="agent", content=None),  # Agent event missing content
      build_event("agent", [{"text": "Response 1"}]),
      Event(author="user", content=None),  # User event missing content
      build_event("user", [{"text": "Query 2"}]),
      Event(
          author="agent", content=types.Content(parts=[])
      ),  # Agent event with empty parts list
      build_event("agent", [{"text": "Response 2"}]),
      # User event with content but no parts (or None parts)
      Event(author="user", content=types.Content(parts=None)),
      build_event("user", [{"text": "Query 3"}]),
      build_event("agent", [{"text": "Response 3"}]),
  ]
  session = Session(id="s1", app_name="app", user_id="u1", events=events)
  expected = [
      {  # Turn 1 (from Query 1)
          "query": "Query 1",
          "expected_tool_use": [],
          "expected_intermediate_agent_responses": [],
          "reference": "Response 1",
      },
      {  # Turn 2 (from Query 2 - user event with None content was skipped)
          "query": "Query 2",
          "expected_tool_use": [],
          "expected_intermediate_agent_responses": [],
          "reference": "Response 2",
      },
      {  # Turn 3 (from Query 3 - user event with None parts was skipped)
          "query": "Query 3",
          "expected_tool_use": [],
          "expected_intermediate_agent_responses": [],
          "reference": "Response 3",
      },
  ]
  assert convert_session_to_eval_format(session) == expected


def test_convert_handles_missing_tool_name_or_args():
  """Test tool calls with missing name or args."""
  events = [
      build_event("user", [{"text": "Call tools"}]),
      # Event where FunctionCall has name=None
      Event(
          author="agent",
          content=types.Content(
              parts=[
                  types.Part(
                      function_call=types.FunctionCall(name=None, args={"a": 1})
                  )
              ]
          ),
      ),
      # Event where FunctionCall has args=None
      Event(
          author="agent",
          content=types.Content(
              parts=[
                  types.Part(
                      function_call=types.FunctionCall(name="tool_B", args=None)
                  )
              ]
          ),
      ),
      # Event where FunctionCall part exists but FunctionCall object is None
      # (should skip)
      Event(
          author="agent",
          content=types.Content(
              parts=[types.Part(function_call=None, text="some text")]
          ),
      ),
      build_event("agent", [{"text": "Done"}]),
  ]
  session = Session(id="s1", app_name="app", user_id="u1", events=events)
  expected = [{
      "query": "Call tools",
      "expected_tool_use": [
          {"tool_name": "", "tool_input": {"a": 1}},  # Defaults name to ""
          {"tool_name": "tool_B", "tool_input": {}},  # Defaults args to {}
      ],
      "expected_intermediate_agent_responses": [{
          "author": "agent",
          "text": "some text",
      }],  # Text part from the event where function_call was None
      "reference": "Done",
  }]
  assert convert_session_to_eval_format(session) == expected


def test_convert_handles_missing_user_query_text():
  """Test user event where the first part has no text."""
  events = [
      # Event where user part has text=None
      Event(
          author="user", content=types.Content(parts=[types.Part(text=None)])
      ),
      build_event("agent", [{"text": "Response 1"}]),
      # Event where user part has text=""
      build_event("user", [{"text": ""}]),
      build_event("agent", [{"text": "Response 2"}]),
  ]
  session = Session(id="s1", app_name="app", user_id="u1", events=events)
  expected = [
      {
          "query": "",  # Defaults to "" if text is None
          "expected_tool_use": [],
          "expected_intermediate_agent_responses": [],
          "reference": "Response 1",
      },
      {
          "query": "",  # Defaults to "" if text is ""
          "expected_tool_use": [],
          "expected_intermediate_agent_responses": [],
          "reference": "Response 2",
      },
  ]
  assert convert_session_to_eval_format(session) == expected


def test_convert_handles_empty_agent_text():
  """Test agent responses with empty string text."""
  events = [
      build_event("user", [{"text": "Query"}]),
      build_event("agent", [{"text": "Okay"}]),
      build_event("agent", [{"text": ""}]),  # Empty text
      build_event("agent", [{"text": "Done"}]),
  ]
  session = Session(id="s1", app_name="app", user_id="u1", events=events)
  expected = [{
      "query": "Query",
      "expected_tool_use": [],
      "expected_intermediate_agent_responses": [
          {"author": "agent", "text": "Okay"},
      ],
      "reference": "Done",
  }]
  assert convert_session_to_eval_format(session) == expected


def test_convert_complex_sample_session():
  """Test using the complex sample session provided earlier."""
  events = [
      build_event("user", [{"text": "What can you do?"}]),
      build_event(
          "root_agent",
          [{"text": "I can roll dice and check if numbers are prime. \n"}],
      ),
      build_event(
          "user",
          [{
              "text": (
                  "Roll a 8 sided dice and then check if 90 is a prime number"
                  " or not."
              )
          }],
      ),
      build_event(
          "root_agent",
          [{
              "func_name": "transfer_to_agent",
              "func_args": {"agent_name": "roll_agent"},
          }],
      ),
      # Skipping FunctionResponse events as they don't have text/functionCall
      # parts used by converter
      build_event(
          "roll_agent", [{"func_name": "roll_die", "func_args": {"sides": 8}}]
      ),
      # Skipping FunctionResponse
      build_event(
          "roll_agent",
          [
              {"text": "I rolled a 2. Now, I'll check if 90 is prime. \n\n"},
              {
                  "func_name": "transfer_to_agent",
                  "func_args": {"agent_name": "prime_agent"},
              },
          ],
      ),
      # Skipping FunctionResponse
      build_event(
          "prime_agent",
          [{"func_name": "check_prime", "func_args": {"nums": [90]}}],
      ),
      # Skipping FunctionResponse
      build_event("prime_agent", [{"text": "90 is not a prime number. \n"}]),
  ]
  session = Session(
      id="some_id",
      app_name="hello_world_ma",
      user_id="user",
      events=events,
  )
  expected = [
      {
          "query": "What can you do?",
          "expected_tool_use": [],
          "expected_intermediate_agent_responses": [],
          "reference": "I can roll dice and check if numbers are prime. \n",
      },
      {
          "query": (
              "Roll a 8 sided dice and then check if 90 is a prime number or"
              " not."
          ),
          "expected_tool_use": [
              {
                  "tool_name": "transfer_to_agent",
                  "tool_input": {"agent_name": "roll_agent"},
              },
              {"tool_name": "roll_die", "tool_input": {"sides": 8}},
              {
                  "tool_name": "transfer_to_agent",
                  "tool_input": {"agent_name": "prime_agent"},
              },  # From combined event
              {"tool_name": "check_prime", "tool_input": {"nums": [90]}},
          ],
          "expected_intermediate_agent_responses": [{
              "author": "roll_agent",
              "text": "I rolled a 2. Now, I'll check if 90 is prime. \n\n",
          }],  # Text from combined event
          "reference": "90 is not a prime number. \n",
      },
  ]

  actual = convert_session_to_eval_format(session)
  assert actual == expected

==== tests/unittests/cli/utils/test_cli_tools_click.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Tests for utilities in cli_tool_click."""


from __future__ import annotations

import builtins
from pathlib import Path
from types import SimpleNamespace
from typing import Any
from typing import Dict
from typing import List
from typing import Tuple

import click
from click.testing import CliRunner
from google.adk.cli import cli_tools_click
import pytest


# Helpers
class _Recorder:
  """Callable that records every invocation."""

  def __init__(self) -> None:
    self.calls: List[Tuple[Tuple[Any, ...], Dict[str, Any]]] = []

  def __call__(self, *args: Any, **kwargs: Any) -> None:  # noqa: D401
    self.calls.append((args, kwargs))


# Fixtures
@pytest.fixture(autouse=True)
def _mute_click(monkeypatch: pytest.MonkeyPatch) -> None:
  """Suppress click output during tests."""
  monkeypatch.setattr(click, "echo", lambda *a, **k: None)
  monkeypatch.setattr(click, "secho", lambda *a, **k: None)


# validate_exclusive
def test_validate_exclusive_allows_single() -> None:
  """Providing exactly one exclusive option should pass."""
  ctx = click.Context(cli_tools_click.main)
  param = SimpleNamespace(name="replay")
  assert (
      cli_tools_click.validate_exclusive(ctx, param, "file.json") == "file.json"
  )


def test_validate_exclusive_blocks_multiple() -> None:
  """Providing two exclusive options should raise UsageError."""
  ctx = click.Context(cli_tools_click.main)
  param1 = SimpleNamespace(name="replay")
  param2 = SimpleNamespace(name="resume")

  # First option registers fine
  cli_tools_click.validate_exclusive(ctx, param1, "replay.json")

  # Second option triggers conflict
  with pytest.raises(click.UsageError):
    cli_tools_click.validate_exclusive(ctx, param2, "resume.json")


# cli create
def test_cli_create_cmd_invokes_run_cmd(
    tmp_path: Path, monkeypatch: pytest.MonkeyPatch
) -> None:
  """`adk create` should forward arguments to cli_create.run_cmd."""
  rec = _Recorder()
  monkeypatch.setattr(cli_tools_click.cli_create, "run_cmd", rec)

  app_dir = tmp_path / "my_app"
  runner = CliRunner()
  result = runner.invoke(
      cli_tools_click.main,
      ["create", "--model", "gemini", "--api_key", "key123", str(app_dir)],
  )
  assert result.exit_code == 0
  assert rec.calls, "cli_create.run_cmd must be called"


# cli run
@pytest.mark.asyncio
async def test_cli_run_invokes_run_cli(
    tmp_path: Path, monkeypatch: pytest.MonkeyPatch
) -> None:
  """`adk run` should call run_cli via asyncio.run with correct parameters."""
  rec = _Recorder()
  monkeypatch.setattr(cli_tools_click, "run_cli", lambda **kwargs: rec(kwargs))
  monkeypatch.setattr(
      cli_tools_click.asyncio, "run", lambda coro: coro
  )  # pass-through

  # create dummy agent directory
  agent_dir = tmp_path / "agent"
  agent_dir.mkdir()
  (agent_dir / "__init__.py").touch()
  (agent_dir / "agent.py").touch()

  runner = CliRunner()
  result = runner.invoke(cli_tools_click.main, ["run", str(agent_dir)])
  assert result.exit_code == 0
  assert rec.calls and rec.calls[0][0][0]["agent_folder_name"] == "agent"


# cli deploy cloud_run
def test_cli_deploy_cloud_run_success(
    tmp_path: Path, monkeypatch: pytest.MonkeyPatch
) -> None:
  """Successful path should call cli_deploy.to_cloud_run once."""
  rec = _Recorder()
  monkeypatch.setattr(cli_tools_click.cli_deploy, "to_cloud_run", rec)

  agent_dir = tmp_path / "agent2"
  agent_dir.mkdir()
  runner = CliRunner()
  result = runner.invoke(
      cli_tools_click.main,
      [
          "deploy",
          "cloud_run",
          "--project",
          "proj",
          "--region",
          "asia-northeast1",
          str(agent_dir),
      ],
  )
  assert result.exit_code == 0
  assert rec.calls, "cli_deploy.to_cloud_run must be invoked"


def test_cli_deploy_cloud_run_failure(
    tmp_path: Path, monkeypatch: pytest.MonkeyPatch
) -> None:
  """Exception from to_cloud_run should be caught and surfaced via click.secho."""

  def _boom(*_a: Any, **_k: Any) -> None:  # noqa: D401
    raise RuntimeError("boom")

  monkeypatch.setattr(cli_tools_click.cli_deploy, "to_cloud_run", _boom)

  # intercept click.secho(error=True) output
  captured: List[str] = []
  monkeypatch.setattr(click, "secho", lambda msg, **__: captured.append(msg))

  agent_dir = tmp_path / "agent3"
  agent_dir.mkdir()
  runner = CliRunner()
  result = runner.invoke(
      cli_tools_click.main, ["deploy", "cloud_run", str(agent_dir)]
  )

  assert result.exit_code == 0
  assert any("Deploy failed: boom" in m for m in captured)


# cli eval
def test_cli_eval_missing_deps_raises(
    tmp_path: Path, monkeypatch: pytest.MonkeyPatch
) -> None:
  """If cli_eval sub-module is missing, command should raise ClickException."""
  # Ensure .cli_eval is not importable
  orig_import = builtins.__import__

  def _fake_import(name: str, *a: Any, **k: Any):
    if name.endswith(".cli_eval") or name == "google.adk.cli.cli_eval":
      raise ModuleNotFoundError()
    return orig_import(name, *a, **k)

  monkeypatch.setattr(builtins, "__import__", _fake_import)


# cli web & api_server (uvicorn patched)
@pytest.fixture()
def _patch_uvicorn(monkeypatch: pytest.MonkeyPatch) -> _Recorder:
  """Patch uvicorn.Config/Server to avoid real network operations."""
  rec = _Recorder()

  class _DummyServer:

    def __init__(self, *a: Any, **k: Any) -> None:
      ...

    def run(self) -> None:
      rec()

  monkeypatch.setattr(
      cli_tools_click.uvicorn, "Config", lambda *a, **k: object()
  )
  monkeypatch.setattr(
      cli_tools_click.uvicorn, "Server", lambda *_a, **_k: _DummyServer()
  )
  monkeypatch.setattr(
      cli_tools_click, "get_fast_api_app", lambda **_k: object()
  )
  return rec


def test_cli_web_invokes_uvicorn(
    tmp_path: Path, _patch_uvicorn: _Recorder
) -> None:
  """`adk web` should configure and start uvicorn.Server.run."""
  agents_dir = tmp_path / "agents"
  agents_dir.mkdir()
  runner = CliRunner()
  result = runner.invoke(cli_tools_click.main, ["web", str(agents_dir)])
  assert result.exit_code == 0
  assert _patch_uvicorn.calls, "uvicorn.Server.run must be called"


def test_cli_api_server_invokes_uvicorn(
    tmp_path: Path, _patch_uvicorn: _Recorder
) -> None:
  """`adk api_server` should configure and start uvicorn.Server.run."""
  agents_dir = tmp_path / "agents_api"
  agents_dir.mkdir()
  runner = CliRunner()
  result = runner.invoke(cli_tools_click.main, ["api_server", str(agents_dir)])
  assert result.exit_code == 0
  assert _patch_uvicorn.calls, "uvicorn.Server.run must be called"


def test_cli_eval_success_path(
    tmp_path: Path, monkeypatch: pytest.MonkeyPatch
) -> None:
  """Test the success path of `adk eval` by fully executing it with a stub module, up to summary generation."""
  import asyncio
  import sys
  import types

  # stub cli_eval module
  stub = types.ModuleType("google.adk.cli.cli_eval")
  eval_sets_manager_stub = types.ModuleType(
      "google.adk.evaluation.local_eval_sets_manager"
  )

  class _EvalMetric:

    def __init__(self, metric_name: str, threshold: float) -> None:
      ...

  class _EvalCaseResult:

    def __init__(self, eval_set_id: str, final_eval_status: str) -> None:
      self.eval_set_id = eval_set_id
      self.final_eval_status = final_eval_status

  class EvalCase:

    def __init__(self, eval_id: str):
      self.eval_id = eval_id

  class EvalSet:

    def __init__(self, eval_cases: list[EvalCase]):
      self.eval_cases = eval_cases

  # minimal enum-like namespace
  _EvalStatus = types.SimpleNamespace(PASSED="PASSED", FAILED="FAILED")

  # helper funcs
  stub.EvalMetric = _EvalMetric
  stub.EvalCaseResult = _EvalCaseResult
  stub.EvalStatus = _EvalStatus
  stub.MISSING_EVAL_DEPENDENCIES_MESSAGE = "stub msg"

  stub.get_evaluation_criteria_or_default = lambda _p: {"foo": 1.0}
  stub.get_root_agent = lambda _p: object()
  stub.try_get_reset_func = lambda _p: None
  stub.parse_and_get_evals_to_run = lambda _paths: {"set1.json": ["e1", "e2"]}
  eval_sets_manager_stub.load_eval_set_from_file = lambda x, y: EvalSet(
      [EvalCase("e1"), EvalCase("e2")]
  )

  # Create an async generator function for run_evals
  async def mock_run_evals(*_a, **_k):
    yield _EvalCaseResult("set1.json", "PASSED")
    yield _EvalCaseResult("set1.json", "FAILED")

  stub.run_evals = mock_run_evals

  # Replace asyncio.run with a function that properly handles coroutines
  def mock_asyncio_run(coro):
    # Create a new event loop
    loop = asyncio.new_event_loop()
    try:
      return loop.run_until_complete(coro)
    finally:
      loop.close()

  monkeypatch.setattr(cli_tools_click.asyncio, "run", mock_asyncio_run)

  # inject stub
  sys.modules["google.adk.cli.cli_eval"] = stub
  sys.modules["google.adk.evaluation.local_eval_sets_manager"] = (
      eval_sets_manager_stub
  )

  # create dummy agent directory
  agent_dir = tmp_path / "agent5"
  agent_dir.mkdir()
  (agent_dir / "__init__.py").touch()

  # inject monkeypatch
  monkeypatch.setattr(
      cli_tools_click.envs, "load_dotenv_for_agent", lambda *a, **k: None
  )

  runner = CliRunner()
  result = runner.invoke(
      cli_tools_click.main,
      ["eval", str(agent_dir), str(tmp_path / "dummy_eval.json")],
  )

  assert result.exit_code == 0
  assert "Eval Run Summary" in result.output
  assert "Tests passed: 1" in result.output
  assert "Tests failed: 1" in result.output

==== tests/unittests/cli/utils/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

==== tests/unittests/cli/utils/test_cli.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Unit tests for utilities in cli."""

from __future__ import annotations

import click
import json
import pytest
import sys
import types

import google.adk.cli.cli as cli

from pathlib import Path
from typing import Any, Dict, List, Tuple

# Helpers
class _Recorder:
    """Callable that records every invocation."""

    def __init__(self) -> None:
        self.calls: List[Tuple[Tuple[Any, ...], Dict[str, Any]]] = []

    def __call__(self, *args: Any, **kwargs: Any) -> None:
        self.calls.append((args, kwargs))


# Fixtures
@pytest.fixture(autouse=True)
def _mute_click(monkeypatch: pytest.MonkeyPatch) -> None:
    """Silence click output in every test."""
    monkeypatch.setattr(click, "echo", lambda *a, **k: None)
    monkeypatch.setattr(click, "secho", lambda *a, **k: None)


@pytest.fixture(autouse=True)
def _patch_types_and_runner(monkeypatch: pytest.MonkeyPatch) -> None:
    """Replace google.genai.types and Runner with lightweight fakes."""

    # Dummy Part / Content
    class _Part:
        def __init__(self, text: str | None = "") -> None:
            self.text = text

    class _Content:
        def __init__(self, role: str, parts: List[_Part]) -> None:
            self.role = role
            self.parts = parts

    monkeypatch.setattr(cli.types, "Part", _Part)
    monkeypatch.setattr(cli.types, "Content", _Content)

    # Fake Runner yielding a single assistant echo
    class _FakeRunner:
        def __init__(self, *a: Any, **k: Any) -> None: ...

        async def run_async(self, *a: Any, **k: Any):
            message = a[2] if len(a) >= 3 else k["new_message"]
            text = message.parts[0].text if message.parts else ""
            response = _Content("assistant", [_Part(f"echo:{text}")])
            yield types.SimpleNamespace(author="assistant", content=response)

    monkeypatch.setattr(cli, "Runner", _FakeRunner)


@pytest.fixture()
def fake_agent(tmp_path: Path, monkeypatch: pytest.MonkeyPatch):
    """Create a minimal importable agent package and patch importlib."""

    parent_dir = tmp_path / "agents"
    parent_dir.mkdir()
    agent_dir = parent_dir / "fake_agent"
    agent_dir.mkdir()
    # __init__.py exposes root_agent with .name
    (agent_dir / "__init__.py").write_text(
        "from types import SimpleNamespace\n"
        "root_agent = SimpleNamespace(name='fake_root')\n"
    )

    # Ensure importable via sys.path
    sys.path.insert(0, str(parent_dir))

    import importlib

    module = importlib.import_module("fake_agent")
    fake_module = types.SimpleNamespace(agent=module)

    monkeypatch.setattr(importlib, "import_module", lambda n: fake_module)
    monkeypatch.setattr(cli.envs, "load_dotenv_for_agent", lambda *a, **k: None)

    yield parent_dir, "fake_agent"

    # Cleanup
    sys.path.remove(str(parent_dir))
    del sys.modules["fake_agent"]


# _run_input_file
@pytest.mark.asyncio
async def test_run_input_file_outputs(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    """run_input_file should echo user & assistant messages and return a populated session."""
    recorder: List[str] = []

    def _echo(msg: str) -> None:
        recorder.append(msg)

    monkeypatch.setattr(click, "echo", _echo)

    input_json = {
        "state": {"foo": "bar"},
        "queries": ["hello world"],
    }
    input_path = tmp_path / "input.json"
    input_path.write_text(json.dumps(input_json))

    artifact_service = cli.InMemoryArtifactService()
    session_service = cli.InMemorySessionService()
    dummy_root = types.SimpleNamespace(name="root")

    session = await cli.run_input_file(
        app_name="app",
        user_id="user",
        root_agent=dummy_root,
        artifact_service=artifact_service,
        session_service=session_service,
        input_path=str(input_path),
    )

    assert session.state["foo"] == "bar"
    assert any("[user]:" in line for line in recorder)
    assert any("[assistant]:" in line for line in recorder)


# _run_cli (input_file branch)
@pytest.mark.asyncio
async def test_run_cli_with_input_file(fake_agent, tmp_path: Path) -> None:
    """run_cli should process an input file without raising and without saving."""
    parent_dir, folder_name = fake_agent
    input_json = {"state": {}, "queries": ["ping"]}
    input_path = tmp_path / "in.json"
    input_path.write_text(json.dumps(input_json))

    await cli.run_cli(
        agent_parent_dir=str(parent_dir),
        agent_folder_name=folder_name,
        input_file=str(input_path),
        saved_session_file=None,
        save_session=False,
    )


# _run_cli (interactive + save session branch)
@pytest.mark.asyncio
async def test_run_cli_save_session(fake_agent, tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    """run_cli should save a session file when save_session=True."""
    parent_dir, folder_name = fake_agent

    # Simulate user typing 'exit' followed by session id 'sess123'
    responses = iter(["exit", "sess123"])
    monkeypatch.setattr("builtins.input", lambda *_a, **_k: next(responses))

    session_file = Path(parent_dir) / folder_name / "sess123.session.json"
    if session_file.exists():
        session_file.unlink()

    await cli.run_cli(
        agent_parent_dir=str(parent_dir),
        agent_folder_name=folder_name,
        input_file=None,
        saved_session_file=None,
        save_session=True,
    )

    assert session_file.exists()
    data = json.loads(session_file.read_text())
    # The saved JSON should at least contain id and events keys
    assert "id" in data and "events" in data


@pytest.mark.asyncio
async def test_run_interactively_whitespace_and_exit(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
  """run_interactively should skip blank input, echo once, then exit."""
  # make a session that belongs to dummy agent
  svc = cli.InMemorySessionService()
  sess = await svc.create_session(app_name="dummy", user_id="u")
  artifact_service = cli.InMemoryArtifactService()
  root_agent = types.SimpleNamespace(name="root")

  # fake user input: blank -> 'hello' -> 'exit'
  answers = iter(["  ", "hello", "exit"])
  monkeypatch.setattr("builtins.input", lambda *_a, **_k: next(answers))

  # capture assisted echo
  echoed: list[str] = []
  monkeypatch.setattr(click, "echo", lambda msg: echoed.append(msg))

  await cli.run_interactively(root_agent, artifact_service, sess, svc)

  # verify: assistant echoed once with 'echo:hello'
  assert any("echo:hello" in m for m in echoed)

==== tests/unittests/cli/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

==== tests/unittests/sessions/test_vertex_ai_session_service.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import re
import this
from typing import Any

from dateutil.parser import isoparse
from google.adk.events import Event
from google.adk.events import EventActions
from google.adk.sessions import Session
from google.adk.sessions import VertexAiSessionService
from google.genai import types
import pytest


MOCK_SESSION_JSON_1 = {
    'name': (
        'projects/test-project/locations/test-location/'
        'reasoningEngines/123/sessions/1'
    ),
    'createTime': '2024-12-12T12:12:12.123456Z',
    'updateTime': '2024-12-12T12:12:12.123456Z',
    'sessionState': {
        'key': {'value': 'test_value'},
    },
    'userId': 'user',
}
MOCK_SESSION_JSON_2 = {
    'name': (
        'projects/test-project/locations/test-location/'
        'reasoningEngines/123/sessions/2'
    ),
    'updateTime': '2024-12-13T12:12:12.123456Z',
    'userId': 'user',
}
MOCK_SESSION_JSON_3 = {
    'name': (
        'projects/test-project/locations/test-location/'
        'reasoningEngines/123/sessions/3'
    ),
    'updateTime': '2024-12-14T12:12:12.123456Z',
    'userId': 'user2',
}
MOCK_EVENT_JSON = [
    {
        'name': (
            'projects/test-project/locations/test-location/'
            'reasoningEngines/123/sessions/1/events/123'
        ),
        'invocationId': '123',
        'author': 'user',
        'timestamp': '2024-12-12T12:12:12.123456Z',
        'content': {
            'parts': [
                {'text': 'test_content'},
            ],
        },
        'actions': {
            'stateDelta': {
                'key': {'value': 'test_value'},
            },
            'transferAgent': 'agent',
        },
        'eventMetadata': {
            'partial': False,
            'turnComplete': True,
            'interrupted': False,
            'branch': '',
            'longRunningToolIds': ['tool1'],
        },
    },
]

MOCK_SESSION = Session(
    app_name='123',
    user_id='user',
    id='1',
    state=MOCK_SESSION_JSON_1['sessionState'],
    last_update_time=isoparse(MOCK_SESSION_JSON_1['updateTime']).timestamp(),
    events=[
        Event(
            id='123',
            invocation_id='123',
            author='user',
            timestamp=isoparse(MOCK_EVENT_JSON[0]['timestamp']).timestamp(),
            content=types.Content(parts=[types.Part(text='test_content')]),
            actions=EventActions(
                transfer_to_agent='agent',
                state_delta={'key': {'value': 'test_value'}},
            ),
            partial=False,
            turn_complete=True,
            interrupted=False,
            branch='',
            long_running_tool_ids={'tool1'},
        ),
    ],
)


SESSION_REGEX = r'^reasoningEngines/([^/]+)/sessions/([^/]+)$'
SESSIONS_REGEX = r'^reasoningEngines/([^/]+)/sessions\?filter=user_id=([^/]+)$'
EVENTS_REGEX = r'^reasoningEngines/([^/]+)/sessions/([^/]+)/events$'
LRO_REGEX = r'^operations/([^/]+)$'


class MockApiClient:
  """Mocks the API Client."""

  def __init__(self) -> None:
    """Initializes MockClient."""
    this.session_dict: dict[str, Any] = {}
    this.event_dict: dict[str, list[Any]] = {}

  def request(self, http_method: str, path: str, request_dict: dict[str, Any]):
    """Mocks the API Client request method."""
    if http_method == 'GET':
      if re.match(SESSION_REGEX, path):
        match = re.match(SESSION_REGEX, path)
        if match:
          session_id = match.group(2)
          if session_id in self.session_dict:
            return self.session_dict[session_id]
          else:
            raise ValueError(f'Session not found: {session_id}')
      elif re.match(SESSIONS_REGEX, path):
        match = re.match(SESSIONS_REGEX, path)
        return {
            'sessions': [
                session
                for session in self.session_dict.values()
                if session['userId'] == match.group(2)
            ],
        }
      elif re.match(EVENTS_REGEX, path):
        match = re.match(EVENTS_REGEX, path)
        if match:
          return {
              'sessionEvents': (
                  self.event_dict[match.group(2)]
                  if match.group(2) in self.event_dict
                  else []
              )
          }
      elif re.match(LRO_REGEX, path):
        return {
            'name': (
                'projects/test-project/locations/test-location/'
                'reasoningEngines/123/sessions/4'
            ),
            'done': True,
        }
      else:
        raise ValueError(f'Unsupported path: {path}')
    elif http_method == 'POST':
      new_session_id = '4'
      self.session_dict[new_session_id] = {
          'name': (
              'projects/test-project/locations/test-location/'
              'reasoningEngines/123/sessions/'
              + new_session_id
          ),
          'userId': request_dict['user_id'],
          'sessionState': request_dict.get('session_state', {}),
          'updateTime': '2024-12-12T12:12:12.123456Z',
      }
      return {
          'name': (
              'projects/test_project/locations/test_location/'
              'reasoningEngines/123/sessions/'
              + new_session_id
              + '/operations/111'
          ),
          'done': False,
      }
    elif http_method == 'DELETE':
      match = re.match(SESSION_REGEX, path)
      if match:
        self.session_dict.pop(match.group(2))
    else:
      raise ValueError(f'Unsupported http method: {http_method}')


def mock_vertex_ai_session_service():
  """Creates a mock Vertex AI Session service for testing."""
  service = VertexAiSessionService(
      project='test-project', location='test-location'
  )
  service.api_client = MockApiClient()
  service.api_client.session_dict = {
      '1': MOCK_SESSION_JSON_1,
      '2': MOCK_SESSION_JSON_2,
      '3': MOCK_SESSION_JSON_3,
  }
  service.api_client.event_dict = {
      '1': MOCK_EVENT_JSON,
  }
  return service


@pytest.mark.asyncio
async def test_get_empty_session():
  session_service = mock_vertex_ai_session_service()
  with pytest.raises(ValueError) as excinfo:
    assert await session_service.get_session(
        app_name='123', user_id='user', session_id='0'
    )
    assert str(excinfo.value) == 'Session not found: 0'


@pytest.mark.asyncio
async def test_get_and_delete_session():
  session_service = mock_vertex_ai_session_service()

  assert (
      await session_service.get_session(
          app_name='123', user_id='user', session_id='1'
      )
      == MOCK_SESSION
  )

  await session_service.delete_session(
      app_name='123', user_id='user', session_id='1'
  )
  with pytest.raises(ValueError) as excinfo:
    assert await session_service.get_session(
        app_name='123', user_id='user', session_id='1'
    )
    assert str(excinfo.value) == 'Session not found: 1'


@pytest.mark.asyncio
async def test_list_sessions():
  session_service = mock_vertex_ai_session_service()
  sessions = await session_service.list_sessions(app_name='123', user_id='user')
  assert len(sessions.sessions) == 2
  assert sessions.sessions[0].id == '1'
  assert sessions.sessions[1].id == '2'


@pytest.mark.asyncio
async def test_create_session():
  session_service = mock_vertex_ai_session_service()

  state = {'key': 'value'}
  session = await session_service.create_session(
      app_name='123', user_id='user', state=state
  )
  assert session.state == state
  assert session.app_name == '123'
  assert session.user_id == 'user'
  assert session.last_update_time is not None

  session_id = session.id
  assert session == await session_service.get_session(
      app_name='123', user_id='user', session_id=session_id
  )


@pytest.mark.asyncio
async def test_create_session_with_custom_session_id():
  session_service = mock_vertex_ai_session_service()

  with pytest.raises(ValueError) as excinfo:
    await session_service.create_session(
        app_name='123', user_id='user', session_id='1'
    )
    assert str(excinfo.value) == (
        'User-provided Session id is not supported for VertexAISessionService.'
    )

==== tests/unittests/sessions/test_session_service.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import enum
import pytest

from google.adk.events import Event
from google.adk.events import EventActions
from google.adk.sessions import DatabaseSessionService
from google.adk.sessions import InMemorySessionService
from google.adk.sessions.base_session_service import GetSessionConfig
from google.genai import types


class SessionServiceType(enum.Enum):
  IN_MEMORY = 'IN_MEMORY'
  DATABASE = 'DATABASE'


def get_session_service(
    service_type: SessionServiceType = SessionServiceType.IN_MEMORY,
):
  """Creates a session service for testing."""
  if service_type == SessionServiceType.DATABASE:
    return DatabaseSessionService('sqlite:///:memory:')
  return InMemorySessionService()


@pytest.mark.asyncio
@pytest.mark.parametrize(
    'service_type', [SessionServiceType.IN_MEMORY, SessionServiceType.DATABASE]
)
async def test_get_empty_session(service_type):
  session_service = get_session_service(service_type)
  assert not await session_service.get_session(
      app_name='my_app', user_id='test_user', session_id='123'
  )


@pytest.mark.asyncio
@pytest.mark.parametrize(
    'service_type', [SessionServiceType.IN_MEMORY, SessionServiceType.DATABASE]
)
async def test_create_get_session(service_type):
  session_service = get_session_service(service_type)
  app_name = 'my_app'
  user_id = 'test_user'
  state = {'key': 'value'}

  session = await session_service.create_session(
      app_name=app_name, user_id=user_id, state=state
  )
  assert session.app_name == app_name
  assert session.user_id == user_id
  assert session.id
  assert session.state == state
  assert (
      await session_service.get_session(
          app_name=app_name, user_id=user_id, session_id=session.id
      )
      == session
  )

  session_id = session.id
  await session_service.delete_session(
      app_name=app_name, user_id=user_id, session_id=session_id
  )

  assert (
      await session_service.get_session(
          app_name=app_name, user_id=user_id, session_id=session.id
      )
      != session
  )


@pytest.mark.asyncio
@pytest.mark.parametrize(
    'service_type', [SessionServiceType.IN_MEMORY, SessionServiceType.DATABASE]
)
async def test_create_and_list_sessions(service_type):
  session_service = get_session_service(service_type)
  app_name = 'my_app'
  user_id = 'test_user'

  session_ids = ['session' + str(i) for i in range(5)]
  for session_id in session_ids:
    await session_service.create_session(
        app_name=app_name, user_id=user_id, session_id=session_id
    )

  list_sessions_response = await session_service.list_sessions(
      app_name=app_name, user_id=user_id
  )
  sessions = list_sessions_response.sessions
  for i in range(len(sessions)):
    assert sessions[i].id == session_ids[i]


@pytest.mark.asyncio
@pytest.mark.parametrize(
    'service_type', [SessionServiceType.IN_MEMORY, SessionServiceType.DATABASE]
)
async def test_session_state(service_type):
  session_service = get_session_service(service_type)
  app_name = 'my_app'
  user_id_1 = 'user1'
  user_id_2 = 'user2'
  session_id_11 = 'session11'
  session_id_12 = 'session12'
  session_id_2 = 'session2'
  state_11 = {'key11': 'value11'}
  state_12 = {'key12': 'value12'}

  session_11 = await session_service.create_session(
      app_name=app_name,
      user_id=user_id_1,
      state=state_11,
      session_id=session_id_11,
  )
  await session_service.create_session(
      app_name=app_name,
      user_id=user_id_1,
      state=state_12,
      session_id=session_id_12,
  )
  await session_service.create_session(
      app_name=app_name, user_id=user_id_2, session_id=session_id_2
  )

  assert session_11.state.get('key11') == 'value11'

  event = Event(
      invocation_id='invocation',
      author='user',
      content=types.Content(role='user', parts=[types.Part(text='text')]),
      actions=EventActions(
          state_delta={
              'app:key': 'value',
              'user:key1': 'value1',
              'temp:key': 'temp',
              'key11': 'value11_new',
          }
      ),
  )
  await session_service.append_event(session=session_11, event=event)

  # User and app state is stored, temp state is filtered.
  assert session_11.state.get('app:key') == 'value'
  assert session_11.state.get('key11') == 'value11_new'
  assert session_11.state.get('user:key1') == 'value1'
  assert not session_11.state.get('temp:key')

  session_12 = await session_service.get_session(
      app_name=app_name, user_id=user_id_1, session_id=session_id_12
  )
  # After getting a new instance, the session_12 got the user and app state,
  # even append_event is not applied to it, temp state has no effect
  assert session_12.state.get('key12') == 'value12'
  assert not session_12.state.get('temp:key')

  # The user1's state is not visible to user2, app state is visible
  session_2 = await session_service.get_session(
      app_name=app_name, user_id=user_id_2, session_id=session_id_2
  )
  assert session_2.state.get('app:key') == 'value'
  assert not session_2.state.get('user:key1')

  assert not session_2.state.get('user:key1')

  # The change to session_11 is persisted
  session_11 = await session_service.get_session(
      app_name=app_name, user_id=user_id_1, session_id=session_id_11
  )
  assert session_11.state.get('key11') == 'value11_new'
  assert session_11.state.get('user:key1') == 'value1'
  assert not session_11.state.get('temp:key')


@pytest.mark.asyncio
@pytest.mark.parametrize(
    'service_type', [SessionServiceType.IN_MEMORY, SessionServiceType.DATABASE]
)
async def test_create_new_session_will_merge_states(service_type):
  session_service = get_session_service(service_type)
  app_name = 'my_app'
  user_id = 'user'
  session_id_1 = 'session1'
  session_id_2 = 'session2'
  state_1 = {'key1': 'value1'}

  session_1 = await session_service.create_session(
      app_name=app_name, user_id=user_id, state=state_1, session_id=session_id_1
  )

  event = Event(
      invocation_id='invocation',
      author='user',
      content=types.Content(role='user', parts=[types.Part(text='text')]),
      actions=EventActions(
          state_delta={
              'app:key': 'value',
              'user:key1': 'value1',
              'temp:key': 'temp',
          }
      ),
  )
  await session_service.append_event(session=session_1, event=event)

  # User and app state is stored, temp state is filtered.
  assert session_1.state.get('app:key') == 'value'
  assert session_1.state.get('key1') == 'value1'
  assert session_1.state.get('user:key1') == 'value1'
  assert not session_1.state.get('temp:key')

  session_2 = await session_service.create_session(
      app_name=app_name, user_id=user_id, state={}, session_id=session_id_2
  )
  # Session 2 has the persisted states
  assert session_2.state.get('app:key') == 'value'
  assert session_2.state.get('user:key1') == 'value1'
  assert not session_2.state.get('key1')
  assert not session_2.state.get('temp:key')


@pytest.mark.asyncio
@pytest.mark.parametrize(
    'service_type', [SessionServiceType.IN_MEMORY, SessionServiceType.DATABASE]
)
async def test_append_event_bytes(service_type):
  session_service = get_session_service(service_type)
  app_name = 'my_app'
  user_id = 'user'

  session = await session_service.create_session(
      app_name=app_name, user_id=user_id
  )
  event = Event(
      invocation_id='invocation',
      author='user',
      content=types.Content(
          role='user',
          parts=[
              types.Part.from_bytes(
                  data=b'test_image_data', mime_type='image/png'
              ),
          ],
      ),
  )
  await session_service.append_event(session=session, event=event)

  assert session.events[0].content.parts[0] == types.Part.from_bytes(
      data=b'test_image_data', mime_type='image/png'
  )

  session = await session_service.get_session(
      app_name=app_name, user_id=user_id, session_id=session.id
  )
  events = session.events
  assert len(events) == 1
  assert events[0].content.parts[0] == types.Part.from_bytes(
      data=b'test_image_data', mime_type='image/png'
  )


@pytest.mark.asyncio
@pytest.mark.parametrize(
    'service_type', [SessionServiceType.IN_MEMORY, SessionServiceType.DATABASE]
)
async def test_append_event_complete(service_type):
  session_service = get_session_service(service_type)
  app_name = 'my_app'
  user_id = 'user'

  session = await session_service.create_session(
      app_name=app_name, user_id=user_id
  )
  event = Event(
      invocation_id='invocation',
      author='user',
      content=types.Content(role='user', parts=[types.Part(text='test_text')]),
      turn_complete=True,
      partial=False,
      actions=EventActions(
          artifact_delta={
              'file': 0,
          },
          transfer_to_agent='agent',
          escalate=True,
      ),
      long_running_tool_ids={'tool1'},
      error_code='error_code',
      error_message='error_message',
      interrupted=True,
  )
  await session_service.append_event(session=session, event=event)

  assert (
      await session_service.get_session(
          app_name=app_name, user_id=user_id, session_id=session.id
      )
      == session
  )


@pytest.mark.asyncio
@pytest.mark.parametrize('service_type', [SessionServiceType.IN_MEMORY])
async def test_get_session_with_config(service_type):
  session_service = get_session_service(service_type)
  app_name = 'my_app'
  user_id = 'user'

  num_test_events = 5
  session = await session_service.create_session(
      app_name=app_name, user_id=user_id
  )
  for i in range(1, num_test_events + 1):
    event = Event(author='user', timestamp=i)
    await session_service.append_event(session, event)

  # No config, expect all events to be returned.
  session = await session_service.get_session(
      app_name=app_name, user_id=user_id, session_id=session.id
  )
  events = session.events
  assert len(events) == num_test_events

  # Only expect the most recent 3 events.
  num_recent_events = 3
  config = GetSessionConfig(num_recent_events=num_recent_events)
  session = await session_service.get_session(
      app_name=app_name, user_id=user_id, session_id=session.id, config=config
  )
  events = session.events
  assert len(events) == num_recent_events
  assert events[0].timestamp == num_test_events - num_recent_events + 1

  # Only expect events after timestamp 4.0 (inclusive), i.e., 2 events.
  after_timestamp = 4.0
  config = GetSessionConfig(after_timestamp=after_timestamp)
  session = await session_service.get_session(
      app_name=app_name, user_id=user_id, session_id=session.id, config=config
  )
  events = session.events
  assert len(events) == num_test_events - after_timestamp + 1
  assert events[0].timestamp == after_timestamp

  # Expect no events if none are > after_timestamp.
  way_after_timestamp = num_test_events * 10
  config = GetSessionConfig(after_timestamp=way_after_timestamp)
  session = await session_service.get_session(
      app_name=app_name, user_id=user_id, session_id=session.id, config=config
  )
  assert not session.events

  # Both filters applied, i.e., of 3 most recent events, only 2 are after
  # timestamp 4.0, so expect 2 events.
  config = GetSessionConfig(
      after_timestamp=after_timestamp, num_recent_events=num_recent_events
  )
  session = await session_service.get_session(
      app_name=app_name, user_id=user_id, session_id=session.id, config=config
  )
  events = session.events
  assert len(events) == num_test_events - after_timestamp + 1

==== tests/unittests/sessions/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

==== tests/unittests/code_executors/test_code_executor_context.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.adk.code_executors.code_execution_utils import File
from google.adk.code_executors.code_executor_context import CodeExecutorContext
from google.adk.sessions.state import State
import pytest


@pytest.fixture
def empty_state() -> State:
  """Fixture for an empty session state."""
  return State({}, {})


@pytest.fixture
def context_with_data() -> CodeExecutorContext:
  """Fixture for a CodeExecutorContext with some pre-populated data."""
  state_data = {
      "_code_execution_context": {
          "execution_session_id": "session123",
          "processed_input_files": ["file1.csv", "file2.txt"],
      },
      "_code_executor_input_files": [
          {"name": "input1.txt", "content": "YQ==", "mime_type": "text/plain"}
      ],
      "_code_executor_error_counts": {"invocationA": 2},
  }
  state = State(state_data, {})
  return CodeExecutorContext(state)


def test_init_empty_state(empty_state: State):
  """Test initialization with an empty state."""
  ctx = CodeExecutorContext(empty_state)
  assert ctx._context == {}
  assert ctx._session_state is empty_state


def test_get_state_delta_empty(empty_state: State):
  """Test get_state_delta when context is empty."""
  ctx = CodeExecutorContext(empty_state)
  delta = ctx.get_state_delta()
  assert delta == {"_code_execution_context": {}}


def test_get_state_delta_with_data(context_with_data: CodeExecutorContext):
  """Test get_state_delta with existing context data."""
  delta = context_with_data.get_state_delta()
  expected_context = {
      "execution_session_id": "session123",
      "processed_input_files": ["file1.csv", "file2.txt"],
  }
  assert delta == {"_code_execution_context": expected_context}


def test_get_execution_id_exists(context_with_data: CodeExecutorContext):
  """Test getting an existing execution ID."""
  assert context_with_data.get_execution_id() == "session123"


def test_get_execution_id_not_exists(empty_state: State):
  """Test getting execution ID when it doesn't exist."""
  ctx = CodeExecutorContext(empty_state)
  assert ctx.get_execution_id() is None


def test_set_execution_id(empty_state: State):
  """Test setting an execution ID."""
  ctx = CodeExecutorContext(empty_state)
  ctx.set_execution_id("new_session_id")
  assert ctx._context["execution_session_id"] == "new_session_id"
  assert ctx.get_execution_id() == "new_session_id"


def test_get_processed_file_names_exists(
    context_with_data: CodeExecutorContext,
):
  """Test getting existing processed file names."""
  assert context_with_data.get_processed_file_names() == [
      "file1.csv",
      "file2.txt",
  ]


def test_get_processed_file_names_not_exists(empty_state: State):
  """Test getting processed file names when none exist."""
  ctx = CodeExecutorContext(empty_state)
  assert ctx.get_processed_file_names() == []


def test_add_processed_file_names_new(empty_state: State):
  """Test adding processed file names to an empty context."""
  ctx = CodeExecutorContext(empty_state)
  ctx.add_processed_file_names(["new_file.py"])
  assert ctx._context["processed_input_files"] == ["new_file.py"]


def test_add_processed_file_names_append(
    context_with_data: CodeExecutorContext,
):
  """Test appending to existing processed file names."""
  context_with_data.add_processed_file_names(["another_file.md"])
  assert context_with_data.get_processed_file_names() == [
      "file1.csv",
      "file2.txt",
      "another_file.md",
  ]


def test_get_input_files_exists(context_with_data: CodeExecutorContext):
  """Test getting existing input files."""
  files = context_with_data.get_input_files()
  assert len(files) == 1
  assert files[0].name == "input1.txt"
  assert files[0].content == "YQ=="
  assert files[0].mime_type == "text/plain"


def test_get_input_files_not_exists(empty_state: State):
  """Test getting input files when none exist."""
  ctx = CodeExecutorContext(empty_state)
  assert ctx.get_input_files() == []


def test_add_input_files_new(empty_state: State):
  """Test adding input files to an empty session state."""
  ctx = CodeExecutorContext(empty_state)
  new_files = [File(name="new.dat", content="Yg==", mime_type="application/octet-stream")]
  ctx.add_input_files(new_files)
  assert empty_state["_code_executor_input_files"] == [
      {"name": "new.dat", "content": "Yg==", "mime_type": "application/octet-stream"}
  ]


def test_add_input_files_append(context_with_data: CodeExecutorContext):
  """Test appending to existing input files."""
  new_file = File(name="input2.log", content="Yw==", mime_type="text/x-log")
  context_with_data.add_input_files([new_file])
  expected_files_data = [
      {"name": "input1.txt", "content": "YQ==", "mime_type": "text/plain"},
      {"name": "input2.log", "content": "Yw==", "mime_type": "text/x-log"},
  ]
  assert (
      context_with_data._session_state["_code_executor_input_files"]
      == expected_files_data
  )


def test_clear_input_files(context_with_data: CodeExecutorContext):
  """Test clearing input files and processed file names."""
  context_with_data.clear_input_files()
  assert context_with_data._session_state["_code_executor_input_files"] == []
  assert context_with_data._context["processed_input_files"] == []


def test_clear_input_files_when_not_exist(empty_state: State):
  """Test clearing input files when they don't exist initially."""
  ctx = CodeExecutorContext(empty_state)
  ctx.clear_input_files()  # Should not raise error
  assert "_code_executor_input_files" not in empty_state  # Or assert it's empty
  assert "_code_execution_context" not in empty_state or not empty_state[
      "_code_execution_context"
  ].get("processed_input_files")


def test_get_error_count_exists(context_with_data: CodeExecutorContext):
  """Test getting an existing error count."""
  assert context_with_data.get_error_count("invocationA") == 2


def test_get_error_count_invocation_not_exists(
    context_with_data: CodeExecutorContext,
):
  """Test getting error count for an unknown invocation ID."""
  assert context_with_data.get_error_count("invocationB") == 0


def test_get_error_count_no_error_key(empty_state: State):
  """Test getting error count when the error key itself doesn't exist."""
  ctx = CodeExecutorContext(empty_state)
  assert ctx.get_error_count("any_invocation") == 0


def test_increment_error_count_new_invocation(empty_state: State):
  """Test incrementing error count for a new invocation ID."""
  ctx = CodeExecutorContext(empty_state)
  ctx.increment_error_count("invocationNew")
  assert empty_state["_code_executor_error_counts"]["invocationNew"] == 1


def test_increment_error_count_existing_invocation(
    context_with_data: CodeExecutorContext,
):
  """Test incrementing error count for an existing invocation ID."""
  context_with_data.increment_error_count("invocationA")
  assert (
      context_with_data._session_state["_code_executor_error_counts"][
          "invocationA"
      ]
      == 3
  )


def test_reset_error_count_exists(context_with_data: CodeExecutorContext):
  """Test resetting an existing error count."""
  context_with_data.reset_error_count("invocationA")
  assert "invocationA" not in (
      context_with_data._session_state["_code_executor_error_counts"]
  )


def test_reset_error_count_not_exists(context_with_data: CodeExecutorContext):
  """Test resetting an error count that doesn't exist."""
  context_with_data.reset_error_count("invocationB")  # Should not raise
  assert "invocationB" not in (
      context_with_data._session_state["_code_executor_error_counts"]
  )


def test_reset_error_count_no_error_key(empty_state: State):
  """Test resetting when the error key itself doesn't exist."""
  ctx = CodeExecutorContext(empty_state)
  ctx.reset_error_count("any_invocation")  # Should not raise
  assert "_code_executor_error_counts" not in empty_state


def test_update_code_execution_result_new_invocation(empty_state: State):
  """Test updating code execution result for a new invocation."""
  ctx = CodeExecutorContext(empty_state)
  ctx.update_code_execution_result(
      "inv1", "print('hi')", "hi", ""
  )
  results = empty_state["_code_execution_results"]["inv1"]
  assert len(results) == 1
  assert results[0]["code"] == "print('hi')"
  assert results[0]["result_stdout"] == "hi"
  assert results[0]["result_stderr"] == ""
  assert "timestamp" in results[0]


def test_update_code_execution_result_append(
    context_with_data: CodeExecutorContext,
):
  """Test appending to existing code execution results for an invocation."""
  # First, let's add an initial result for a new invocation to the existing state
  context_with_data._session_state["_code_execution_results"] = {
      "invocationX": [{
          "code": "old_code",
          "result_stdout": "old_out",
          "result_stderr": "old_err",
          "timestamp": 123,
      }]
  }
  context_with_data.update_code_execution_result(
      "invocationX", "new_code", "new_out", "new_err"
  )
  results = context_with_data._session_state["_code_execution_results"][
      "invocationX"
  ]
  assert len(results) == 2
  assert results[1]["code"] == "new_code"
  assert results[1]["result_stdout"] == "new_out"
  assert results[1]["result_stderr"] == "new_err"
==== tests/unittests/code_executors/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
==== tests/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

==== tests/integration/test_system_instruction.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import pytest

# Skip until fixed.
pytest.skip(allow_module_level=True)

from google.adk.agents import InvocationContext
from google.adk.sessions import Session
from google.genai import types

from .fixture import context_variable_agent
from .utils import TestRunner

nl_planner_si = """
You are an intelligent tool use agent built upon the Gemini large language model. When answering the question, try to leverage the available tools to gather the information instead of your memorized knowledge.

Follow this process when answering the question: (1) first come up with a plan in natural language text format; (2) Then use tools to execute the plan and provide reasoning between tool code snippets to make a summary of current state and next step. Tool code snippets and reasoning should be interleaved with each other. (3) In the end, return one final answer.

Follow this format when answering the question: (1) The planning part should be under /*PLANNING*/. (2) The tool code snippets should be under /*ACTION*/, and the reasoning parts should be under /*REASONING*/. (3) The final answer part should be under /*FINAL_ANSWER*/.


Below are the requirements for the planning:
The plan is made to answer the user query if following the plan. The plan is coherent and covers all aspects of information from user query, and only involves the tools that are accessible by the agent. The plan contains the decomposed steps as a numbered list where each step should use one or multiple available tools. By reading the plan, you can intuitively know which tools to trigger or what actions to take.
If the initial plan cannot be successfully executed, you should learn from previous execution results and revise your plan. The revised plan should be be under /*REPLANNING*/. Then use tools to follow the new plan.

Below are the requirements for the reasoning:
The reasoning makes a summary of the current trajectory based on the user query and tool outputs. Based on the tool outputs and plan, the reasoning also comes up with instructions to the next steps, making the trajectory closer to the final answer.



Below are the requirements for the final answer:
The final answer should be precise and follow query formatting requirements. Some queries may not be answerable with the available tools and information. In those cases, inform the user why you cannot process their query and ask for more information.



Below are the requirements for the tool code:

**Custom Tools:** The available tools are described in the context and can be directly used.
- Code must be valid self-contained Python snippets with no imports and no references to tools or Python libraries that are not in the context.
- You cannot use any parameters or fields that are not explicitly defined in the APIs in the context.
- Use "print" to output execution results for the next step or final answer that you need for responding to the user. Never generate ```tool_outputs yourself.
- The code snippets should be readable, efficient, and directly relevant to the user query and reasoning steps.
- When using the tools, you should use the library name together with the function name, e.g., vertex_search.search().
- If Python libraries are not provided in the context, NEVER write your own code other than the function calls using the provided tools.



VERY IMPORTANT instruction that you MUST follow in addition to the above instructions:

You should ask for clarification if you need more information to answer the question.
You should prefer using the information available in the context instead of repeated tool use.

You should ONLY generate code snippets prefixed with "```tool_code" if you need to use the tools to answer the question.

If you are asked to write code by user specifically,
- you should ALWAYS use "```python" to format the code.
- you should NEVER put "tool_code" to format the code.
- Good example:
```python
print('hello')
```
- Bad example:
```tool_code
print('hello')
```
"""


@pytest.mark.parametrize(
    "agent_runner",
    [{"agent": context_variable_agent.agent.state_variable_echo_agent}],
    indirect=True,
)
def test_context_variable(agent_runner: TestRunner):
  session = Session(
      context={
          "customerId": "1234567890",
          "customerInt": 30,
          "customerFloat": 12.34,
          "customerJson": {"name": "John Doe", "age": 30, "count": 11.1},
      }
  )
  si = UnitFlow()._build_system_instruction(
      InvocationContext(
          invocation_id="1234567890", agent=agent_runner.agent, session=session
      )
  )

  assert (
      "Use the echo_info tool to echo 1234567890, 30, 12.34, and {'name': 'John"
      " Doe', 'age': 30, 'count': 11.1}. Ask for it if you need to."
      in si
  )


@pytest.mark.parametrize(
    "agent_runner",
    [{
        "agent": (
            context_variable_agent.agent.state_variable_with_complicated_format_agent
        )
    }],
    indirect=True,
)
def test_context_variable_with_complicated_format(agent_runner: TestRunner):
  session = Session(
      context={"customerId": "1234567890", "customer_int": 30},
      artifacts={"fileName": [types.Part(text="test artifact")]},
  )
  si = _context_formatter.populate_context_and_artifact_variable_values(
      agent_runner.agent.instruction,
      session.get_state(),
      session.get_artifact_dict(),
  )

  assert (
      si
      == "Use the echo_info tool to echo 1234567890, 30, { "
      " non-identifier-float}}, test artifact, {'key1': 'value1'} and"
      " {{'key2': 'value2'}}. Ask for it if you need to."
  )


@pytest.mark.parametrize(
    "agent_runner",
    [{
        "agent": (
            context_variable_agent.agent.state_variable_with_nl_planner_agent
        )
    }],
    indirect=True,
)
def test_nl_planner(agent_runner: TestRunner):
  session = Session(context={"customerId": "1234567890"})
  si = UnitFlow()._build_system_instruction(
      InvocationContext(
          invocation_id="1234567890",
          agent=agent_runner.agent,
          session=session,
      )
  )

  for line in nl_planner_si.splitlines():
    assert line in si


@pytest.mark.parametrize(
    "agent_runner",
    [{
        "agent": (
            context_variable_agent.agent.state_variable_with_function_instruction_agent
        )
    }],
    indirect=True,
)
def test_function_instruction(agent_runner: TestRunner):
  session = Session(context={"customerId": "1234567890"})
  si = UnitFlow()._build_system_instruction(
      InvocationContext(
          invocation_id="1234567890", agent=agent_runner.agent, session=session
      )
  )

  assert "This is the plain text sub agent instruction." in si

==== tests/integration/test_context_variable.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import json

import pytest

# Skip until fixed.
pytest.skip(allow_module_level=True)

from .fixture import context_variable_agent
from .utils import TestRunner


@pytest.mark.parametrize(
    "agent_runner",
    [{"agent": context_variable_agent.agent.state_variable_echo_agent}],
    indirect=True,
)
def test_context_variable_missing(agent_runner: TestRunner):
  with pytest.raises(KeyError) as e_info:
    agent_runner.run("Hi echo my customer id.")
  assert "customerId" in str(e_info.value)


@pytest.mark.parametrize(
    "agent_runner",
    [{"agent": context_variable_agent.agent.state_variable_update_agent}],
    indirect=True,
)
def test_context_variable_update(agent_runner: TestRunner):
  _call_function_and_assert(
      agent_runner,
      "update_fc",
      ["RRRR", "3.141529", ["apple", "banana"], [1, 3.14, "hello"]],
      "successfully",
  )


def _call_function_and_assert(
    agent_runner: TestRunner, function_name: str, params, expected
):
  param_section = (
      " with params"
      f" {params if isinstance(params, str) else json.dumps(params)}"
      if params is not None
      else ""
  )
  agent_runner.run(
      f"Call {function_name}{param_section} and show me the result"
  )

  model_response_event = agent_runner.get_events()[-1]
  assert model_response_event.author == "context_variable_update_agent"
  assert model_response_event.content.role == "model"
  assert expected in model_response_event.content.parts[0].text.strip()

==== tests/integration/utils/asserts.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from typing import TypedDict

from .test_runner import TestRunner


class Message(TypedDict):
  agent_name: str
  expected_text: str


def assert_current_agent_is(agent_name: str, *, agent_runner: TestRunner):
  assert agent_runner.get_current_agent_name() == agent_name


def assert_agent_says(
    expected_text: str, *, agent_name: str, agent_runner: TestRunner
):
  for event in reversed(agent_runner.get_events()):
    if event.author == agent_name and event.content.parts[0].text:
      assert event.content.parts[0].text.strip() == expected_text
      return


def assert_agent_says_in_order(
    expected_conversation: list[Message], agent_runner: TestRunner
):
  expected_conversation_idx = len(expected_conversation) - 1
  for event in reversed(agent_runner.get_events()):
    if event.content.parts and event.content.parts[0].text:
      assert (
          event.author
          == expected_conversation[expected_conversation_idx]['agent_name']
      )
      assert (
          event.content.parts[0].text.strip()
          == expected_conversation[expected_conversation_idx]['expected_text']
      )
      expected_conversation_idx -= 1
      if expected_conversation_idx < 0:
        return


def assert_agent_transfer_path(
    expected_path: list[str], *, agent_runner: TestRunner
):
  events = agent_runner.get_events()
  idx_in_expected_path = len(expected_path) - 1
  # iterate events in reverse order
  for event in reversed(events):
    function_calls = event.get_function_calls()
    if (
        len(function_calls) == 1
        and function_calls[0].name == 'transfer_to_agent'
    ):
      assert (
          function_calls[0].args['agent_name']
          == expected_path[idx_in_expected_path]
      )
      idx_in_expected_path -= 1
      if idx_in_expected_path < 0:
        return

==== tests/integration/utils/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from .asserts import *
from .test_runner import TestRunner

==== tests/integration/utils/test_runner.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import importlib
from typing import Optional

from google.adk import Agent
from google.adk import Runner
from google.adk.artifacts import BaseArtifactService
from google.adk.artifacts import InMemoryArtifactService
from google.adk.events import Event
from google.adk.sessions import BaseSessionService
from google.adk.sessions import InMemorySessionService
from google.adk.sessions import Session
from google.genai import types


class TestRunner:
  """Agents runner for testing."""

  app_name = "test_app"
  user_id = "test_user"

  def __init__(
      self,
      agent: Agent,
      artifact_service: BaseArtifactService = InMemoryArtifactService(),
      session_service: BaseSessionService = InMemorySessionService(),
  ) -> None:
    self.agent = agent
    self.agent_client = Runner(
        app_name=self.app_name,
        agent=agent,
        artifact_service=artifact_service,
        session_service=session_service,
    )
    self.session_service = session_service
    self.current_session_id = session_service.create_session(
        app_name=self.app_name, user_id=self.user_id
    ).id

  def new_session(self, session_id: Optional[str] = None) -> None:
    self.current_session_id = self.session_service.create_session(
        app_name=self.app_name, user_id=self.user_id, session_id=session_id
    ).id

  def run(self, prompt: str) -> list[Event]:
    current_session = self.session_service.get_session(
        app_name=self.app_name,
        user_id=self.user_id,
        session_id=self.current_session_id,
    )
    assert current_session is not None

    return list(
        self.agent_client.run(
            user_id=current_session.user_id,
            session_id=current_session.id,
            new_message=types.Content(
                role="user",
                parts=[types.Part.from_text(text=prompt)],
            ),
        )
    )

  def get_current_session(self) -> Optional[Session]:
    return self.session_service.get_session(
        app_name=self.app_name,
        user_id=self.user_id,
        session_id=self.current_session_id,
    )

  def get_events(self) -> list[Event]:
    return self.get_current_session().events

  @classmethod
  def from_agent_name(cls, agent_name: str):
    agent_module_path = f"tests.integration.fixture.{agent_name}"
    agent_module = importlib.import_module(agent_module_path)
    agent: Agent = agent_module.agent.root_agent
    return cls(agent)

  def get_current_agent_name(self) -> str:
    return self.agent_client._find_agent_to_run(
        self.get_current_session(), self.agent
    ).name

==== tests/integration/.env.example ====
# Copy as .env file and fill your values below to run integration tests.

# Choose Backend: GOOGLE_AI_ONLY | VERTEX_ONLY | BOTH (default)
TEST_BACKEND=BOTH

# ML Dev backend config
GOOGLE_API_KEY=YOUR_VALUE_HERE
# Vertex backend config
GOOGLE_CLOUD_PROJECT=YOUR_VALUE_HERE
GOOGLE_CLOUD_LOCATION=YOUR_VALUE_HERE

==== tests/integration/fixture/trip_planner_agent/test_files/test_config.json ====
{
  "criteria": {
    "response_match_score": 0.5
  }
}

==== tests/integration/fixture/trip_planner_agent/test_files/trip_inquiry_sub_agent.test.json ====
{
  "eval_set_id": "189d6856-9b90-4b9c-bda8-7cec899507ae",
  "name": "189d6856-9b90-4b9c-bda8-7cec899507ae",
  "description": null,
  "eval_cases": [
    {
      "eval_id": "tests/integration/fixture/trip_planner_agent/test_files/trip_inquiry_sub_agent.test.json",
      "conversation": [
        {
          "invocation_id": "1c2e8003-d19c-4912-b0ae-17b9d568f8fb",
          "user_content": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "Based on my interests, where should I go, Yosemite national park or Los Angeles?"
              }
            ],
            "role": "user"
          },
          "final_response": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "Given your interests in food, shopping, and museums, Los Angeles would be a better choice than Yosemite National Park. Yosemite is primarily focused on outdoor activities and natural landscapes, while Los Angeles offers a diverse range of culinary experiences, shopping districts, and world-class museums. I will now gather information to create an in-depth guide for your trip to Los Angeles.\n"
              }
            ],
            "role": "model"
          },
          "intermediate_data": {
            "tool_uses": [],
            "intermediate_responses": []
          },
          "creation_timestamp": 1747339378.484014
        }
      ],
      "session_input": {
        "app_name": "trip_planner_agent",
        "user_id": "test_user",
        "state": {
          "origin": "San Francisco",
          "interests": "Food, Shopping, Museums",
          "range": "1000 miles",
          "cities": ""
        }
      },
      "creation_timestamp": 1747339378.484044
    }
  ],
  "creation_timestamp": 1747339378.484056
}
==== tests/integration/fixture/trip_planner_agent/test_config.json ====
{
  "criteria": {
    "response_match_score": 0.5
  }
}

==== tests/integration/fixture/trip_planner_agent/trip_inquiry.test.json ====
[
  {
    "query": "Hi, who are you? What can you do?",
    "expected_tool_use": [],
    "reference": "I am trip_planner, and my goal is to plan the best trip ever. I can describe why a city was chosen, list its top attractions, and provide a detailed itinerary for each day of the trip.\n"
  },
  {
    "query": "I want to travel from San Francisco to an European country in fall next year. I am considering London and Paris. What is your advice?",
    "expected_tool_use": [
      {
        "tool_name": "transfer_to_agent",
        "tool_input": {
          "agent_name": "indentify_agent"
        }
      }
    ],
    "reference": "Okay, I can help you analyze London and Paris to determine which city is better for your trip next fall. I will consider weather patterns, seasonal events, travel costs (including flights from San Francisco), and your interests (food, shopping, and museums). After gathering this information, I'll provide a detailed report on my chosen city.\n"
  }
]

==== tests/integration/fixture/trip_planner_agent/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from . import agent

==== tests/integration/fixture/trip_planner_agent/agent.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# https://github.com/crewAIInc/crewAI-examples/tree/main/trip_planner

from google.adk import Agent

# Agent that selects the best city for the trip.
identify_agent = Agent(
    name='identify_agent',
    description='Select the best city based on weather, season, and prices.',
    instruction="""
  Analyze and select the best city for the trip based
  on specific criteria such as weather patterns, seasonal
  events, and travel costs. This task involves comparing
  multiple cities, considering factors like current weather
  conditions, upcoming cultural or seasonal events, and
  overall travel expenses.

  Your final answer must be a detailed
  report on the chosen city, and everything you found out
  about it, including the actual flight costs, weather
  forecast and attractions.

  Traveling from: {origin}
  City Options: {cities}
  Trip Date: {range}
  Traveler Interests: {interests}
""",
)

# Agent that gathers information about the city.
gather_agent = Agent(
    name='gather_agent',
    description='Provide the BEST insights about the selected city',
    instruction="""
  As a local expert on this city you must compile an
  in-depth guide for someone traveling there and wanting
  to have THE BEST trip ever!
  Gather information about key attractions, local customs,
  special events, and daily activity recommendations.
  Find the best spots to go to, the kind of place only a
  local would know.
  This guide should provide a thorough overview of what
  the city has to offer, including hidden gems, cultural
  hotspots, must-visit landmarks, weather forecasts, and
  high level costs.

  The final answer must be a comprehensive city guide,
  rich in cultural insights and practical tips,
  tailored to enhance the travel experience.

  Trip Date: {range}
  Traveling from: {origin}
  Traveler Interests: {interests}
""",
)

# Agent that plans the trip.
plan_agent = Agent(
    name='plan_agent',
    description="""Create the most amazing travel itineraries with budget and
    packing suggestions for the city""",
    instruction="""
  Expand this guide into a full 7-day travel
  itinerary with detailed per-day plans, including
  weather forecasts, places to eat, packing suggestions,
  and a budget breakdown.

  You MUST suggest actual places to visit, actual hotels
  to stay and actual restaurants to go to.

  This itinerary should cover all aspects of the trip,
  from arrival to departure, integrating the city guide
  information with practical travel logistics.

  Your final answer MUST be a complete expanded travel plan,
  formatted as markdown, encompassing a daily schedule,
  anticipated weather conditions, recommended clothing and
  items to pack, and a detailed budget, ensuring THE BEST
  TRIP EVER. Be specific and give it a reason why you picked
  each place, what makes them special!

  Trip Date: {range}
  Traveling from: {origin}
  Traveler Interests: {interests}
""",
)

root_agent = Agent(
    model='gemini-2.0-flash-001',
    name='trip_planner',
    description='Plan the best trip ever',
    instruction="""
  Your goal is to plan the best trip according to information listed above.
  You describe why did you choose the city, list top 3
  attactions and provide a detailed itinerary for each day.""",
    sub_agents=[identify_agent, gather_agent, plan_agent],
)

==== tests/integration/fixture/trip_planner_agent/initial.session.json ====
{
  "id": "test_id",
  "app_name": "trip_planner_agent",
  "user_id": "test_user",
  "state": {
    "origin": "San Francisco",
    "interests": "Food, Shopping, Museums",
    "range": "1000 miles",
    "cities": ""
  },
  "events": [],
  "last_update_time": 1741218714.258285
}

==== tests/integration/fixture/hello_world_agent/test_config.json ====
{
  "criteria": {
    "tool_trajectory_avg_score": 1.0,
    "response_match_score": 0.5
  }
}

==== tests/integration/fixture/hello_world_agent/roll_die.test.json ====
{
  "eval_set_id": "56540925-a5ff-49fe-a4e1-589fe78066f2",
  "name": "56540925-a5ff-49fe-a4e1-589fe78066f2",
  "description": null,
  "eval_cases": [
    {
      "eval_id": "tests/integration/fixture/hello_world_agent/roll_die.test.json",
      "conversation": [
        {
          "invocation_id": "b01f67f0-9f23-44d6-bbe4-36ea235cb9fb",
          "user_content": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "Hi who are you?"
              }
            ],
            "role": "user"
          },
          "final_response": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "I am a data processing agent. I can roll dice and check if the results are prime numbers. What would you like me to do? \n"
              }
            ],
            "role": "model"
          },
          "intermediate_data": {
            "tool_uses": [],
            "intermediate_responses": []
          },
          "creation_timestamp": 1747341775.8937013
        },
        {
          "invocation_id": "13be0093-ac29-4828-98c6-5bbd570c010c",
          "user_content": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "What can you do?"
              }
            ],
            "role": "user"
          },
          "final_response": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "I can roll dice for you of different sizes, and I can check if the results are prime numbers.  I can also remember previous rolls if you'd like to check those for primes as well.  What would you like me to do? \n"
              }
            ],
            "role": "model"
          },
          "intermediate_data": {
            "tool_uses": [],
            "intermediate_responses": []
          },
          "creation_timestamp": 1747341775.8937378
        },
        {
          "invocation_id": "7deda353-c936-4c21-b242-9fa75e45b6a7",
          "user_content": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "Can you roll a die with 6 sides"
              }
            ],
            "role": "user"
          },
          "final_response": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": null
              }
            ],
            "role": "model"
          },
          "intermediate_data": {
            "tool_uses": [
              {
                "id": null,
                "args": {
                  "sides": 6
                },
                "name": "roll_die"
              }
            ],
            "intermediate_responses": []
          },
          "creation_timestamp": 1747341775.8937788
        }
      ],
      "session_input": null,
      "creation_timestamp": 1747341775.8937826
    }
  ],
  "creation_timestamp": 1747341775.8937957
}
==== tests/integration/fixture/hello_world_agent/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from . import agent

==== tests/integration/fixture/hello_world_agent/agent.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Hello world agent from agent 1.0 - https://colab.sandbox.google.com/drive/1Zq-nqmgK0nCERCv8jKIaoeTTgbNn6oSo?resourcekey=0-GYaz9pFT4wY8CI8Cvjy5GA#scrollTo=u3X3XwDOaCv9
import random

from google.adk import Agent
from google.genai import types


def roll_die(sides: int) -> int:
  """Roll a die and return the rolled result.

  Args:
    sides: The integer number of sides the die has.

  Returns:
    An integer of the result of rolling the die.
  """
  return random.randint(1, sides)


def check_prime(nums: list[int]) -> list[str]:
  """Check if a given list of numbers are prime.

  Args:
    nums: The list of numbers to check.

  Returns:
    A str indicating which number is prime.
  """
  primes = set()
  for number in nums:
    number = int(number)
    if number <= 1:
      continue
    is_prime = True
    for i in range(2, int(number**0.5) + 1):
      if number % i == 0:
        is_prime = False
        break
    if is_prime:
      primes.add(number)
  return (
      'No prime numbers found.'
      if not primes
      else f"{', '.join(str(num) for num in primes)} are prime numbers."
  )


root_agent = Agent(
    model='gemini-2.0-flash-001',
    name='data_processing_agent',
    instruction="""
      You roll dice and answer questions about the outcome of the dice rolls.
      You can roll dice of different sizes.
      You can use multiple tools in parallel by calling functions in parallel(in one request and in one round).
      The only things you do are roll dice for the user and discuss the outcomes.
      It is ok to discuss previous dice roles, and comment on the dice rolls.
      When you are asked to roll a die, you must call the roll_die tool with the number of sides. Be sure to pass in an integer. Do not pass in a string.
      You should never roll a die on your own.
      When checking prime numbers, call the check_prime tool with a list of integers. Be sure to pass in a list of integers. You should never pass in a string.
      You should not check prime numbers before calling the tool.
      When you are asked to roll a die and check prime numbers, you should always make the following two function calls:
      1. You should first call the roll_die tool to get a roll. Wait for the function response before calling the check_prime tool.
      2. After you get the function response from roll_die tool, you should call the check_prime tool with the roll_die result.
        2.1 If user asks you to check primes based on previous rolls, make sure you include the previous rolls in the list.
      3. When you respond, you must include the roll_die result from step 1.
      You should always perform the previous 3 steps when asking for a roll and checking prime numbers.
      You should not rely on the previous history on prime results.
    """,
    tools=[
        roll_die,
        check_prime,
    ],
    generate_content_config=types.GenerateContentConfig(
        safety_settings=[
            types.SafetySetting(  # avoid false alarm about rolling dice.
                category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
                threshold=types.HarmBlockThreshold.OFF,
            ),
        ]
    ),
)

==== tests/integration/fixture/ecommerce_customer_service_agent/test_config.json ====
{
  "criteria": {
    "tool_trajectory_avg_score": 0.7,
    "response_match_score": 0.5
  }
}

==== tests/integration/fixture/ecommerce_customer_service_agent/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from . import agent

==== tests/integration/fixture/ecommerce_customer_service_agent/order_query.test.json ====
{
  "eval_set_id": "a1157c01-851f-48a8-b956-83cf7f463510",
  "name": "a1157c01-851f-48a8-b956-83cf7f463510",
  "description": null,
  "eval_cases": [
    {
      "eval_id": "tests/integration/fixture/ecommerce_customer_service_agent/order_query.test.json",
      "conversation": [
        {
          "invocation_id": "38d54523-d789-4873-8cc0-d38826c7feb4",
          "user_content": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "Send an email to user user_a whose email address is alice@example.com"
              }
            ],
            "role": "user"
          },
          "final_response": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "Email sent to alice@example.com for user id user_a."
              }
            ],
            "role": "model"
          },
          "intermediate_data": {
            "tool_uses": [
              {
                "id": null,
                "args": {
                  "email": "alice@example.com",
                  "user_id": "user_a"
                },
                "name": "send_email"
              }
            ],
            "intermediate_responses": []
          },
          "creation_timestamp": 1747341706.6240807
        },
        {
          "invocation_id": "916393ab-0bce-4cb0-98de-6573d4e8e25c",
          "user_content": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "Can you tell me the status of my order with ID 1?"
              }
            ],
            "role": "user"
          },
          "final_response": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "Your order with ID 1 is FINISHED."
              }
            ],
            "role": "model"
          },
          "intermediate_data": {
            "tool_uses": [
              {
                "id": null,
                "args": {
                  "order_id": "1"
                },
                "name": "get_order_status"
              }
            ],
            "intermediate_responses": []
          },
          "creation_timestamp": 1747341706.6241167
        },
        {
          "invocation_id": "511b23d9-56f9-423b-9c31-7626f3411c32",
          "user_content": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "Cancel all pending order for the user with user id user_a"
              }
            ],
            "role": "user"
          },
          "final_response": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "I have checked your orders and order 4 was in pending status, so I have cancelled it. Order 1 was already finished and couldn't be cancelled.\n"
              }
            ],
            "role": "model"
          },
          "intermediate_data": {
            "tool_uses": [
              {
                "id": null,
                "args": {
                  "user_id": "user_a"
                },
                "name": "get_order_ids_for_user"
              },
              {
                "id": null,
                "args": {
                  "order_id": "1"
                },
                "name": "get_order_status"
              },
              {
                "id": null,
                "args": {
                  "order_id": "4"
                },
                "name": "get_order_status"
              },
              {
                "id": null,
                "args": {
                  "order_id": "4"
                },
                "name": "cancel_order"
              }
            ],
            "intermediate_responses": []
          },
          "creation_timestamp": 1747341706.6241703
        },
        {
          "invocation_id": "dcdf4b6d-96dd-4602-8c14-0563c6f6b5d0",
          "user_content": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "What orders have I placed under the username user_b?"
              }
            ],
            "role": "user"
          },
          "final_response": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "User user_b has placed one order with order ID 2.\n"
              }
            ],
            "role": "model"
          },
          "intermediate_data": {
            "tool_uses": [
              {
                "id": null,
                "args": {
                  "user_id": "user_b"
                },
                "name": "get_order_ids_for_user"
              }
            ],
            "intermediate_responses": []
          },
          "creation_timestamp": 1747341706.624196
        }
      ],
      "session_input": null,
      "creation_timestamp": 1747341706.6242023
    }
  ],
  "creation_timestamp": 1747341706.6242158
}
==== tests/integration/fixture/ecommerce_customer_service_agent/agent.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.adk import Agent

# A lightweight in-memory mock database
ORDER_DB = {
    "1": "FINISHED",
    "2": "CANCELED",
    "3": "PENDING",
    "4": "PENDING",
}  # Order id to status mapping. Available states: 'FINISHED', 'PENDING', and 'CANCELED'
USER_TO_ORDER_DB = {
    "user_a": ["1", "4"],
    "user_b": ["2"],
    "user_c": ["3"],
}  # User id to Order id mapping
TICKET_DB = [{
    "ticket_id": "1",
    "user_id": "user_a",
    "issue_type": "LOGIN_ISSUE",
    "status": "OPEN",
}]  # Available states: 'OPEN', 'CLOSED', 'ESCALATED'
USER_INFO_DB = {
    "user_a": {"name": "Alice", "email": "alice@example.com"},
    "user_b": {"name": "Bob", "email": "bob@example.com"},
}


def reset_data():
  global ORDER_DB
  global USER_TO_ORDER_DB
  global TICKET_DB
  global USER_INFO_DB
  ORDER_DB = {
      "1": "FINISHED",
      "2": "CANCELED",
      "3": "PENDING",
      "4": "PENDING",
  }
  USER_TO_ORDER_DB = {
      "user_a": ["1", "4"],
      "user_b": ["2"],
      "user_c": ["3"],
  }
  TICKET_DB = [{
      "ticket_id": "1",
      "user_id": "user_a",
      "issue_type": "LOGIN_ISSUE",
      "status": "OPEN",
  }]
  USER_INFO_DB = {
      "user_a": {"name": "Alice", "email": "alice@example.com"},
      "user_b": {"name": "Bob", "email": "bob@example.com"},
  }


def get_order_status(order_id: str) -> str:
  """Get the status of an order.

  Args:
      order_id (str): The unique identifier of the order.

  Returns:
      str: The status of the order (e.g., 'FINISHED', 'CANCELED', 'PENDING'),
           or 'Order not found' if the order_id does not exist.
  """
  return ORDER_DB.get(order_id, "Order not found")


def get_order_ids_for_user(user_id: str) -> list:
  """Get the list of order IDs assigned to a specific transaction associated with a user.

  Args:
      user_id (str): The unique identifier of the user.

  Returns:
      List[str]: A list of order IDs associated with the user, or an empty list
      if no orders are found.
  """
  return USER_TO_ORDER_DB.get(user_id, [])


def cancel_order(order_id: str) -> str:
  """Cancel an order if it is in a 'PENDING' state.

  You should call "get_order_status" to check the status first, before calling
  this tool.

  Args:
      order_id (str): The unique identifier of the order to be canceled.

  Returns:
      str: A message indicating whether the order was successfully canceled or
      not.
  """
  if order_id in ORDER_DB and ORDER_DB[order_id] == "PENDING":
    ORDER_DB[order_id] = "CANCELED"
    return f"Order {order_id} has been canceled."
  return f"Order {order_id} cannot be canceled."


def refund_order(order_id: str) -> str:
  """Process a refund for an order if it is in a 'CANCELED' state.

  You should call "get_order_status" to check if status first, before calling
  this tool.

  Args:
      order_id (str): The unique identifier of the order to be refunded.

  Returns:
      str: A message indicating whether the order was successfully refunded or
      not.
  """
  if order_id in ORDER_DB and ORDER_DB[order_id] == "CANCELED":
    return f"Order {order_id} has been refunded."
  return f"Order {order_id} cannot be refunded."


def create_ticket(user_id: str, issue_type: str) -> str:
  """Create a new support ticket for a user.

  Args:
      user_id (str): The unique identifier of the user creating the ticket.
      issue_type (str): An issue type the user is facing. Available types:
        'LOGIN_ISSUE', 'ORDER_ISSUE', 'OTHER'.

  Returns:
      str: A message indicating that the ticket was created successfully,
      including the ticket ID.
  """
  ticket_id = str(len(TICKET_DB) + 1)
  TICKET_DB.append({
      "ticket_id": ticket_id,
      "user_id": user_id,
      "issue_type": issue_type,
      "status": "OPEN",
  })
  return f"Ticket {ticket_id} created successfully."


def get_ticket_info(ticket_id: str) -> str:
  """Retrieve the information of a support ticket.

  current status of a support ticket.

  Args:
      ticket_id (str): The unique identifier of the ticket.

  Returns:
      A dictionary contains the following fields, or 'Ticket not found' if the
      ticket_id does not exist:
        - "ticket_id": str, the current ticket id
        - "user_id": str, the associated user id
        - "issue": str, the issue type
        - "status": The current status of the ticket (e.g., 'OPEN', 'CLOSED',
        'ESCALATED')

      Example: {"ticket_id": "1", "user_id": "user_a", "issue": "Login issue",
      "status": "OPEN"}
  """
  for ticket in TICKET_DB:
    if ticket["ticket_id"] == ticket_id:
      return ticket
  return "Ticket not found"


def get_tickets_for_user(user_id: str) -> list:
  """Get all the ticket IDs associated with a user.

  Args:
      user_id (str): The unique identifier of the user.

  Returns:
      List[str]: A list of ticket IDs associated with the user.
                 If no tickets are found, returns an empty list.
  """
  return [
      ticket["ticket_id"]
      for ticket in TICKET_DB
      if ticket["user_id"] == user_id
  ]


def update_ticket_status(ticket_id: str, status: str) -> str:
  """Update the status of a support ticket.

  Args:
      ticket_id (str): The unique identifier of the ticket.
      status (str): The new status to assign to the ticket (e.g., 'OPEN',
        'CLOSED', 'ESCALATED').

  Returns:
      str: A message indicating whether the ticket status was successfully
      updated.
  """
  for ticket in TICKET_DB:
    if ticket["ticket_id"] == ticket_id:
      ticket["status"] = status
      return f"Ticket {ticket_id} status updated to {status}."
  return "Ticket not found"


def get_user_info(user_id: str) -> dict:
  """Retrieve information (name, email) about a user.

  Args:
      user_id (str): The unique identifier of the user.

  Returns:
      dict or str: A dictionary containing user information of the following
        fields, or 'User not found' if the user_id does not exist:

       - name:  The name of the user
       - email: The email address of the user

       For example, {"name": "Chelsea", "email": "123@example.com"}
  """
  return USER_INFO_DB.get(user_id, "User not found")


def send_email(user_id: str, email: str) -> list:
  """Send email to user for notification.

  Args:
      user_id (str): The unique identifier of the user.
      email (str): The email address of the user.

  Returns:
      str: A message indicating whether the email was successfully sent.
  """
  if user_id in USER_INFO_DB:
    return f"Email sent to {email} for user id {user_id}"
  return "Cannot find this user"


# def update_user_info(user_id: str, new_info: dict[str, str]) -> str:
def update_user_info(user_id: str, email: str, name: str) -> str:
  """Update a user's information.

  Args:
      user_id (str): The unique identifier of the user.
      new_info (dict): A dictionary containing the fields to be updated (e.g.,
        {'email': 'new_email@example.com'}). Available field keys: 'email' and
        'name'.

  Returns:
      str: A message indicating whether the user's information was successfully
      updated or not.
  """
  if user_id in USER_INFO_DB:
    # USER_INFO_DB[user_id].update(new_info)
    if email and name:
      USER_INFO_DB[user_id].update({"email": email, "name": name})
    elif email:
      USER_INFO_DB[user_id].update({"email": email})
    elif name:
      USER_INFO_DB[user_id].update({"name": name})
    else:
      raise ValueError("this should not happen.")
    return f"User {user_id} information updated."
  return "User not found"


def get_user_id_from_cookie() -> str:
  """Get user ID(username) from the cookie.

  Only use this function when you do not know user ID(username).

  Args: None

  Returns:
      str: The user ID.
  """
  return "user_a"


root_agent = Agent(
    model="gemini-2.0-flash-001",
    name="Ecommerce_Customer_Service",
    instruction="""
      You are an intelligent customer service assistant for an e-commerce platform. Your goal is to accurately understand user queries and use the appropriate tools to fulfill requests. Follow these guidelines:

      1. **Understand the Query**:
        - Identify actions and conditions (e.g., create a ticket only for pending orders).
        - Extract necessary details (e.g., user ID, order ID) from the query or infer them from the context.

      2. **Plan Multi-Step Workflows**:
        - Break down complex queries into sequential steps. For example
        - typical workflow:
          - Retrieve IDs or references first (e.g., orders for a user).
          - Evaluate conditions (e.g., check order status).
          - Perform actions (e.g., create a ticket) only when conditions are met.
        - another typical workflows - order cancellation and refund:
          - Retrieve all orders for the user (`get_order_ids_for_user`).
          - Cancel pending orders (`cancel_order`).
          - Refund canceled orders (`refund_order`).
          - Notify the user (`send_email`).
        - another typical workflows - send user report:
          - Get user id.
          - Get user info(like emails)
          - Send email to user.

      3. **Avoid Skipping Steps**:
        - Ensure each intermediate step is completed before moving to the next.
        - Do not create tickets or take other actions without verifying the conditions specified in the query.

      4. **Provide Clear Responses**:
        - Confirm the actions performed, including details like ticket ID or pending orders.
        - Ensure the response aligns with the steps taken and query intent.
      """,
    tools=[
        get_order_status,
        cancel_order,
        get_order_ids_for_user,
        refund_order,
        create_ticket,
        update_ticket_status,
        get_tickets_for_user,
        get_ticket_info,
        get_user_info,
        send_email,
        update_user_info,
        get_user_id_from_cookie,
    ],
)

==== tests/integration/fixture/agent_with_config/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from . import agent

==== tests/integration/fixture/agent_with_config/agent.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.adk import Agent
from google.genai import types

new_message = types.Content(
    role="user",
    parts=[types.Part.from_text(text="Count a number")],
)

google_agent_1 = Agent(
    model="gemini-1.5-flash",
    name="agent_1",
    description="The first agent in the team.",
    instruction="Just say 1",
    generate_content_config=types.GenerateContentConfig(
        temperature=0.1,
    ),
)

google_agent_2 = Agent(
    model="gemini-1.5-flash",
    name="agent_2",
    description="The second agent in the team.",
    instruction="Just say 2",
    generate_content_config=types.GenerateContentConfig(
        temperature=0.2,
        safety_settings=[{
            "category": "HARM_CATEGORY_HATE_SPEECH",
            "threshold": "BLOCK_ONLY_HIGH",
        }],
    ),
)

google_agent_3 = Agent(
    model="gemini-1.5-flash",
    name="agent_3",
    description="The third agent in the team.",
    instruction="Just say 3",
    generate_content_config=types.GenerateContentConfig(
        temperature=0.5,
        safety_settings=[{
            "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
            "threshold": "BLOCK_NONE",
        }],
    ),
)

google_agent_with_instruction_in_config = Agent(
    model="gemini-1.5-flash",
    name="agent",
    generate_content_config=types.GenerateContentConfig(
        temperature=0.5, system_instruction="Count 1"
    ),
)


def function():
  pass


google_agent_with_tools_in_config = Agent(
    model="gemini-1.5-flash",
    name="agent",
    generate_content_config=types.GenerateContentConfig(
        temperature=0.5, tools=[function]
    ),
)

google_agent_with_response_schema_in_config = Agent(
    model="gemini-1.5-flash",
    name="agent",
    generate_content_config=types.GenerateContentConfig(
        temperature=0.5, response_schema={"key": "value"}
    ),
)

==== tests/integration/fixture/flow_complex_spark/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from . import agent

==== tests/integration/fixture/flow_complex_spark/sample.session.json ====
{
  "id": "683bcc98-7359-4b65-9cdb-307f85ae62c0",
  "context": {
    "_time": "2024-12-15 11:52:21.958542"
  },
  "events": [
    {
      "invocation_id": "UfYAgiCT",
      "author": "user",
      "content": {
        "parts": [
          {
            "text": "Research on the factors that affect floods in Florida. "
          }
        ],
        "role": "user"
      },
      "options": {},
      "is_greeting": false,
      "id": "qKEz3Vss",
      "timestamp": 1734292270.899412
    },
    {
      "invocation_id": "UfYAgiCT",
      "author": "spark_assistant",
      "content": {
        "parts": [
          {
            "function_call": {
              "args": {
                "agent_name": "research_assistant"
              },
              "name": "transfer_to_other_agent"
            }
          }
        ],
        "role": "model"
      },
      "options": {},
      "is_greeting": false,
      "id": "MEQQWBGe",
      "timestamp": 1734292272.522898
    },
    {
      "invocation_id": "UfYAgiCT",
      "author": "spark_assistant",
      "content": {
        "parts": [
          {
            "function_response": {
              "name": "transfer_to_other_agent",
              "response": {
                "status": "ok",
                "target_agent_name": "research_assistant",
                "message": "Transfered to research_assistant"
              }
            }
          }
        ],
        "role": "user"
      },
      "options": {
        "skip_summarization": true,
        "function_call_event_id": "MEQQWBGe"
      },
      "is_greeting": false,
      "id": "QjLptHaG",
      "timestamp": 1734292272.524573
    },
    {
      "invocation_id": "UfYAgiCT",
      "author": "research_plan_agent",
      "content": {
        "parts": [
          {
            "text": "[research_plan_agent]:  I can help you with that! Here is a research plan for the factors that affect floods in Florida:\n\n**Factors that affect floods in Florida**\nI will research the factors that affect floods in Florida, such as rainfall, sea level rise, and urbanization.\n\n**Rainfall in Florida**\nI will research the average rainfall in Florida, as well as the frequency and intensity of rainfall events.\n\n**Sea Level Rise in Florida**\nI will research the rate of sea level rise in Florida, as well as the impact of sea level rise on flooding.\n\n**Urbanization in Florida**\nI will research the impact of urbanization on flooding in Florida, such as the effects of impervious surfaces and drainage systems.\n\n**Flood History in Florida**\nI will research the history of floods in Florida, including the frequency, severity, and causes of past floods.\n\n**Flood Mitigation Efforts in Florida**\nI will research the flood mitigation efforts that are currently in place in Florida, as well as the effectiveness of these efforts.\n\nI will start researching now. \n"
          }
        ],
        "role": "model"
      },
      "options": {},
      "is_greeting": false,
      "id": "NcWJjpm9",
      "timestamp": 1734292274.707415
    },
    {
      "invocation_id": "UfYAgiCT",
      "author": "question_generation_agent",
      "content": {
        "parts": [
          {
            "text": "1. [question_generation_agent]: What are the specific types of rainfall events that contribute to flooding in Florida?\n2. [question_generation_agent]: How does the rate of sea level rise in Florida compare to the global average?\n3. [question_generation_agent]: What are the specific ways that urbanization in Florida contributes to increased flooding?\n4. [question_generation_agent]: Are there any specific regions in Florida that are particularly vulnerable to flooding?\n5. [question_generation_agent]: What are the most significant flood events in Florida's history, and what were their causes?\n6. [question_generation_agent]: What are the different types of flood mitigation efforts currently in place in Florida?\n7. [question_generation_agent]: How effective have these flood mitigation efforts been in reducing flood risk in Florida?\n8. [question_generation_agent]: What are the potential future impacts of climate change on flooding in Florida?\n9. [question_generation_agent]: What are the economic and social consequences of flooding in Florida?\n10. [question_generation_agent]: What are the recommendations for improving flood mitigation efforts in Florida? \n"
          }
        ],
        "role": "model"
      },
      "options": {},
      "is_greeting": false,
      "id": "9DZFuhg7",
      "timestamp": 1734292277.283785
    },
    {
      "invocation_id": "UfYAgiCT",
      "author": "information_retrieval_agent",
      "content": {
        "parts": [
          {
            "text": "[information_retrieval_agent]: **No. 1: Types of Rainfall Events Contributing to Flooding in Florida**\n\nFlorida experiences various types of rainfall events that contribute to flooding. These include:\n\n* **Tropical Storms and Hurricanes:** These storms bring heavy rainfall over extended periods, often exceeding the capacity of drainage systems and leading to widespread flooding.\n* **Thunderstorms:** While less intense than hurricanes, thunderstorms can produce heavy downpours in a short time, causing localized flooding, especially in urban areas with limited drainage.\n* **Frontal Systems:** Cold fronts moving across Florida can bring significant rainfall, particularly during the winter months, leading to flooding in low-lying areas.\n* **El Nio-Southern Oscillation (ENSO):** This climate pattern can influence rainfall patterns in Florida, with El Nio years often associated with increased rainfall and flooding.\n\n[information_retrieval_agent]: **No. 2: Sea Level Rise Rate in Florida Compared to Global Average**\n\nFlorida's sea level rise rate is significantly higher than the global average. While the global average sea level rise is about 3.4 millimeters per year, Florida's rate is estimated to be around 9 millimeters per year. This accelerated rate is attributed to factors such as land subsidence and the Gulf Stream's influence.\n\n[information_retrieval_agent]: **No. 3: Urbanization's Impact on Flooding in Florida**\n\nUrbanization in Florida contributes to increased flooding through several mechanisms:\n\n* **Impervious Surfaces:** Concrete and asphalt surfaces in urban areas reduce infiltration, forcing rainwater to run off into drainage systems, which can become overwhelmed during heavy rainfall.\n* **Modified Drainage Patterns:** Urban development often alters natural drainage patterns, leading to concentrated runoff and increased flood risk in certain areas.\n* **Increased Runoff Velocity:** Urban surfaces accelerate runoff, increasing the volume and speed of water flowing into drainage systems, potentially exceeding their capacity.\n\n[information_retrieval_agent]: **No. 4: Regions in Florida Particularly Vulnerable to Flooding**\n\nSeveral regions in Florida are particularly vulnerable to flooding due to their geographic characteristics and exposure to various flood risks:\n\n* **Coastal Areas:** Coastal areas are susceptible to storm surge, sea level rise, and coastal erosion, increasing their vulnerability to flooding.\n* **Low-Lying Areas:** Areas with low elevation are prone to flooding from heavy rainfall and rising sea levels.\n* **Urban Areas:** Urban areas with limited drainage capacity and high concentrations of impervious surfaces are at risk of flooding during heavy rainfall events.\n\n[information_retrieval_agent]: **No. 5: Significant Flood Events in Florida's History**\n\nFlorida has experienced numerous significant flood events throughout its history, with some notable examples:\n\n* **Hurricane Andrew (1992):** This Category 5 hurricane caused widespread flooding in South Florida, primarily due to storm surge and heavy rainfall.\n* **Hurricane Irma (2017):** This Category 4 hurricane brought significant rainfall and storm surge, leading to extensive flooding across the state.\n* **Hurricane Michael (2018):** This Category 5 hurricane caused significant flooding in the Panhandle region, primarily due to heavy rainfall and storm surge.\n\n[information_retrieval_agent]: **No. 6: Flood Mitigation Efforts in Florida**\n\nFlorida has implemented various flood mitigation efforts to reduce flood risk and protect communities:\n\n* **Levees and Seawalls:** These structures are designed to protect coastal areas from storm surge and rising sea levels.\n* **Drainage Systems:** Drainage systems are designed to collect and remove excess rainwater, reducing the risk of flooding in urban areas.\n* **Floodplain Management:** Regulations are in place to restrict development in floodplains, minimizing the risk of damage and loss of life.\n* **Early Warning Systems:** Advanced weather forecasting and warning systems provide timely alerts to residents, allowing them to prepare for potential flooding.\n\n[information_retrieval_agent]: **No. 7: Effectiveness of Flood Mitigation Efforts in Florida**\n\nThe effectiveness of flood mitigation efforts in Florida varies depending on the specific measures implemented and the severity of the flood event. While some efforts have been successful in reducing flood risk, others have proven less effective, particularly in the face of extreme weather events.\n\n[information_retrieval_agent]: **No. 8: Potential Future Impacts of Climate Change on Flooding in Florida**\n\nClimate change is expected to exacerbate flooding in Florida through several mechanisms:\n\n* **Increased Rainfall Intensity:** Climate change is projected to increase the frequency and intensity of rainfall events, leading to more frequent and severe flooding.\n* **Sea Level Rise:** Continued sea level rise will increase the risk of coastal flooding, particularly during storm surge events.\n* **Ocean Warming:** Warmer ocean temperatures can lead to more intense hurricanes, further increasing the risk of flooding.\n\n[information_retrieval_agent]: **No. 9: Economic and Social Consequences of Flooding in Florida**\n\nFlooding in Florida has significant economic and social consequences:\n\n* **Property Damage:** Flooding can cause extensive damage to homes, businesses, and infrastructure, resulting in substantial financial losses.\n* **Disruption of Transportation:** Flooding can disrupt transportation systems, including roads, bridges, and airports, leading to economic losses and social disruption.\n* **Health Risks:** Flooding can create health risks, such as waterborne diseases and injuries from debris.\n* **Displacement of Residents:** Flooding can force residents to evacuate their homes, leading to displacement and social disruption.\n\n[information_retrieval_agent]: **No. 10: Recommendations for Improving Flood Mitigation Efforts in Florida**\n\nTo improve flood mitigation efforts in Florida, several recommendations can be considered:\n\n* **Invest in Infrastructure:** Increased investment in drainage systems, levees, and seawalls is crucial to enhance flood protection.\n* **Promote Sustainable Development:** Encourage development practices that minimize impervious surfaces and preserve natural drainage patterns.\n* **Strengthen Early Warning Systems:** Enhance weather forecasting and warning systems to provide timely and accurate alerts to residents.\n* **Implement Comprehensive Floodplain Management:** Enforce strict regulations to restrict development in floodplains and minimize flood risk.\n* **Promote Public Awareness:** Educate residents about flood risks and encourage them to take steps to prepare for potential flooding.\n\n[exit] \n"
          }
        ],
        "role": "model"
      },
      "options": {},
      "is_greeting": false,
      "id": "o11CKE8Q",
      "timestamp": 1734292284.446259
    },
    {
      "invocation_id": "UfYAgiCT",
      "author": "summary_agent",
      "content": {
        "parts": [
          {
            "text": "## Flooding in Florida: A Comprehensive Analysis of Causes, Impacts, and Mitigation Strategies\n\n**Abstract:** This essay explores the complex issue of flooding in Florida, a state highly vulnerable to various flood threats. It examines the key factors contributing to flooding, including rainfall patterns, sea level rise, and urbanization, and analyzes their historical impact.  Furthermore, it evaluates the effectiveness of existing flood mitigation efforts and explores recommendations for future improvements. \n\n**Rainfall Patterns and Flood Risk:**\n\nFlorida's climate is characterized by frequent and intense rainfall events, significantly contributing to flood risk.  Tropical storms and hurricanes, particularly during the hurricane season, bring heavy rainfall over prolonged periods, overwhelming drainage systems and causing widespread flooding.  Thunderstorms, though less intense, can generate heavy downpours in short bursts, leading to localized flooding, especially in urban areas.  Furthermore, frontal systems, particularly during winter months, can bring substantial rainfall, exacerbating flooding in low-lying areas. El Nio-Southern Oscillation (ENSO) events can also influence rainfall patterns, with El Nio years often associated with increased rainfall and subsequent flooding.\n\n**Sea Level Rise and Coastal Flooding:**\n\nFlorida's sea level rise rate surpasses the global average, posing a significant threat to coastal areas.  The rate of sea level rise in Florida is estimated to be around 9 millimeters per year, compared to the global average of 3.4 millimeters per year.  This accelerated rise is attributed to factors such as land subsidence and the Gulf Stream's influence.  As sea levels continue to rise, coastal areas face an increased risk of flooding, particularly during storm surge events, leading to erosion, saltwater intrusion, and potential displacement of coastal communities. \n\n**Urbanization and Flood Risk:**\n\nUrbanization in Florida, while contributing to economic growth, also exacerbates flood risk.  The increasing development of impervious surfaces, such as concrete and asphalt, reduces rainwater infiltration, forcing excess water to flow into drainage systems. This can overwhelm the capacity of drainage systems, leading to flooding in urban areas.  Furthermore, urban development often alters natural drainage patterns, diverting water flow and increasing flooding risks in specific locations.  Finally, urban surfaces accelerate runoff velocity, increasing the volume and speed of water entering drainage systems, further enhancing the risk of flooding.\n\n**Historical Flood Events and Their Impact:**\n\nFlorida has experienced numerous significant flood events throughout its history, highlighting the state's vulnerability.  Hurricane Andrew in 1992, a Category 5 hurricane, caused widespread flooding in South Florida, primarily due to storm surge and heavy rainfall.  Hurricane Irma in 2017, a Category 4 hurricane, brought significant rainfall and storm surge, leading to extensive flooding across the state.  Hurricane Michael in 2018, a Category 5 hurricane, caused substantial flooding in the Panhandle region, primarily due to heavy rainfall and storm surge.  These events demonstrate the devastating impact of flooding on infrastructure, property, and human lives. \n\n**Flood Mitigation Efforts and Their Effectiveness:**\n\nFlorida has implemented various flood mitigation efforts to reduce flood risk and protect communities.  These efforts include construction of levees and seawalls to protect coastal areas from storm surge and rising sea levels, construction of drainage systems to collect and remove excess rainwater, implementation of floodplain management regulations to restrict development in floodplains, and development of early warning systems to provide timely alerts to residents.  While these efforts have contributed to reducing flood risk in some areas, their effectiveness varies depending on the severity of the flood event.  Extreme weather events, such as hurricanes, can overwhelm existing infrastructure and mitigation measures, highlighting the need for continuous improvement and adaptation.\n\n**Future Impacts of Climate Change on Flooding:**\n\nClimate change is expected to exacerbate flooding in Florida, posing significant challenges for the state's future.  Increased rainfall intensity, driven by climate change, is projected to lead to more frequent and severe flooding events.  Continued sea level rise will further increase the risk of coastal flooding, especially during storm surge events.  Ocean warming, a consequence of climate change, can contribute to more intense hurricanes, further amplifying flood risk.  These compounding factors necessitate proactive measures to adapt to changing climate conditions and mitigate future flood risks. \n\n**Economic and Social Consequences of Flooding:**\n\nFlooding in Florida carries significant economic and social consequences.  Property damage from flooding can be extensive, resulting in substantial financial losses for individuals, businesses, and the state.  Flooding disrupts transportation systems, including roads, bridges, and airports, causing economic losses and social disruption.  Flooding can also create health risks, such as waterborne diseases and injuries from debris.  Furthermore, displacement of residents due to flooding can lead to social disruption and strain on existing resources.  The economic and social costs of flooding underscore the importance of effective flood mitigation and adaptation strategies.\n\n**Recommendations for Improving Flood Mitigation Efforts:**\n\nTo improve flood mitigation efforts in Florida and address the challenges posed by climate change, several recommendations are crucial.  Increased investment in infrastructure, including drainage systems, levees, and seawalls, is essential to enhance flood protection.  Promoting sustainable development practices, such as minimizing impervious surfaces and preserving natural drainage patterns, can reduce runoff and mitigate flood risk.  Strengthening early warning systems to provide timely and accurate alerts to residents is crucial for preparedness and response.  Implementing comprehensive floodplain management regulations to restrict development in floodplains and minimize flood risk is essential.  Finally, promoting public awareness about flood risks and encouraging residents to take steps to prepare for potential flooding is vital for community resilience.\n\n**Conclusion:**\n\nFlooding in Florida is a complex issue with multifaceted causes, impacts, and mitigation strategies.  Rainfall patterns, sea level rise, and urbanization all contribute to flood risk, while historical events highlight the state's vulnerability.  Existing flood mitigation efforts, while valuable, need continuous improvement and adaptation to address the challenges posed by climate change.  Investing in infrastructure, promoting sustainable development, strengthening early warning systems, implementing comprehensive floodplain management, and fostering public awareness are key recommendations for enhancing flood resilience and safeguarding Florida's communities from the devastating impacts of flooding. \n"
          }
        ],
        "role": "model"
      },
      "options": {},
      "is_greeting": false,
      "id": "om1YdTV1",
      "timestamp": 1734292291.449593
    },
    {
      "invocation_id": "UfYAgiCT",
      "author": "spark_assistant",
      "content": {
        "parts": [
          {
            "function_call": {
              "args": {
                "agent_name": "spark_assistant"
              },
              "name": "transfer_to_other_agent"
            }
          }
        ],
        "role": "model"
      },
      "options": {
        "skip_summarization": true
      },
      "is_greeting": false,
      "id": "oRxzw1Wp",
      "timestamp": 1734292291.451956
    },
    {
      "invocation_id": "UfYAgiCT",
      "author": "spark_assistant",
      "content": {
        "parts": [
          {
            "function_response": {
              "name": "transfer_to_other_agent",
              "response": {
                "status": "ok",
                "target_agent_name": "spark_assistant",
                "message": "Transfered to spark_assistant"
              }
            }
          }
        ],
        "role": "user"
      },
      "options": {
        "skip_summarization": true,
        "function_call_event_id": "oRxzw1Wp"
      },
      "is_greeting": false,
      "id": "s2OiE3PP",
      "timestamp": 1734292291.453157
    }
  ],
  "past_events": [],
  "current_agent_name": "spark_assistant",
  "pending_events": {},
  "artifacts": {},
  "last_update_time": 1734292291.453157,
  "event_logs": []
}
==== tests/integration/fixture/flow_complex_spark/agent.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.adk import Agent
from google.genai import types

research_plan_agent = Agent(
    model="gemini-1.5-flash",
    name="research_plan_agent",
    description="I can help generate research plan.",
    instruction="""\
Your task is to create a research plan according to the user's query.

# Here are the instructions for creating the research plan:

+ Focus on finding specific things, e.g. products, data, etc.
+ Have the personality of a work colleague that is very helpful and explains things very nicely.
+ Don't mention your name unless you are asked.
+ Think about the most common things that you would need to research.
+ Think about possible answers when creating the plan.
+ Your task is to create the sections that should be researched. You will output high level headers, preceded by ##
+ Underneath each header, write a short sentence on what we want to find there.
+ The headers will follow the logical analysis pattern, as well as logical exploration pattern.
+ The headers should be a statement, not be in the form of questions.
+ The header will not include roman numerals or anything of the sort, e.g. ":", etc
+ Do not include things that you cannot possibly know about from using Google Search: e.g. sales forecasting, competitors, profitability analysis, etc.
+ Do not have an executive summary
+ In each section describe specifically what will be researched.
+ Never use "we will", but rather "I will".
+ Don't ask for clarifications from the user.
+ Do not ask the user for clarifications or if they have any other questions.
+ All headers should be bolded.
+ If you have steps in the plan that depend on other information, make sure they are 2 diferent sections in the plan.
+ At the end mention that you will start researching.

# Instruction on replying format

+ Start with your name as "[research_plan_agent]: ".
+ Output the content you want to say.

Output summary:
""",
    flow="single",
    sub_agents=[],
    generate_content_config=types.GenerateContentConfig(
        temperature=0.1,
    ),
)


question_generation_agent = Agent(
    model="gemini-1.5-flash",
    name="question_generation_agent",
    description="I can help generate questions related to user's question.",
    instruction="""\
Generate questions related to the research plan generated by research_plan_agent.

# Instruction on replying format

Your reply should be a numbered lsit.

For each question, reply in the following format: "[question_generation_agent]: [generated questions]"

Here is an example of the generated question list:

1. [question_generation_agent]: which state is San Jose in?
2. [question_generation_agent]: how google website is designed?
""",
    flow="single",
    sub_agents=[],
    generate_content_config=types.GenerateContentConfig(
        temperature=0.1,
    ),
)

information_retrieval_agent = Agent(
    model="gemini-1.5-flash",
    name="information_retrieval_agent",
    description=(
        "I can help retrieve information related to question_generation_agent's"
        " question."
    ),
    instruction="""\
Inspect all the questions after "[question_generation_agent]: " and asnwer them.

# Instruction on replying format

Always start with "[information_retrieval_agent]: "

For the answer of one question:

- Start with a title with one line summary of the reply.
- The title line should be bolded and starts with No.x of the corresponding question.
- Have a paragraph of detailed explain.

# Instruction on exiting the loop

- If you see there are less than 20 questions by "question_generation_agent", do not say "[exit]".
- If you see there are already great or equal to 20 questions asked by "question_generation_agent", say "[exit]" at last to exit the loop.
""",
    flow="single",
    sub_agents=[],
    generate_content_config=types.GenerateContentConfig(
        temperature=0.1,
    ),
)

question_sources_generation_agent = Agent(
    model="gemini-1.5-flash",
    name="question_sources_generation_agent",
    description=(
        "I can help generate questions and retrieve related information."
    ),
    instruction="Generate questions and retrieve information.",
    flow="loop",
    sub_agents=[
        question_generation_agent,
        information_retrieval_agent,
    ],
    generate_content_config=types.GenerateContentConfig(
        temperature=0.1,
    ),
)

summary_agent = Agent(
    model="gemini-1.5-flash",
    name="summary_agent",
    description="I can help summarize information of previous content.",
    instruction="""\
Summarize information in all historical messages that were replied by "question_generation_agent" and "information_retrieval_agent".

# Instruction on replying format

- The output should be like an essay that has a title, an abstract, multiple paragraphs for each topic and a conclusion.
- Each paragraph should maps to one or more question in historical content.
""",
    flow="single",
    generate_content_config=types.GenerateContentConfig(
        temperature=0.8,
    ),
)

research_assistant = Agent(
    model="gemini-1.5-flash",
    name="research_assistant",
    description="I can help with research question.",
    instruction="Help customers with their need.",
    flow="sequential",
    sub_agents=[
        research_plan_agent,
        question_sources_generation_agent,
        summary_agent,
    ],
    generate_content_config=types.GenerateContentConfig(
        temperature=0.1,
    ),
)

spark_agent = Agent(
    model="gemini-1.5-flash",
    name="spark_assistant",
    description="I can help with non-research question.",
    instruction="Help customers with their need.",
    flow="auto",
    sub_agents=[research_assistant],
    generate_content_config=types.GenerateContentConfig(
        temperature=0.1,
    ),
)

root_agent = spark_agent

==== tests/integration/fixture/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

==== tests/integration/fixture/context_update_test/OWNERS ====
gkcng

==== tests/integration/fixture/context_update_test/successful_test.session.json ====
{
  "id": "ead43200-b575-4241-9248-233b4be4f29a",
  "context": {
    "_time": "2024-12-01 09:02:43.531503",
    "data_one": "RRRR",
    "data_two": "3.141529",
    "data_three": [
      "apple",
      "banana"
    ],
    "data_four": [
      "1",
      "hello",
      "3.14"
    ]
  },
  "events": [
    {
      "invocation_id": "6BGrtKJu",
      "author": "user",
      "content": {
        "parts": [
          {
            "text": "hi"
          }
        ],
        "role": "user"
      },
      "options": {},
      "id": "ltzQTqR4",
      "timestamp": 1733043686.8428597
    },
    {
      "invocation_id": "6BGrtKJu",
      "author": "root_agent",
      "content": {
        "parts": [
          {
            "text": "Hello!   How can I help you today? \n"
          }
        ],
        "role": "model"
      },
      "options": {
        "partial": false
      },
      "id": "ClSROx8b",
      "timestamp": 1733043688.1030986
    },
    {
      "invocation_id": "M3dUcVa8",
      "author": "user",
      "content": {
        "parts": [
          {
            "text": "update data_one to be RRRR, data_two to be 3.141529, data_three to be apple and banana, data_four to be 1, hello, and 3.14"
          }
        ],
        "role": "user"
      },
      "options": {},
      "id": "yxigGwIZ",
      "timestamp": 1733043745.9900541
    },
    {
      "invocation_id": "M3dUcVa8",
      "author": "root_agent",
      "content": {
        "parts": [
          {
            "function_call": {
              "args": {
                "data_four": [
                  "1",
                  "hello",
                  "3.14"
                ],
                "data_two": "3.141529",
                "data_three": [
                  "apple",
                  "banana"
                ],
                "data_one": "RRRR"
              },
              "name": "update_fc"
            }
          }
        ],
        "role": "model"
      },
      "options": {
        "partial": false
      },
      "id": "8V6de8th",
      "timestamp": 1733043747.4545543
    },
    {
      "invocation_id": "M3dUcVa8",
      "author": "root_agent",
      "content": {
        "parts": [
          {
            "function_response": {
              "name": "update_fc",
              "response": {}
            }
          }
        ],
        "role": "user"
      },
      "options": {
        "update_context": {
          "data_one": "RRRR",
          "data_two": "3.141529",
          "data_three": [
            "apple",
            "banana"
          ],
          "data_four": [
            "1",
            "hello",
            "3.14"
          ]
        },
        "function_call_event_id": "8V6de8th"
      },
      "id": "dkTj5v8B",
      "timestamp": 1733043747.457031
    },
    {
      "invocation_id": "M3dUcVa8",
      "author": "root_agent",
      "content": {
        "parts": [
          {
            "text": "OK. I've updated the data. Anything else? \n"
          }
        ],
        "role": "model"
      },
      "options": {
        "partial": false
      },
      "id": "OZ77XR41",
      "timestamp": 1733043748.7901294
    }
  ],
  "past_events": [],
  "pending_events": {},
  "artifacts": {},
  "event_logs": [
    {
      "invocation_id": "6BGrtKJu",
      "event_id": "ClSROx8b",
      "model_request": {
        "model": "gemini-1.5-flash",
        "contents": [
          {
            "parts": [
              {
                "text": "hi"
              }
            ],
            "role": "user"
          }
        ],
        "config": {
          "system_instruction": "You are an agent. Your name is root_agent.\nCall tools",
          "tools": [
            {
              "function_declarations": [
                {
                  "description": "Hello",
                  "name": "update_fc",
                  "parameters": {
                    "type": "OBJECT",
                    "properties": {
                      "data_one": {
                        "type": "STRING"
                      },
                      "data_two": {
                        "type": "STRING"
                      },
                      "data_three": {
                        "type": "ARRAY",
                        "items": {
                          "type": "STRING"
                        }
                      },
                      "data_four": {
                        "type": "ARRAY",
                        "items": {
                          "any_of": [
                            {
                              "type": "INTEGER"
                            },
                            {
                              "type": "NUMBER"
                            },
                            {
                              "type": "STRING"
                            }
                          ],
                          "type": "STRING"
                        }
                      }
                    }
                  }
                }
              ]
            }
          ]
        }
      },
      "model_response": {
        "candidates": [
          {
            "content": {
              "parts": [
                {
                  "text": "Hello!   How can I help you today? \n"
                }
              ],
              "role": "model"
            },
            "avg_logprobs": -0.15831730915949896,
            "finish_reason": "STOP",
            "safety_ratings": [
              {
                "category": "HARM_CATEGORY_HATE_SPEECH",
                "probability": "NEGLIGIBLE",
                "probability_score": 0.071777344,
                "severity": "HARM_SEVERITY_NEGLIGIBLE",
                "severity_score": 0.07080078
              },
              {
                "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                "probability": "NEGLIGIBLE",
                "probability_score": 0.16308594,
                "severity": "HARM_SEVERITY_NEGLIGIBLE",
                "severity_score": 0.14160156
              },
              {
                "category": "HARM_CATEGORY_HARASSMENT",
                "probability": "NEGLIGIBLE",
                "probability_score": 0.09423828,
                "severity": "HARM_SEVERITY_NEGLIGIBLE",
                "severity_score": 0.037841797
              },
              {
                "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                "probability": "NEGLIGIBLE",
                "probability_score": 0.059326172,
                "severity": "HARM_SEVERITY_NEGLIGIBLE",
                "severity_score": 0.02368164
              }
            ]
          }
        ],
        "model_version": "gemini-1.5-flash-001",
        "usage_metadata": {
          "candidates_token_count": 13,
          "prompt_token_count": 32,
          "total_token_count": 45
        }
      }
    },
    {
      "invocation_id": "M3dUcVa8",
      "event_id": "8V6de8th",
      "model_request": {
        "model": "gemini-1.5-flash",
        "contents": [
          {
            "parts": [
              {
                "text": "hi"
              }
            ],
            "role": "user"
          },
          {
            "parts": [
              {
                "text": "Hello!   How can I help you today? \n"
              }
            ],
            "role": "model"
          },
          {
            "parts": [
              {
                "text": "update data_one to be RRRR, data_two to be 3.141529, data_three to be apple and banana, data_four to be 1, hello, and 3.14"
              }
            ],
            "role": "user"
          }
        ],
        "config": {
          "system_instruction": "You are an agent. Your name is root_agent.\nCall tools",
          "tools": [
            {
              "function_declarations": [
                {
                  "description": "Hello",
                  "name": "update_fc",
                  "parameters": {
                    "type": "OBJECT",
                    "properties": {
                      "data_one": {
                        "type": "STRING"
                      },
                      "data_two": {
                        "type": "STRING"
                      },
                      "data_three": {
                        "type": "ARRAY",
                        "items": {
                          "type": "STRING"
                        }
                      },
                      "data_four": {
                        "type": "ARRAY",
                        "items": {
                          "any_of": [
                            {
                              "type": "INTEGER"
                            },
                            {
                              "type": "NUMBER"
                            },
                            {
                              "type": "STRING"
                            }
                          ],
                          "type": "STRING"
                        }
                      }
                    }
                  }
                }
              ]
            }
          ]
        }
      },
      "model_response": {
        "candidates": [
          {
            "content": {
              "parts": [
                {
                  "function_call": {
                    "args": {
                      "data_four": [
                        "1",
                        "hello",
                        "3.14"
                      ],
                      "data_two": "3.141529",
                      "data_three": [
                        "apple",
                        "banana"
                      ],
                      "data_one": "RRRR"
                    },
                    "name": "update_fc"
                  }
                }
              ],
              "role": "model"
            },
            "avg_logprobs": -2.100960955431219e-6,
            "finish_reason": "STOP",
            "safety_ratings": [
              {
                "category": "HARM_CATEGORY_HATE_SPEECH",
                "probability": "NEGLIGIBLE",
                "probability_score": 0.12158203,
                "severity": "HARM_SEVERITY_NEGLIGIBLE",
                "severity_score": 0.13671875
              },
              {
                "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                "probability": "NEGLIGIBLE",
                "probability_score": 0.421875,
                "severity": "HARM_SEVERITY_LOW",
                "severity_score": 0.24511719
              },
              {
                "category": "HARM_CATEGORY_HARASSMENT",
                "probability": "NEGLIGIBLE",
                "probability_score": 0.15722656,
                "severity": "HARM_SEVERITY_NEGLIGIBLE",
                "severity_score": 0.072753906
              },
              {
                "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                "probability": "NEGLIGIBLE",
                "probability_score": 0.083984375,
                "severity": "HARM_SEVERITY_NEGLIGIBLE",
                "severity_score": 0.03564453
              }
            ]
          }
        ],
        "model_version": "gemini-1.5-flash-001",
        "usage_metadata": {
          "candidates_token_count": 32,
          "prompt_token_count": 94,
          "total_token_count": 126
        }
      }
    },
    {
      "invocation_id": "M3dUcVa8",
      "event_id": "OZ77XR41",
      "model_request": {
        "model": "gemini-1.5-flash",
        "contents": [
          {
            "parts": [
              {
                "text": "hi"
              }
            ],
            "role": "user"
          },
          {
            "parts": [
              {
                "text": "Hello!   How can I help you today? \n"
              }
            ],
            "role": "model"
          },
          {
            "parts": [
              {
                "text": "update data_one to be RRRR, data_two to be 3.141529, data_three to be apple and banana, data_four to be 1, hello, and 3.14"
              }
            ],
            "role": "user"
          },
          {
            "parts": [
              {
                "function_call": {
                  "args": {
                    "data_four": [
                      "1",
                      "hello",
                      "3.14"
                    ],
                    "data_two": "3.141529",
                    "data_three": [
                      "apple",
                      "banana"
                    ],
                    "data_one": "RRRR"
                  },
                  "name": "update_fc"
                }
              }
            ],
            "role": "model"
          },
          {
            "parts": [
              {
                "function_response": {
                  "name": "update_fc",
                  "response": {}
                }
              }
            ],
            "role": "user"
          }
        ],
        "config": {
          "system_instruction": "You are an agent. Your name is root_agent.\nCall tools",
          "tools": [
            {
              "function_declarations": [
                {
                  "description": "Hello",
                  "name": "update_fc",
                  "parameters": {
                    "type": "OBJECT",
                    "properties": {
                      "data_one": {
                        "type": "STRING"
                      },
                      "data_two": {
                        "type": "STRING"
                      },
                      "data_three": {
                        "type": "ARRAY",
                        "items": {
                          "type": "STRING"
                        }
                      },
                      "data_four": {
                        "type": "ARRAY",
                        "items": {
                          "any_of": [
                            {
                              "type": "INTEGER"
                            },
                            {
                              "type": "NUMBER"
                            },
                            {
                              "type": "STRING"
                            }
                          ],
                          "type": "STRING"
                        }
                      }
                    }
                  }
                }
              ]
            }
          ]
        }
      },
      "model_response": {
        "candidates": [
          {
            "content": {
              "parts": [
                {
                  "text": "OK. I've updated the data. Anything else? \n"
                }
              ],
              "role": "model"
            },
            "avg_logprobs": -0.22089435373033797,
            "finish_reason": "STOP",
            "safety_ratings": [
              {
                "category": "HARM_CATEGORY_HATE_SPEECH",
                "probability": "NEGLIGIBLE",
                "probability_score": 0.04663086,
                "severity": "HARM_SEVERITY_NEGLIGIBLE",
                "severity_score": 0.09423828
              },
              {
                "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                "probability": "NEGLIGIBLE",
                "probability_score": 0.18554688,
                "severity": "HARM_SEVERITY_NEGLIGIBLE",
                "severity_score": 0.111328125
              },
              {
                "category": "HARM_CATEGORY_HARASSMENT",
                "probability": "NEGLIGIBLE",
                "probability_score": 0.071777344,
                "severity": "HARM_SEVERITY_NEGLIGIBLE",
                "severity_score": 0.03112793
              },
              {
                "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                "probability": "NEGLIGIBLE",
                "probability_score": 0.043945313,
                "severity": "HARM_SEVERITY_NEGLIGIBLE",
                "severity_score": 0.057373047
              }
            ]
          }
        ],
        "model_version": "gemini-1.5-flash-001",
        "usage_metadata": {
          "candidates_token_count": 14,
          "prompt_token_count": 129,
          "total_token_count": 143
        }
      }
    }
  ]
}
==== tests/integration/fixture/context_update_test/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from . import agent

==== tests/integration/fixture/context_update_test/agent.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from typing import List
from typing import Union

from google.adk import Agent
from google.adk.tools import ToolContext
from pydantic import BaseModel


def update_fc(
    data_one: str,
    data_two: Union[int, float, str],
    data_three: list[str],
    data_four: List[Union[int, float, str]],
    tool_context: ToolContext,
):
  """Simply ask to update these variables in the context"""
  tool_context.actions.update_state("data_one", data_one)
  tool_context.actions.update_state("data_two", data_two)
  tool_context.actions.update_state("data_three", data_three)
  tool_context.actions.update_state("data_four", data_four)


root_agent = Agent(
    model="gemini-1.5-flash",
    name="root_agent",
    instruction="Call tools",
    flow="auto",
    tools=[update_fc],
)

==== tests/integration/fixture/callback_agent/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from . import agent

==== tests/integration/fixture/callback_agent/agent.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from typing import Optional

from google.adk import Agent
from google.adk.agents.callback_context import CallbackContext
from google.adk.agents.invocation_context import InvocationContext
from google.adk.models import LlmRequest
from google.adk.models import LlmResponse
from google.genai import types


def before_agent_call_end_invocation(
    callback_context: CallbackContext,
) -> types.Content:
  return types.Content(
      role='model',
      parts=[types.Part(text='End invocation event before agent call.')],
  )


def before_agent_call(
    invocation_context: InvocationContext,
) -> types.Content:
  return types.Content(
      role='model',
      parts=[types.Part.from_text(text='Plain text event before agent call.')],
  )


def before_model_call_end_invocation(
    callback_context: CallbackContext, llm_request: LlmRequest
) -> LlmResponse:
  return LlmResponse(
      content=types.Content(
          role='model',
          parts=[
              types.Part.from_text(
                  text='End invocation event before model call.'
              )
          ],
      )
  )


def before_model_call(
    invocation_context: InvocationContext, request: LlmRequest
) -> LlmResponse:
  request.config.system_instruction = 'Just return 999 as response.'
  return LlmResponse(
      content=types.Content(
          role='model',
          parts=[
              types.Part.from_text(
                  text='Update request event before model call.'
              )
          ],
      )
  )


def after_model_call(
    callback_context: CallbackContext,
    llm_response: LlmResponse,
) -> Optional[LlmResponse]:
  content = llm_response.content
  if not content or not content.parts or not content.parts[0].text:
    return

  content.parts[0].text += 'Update response event after model call.'
  return llm_response


before_agent_callback_agent = Agent(
    model='gemini-1.5-flash',
    name='before_agent_callback_agent',
    instruction='echo 1',
    before_agent_callback=before_agent_call_end_invocation,
)

before_model_callback_agent = Agent(
    model='gemini-1.5-flash',
    name='before_model_callback_agent',
    instruction='echo 2',
    before_model_callback=before_model_call_end_invocation,
)

after_model_callback_agent = Agent(
    model='gemini-1.5-flash',
    name='after_model_callback_agent',
    instruction='Say hello',
    after_model_callback=after_model_call,
)

==== tests/integration/fixture/tool_agent/files/Agent_test_plan.pdf ====
%PDF-1.4
%
1 0 obj
<</Title (Agent SDK2.0 Testing Plan)
/Producer (Skia/PDF m133 Google Docs Renderer)>>
endobj
3 0 obj
<</ca 1
/BM /Normal>>
endobj
6 0 obj
<</CA 1
/ca 1
/LC 0
/LJ 0
/LW .25
/ML 10
/SA true
/BM /Normal>>
endobj
10 0 obj
<</CA 1
/ca 1
/LC 0
/LJ 0
/LW 1.36437905
/ML 10
/SA true
/BM /Normal>>
endobj
11 0 obj
<</Type /Annot
/Subtype /Link
/F 4
/Border [0 0 0]
/Rect [115.587746 661.3067 176.55225 676.37781]
/A <</Type /Action
/S /URI
/URI (mailto:hangfei@google.com)>>
/StructParent 100000>>
endobj
12 0 obj
<</Type /Annot
/Subtype /Link
/F 4
/Border [0 0 0]
/Rect [179.0444 661.3067 234.78835 676.37781]
/A <</Type /Action
/S /URI
/URI (mailto:cbao@google.com)>>
/StructParent 100001>>
endobj
13 0 obj
<</Filter /FlateDecode
/Length 4745>> stream
x][8r}_&Y,^ &$y ,rJ)QV;}ZbN*^\51/${.*MJ@	\z]T4j4t_7"+EVy&m-U%no}Cloo5^26o)Z>hE`K6\UCmo\<}xy^ ?Hg(y=x_JLUh]Z%g_0:H{G{jU:8<@U00J`/0^Pt}] _I/M:9O?r,ynI,RNt72A.4ObhCtNv	+6=l/OLHLbsFa<kh/$BT};3Nv`a:
>%MbJDqOi GwLG`JR	!$cV>/rF]fC|T@'>B-ha56m>,{WACp*?!P%<l-Lce}@K`C Ld`i:EjKn2;~.C& quTn^Lt7q{teWT0?nS7Mts>LJG	*DT[8n/Sb2)"HC3r^&.qUCy6{CvCp<mnG"U~p9<>7zf2dcQ5
/M|Unr}n1<P*.|{u%?p&Rkb?mcV;P#k *c*4k>]h-h.*7p5-Oo9^rcFXw|z&xp;}7b`q>[S4 K^q$w
$EJd9s3|=nsA\>QB!J\P12uB:R!\avmZG+ Bhz'f*dJ)P\2E-2YFe*zS&r\.Wr2?\
P$!dN$6Jo<%@J2lIU/o(ri7A)*>BF>	1DY2W08Jgv;^{P20CJpFJkjBaw8JE@{hAA}mQI+~}`2y=t07zrJ\-iE
?!Z7J}qp*8b>dSAoL24BY$!Lb}BX/ ~+&Z=G6_.)$&y}U$pLse= {&YC4^)RP{!6yQgf>' 54W&IvCb:9ZE&~p-i}(3gg//.kO)d1Y=BE2[1-r=hWjM[^f m	>iW K' ndyM++$*(Y$+x>
,5HvvptVx\\>-@s&]]|74?+dM\ P&wJAZ{e:n\ Op,'(UbXdSL+qHH.tY3KV)-vKfAXH r4Ty]jZ+L'5fA+C nOV+z"#q,>v}9$j;:<cp6(Z]-M?5/t?;M`&1	'(2D,(|-\7rn$,#Ro=O>2U,}i0mh|U[qp*(|<]a-{"|Tq+q/9o[dGdu{}}/>$ye2JbA.^bi/[h#J^x{fq1T:/Rzo2(xccdtv/HBwU<VGYXqxP&A5
GU$PsU.-@1%-FQ_WJ?k#A19))VPmvU6!H6	`8^6.&NGe'=ELBqty?-9JrNb\RFZ	Xz=1-jQI!To1a *wFTkP?`y@uZ-FcYmK	1"I YFJ 	: j`^>O.4)%LVc  CkZ[Nv3OQ3]8=a">i%\im+NNwX+E!VnW Fk3fg5Lg[vGHNvH\vqMk:bp$m"ae|2"#"j"
FD6:@Yp$	b7,clp:'"^0a:w/|v:cwt`	#Oxali<9-wNVSGjJr~M+9TBz23!~ vh88yI3 DTUBTLVj\}[h99
TK`@U-Zv<o:;F* 2J/N\]YZE^OuqS]nVio[~mKe-Z@v')1N&LCr<:R0awb?Ey7L;MIC_HNRF#xL|V!%& Da``ICfUOD$mYYvUGYS$4DJ2veP{hyT+T-v!'5uQ;<L%{	EU'/-G<P3o"(@w]&`q?j,4%Y&-9if-W-w.93AN(b)->{Ix'' _t<g><Nk}>jP"<)E2/jM]XT avCl#d,B&6RW?&%M^<b65{t%Yb_e`^]~q+$>^+~waZ:vz+)[[&=G{P~84(Yi8eq.FjoH'A mF+)|1|S+g/S%k`I}S>[pSM]2}/emWbQ}R;EZM^2G	EK\/CVWZ~V@J%'&KxxV! 't#W7:F]dM1m[lk[sWqZXr>	l_CUP:9 v_99MKl$_Ck%G({a9?+7{(	A!l_op%F kkWx|{IaZ[=|7`coJ7Y07z0Xz	7 4s9> =[,W?`N^_Y79Htes{}F37[Hy$'jh;^F%ir4 ||;jrL6vw@ Wc.-i72/"jLA2	4F@597?\;MJEtFy>F9N\gw;-&B*snA	78T:q)nC;]XYe=Zyn]NC`9=.oQs3.nZ;26e"*
endstream
endobj
16 0 obj
<</Type /Annot
/Subtype /Link
/F 4
/Border [0 0 0]
/Rect [382.22516 600.42859 436.63699 615.49969]
/A <</Type /Action
/S /URI
/URI (mailto:kech@google.com)>>
/StructParent 100002>>
endobj
17 0 obj
<</Type /Annot
/Subtype /Link
/F 4
/Border [0 0 0]
/Rect [382.22516 524.60608 458.85199 539.67712]
/A <</Type /Action
/S /URI
/URI (mailto:deanchen@google.com)>>
/StructParent 100003>>
endobj
18 0 obj
<</Filter /FlateDecode
/Length 2909>> stream
x[}gXH@c x<A69no; vTy):UPe9L8O$C?_KD#b]	kP$,g]:}NeZ%.iL8pN$>2wL,1buJN3E7U8&YtB.fX?uYy|??^LcV[wWxN1y={}Pfvz1`fdx@|~#{!<<x|ppdIH"8_]:.Ki?|HXy]=ckn^c^V=O'\(JnEp"r*	`MS20x)r&5o phFx0f;k	q|jb~}I1Pe;4; Mg0C`,10Kufe+`+79Z]&Jtv1%4>?yYFg(W\, Th2tc*1Gg {o4}W~QPvz0w9{=%(}W[m'DHt?~3OZOlgh-XW\:+dkx1De?raI6yRe>~kdb-mPlAHl-@-'O]%W)"!+]&XwvDKU\9W=?p]);	X[SbnU`ov`D8\4L#z:?}SDHDk-%:gtn}|wf6
v;
>q/tuXp7{cXfiYupb#LD,)C%IH6&SD!%cA	P:0mE`XM]W=OOoz}$~RBNx:kh0oZWeR~X?xnZF1ANHtw%1inbcA,LNmU~f)f4`bF
H6
619:	NVe5Te[#u<:f9v3H~?c
c}+
z1=^2Wg$[apvZ1Ofld6e%nPO_	`nSYvWG3AY-s	5c7+Mq#ZtD et.X&> C{iqfJ}n<ORsqg%C5Le	,PiSF2F2*nH_3^>'F	4 @%"2CUCcAaW$&Jurs\kRRE=1;W>1
'TwD%Z +^ay9[UH*oL=:6|SmjZhA!#n Xz65U@S>/OT81>x_):J9Y^og\+/&=.6	G2\,gL!`N~VU+^cU(jo$`CkJHo\/,_:W#ieeMV3 ?It"Q,s32uXg,359(\$s`=sNYM/UVL3Kp5ypdd
9<SF&rkQd&PU	f9+e[)r~bLDUKLY.H|8/Kdcq,.f_WH.0A
W\IaduOoyB*9u=W8?``uD]_I\	>We"=
gt.M+]$4<1lo[/tgpek4brt("\lt'V](qr/tqEDs|e>Q}" ,/>Q`	;w*s/#4(tFd>M?scE|D<dDf}1D]{w,\fmo1%Op[Sff*H%"Fk=_	C_J) V.Yc**zGr>z_v0U<nBq,E`m]Pf,Jx#r:X.(F:iV`hJ'9@W9*SQGdHTWy!e4V&Sx[qAt<Ru1]r6rC3 0EPXs	. qs1uJ)mAaWfT9&jp1Cw/Q!zK:TWuB GF2j]}W5^8QAzg=
endstream
endobj
2 0 obj
<</Type /Page
/Resources <</ProcSet [/PDF /Text /ImageB /ImageC /ImageI]
/ExtGState <</G3 3 0 R
/G6 6 0 R
/G10 10 0 R>>
/Font <</F4 4 0 R
/F5 5 0 R
/F7 7 0 R
/F8 8 0 R
/F9 9 0 R>>>>
/MediaBox [0 0 612 792]
/Annots [11 0 R 12 0 R]
/Contents 13 0 R
/StructParents 0
/Tabs /S
/Parent 19 0 R>>
endobj
14 0 obj
<</Type /Page
/Resources <</ProcSet [/PDF /Text /ImageB /ImageC /ImageI]
/ExtGState <</G3 3 0 R
/G6 6 0 R
/G10 10 0 R>>
/Font <</F5 5 0 R
/F8 8 0 R
/F9 9 0 R
/F15 15 0 R>>>>
/MediaBox [0 0 612 792]
/Annots [16 0 R 17 0 R]
/Contents 18 0 R
/StructParents 1
/Tabs /S
/Parent 19 0 R>>
endobj
19 0 obj
<</Type /Pages
/Count 2
/Kids [2 0 R 14 0 R]>>
endobj
20 0 obj
<</h.by0zp5tdp0uu [2 0 R /XYZ 77.324547 721.63831 0]
/h.xso18k2nbgp0 [2 0 R /XYZ 77.324547 649.51544 0]
/h.9gz09yarue6f [2 0 R /XYZ 77.324547 548.43915 0]
/h.81vwhk8bzont [2 0 R /XYZ 77.324547 503.56757 0]
/h.z02bu5ud8ei1 [2 0 R /XYZ 77.324547 466.27859 0]
/h.64ymcro8hg3f [14 0 R /XYZ 77.324547 469.04004 0]>>
endobj
23 0 obj
<</Type /StructElem
/S /H1
/P 22 0 R
/Pg 2 0 R
/K [0]>>
endobj
25 0 obj
<</Type /StructElem
/S /Span
/P 24 0 R
/Pg 2 0 R
/K [1]>>
endobj
27 0 obj
<</Type /StructElem
/S /Span
/P 26 0 R
/Pg 2 0 R
/K [3]>>
endobj
26 0 obj
<</Type /StructElem
/S /Link
/P 24 0 R
/K [27 0 R <</Type /OBJR
/Obj 11 0 R
/Pg 2 0 R>>]>>
endobj
28 0 obj
<</Type /StructElem
/S /Span
/P 24 0 R
/Pg 2 0 R
/K [2]>>
endobj
30 0 obj
<</Type /StructElem
/S /Span
/P 29 0 R
/Pg 2 0 R
/K [4]>>
endobj
29 0 obj
<</Type /StructElem
/S /Link
/P 24 0 R
/K [30 0 R <</Type /OBJR
/Obj 12 0 R
/Pg 2 0 R>>]>>
endobj
24 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/K [25 0 R 26 0 R 28 0 R 29 0 R]>>
endobj
31 0 obj
<</Type /StructElem
/S /H1
/P 22 0 R
/Pg 2 0 R
/K [5]>>
endobj
32 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 2 0 R
/K [6]>>
endobj
33 0 obj
<</Type /StructElem
/S /H1
/P 22 0 R
/Pg 2 0 R
/K [7]>>
endobj
34 0 obj
<</Type /StructElem
/S /H2
/P 22 0 R
/Pg 2 0 R
/K [8]>>
endobj
35 0 obj
<</Type /StructElem
/S /H3
/P 22 0 R
/Pg 2 0 R
/K [9]>>
endobj
36 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 2 0 R
/K [10]>>
endobj
37 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 2 0 R
/K [11]>>
endobj
38 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 2 0 R
/K [12]>>
endobj
39 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 2 0 R
/K [13]>>
endobj
40 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 2 0 R
/K [14]>>
endobj
41 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 2 0 R
/K [15]>>
endobj
42 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 2 0 R
/K [16]>>
endobj
43 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 2 0 R
/K [17]>>
endobj
44 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 2 0 R
/K [18]>>
endobj
45 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 2 0 R
/K [19]>>
endobj
46 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 2 0 R
/K [20]>>
endobj
47 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 2 0 R
/K [21]>>
endobj
48 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 2 0 R
/K [22]>>
endobj
49 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 2 0 R
/K [23]>>
endobj
50 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 2 0 R
/K [24]>>
endobj
51 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 14 0 R
/K [0]>>
endobj
52 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 14 0 R
/K [1]>>
endobj
53 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 14 0 R
/K [2]>>
endobj
55 0 obj
<</Type /StructElem
/S /LI
/P 54 0 R
/Pg 14 0 R
/K [3]>>
endobj
56 0 obj
<</Type /StructElem
/S /LI
/P 54 0 R
/Pg 14 0 R
/K [4]>>
endobj
54 0 obj
<</Type /StructElem
/S /L
/P 22 0 R
/K [55 0 R 56 0 R]>>
endobj
57 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 14 0 R
/K [5]>>
endobj
59 0 obj
<</Type /StructElem
/S /LI
/P 58 0 R
/Pg 14 0 R
/K [6]>>
endobj
60 0 obj
<</Type /StructElem
/S /LI
/P 58 0 R
/Pg 14 0 R
/K [7]>>
endobj
58 0 obj
<</Type /StructElem
/S /L
/P 22 0 R
/K [59 0 R 60 0 R]>>
endobj
63 0 obj
<</Type /StructElem
/S /Span
/P 62 0 R
/Pg 14 0 R
/K [8]>>
endobj
62 0 obj
<</Type /StructElem
/S /Link
/P 61 0 R
/K [63 0 R <</Type /OBJR
/Obj 16 0 R
/Pg 14 0 R>>]>>
endobj
61 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/K [62 0 R]>>
endobj
64 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 14 0 R
/K [9]>>
endobj
65 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 14 0 R
/K [10]>>
endobj
68 0 obj
<</Type /StructElem
/S /Span
/P 67 0 R
/Pg 14 0 R
/K [11]>>
endobj
67 0 obj
<</Type /StructElem
/S /Link
/P 66 0 R
/K [68 0 R <</Type /OBJR
/Obj 17 0 R
/Pg 14 0 R>>]>>
endobj
66 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/K [67 0 R]>>
endobj
69 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 14 0 R
/K [12]>>
endobj
70 0 obj
<</Type /StructElem
/S /H3
/P 22 0 R
/Pg 14 0 R
/K [13]>>
endobj
71 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 14 0 R
/K [14]>>
endobj
72 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 14 0 R
/K [15]>>
endobj
73 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 14 0 R
/K [16]>>
endobj
74 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 14 0 R
/K [17]>>
endobj
75 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 14 0 R
/K [18]>>
endobj
76 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 14 0 R
/K [19]>>
endobj
77 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 14 0 R
/K [20]>>
endobj
78 0 obj
<</Type /StructElem
/S /P
/P 22 0 R
/Pg 14 0 R
/K [21]>>
endobj
22 0 obj
<</Type /StructElem
/S /Document
/P 21 0 R
/K [23 0 R 24 0 R 31 0 R 32 0 R 33 0 R 34 0 R 35 0 R 36 0 R 37 0 R 38 0 R 39 0 R 40 0 R 41 0 R 42 0 R 43 0 R 44 0 R 45 0 R 46 0 R 47 0 R 48 0 R 49 0 R 50 0 R 51 0 R 52 0 R 53 0 R 54 0 R 57 0 R 58 0 R 61 0 R 64 0 R 65 0 R 66 0 R 69 0 R 70 0 R 71 0 R 72 0 R 73 0 R 74 0 R 75 0 R 76 0 R 77 0 R 78 0 R]>>
endobj
79 0 obj
[23 0 R 25 0 R 28 0 R 27 0 R 30 0 R 31 0 R 32 0 R 33 0 R 34 0 R 35 0 R 36 0 R 37 0 R 38 0 R 39 0 R 40 0 R 41 0 R 42 0 R 43 0 R 44 0 R 45 0 R 46 0 R 47 0 R 48 0 R 49 0 R 50 0 R]
endobj
80 0 obj
[51 0 R 52 0 R 53 0 R 55 0 R 56 0 R 57 0 R 59 0 R 60 0 R 63 0 R 64 0 R 65 0 R 68 0 R 69 0 R 70 0 R 71 0 R 72 0 R 73 0 R 74 0 R 75 0 R 76 0 R 77 0 R 78 0 R]
endobj
81 0 obj
<</Type /ParentTree
/Nums [0 79 0 R 1 80 0 R 100000 26 0 R 100001 29 0 R 100002 62 0 R 100003 67 0 R]>>
endobj
21 0 obj
<</Type /StructTreeRoot
/K 22 0 R
/ParentTreeNextKey 2
/ParentTree 81 0 R>>
endobj
82 0 obj
<</Title (Agent SDK2.0 Testing Plan)
/Dest [2 0 R /XYZ 144.882202 715.23541 0]
/Parent 82 0 R
/SE 23 0 R
/Next 83 0 R>>
endobj
83 0 obj
<</Title (Testing Strategy)
/Dest [2 0 R /XYZ 77.711533 631.7179 0]
/Parent 83 0 R
/SE 31 0 R
/Prev 82 0 R
/Next 84 0 R>>
endobj
86 0 obj
<</Title (Current Testing Plan)
/Dest [2 0 R /XYZ 77.84053 455.71652 0]
/Parent 86 0 R
/SE 35 0 R
/Next 87 0 R>>
endobj
87 0 obj
<</Title (Future Testing Plan)
/Dest [14 0 R /XYZ 78.250977 462.31659 0]
/Parent 87 0 R
/SE 70 0 R
/Prev 86 0 R>>
endobj
85 0 obj
<</Title (Integration Tests)
/Dest [2 0 R /XYZ 78.40538 488.55707 0]
/Parent 85 0 R
/SE 34 0 R
/First 86 0 R
/Last 87 0 R
/Count 2>>
endobj
84 0 obj
<</Title (Testing Plan)
/Dest [2 0 R /XYZ 77.711533 530.53601 0]
/Parent 84 0 R
/SE 33 0 R
/Prev 83 0 R
/First 85 0 R
/Last 85 0 R
/Count 3>>
endobj
88 0 obj
<</Type /Outlines
/First 82 0 R
/Last 84 0 R
/Count 6>>
endobj
89 0 obj
<</Type /Catalog
/Pages 19 0 R
/Dests 20 0 R
/MarkInfo <</Type /MarkInfo
/Marked true>>
/StructTreeRoot 21 0 R
/Outlines 88 0 R
/ViewerPreferences <</Type /ViewerPreferences
/DisplayDocTitle true>>
/Lang (en)>>
endobj
90 0 obj
<</Length1 47044
/Filter /FlateDecode
/Length 4449>> stream
x]tTygz"-jHcWZi$BBI=e`a1uH&i^k1q|j`v	4-n;%=3J	0gg@ i]s| <kmzN c[-f@](9eSHO{B4K R&_
d~2>C3OA 8@hoX};d;m1	s+m;nJ=~rj`rXe91$D|BI
SAyI#XQ-7 Zqo-{%8/Ac5oy=/U_-{K*M5*yQA~C|X@Kgg6mz46B+iX| + e@'&& OM$thd7J R:?6A)P\(I<A>>	[jYmHH@xI$G$D"1$S`ZL1 ~f} q/EQA`(4`V")J#GucM0	Us_w5jy <*0$7w""STe"kqYsoePIF-jl]s#)r_VW=2{[-E?m0c(3=oCaj	p~fX>07#9mKq]0mPols~m=3[V-E&aaKprlDklF6|?AL&]F5M{lhjlt|GL}d)S0=rn,7<6E`^\Mhh;S3>8d|9=0!szGx<=Z%~YZ,6JQUSbLuez,-^ul`:/-Ui6S=P{oS'xOK<OyzS`0,o(zDMSQjJ,{n3sF~	zL%Sd;i&%$h8'	"w1zs\EdYVFr\9ETY_?uGf+nF}NY,ouR:(RQJ%R:0tG{*uYn	(>m8Ji@R?#f9YX:>1.!<#<{c<<rG{xTi4PcC$wltfXY FLCqQ	0= gX<f4z$tJ%UI%'TrJ,lT1*SU^%TV%dJNS*YRU2UD%[Urd?}Spo5/()G)?%IzXm'WXG< \HQN=|/DWY<Tc4q%qktE|Kky}2DErtE^FN]6/<^{3]voYwe+k]YZ>=n*7slR}e)"|gwyjueE97_~*rJ~O5$(_Z>/-N9GbU6_b6YwXb54raQ*3:9w},$yn|g-9Q>"2=Y+S1IKk~dfEk_>f_Cc|~='-{_osx?/FUPK|_7*`gB!r=tNN4FBPn:
oL/"]bfi7;q
UMD?A|QCr;RE?^$.bLM?|:+<4kMS&<bwYd2<;TSG65=52zrpb','~Kg/$Lt}S}yvxlG55,;
tmjD%z`]Zp@/\lMI,	v2o[h{ktrGs}M*m*dUWbsk=e}eoNf[f1|N_
[U+Nnqo	kC.rD.# [pbbbv;Mq"Jvn^SjKnom3Vc9UMN{IvaW[

MelE8eO$}):ql!V_l45hxp>Al)d+
J-|EW^`Co!]w0^Oanzk~+*!^;7tv4]akdxk{55^'i|I^OZ^^ZAaJs1=jj{l'(g40vivm,#wHU[Mq[~?>xy|GX\=kScM$g7gyCAsA]v]
ZCBJI`k}yyu@*-]Pwmnru\k/jp6!PgZ
ii\i?CWKH.\!a|:T4OhOO2~]QgiN:=|EcN45X_+&] JhF (cmOA7$p=MYp/kw]v=Vx=UU^ojG!87`'8Vkybs<\P'hvK]T(J(vm.qg+-9WT
cdWm+]#]N/?%,Z%3=MH}A@[o&ogs.[KI_eq-%k<559e$@_wjd0>A-4-5gRyfa5dR5O4&Y4/Z`zi+0gv>tftg?)O3} Kxy`^o5SC8c;Jc6F/\7Kwp.u#[?UWV9-mo--io3u|::m]`pa0a]vnItjnZ:iJh++Iyb,besW~*QN#Vu&h+p_L;3233]L7weh;#%v^SY|'/i;P~!^.+n[od>bV4$~B>?X 5*<Gn eJJKx?on~OPP%(((dz'((8O']/









|FPPPP:|UP/*/((((x2"(x=j-7vN/2H>~smeA_e^>z,5ook~{/^ZlWHn5Um~[#Pq Q6{V
;dL9>6A`Awm=q3t>q.8
1^i`|W[E@@@@@@@@@CJ   {v}Ndt$X
endstream
endobj
91 0 obj
<</Type /FontDescriptor
/FontName /AAAAAA+GoogleSans-Regular
/Flags 4
/Ascent 966
/Descent -286
/StemV 94
/CapHeight 716
/ItalicAngle 0
/FontBBox [-978 -989 3284 1263]
/FontFile2 90 0 R>>
endobj
92 0 obj
<</Type /Font
/FontDescriptor 91 0 R
/BaseFont /AAAAAA+GoogleSans-Regular
/Subtype /CIDFontType2
/CIDToGIDMap /Identity
/CIDSystemInfo <</Registry (Adobe)
/Ordering (Identity)
/Supplement 0>>
/W [0 [580 670] 34 [701] 79 [627] 119 [574] 126 [555] 132 [530] 177 [531] 213 [561] 233 [595] 265 [559] 299 [370 0 0 0 471] 310 [364] 341 [508] 934 [643 0 524] 1041 [236] 1111 [232]]
/DW 209>>
endobj
93 0 obj
<</Filter /FlateDecode
/Length 349>> stream
x]n0<E"	Z	!8C i(o`vj lmc',Ci05\B2Ba4MdcjZse|:0#A3Zl]joi5{jpBqr0/9.MS9>X3II#'=R"%H!mb")(A:nRI Z"HrJ","RDX]$T/|'aXPuOr2i^BQe]+(a)g2?s~pn[h{;q
endstream
endobj
4 0 obj
<</Type /Font
/Subtype /Type0
/BaseFont /AAAAAA+GoogleSans-Regular
/Encoding /Identity-H
/DescendantFonts [92 0 R]
/ToUnicode 93 0 R>>
endobj
94 0 obj
<</Length1 57760
/Filter /FlateDecode
/Length 9707>> stream
x=	x[3=mY,)[d,Yl;>Cq!8Jvmh(KiBn!@`C-I7de3Izep(y3y0BHPc!v?BxmcG{*kRB(k[)t8,P1Stjxu|pogFwO~?~l/B'GeP(BFs=wt|zC98c;*L	&O&C}#0wh({zn+r)_5sWpWP{l@qX@,LQ4Bq'+i]?!%/^ O;_W9x#FhH|aH>Qv.#@#2<mi sH% %
D2}9NDh4#U[>=83@RfpI&AxaFCHe,mMC9,Q1rJZQ;@mBhkC@I%E-qB)Q!R0P%rNu
}
B9s":7y4Xcpv\KWv=x{Q&A>qp Jm2<A%rC3!OC~]
x[!\33SV@LyZ@ h }$)b~Ld~J< F!a L@zy!,%z*\!B*Q*~}D{Ho&!r*!@42[>,+43>LaOqB:~3FhmG[amCCC7F'!M&rv@	.xA{ w)5'm)r*rPB`r~ 6k
lZ4S5-xu7@yH&!5M+`Pc2

QJb/&Y*|A=xfpj|lpboz`jl=C)l	t)<ct|
Do4is|l~sdQ}mztE`dhG**jQsc  -=&h72m]&D<E9E9(D2cm;A#+1Q4F^OS{~9i>XJhUPAKTBI@/I(77-%otH=}:8/^`OMe `W,|"b{sGzXE&C'}6JM3{*/
^'/@x/:/OEMe^z^$#.k	CI;h_c|3R`'#`$QK-'><4x
4z7#N KI@[?	6k3x+Lx7g
BIm<p70A,?-h4F2C4>Gi&\&yPxFDsd[hi>T9;#'{F@2Xq.2Iuduk ;QKhgO1>g<\d)|''RD{'tOw_tG)&%I.oR~Ix7aD)_/8*AQiUUJr)?FyXyQ5P)eJ2NOspb*t.tUL2ffK}>%?I=CK=#{.7P|%{^/^y#A@}s%78xhp1[_p:N|6zG}SEDQZ+JkDQZ-Jqt(3Di(#J+EQZ!JEi(m9Q(J(D$Q(,JmwO?T(((\CS%h$Ks+BB	+&&R_ $kiXcKx	RN*?<,J):*Ge!#r*3=&wT<]*qZ{^ud7o &M (P9T`#4
z zXBIx	ccs/#HW:</<k*a`]RDUq~w<i/k<}b;)r",;r??/RuEuo/o0_dE9*PD%@1JFsH= j6gw6@=v|8'.<w;Tz+@zX|qfl7,PQWVcpramp =Rr`iBNu98*41Mt((rJC)(RVC` yVcd@.3	`O*9n{VV.j=-9;:o^&vj]+r&f}`NQJ]I7[[7B+jiw>I!GdoH(ZRJkM/XiTk@Gid(LH\xBIAD%vt }
]KZyO<#nIV ^ob$C%z/{x'z/@W.U
k-B&_%dK"5FM1jY%]t&5UO~:\bxN,J[@VrV{Vseg(r^g`iEbt{*V*^^zypt	S#xZqxBdEQn/I<tq|h|'6YqR/R`gEky>(;.DC[|ZBIka@}9/Ux>UsQy"Z	|oT=PN-go('ay)C)2H>7\L9")Qo*7,ASiJS{$x0}k0G"I( 'o%[>5_=JO	^x	zl:-Jj4#/FKZ?hw P%i"K0Z8j	RK@-ZXj	c%9mK@-\2zI.STjqTR1T:T:r*PP)<}Y"(* C<i5Udi.85si+h'y.8W0	Pzb"9pwp.[4&8.+JB)KgD}s"#9)F!90>nx4If~'tHZDO15fk- 7x+_e1_z1Z]
2d	Xk6<?=m3 hz039Y$Wi$7nqYf6`\S^Rq^fU+p'qo]n4g_Tddzs4
bhBrwqE1cI0XAyC7umW_0ngoT]8<TTeZPSeR-H{Os9l''kz9\Y{p``0'gml,D -(n~w2:g_~h	+_=./ Hx4xa}R&lw6_ZO"bifruE>C@qI!^[3^nMokOX"m^]"R.Ee!zTv')B5Aw6~V9\q9[M*3`x6pB5*964JPOKUlF8#xtH-Vy:`+wozwGv_v~si3|(3UFfjS=]lYC&K'P6][WonpeV2[jcsTW[)dxrDMlV}QVzL59][2piv7xsE'B%	,\:zW4~?qxnwg7\:!dySj?EiA]Z{+masQ 3^r2w
 Xw\urwtuwlH'-55nyWM#S\5u3RJ&3ZU@C.AltA+SS_vc
"R_?U_?jczacdso O";L0Fkn" ^WZ* IYU5Ro-6AUYovdLl~99?pu&Wh/#A'tm6.(nmu"\g/]556Mj70^hL6\\V2P/)A4q A[Z\oM."yuIMm7RGUYly
KesD2dXf*I83QnxFR)/m<7VxROc
z[.,{-U&T6g9	C7lPiomm3WFXC	[V9ga)jsr`D2wg#vCE\_[ul,j-[Wl]`rd9.({z{//P*&HHkFA{9V vMe* yQC"&I-0Sf2zL5"fLNlln^0	:c)*SZyEiyaqw}6RRPZz,[{21i)Gq>A[tSyJG+/3~Uxb++Sm^Bl1k4WW5+VWjaw-	OZk.-|o%9e-ZI~m|Xtvv:4MW^|Em|<[j| dxj6uFwFUCz=#2Z'Zknx-W`W`F,EHK"rChT0.vWlX9;QTgRc5oL^7oxol\BN`%VE5dE3[c8*Vjlv^cYa)vZ-*"xXcL&Nq4X8wb] sg4Q%x^h7'	5JPV2sV3	 :%bw'[XvhM3[~;t47'A%_#t^*
ep6Xo6x-
ly%<Msy>1`t.f	1*\ct^	P>2YiI+foY~7G~9CET41d67/$UWW]U1+8Y6gi2eW=?mn9xU|LdlN1{t]S~~f7jj]WfKv}aF9/P^M%Mv{SIqv*C>*@)~c2-SV|W_GC}m[5ThkrTbgq!LzezGfaNpbm5doRx|K _<Yf7#mK
muPevhHD[2a.Eo6s59M.1o0#lO\uf#H4VuX"*?uu#v{{
]W7uEQ9/>Fd6m[bC+*{z*+5TTxCn'A!d+l.0}wp~Yydx8_ePsl}!YKLU6KyMUQ19-
f|W0<Tw92+5Vx
lOIxA[:]RfrV3C*o(3&5;2=4SI9<=/]UXK2o'+W
9	i$':C9*<g>hGfsl^4YZ);Pz%>oD3v7G xP' mn?0=?GQYKs2m)%9Wm(0yS
w'eK,a29S)(gpUL9l99nzN~<_+j6k!1ALtyE]g-UaJ5{	bEo
<sGrG/:MX[R-4_sF]r+_W/|&6hU8DZ7iL8Cr,Yt$XlqC>JH)GQf'tn?.fF~rig.(ee+2Fa=\gy[9B7?CZpFzX/k@bf&HI/S'!x(cN}iEkoUMT=O't[\m9v1_.V*'B- t|M-[WS:Nth\Cj{fMz&GV(1n9_sbmMnC?D-:E4AoB'Du?5+O#lvub{B.KJ#xq4Ms7Aykk<#}tqKIx;i~G;Ov&Fm!q_9;ADH}=HuAX/Bqz1re\wjR=~d;+WUT@	zGj>AjC|-t;l9]gT/b,*gA-s1ldq(`wYM6_vQRUiS6#&P.a	Ec\pMmBkr<^`-8YZf9%d)7K:(BEuB-s:Q&L=KH*Cz$XR=>:9Q%5j[(kmUiKOZmnH/r'D,.v"[U)AKvt$&^nMyvI(nox}DDzy\?KB\<.1pEw/z0D?-5pm|y<-p>}o{>Y6Fs|\7? q[mm??'!'"
6	=>#G,8!g|}c<_8]O0dD\0(>{e0r@xaa<\?*cfe_Kyo(q4lPB	%K1*hjUUjWT?U`nl] o}(s~	?^n	%P7)~=O>w> !'/yAI(J(J(uKu0!W	%PB	%8pSwER%piECsXB	%mi^i3$PB	%GKQWhoPBTN}J,H,OI8 sr~_ +{]}NiSucbv;Kgh0hQ@%]Ky?P!{u3:x tG3=2dd8i.~>J/nKS._&Y+:eGGE~q"w 9)1XwJ;QAFw^?~(gP}KE	$@	$?\L*dwLt5?x@['/Ikb(^wR&3BK<|!D{F	$2QM}TH H @Pb|m,	.-8SQzp7tIXbJ |T@}DZ^"|?&;H H H H H H _@	$@	$Dy\r9
{KMH	P$$H XXYe9/5YH H H GB8
C@7\j$@rxe'!qKA
@G!1=x7 ~ P
endstream
endobj
95 0 obj
<</Type /FontDescriptor
/FontName /AAAAAA+GoogleSans-Regular
/Flags 4
/Ascent 966
/Descent -286
/StemV 94
/CapHeight 716
/ItalicAngle 0
/FontBBox [-978 -989 3284 1263]
/FontFile2 94 0 R>>
endobj
96 0 obj
<</Type /Font
/FontDescriptor 95 0 R
/BaseFont /AAAAAA+GoogleSans-Regular
/Subtype /CIDFontType2
/CIDToGIDMap /Identity
/CIDSystemInfo <</Registry (Adobe)
/Ordering (Identity)
/Supplement 0>>
/W [0 [580 670] 28 [736] 34 [701 0 0 0 544] 56 [529 806] 62 [696 0 0 243] 79 [627 0 505] 88 [706] 119 [574] 126 [555] 132 [530] 137 [667] 157 [944] 177 [531] 203 [540] 213 [561] 232 [362 595] 238 [562] 241 253 209 256 [504 0 0 209] 264 [873 559] 271 [594] 299 [370 0 0 0 471] 310 [364] 315 [559] 334 [508 775] 340 [473 508] 358 [682] 367 370 585 934 [643 430 524 533] 1041 1043 236 1072 1073 321 1078 [439] 1083 [476] 1111 [232]]
/DW 600>>
endobj
97 0 obj
<</Filter /FlateDecode
/Length 497>> stream
x]0E|=~a!Rd8 ,m:@:.WuWqXXM.4:<%}K;Gw>m;{+hEO[7g<x>^09G?e1{o}L^6rl'nSu]k$%H(!R5(#oj@;$JP( LQAm@@)TWW% `	;ALS$pv *A8i$Nrl)A(,i^)/t,APHdBtZ!<I+U{6Q%%SSMQyYp0Ycg	QZ<,V(<jL 4=	:#^PRPxEMUsXs~N@0ck}?
endstream
endobj
5 0 obj
<</Type /Font
/Subtype /Type0
/BaseFont /AAAAAA+GoogleSans-Regular
/Encoding /Identity-H
/DescendantFonts [96 0 R]
/ToUnicode 97 0 R>>
endobj
98 0 obj
<</Length1 43252
/Filter /FlateDecode
/Length 2407>> stream
xkL%\L&)1@b 8;$8beJjt7eQ?KRiE6uHk2eZ-RR{9R-9| 4(w\.)*4= SG  kv[^4}??6>X(^TW1B?{hb2	KXEA|]$\2N*< ?O.]) {RJ#Uc8[qlCj/$0]>#byWY(Y`4cPTrnyWfy>cRn?|1ptQ_.z
]^+?9VcVRR*\%rX~S0[Xz`l72s0%wv>F7wTOQK(+(C1xb`Zp0mf#J|dZ4_v8I20g@IJ@ILNIlW&x}X9i<aT!U|S%Jm030I+t=}:qxu.caiQW]a94sX<Txp22/$d:#3X>%sSXy1c<83sXNh'#!3{YA%?gA+"L?gc@)W}36=+Y
m%X9}1T	\2c+lQ.7I<($88l		I7h[F9X&tKC8a%Gmq>}p:6q#y >Weq80-8>~T?zc[$*htWNaK}cH}]Yo6ZTSxKfL	}^C~r}QRcw-_{Q]wRJlJBZ-Q|Xg.qOK(6#nhZ)R9UbNU{TC?yOw"};wwy??U!_d-G)Wm^%;S!Fe=<j5e5A%Q[4sa;he	^{w1WO/>.`+SjHjsf1=fue&D:n;[;jX7iXw0T7VLnjh	'R	zbVW+pR>pWfh=?c,cY:>fAKytpjX{kwsZ.I6Pt9jM,_x=';j{VVU*G<&gjk:NuN/3[&]<R~ZuPWg2X*%I'YeR:K(NOx6;:ScAj1Ja3P[7/>S1b:|1tw)dSDWeaswuEcfglD~~`C`}l5{fj7/>8Q[rZG^kC<4w3s}g2ZF|2h[~W<3^j}rMux[`Y+JWy"u{pd.<R~V_?`+K~xV?l3zE9{re|"i\O/u9_H$D"=4$D"H$D"H$D"H$D"H$D"0z&> E*vGF"sCj|LvY";0|l#    Af!>AAAAAAAAAAAAAAAAAAA=:jq
endstream
endobj
99 0 obj
<</Type /FontDescriptor
/FontName /AAAAAA+GoogleSans-Regular
/Flags 4
/Ascent 966
/Descent -286
/StemV 94
/CapHeight 716
/ItalicAngle 0
/FontBBox [-978 -989 3284 1263]
/FontFile2 98 0 R>>
endobj
100 0 obj
<</Type /Font
/FontDescriptor 99 0 R
/BaseFont /AAAAAA+GoogleSans-Regular
/Subtype /CIDFontType2
/CIDToGIDMap /Identity
/CIDSystemInfo <</Registry (Adobe)
/Ordering (Identity)
/Supplement 0>>
/W [0 [580] 65 [243] 132 [530] 177 [531] 213 [561] 233 [595] 265 [559] 271 [594] 299 [370 0 0 0 471] 310 [364] 1111 [232]]
/DW 209>>
endobj
101 0 obj
<</Filter /FlateDecode
/Length 310>> stream
x]n0~
C0C=skbFyLtlNFf-XK%LpJE
Bx$r<Y,)>:Y3/Dw#Huci(KcRUT@2vFm.5k)rIwL@[%tw3=K+OR!S(G:HYx@5Rz@*@A+vH;gyxC	[:cwC+Z\okQ~
endstream
endobj
7 0 obj
<</Type /Font
/Subtype /Type0
/BaseFont /AAAAAA+GoogleSans-Regular
/Encoding /Identity-H
/DescendantFonts [100 0 R]
/ToUnicode 101 0 R>>
endobj
102 0 obj
<</Length1 43596
/Filter /FlateDecode
/Length 2688>> stream
x]{l?~~%v;/'!BQ 0v8@umi*N&mcG6mPiNNv`]sXK={9| @
 'C}$4 ;m&@y	H'ZW~&"3y=z?O]lgNOG#q1Q++l+CAu1@ b?n"rhL~5["h}Qezfzv.6x@$3qc?WXT_.t
	Y	1uZ+1[y9knkw7T+\E@y`W<;Ud'g!X@7[da0J lOa+XhSE&}zR 93]cD,n >1L/s2|v [>8V#4#<d8I$7dplsXnag~lXV[E=a*3@b00wX2V5'81GC0G)*|Y9Z>I\xSwf8I&TN=QD,:$jbAD<&f22mLxaO\txKY`YE`*RjS'+<ss
DT9(br2GYY VyFV^jYYKHF6bfeXp|^
'$aEl8EQwXsN[`#hiduQEf6:{Im ~m h?\kV^RcvS^-]u8>XPZ:g @5YLvZfZ .2YKjs^&RTs29lshA2#R>/M.-ot.2EeRKE*i5w^Z*eTc3Y?7j"].].j}5W]+ZA/xDq7t2>wvGF?5S(eOwlxy.UfZ-3qkeZw['u\g@aL%V8[d-[az:}BZk^T
h0SIg?mn>njnxt'Xu\}:<Teu2l83ohm[}EjS?3W38OkDX
f+~_a/~Zagb	8=vy!";q4uJnxl sP52fAI1|>8^=m\NC`?8.Y_lht(i[Kv~k*F7z8?0zgUF}Dc^6-.Ov76{l}m^9m c/F'I.0>x}"<e-Dgg+T5*#-vopp241w@huh{h
6O0sjJpCA16WVl6JqCeJ^<m9cTyFBi5f(V5:+YOlOZR="JrKV;KmmVwtW=\Uv
|1Nx%/L_hR0`h[[ty[;Co_k8%kL9.QnX,~WF0P|kE/xoG&`JIiSc,:3YR=0_NAyw'8l2b}CQM:__r]*]NUO{5N<phAo_CkG^		9vWy|puXo!_UW.pH$D"SD"H$D"H$D"H$D"H$D"Hy_/	Wtg;J0_n'x1n?|{o]w,[0vrz;w@ @M@n@ @ @ @ @ @ @ @ @ @ ]8=/J=
endstream
endobj
103 0 obj
<</Type /FontDescriptor
/FontName /AAAAAA+GoogleSans-Regular
/Flags 4
/Ascent 966
/Descent -286
/StemV 94
/CapHeight 716
/ItalicAngle 0
/FontBBox [-978 -989 3284 1263]
/FontFile2 102 0 R>>
endobj
104 0 obj
<</Type /Font
/FontDescriptor 103 0 R
/BaseFont /AAAAAA+GoogleSans-Regular
/Subtype /CIDFontType2
/CIDToGIDMap /Identity
/CIDSystemInfo <</Registry (Adobe)
/Ordering (Identity)
/Supplement 0>>
/W [0 [580] 28 [736] 56 [529] 119 [574] 132 [530] 177 [531] 213 [561] 233 [595] 265 [559] 299 [370 0 0 0 471] 310 [364] 315 [559] 1111 [232]]
/DW 209>>
endobj
105 0 obj
<</Filter /FlateDecode
/Length 325>> stream
x]0 OcP4D<kl2v5|M&bd&8U}eoHG!]/ik
^4&f <jAQ~l^x t/od]5]_@eItvV6qMm(`R-EdGIe R<];jN+EiR:%;/sTvW:PcN{u^"N4J*%<:{hR%K38J)1VLL7)]>E_`o\Wz	F ;
endstream
endobj
8 0 obj
<</Type /Font
/Subtype /Type0
/BaseFont /AAAAAA+GoogleSans-Regular
/Encoding /Identity-H
/DescendantFonts [104 0 R]
/ToUnicode 105 0 R>>
endobj
106 0 obj
<</Length1 45204
/Filter /FlateDecode
/Length 3742>> stream
x]{lu?~|IzEK/RDM(Q,5V$[)D)dqCEbf2-X:di?:X[[`[&w%%Q~ikz{=s)   B0/((. ]Y@zqx+7~ml_ W"\,~?t8p2~q~razIK5zc??j7zo.:}5|~{p UH ' :Rp~97M~D{siqy%y.|)]S}_(] $c%AC^Rq&	/y32P:i/'/sAsMi*
Cw(9&@$2 oVS)fBOL3P| PK`mvnH	+0*	I~goZSR1mwgu>Ak	bz	C9@5H/#	$Hn!	A"	,e>%a".,e'd4}"qMou)Fyb4LI,yXUY,dR>Q/%(|il9Z?V/EmS }ak:,Y7l<Ssb3qGbs8~vn!E3+WP^Y9Zc{ene,6@<#;=4zvx/g8UfD0& I)[	<g|??	)WEN<~<vn'{Z3],lO-J	Y:mM%RmVKU`mFhK;MzYqw/$.C-r
~[ac{$fcFU|2cGws8 X6[V5 Y[eh^Gq9jBK/c'L@;Vi###s,ed~ -yuj3{yw02!#c;y/5p]wBP~Ks8l4Q,$ByVQ\sPc<;|o,o']Bv6#`rl61[[Jl<O+xVV*2V*JWRU|HV@Y[x3mw,er1S%7o((Ce7TNv*/3V5WC[u?cv>7qu^HhF
G[XOK!?;gYS1;q8VVro3po7R/=niZUP5F4:M|@oQG]zeCI=->j'U*]^(}\D./w/v'j;MLX%j:EWRvl|L$JN3[G/gQ
+E gjl<jh[[Ky>JmK?cQ4=]XoFc|^m	QXyCii}Q	}lB[6}Ib+K[+:LsgY`y+G^'\d+/E}UM	oS/rK:Rhn4O_xt}>$Y~Oyxe!Vy*:roShCY
c*k4Fyo~0LNTN~D<S5++=r:x3ox5NW6;r}^KPw~us6BVQ_iUOUY0?xhFn[o69XT&5HfZ72.5r>:?2Qp}^Qj6#p[:A?nE=W]C}:(IQhnXl_xA9Y`195-==k.Yxd=x6nju5o!\G#r->>04[7a[cUgl7fe~2?R5Spb@ve$zyS\.g"KtqZ62R2gSc845u 	.~,mT^<
mnBjVnAbu2;=GtO.tEuYHFoga>j2Kglh YK;9D}F^g&RZ7TzmB)[-[.kogypI\Qp88l&[XZXT.,mso]r#vi'	0x0<Si[<io"Z:HPR5x`vD0yG^k""e{d@Qk_9z;[RYb9:)Q-goyM|OuGdV&55&`"w9zl#o
hqtXu	F	;]AOw@lIs.#)oJz8>*}55}^jCkjntO~|hW%.M_I)dQqNNIZu^P'l
PF0t"G/:}fb{*g^?&1/<Wp
k%S;8ywK|w_F~&IQmOso0SBE)8in~	_nOs33	





































; o;[yoGIOi?9B~A[?>4dOGH*HW?;]W3(}:u(yH8t>Y(2{7PK{Go?lSOdg7 uuow\;
endstream
endobj
107 0 obj
<</Type /FontDescriptor
/FontName /BAAAAA+GoogleSans-Bold
/Flags 4
/Ascent 966
/Descent -286
/StemV 141
/CapHeight 716
/ItalicAngle 0
/FontBBox [-1012 -1027 3284 1319]
/FontFile2 106 0 R>>
endobj
108 0 obj
<</Type /Font
/FontDescriptor 107 0 R
/BaseFont /BAAAAA+GoogleSans-Bold
/Subtype /CIDFontType2
/CIDToGIDMap /Identity
/CIDSystemInfo <</Registry (Adobe)
/Ordering (Identity)
/Supplement 0>>
/W [0 [590] 28 [745] 34 [736] 94 [838] 119 [608] 126 [582] 132 [579] 177 [560] 203 [567] 213 [584] 233 [622] 265 [597] 271 [613] 296 [628 0 0 421 0 0 0 503] 310 [415] 315 [597] 1111 [234]]
/DW 257>>
endobj
109 0 obj
<</Filter /FlateDecode
/Length 322>> stream
x]j0{"E1I j+x 69v!~9
?r&$.smnTv0w]HH{5Z>,Cm1s?;nag=^)|ws03QQ0Kk_Xm|?/[\,05jlQ(X^QD`y)vwB(}9Be*$K)wHH;	^*))E]Uc;RIZ+/;8$*3\]V^Or<V?}nW6t5
endstream
endobj
9 0 obj
<</Type /Font
/Subtype /Type0
/BaseFont /BAAAAA+GoogleSans-Bold
/Encoding /Identity-H
/DescendantFonts [108 0 R]
/ToUnicode 109 0 R>>
endobj
110 0 obj
<</Length1 24180
/Filter /FlateDecode
/Length 6304>> stream
xxEU=$@.$d: j\A# `EI\"/0BDqYd]**8AVUx 7>|9:UuL5 3aAQ%b`>zW3|rnOxo4 YIc*u5s(d5OU\^?c+K|.uQP$D}9cm`iu,>yo>FVOoNW`qL'tb7{^Mss7/vd^\o;%sjrkXgb=F}Ccv1wa$ t6m#'YD.&<+y^F?#F!`:.F7<Fn/kiPku+NuvPJ-}j/)2Noact(9^=S)s^8'c?k}enPR*.Y!`Ox,P3[_o'E>ei4/qq`{A2f,n4bKH4s.jkd[cdc,\BD'l-X^AF(|D5fc*jo`<wopw5kyX%03;TC55iW}GP9:V|Ya_f:5zo0f9`	#|Hv>d?~lm3z#S)	x;86["Qp-FF,Ys<Q1d}+?eT{{	b;D	a:ZOz9EBL01
^(F{o1:MmG'/amQA"i WqbbH$k"r+2lv1H)}/bz6<wDgOR~X6HBe<<pyhkkZ?>3.Ky,S^+{c<n"Wd9OcU3.ldoy{[w;AVe*u-y1GC8Q'7;^q@|,dBT+-<&X,`q[esm}7`r6+k~	x"]LX*nq^cR|''m2E<rJw<OJCR)#2QQK7~ynn>j}zm-|?nCmm[|.Rk?9_n"S83S,qX^lc\,)Nr12s_9H<.Jy\+CbWXR.Uje)(+yHdYFYZZ|d:C[m[<{>~}}s7vurDydOz*7:U.8ep_Wr2F	%[u<de7NXvhTEY@e+,YxG9"{%R$!iK]x\R\'d	9Vs_,a\y;cy1W`8~+[8x%([f#<u-U$gZeg0n)k\/.U6NSoa/~2r:^	7J}9X+-P$dXZU,L1LaL{;@2%I\9q]Ldv	WL>0V[``?;Elq>l+(OaqT9Q-'/g;C$<g&Fjw`.he],R{tD>cgk5^5JmLgMP%,a	KX%7-XQ<hrdge#]uuOMK8glf(R ]Zj*qc,>JSYTGSL7Oo{S8Umo[*i\	cvt$RKEu%Ul)*]T(QDw}H!K5I8b8(DKv#Zt_N&j4,Ef7H3MjS'UeEOwOR)>,[%^AY6_Ty)JcIL66j<66x(j,e9eT&W*5]WZwQR5K"YU55_EoELqSq-^5}MNv3.8MbCFtF:2lpAhjTyMCAcQ|giyGfjEUaFqfp/>iP-%X'gZVi,{)od/
H2s[OO7nM/1U*4dQLMFL\[aW9L\R7L	KumllJ*4er!gBRI!K(f-F2Zdf.,j/2=<)22OS>?]_e#q; p2]-0Of!R4/pSBbRRZXX"6TY8}M)ZjNC!Q+5y	+[Y
YTUk(5
jdP&xaxYk1|M@,s)	`Ld%X51bLQE|$}9@*[<I;>hJOsVwWK<(-]br}TyT%NrOLI=@QRQ7R[dkUqS\XTF3JQQwRO5^%y =&32kvf\jf\cnn^4>#o1y
^d^O
b=JWhTB%^%~KOOBt]h+<xgDF).oc6SwRyQyd1HFN~IM8<X>r#S;'v>aJ%c;ph7bY!2SBF|B^@m(4WSJc9+$5
[,=AhTdRUz!ZJQH'U{PK-:fv=OE3}E`/%iL\(b=xi.[z8s"s#cSk6Shg#Oal'f s;q<ElT7zfxnYKx^Ng"Z<g2<
ZD@d^cjAtg*UZo?^Z_*_&Y*iN_x&	L#SU103R`<tLgtt~ntR{|ay
F<q7onZxvsf#@,9:zSm1KRGRRQORmpNR%XnhcGtLuf9G+kRElHH >1DD[t5i+ no<**4W
`:f~RF:QyxZl']t26'I\ohvGrpd' lWM!YHK"V\7535Nsy6\#^sqYA3jvN388 JXy<{=w8NG'G#pt%zo/mvJFuVdBQA4Uj; "[_BmHVYgiT6	q\O){A[qs^qE#F--T$k&Tjtiywi0^ZTIqH|-JdQ|e1*>WTGZoC//"_FDg_SC=MDOCzdd>	~1}$-tIMKZ"!tILI?\VuYe}R>1g|bZJmaV2W3xrR%iiTyiusk5bibTw7aJIEeomqpwuol_rF_L`z`F_`&
}Z+LpwxzlB_yC5r
r
*>SFU':Ttxzv)TdqY6,DROEdV/	J\ (2'i#mYZe\6LYTT	,f*YGlQr_J/"ib|VV!
*B02>|%vVy|F,YXJg3SrV:;c!
aUQ63i.|(hD1!;E'X283.Lv%CJ&DL;TB!U[_*~PI7z"@C~^pi2d$sECyK@.9 ?9!CM r8<|!GbF`8Yd9q>Y|#S/9($/4Y""cP&bY8\&'Be	LrKp1YLo0L /EyUDVrGNd!/0YKLPE
QM4E9d=J1l0 u3EE^E~\9K^cZ#C=W`I?X@uE&W*nbF,!Wjr7:&f,%o2r=~K?z+#Vv*r7wa5'wr#V^}c-g|  nCXOnM>GqI>fqEnHwM;hFr!>m<3d$|
xXO;(!g8Cx<7|[x	[=x|W$rZ&`;*viuNx|;C7Mg||0xICqC%}G8&??&O $$Oo_m_x/_=e|qoq<V;%7/:>$1}LWoO~!/~ob_~'11$1(pL_>i1b:/G98ka(bGtDDt8#&2t(q 6**|_:D/N"c\X:DsN$
]N$1H7eaP.]mYX:8}`5).CIg''K.HME
KdYX:$ml$y.,Hp^>kLX:cXv%nt(!C3,Jr0!?HO#,%SJJnq2c%#	

endstream
endobj
111 0 obj
<</Type /FontDescriptor
/FontName /CAAAAA+ArialMT
/Flags 4
/Ascent 905.27344
/Descent -211.91406
/StemV 45.898438
/CapHeight 715.82031
/ItalicAngle 0
/FontBBox [-664.55078 -324.70703 2000 1005.85938]
/FontFile2 110 0 R>>
endobj
112 0 obj
<</Type /Font
/FontDescriptor 111 0 R
/BaseFont /CAAAAA+ArialMT
/Subtype /CIDFontType2
/CIDToGIDMap /Identity
/CIDSystemInfo <</Registry (Adobe)
/Ordering (Identity)
/Supplement 0>>
/W [3 [277.83203] 404 [604.00391]]
/DW 750>>
endobj
113 0 obj
<</Filter /FlateDecode
/Length 234>> stream
x]j >,om Bi$cyrP83.Oar&\`U8f\z? kN;md19?H[? R`qI/:W[s|AViLFm0i?#kJ1__8oBHH5w}wWRF4[J*b*Wr
endstream
endobj
15 0 obj
<</Type /Font
/Subtype /Type0
/BaseFont /CAAAAA+ArialMT
/Encoding /Identity-H
/DescendantFonts [112 0 R]
/ToUnicode 113 0 R>>
endobj
xref
0 114
0000000000 65535 f 
0000000015 00000 n 
0000008910 00000 n 
0000000116 00000 n 
0000021749 00000 n 
0000033113 00000 n 
0000000153 00000 n 
0000036685 00000 n 
0000040578 00000 n 
0000045566 00000 n 
0000000232 00000 n 
0000000319 00000 n 
0000000519 00000 n 
0000000714 00000 n 
0000009215 00000 n 
0000052895 00000 n 
0000005531 00000 n 
0000005728 00000 n 
0000005929 00000 n 
0000009513 00000 n 
0000009576 00000 n 
0000014957 00000 n 
0000014112 00000 n 
0000009903 00000 n 
0000010485 00000 n 
0000009975 00000 n 
0000010123 00000 n 
0000010049 00000 n 
0000010230 00000 n 
0000010378 00000 n 
0000010304 00000 n 
0000010572 00000 n 
0000010644 00000 n 
0000010715 00000 n 
0000010787 00000 n 
0000010859 00000 n 
0000010931 00000 n 
0000011003 00000 n 
0000011075 00000 n 
0000011147 00000 n 
0000011219 00000 n 
0000011291 00000 n 
0000011363 00000 n 
0000011435 00000 n 
0000011507 00000 n 
0000011579 00000 n 
0000011651 00000 n 
0000011723 00000 n 
0000011795 00000 n 
0000011867 00000 n 
0000011939 00000 n 
0000012011 00000 n 
0000012083 00000 n 
0000012155 00000 n 
0000012373 00000 n 
0000012227 00000 n 
0000012300 00000 n 
0000012446 00000 n 
0000012664 00000 n 
0000012518 00000 n 
0000012591 00000 n 
0000012920 00000 n 
0000012812 00000 n 
0000012737 00000 n 
0000012986 00000 n 
0000013058 00000 n 
0000013315 00000 n 
0000013207 00000 n 
0000013131 00000 n 
0000013381 00000 n 
0000013454 00000 n 
0000013528 00000 n 
0000013601 00000 n 
0000013674 00000 n 
0000013747 00000 n 
0000013820 00000 n 
0000013893 00000 n 
0000013966 00000 n 
0000014039 00000 n 
0000014472 00000 n 
0000014665 00000 n 
0000014837 00000 n 
0000015049 00000 n 
0000015185 00000 n 
0000015731 00000 n 
0000015582 00000 n 
0000015323 00000 n 
0000015452 00000 n 
0000015889 00000 n 
0000015961 00000 n 
0000016188 00000 n 
0000020724 00000 n 
0000020928 00000 n 
0000021329 00000 n 
0000021899 00000 n 
0000031693 00000 n 
0000031897 00000 n 
0000032545 00000 n 
0000033263 00000 n 
0000035757 00000 n 
0000035961 00000 n 
0000036303 00000 n 
0000036837 00000 n 
0000039613 00000 n 
0000039819 00000 n 
0000040181 00000 n 
0000040730 00000 n 
0000044560 00000 n 
0000044766 00000 n 
0000045172 00000 n 
0000045715 00000 n 
0000052107 00000 n 
0000052345 00000 n 
0000052589 00000 n 
trailer
<</Size 114
/Root 89 0 R
/Info 1 0 R>>
startxref
53037
%%EOF

==== tests/integration/fixture/tool_agent/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from . import agent

==== tests/integration/fixture/tool_agent/agent.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
from typing import Any

from crewai_tools import DirectoryReadTool
from google.adk import Agent
from google.adk.tools.agent_tool import AgentTool
from google.adk.tools.crewai_tool import CrewaiTool
from google.adk.tools.langchain_tool import LangchainTool
from google.adk.tools.retrieval.files_retrieval import FilesRetrieval
from google.adk.tools.retrieval.vertex_ai_rag_retrieval import VertexAiRagRetrieval
from langchain_community.tools import ShellTool
from pydantic import BaseModel


class TestCase(BaseModel):
  case: str


class Test(BaseModel):
  test_title: list[str]


def simple_function(param: str) -> str:
  if isinstance(param, str):
    return "Called simple function successfully"
  return "Called simple function with wrong param type"


def no_param_function() -> str:
  return "Called no param function successfully"


def no_output_function(param: str):
  return


def multiple_param_types_function(
    param1: str, param2: int, param3: float, param4: bool
) -> str:
  if (
      isinstance(param1, str)
      and isinstance(param2, int)
      and isinstance(param3, float)
      and isinstance(param4, bool)
  ):
    return "Called multiple param types function successfully"
  return "Called multiple param types function with wrong param types"


def throw_error_function(param: str) -> str:
  raise ValueError("Error thrown by throw_error_function")


def list_str_param_function(param: list[str]) -> str:
  if isinstance(param, list) and all(isinstance(item, str) for item in param):
    return "Called list str param function successfully"
  return "Called list str param function with wrong param type"


def return_list_str_function(param: str) -> list[str]:
  return ["Called return list str function successfully"]


def complex_function_list_dict(
    param1: dict[str, Any], param2: list[dict[str, Any]]
) -> list[Test]:
  if (
      isinstance(param1, dict)
      and isinstance(param2, list)
      and all(isinstance(item, dict) for item in param2)
  ):
    return [
        Test(test_title=["function test 1", "function test 2"]),
        Test(test_title=["retrieval test"]),
    ]
  raise ValueError("Wrong param")


def repetive_call_1(param: str):
  return f"Call repetive_call_2 tool with param {param + '_repetive'}"


def repetive_call_2(param: str):
  return param


test_case_retrieval = FilesRetrieval(
    name="test_case_retrieval",
    description="General guidence for agent test cases",
    input_dir=os.path.join(os.path.dirname(__file__), "files"),
)

valid_rag_retrieval = VertexAiRagRetrieval(
    name="valid_rag_retrieval",
    rag_corpora=[
        "projects/1096655024998/locations/us-central1/ragCorpora/4985766262475849728"
    ],
    description="General guidence for agent test cases",
)

invalid_rag_retrieval = VertexAiRagRetrieval(
    name="invalid_rag_retrieval",
    rag_corpora=[
        "projects/1096655024998/locations/us-central1/InValidRagCorporas/4985766262475849728"
    ],
    description="Invalid rag retrieval resource name",
)

non_exist_rag_retrieval = VertexAiRagRetrieval(
    name="non_exist_rag_retrieval",
    rag_corpora=[
        "projects/1096655024998/locations/us-central1/RagCorpora/1234567"
    ],
    description="Non exist rag retrieval resource name",
)

shell_tool = LangchainTool(ShellTool())

docs_tool = CrewaiTool(
    name="direcotry_read_tool",
    description="use this to find files for you.",
    tool=DirectoryReadTool(directory="."),
)

no_schema_agent = Agent(
    model="gemini-1.5-flash",
    name="no_schema_agent",
    instruction="""Just say 'Hi'
""",
)

schema_agent = Agent(
    model="gemini-1.5-flash",
    name="schema_agent",
    instruction="""
    You will be given a test case.
    Return a list of the received test case appended with '_success' and '_failure' as test_titles
""",
    input_schema=TestCase,
    output_schema=Test,
)

no_input_schema_agent = Agent(
    model="gemini-1.5-flash",
    name="no_input_schema_agent",
    instruction="""
    Just return ['Tools_success, Tools_failure']
""",
    output_schema=Test,
)

no_output_schema_agent = Agent(
    model="gemini-1.5-flash",
    name="no_output_schema_agent",
    instruction="""
    Just say 'Hi'
""",
    input_schema=TestCase,
)

single_function_agent = Agent(
    model="gemini-1.5-flash",
    name="single_function_agent",
    description="An agent that calls a single function",
    instruction="When calling tools, just return what the tool returns.",
    tools=[simple_function],
)

root_agent = Agent(
    model="gemini-1.5-flash",
    name="tool_agent",
    description="An agent that can call other tools",
    instruction="When calling tools, just return what the tool returns.",
    tools=[
        simple_function,
        no_param_function,
        no_output_function,
        multiple_param_types_function,
        throw_error_function,
        list_str_param_function,
        return_list_str_function,
        # complex_function_list_dict,
        repetive_call_1,
        repetive_call_2,
        test_case_retrieval,
        valid_rag_retrieval,
        invalid_rag_retrieval,
        non_exist_rag_retrieval,
        shell_tool,
        docs_tool,
        AgentTool(
            agent=no_schema_agent,
        ),
        AgentTool(
            agent=schema_agent,
        ),
        AgentTool(
            agent=no_input_schema_agent,
        ),
        AgentTool(
            agent=no_output_schema_agent,
        ),
    ],
)

==== tests/integration/fixture/home_automation_agent/test_files/simple_test2.test.json ====
{
  "eval_set_id": "e141f90b-9e7e-4f06-94d7-bbe7e8080ead",
  "name": "e141f90b-9e7e-4f06-94d7-bbe7e8080ead",
  "description": null,
  "eval_cases": [
    {
      "eval_id": "tests/integration/fixture/home_automation_agent/test_files/simple_test2.test.json",
      "conversation": [
        {
          "invocation_id": "c35582f7-838a-460f-b783-039e278165e0",
          "user_content": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "Turn off device_3 in the Bedroom."
              }
            ],
            "role": "user"
          },
          "final_response": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "I have set the device_3 status to off."
              }
            ],
            "role": "model"
          },
          "intermediate_data": {
            "tool_uses": [
              {
                "id": null,
                "args": {
                  "location": "Bedroom",
                  "device_id": "device_3",
                  "status": "OFF"
                },
                "name": "set_device_info"
              }
            ],
            "intermediate_responses": []
          },
          "creation_timestamp": 1747340814.8645504
        }
      ],
      "session_input": null,
      "creation_timestamp": 1747340814.86456
    }
  ],
  "creation_timestamp": 1747340814.864572
}
==== tests/integration/fixture/home_automation_agent/test_files/test_config.json ====
{
  "criteria": {
    "tool_trajectory_avg_score": 1.0
  }
}

==== tests/integration/fixture/home_automation_agent/test_files/memorizing_past_events/test_config.json ====
{
  "criteria": {
    "tool_trajectory_avg_score": 1.0,
    "response_match_score": 0.5
  }
}

==== tests/integration/fixture/home_automation_agent/test_files/memorizing_past_events/eval_data.test.json ====
{
  "eval_set_id": "94553685-5f19-492b-bc44-f3bc775955e9",
  "name": "94553685-5f19-492b-bc44-f3bc775955e9",
  "description": null,
  "eval_cases": [
    {
      "eval_id": "tests/integration/fixture/home_automation_agent/test_files/memorizing_past_events/eval_data.test.json",
      "conversation": [
        {
          "invocation_id": "a958b622-21d3-4a6c-9c15-1274bbb8a6b6",
          "user_content": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "Turn off device_2 in the Bedroom."
              }
            ],
            "role": "user"
          },
          "final_response": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "OK. I've turned off device_2 in the Bedroom. Anything else?\n"
              }
            ],
            "role": "model"
          },
          "intermediate_data": {
            "tool_uses": [
              {
                "id": null,
                "args": {
                  "location": "Bedroom",
                  "device_id": "device_2",
                  "status": "OFF"
                },
                "name": "set_device_info"
              }
            ],
            "intermediate_responses": []
          },
          "creation_timestamp": 1747340865.7043095
        },
        {
          "invocation_id": "1c07123d-4bed-4eb0-9e55-c7f80c70dadf",
          "user_content": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "What's the command I just issued?"
              }
            ],
            "role": "user"
          },
          "final_response": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "You asked me to turn off device_2 in the Bedroom.\n"
              }
            ],
            "role": "model"
          },
          "intermediate_data": {
            "tool_uses": [],
            "intermediate_responses": []
          },
          "creation_timestamp": 1747340865.7043421
        }
      ],
      "session_input": null,
      "creation_timestamp": 1747340865.7043483
    }
  ],
  "creation_timestamp": 1747340865.704361
}
==== tests/integration/fixture/home_automation_agent/test_files/simple_multi_turn_conversation.test.json ====
{
  "eval_set_id": "4412cca6-dfcd-43ab-bbc5-9155380c7137",
  "name": "4412cca6-dfcd-43ab-bbc5-9155380c7137",
  "description": null,
  "eval_cases": [
    {
      "eval_id": "tests/integration/fixture/home_automation_agent/test_files/simple_multi_turn_conversation.test.json",
      "conversation": [
        {
          "invocation_id": "9f51a1ac-56a4-4b4a-9878-36ff1ae312ce",
          "user_content": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "Turn off device_2 in the Bedroom."
              }
            ],
            "role": "user"
          },
          "final_response": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "I have set the device 2 status to off."
              }
            ],
            "role": "model"
          },
          "intermediate_data": {
            "tool_uses": [
              {
                "id": null,
                "args": {
                  "location": "Bedroom",
                  "device_id": "device_2",
                  "status": "OFF"
                },
                "name": "set_device_info"
              }
            ],
            "intermediate_responses": []
          },
          "creation_timestamp": 1747340791.7353904
        },
        {
          "invocation_id": "c82d54d0-5fa8-4f79-a6dc-692090f0d42b",
          "user_content": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "Turn on device_2 in the Bedroom."
              }
            ],
            "role": "user"
          },
          "final_response": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "I have set the device 2 status to on."
              }
            ],
            "role": "model"
          },
          "intermediate_data": {
            "tool_uses": [
              {
                "id": null,
                "args": {
                  "location": "Bedroom",
                  "status": "ON",
                  "device_id": "device_2"
                },
                "name": "set_device_info"
              }
            ],
            "intermediate_responses": []
          },
          "creation_timestamp": 1747340791.7354295
        }
      ],
      "session_input": null,
      "creation_timestamp": 1747340791.7354348
    }
  ],
  "creation_timestamp": 1747340791.735446
}
==== tests/integration/fixture/home_automation_agent/test_files/dependent_tool_calls.test.json ====
{
  "eval_set_id": "1be50511-ff75-4d68-b2d7-2165cbdc1044",
  "name": "1be50511-ff75-4d68-b2d7-2165cbdc1044",
  "description": null,
  "eval_cases": [
    {
      "eval_id": "tests/integration/fixture/home_automation_agent/test_files/dependent_tool_calls.test.json",
      "conversation": [
        {
          "invocation_id": "cbece1c0-3811-45c0-96fc-9a4279075483",
          "user_content": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "Turn off device_2 in the Bedroom."
              }
            ],
            "role": "user"
          },
          "final_response": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "I have set the device 2 status to off."
              }
            ],
            "role": "model"
          },
          "intermediate_data": {
            "tool_uses": [
              {
                "id": null,
                "args": {
                  "location": "Bedroom",
                  "status": "OFF",
                  "device_id": "device_2"
                },
                "name": "set_device_info"
              }
            ],
            "intermediate_responses": []
          },
          "creation_timestamp": 1747340826.1082227
        },
        {
          "invocation_id": "cc85cdae-4258-4b94-8fe7-a985b8356190",
          "user_content": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "What's the status of device_2 in the Bedroom?"
              }
            ],
            "role": "user"
          },
          "final_response": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "Status of device_2 is off."
              }
            ],
            "role": "model"
          },
          "intermediate_data": {
            "tool_uses": [
              {
                "id": null,
                "args": {
                  "device_id": "device_2"
                },
                "name": "get_device_info"
              }
            ],
            "intermediate_responses": []
          },
          "creation_timestamp": 1747340826.1082554
        }
      ],
      "session_input": null,
      "creation_timestamp": 1747340826.108262
    }
  ],
  "creation_timestamp": 1747340826.108275
}
==== tests/integration/fixture/home_automation_agent/test_files/simple_test.test.json ====
{
  "eval_set_id": "9100bfc9-cc28-4ab9-b920-2dc72e138997",
  "name": "9100bfc9-cc28-4ab9-b920-2dc72e138997",
  "description": null,
  "eval_cases": [
    {
      "eval_id": "tests/integration/fixture/home_automation_agent/test_files/simple_test.test.json",
      "conversation": [
        {
          "invocation_id": "9f5e8d91-8e51-41d6-addf-196a828168c5",
          "user_content": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "Turn off device_2 in the Bedroom."
              }
            ],
            "role": "user"
          },
          "final_response": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "OK. I've turned off device_2 in the Bedroom. Anything else?\n"
              }
            ],
            "role": "model"
          },
          "intermediate_data": {
            "tool_uses": [
              {
                "id": null,
                "args": {
                  "location": "Bedroom",
                  "device_id": "device_2",
                  "status": "OFF"
                },
                "name": "set_device_info"
              }
            ],
            "intermediate_responses": []
          },
          "creation_timestamp": 1747340849.0429707
        },
        {
          "invocation_id": "767b2451-5f7b-4c73-aeaf-a82c71e15788",
          "user_content": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "What's the command I just issued?"
              }
            ],
            "role": "user"
          },
          "final_response": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "You asked me to turn off device_2 in the Bedroom.\n"
              }
            ],
            "role": "model"
          },
          "intermediate_data": {
            "tool_uses": [],
            "intermediate_responses": []
          },
          "creation_timestamp": 1747340849.0429986
        }
      ],
      "session_input": null,
      "creation_timestamp": 1747340849.0430045
    }
  ],
  "creation_timestamp": 1747340849.0430162
}
==== tests/integration/fixture/home_automation_agent/simple_test2.test.json ====
[{
  "query": "Turn off device_3 in the Bedroom.",
  "expected_tool_use": [{"tool_name": "set_device_info", "tool_input": {"location": "Bedroom", "device_id": "device_3", "status": "OFF"}}],
  "reference": "I have set the device_3 status to off."
}]

==== tests/integration/fixture/home_automation_agent/test_config.json ====
{
  "criteria": {
    "tool_trajectory_avg_score": 1.0
  }
}

==== tests/integration/fixture/home_automation_agent/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from . import agent

==== tests/integration/fixture/home_automation_agent/agent.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import sys

from google.adk import Agent

DEVICE_DB = {
    "device_1": {"status": "ON", "location": "Living Room"},
    "device_2": {"status": "OFF", "location": "Bedroom"},
    "device_3": {"status": "OFF", "location": "Kitchen"},
}

TEMPERATURE_DB = {
    "Living Room": 22,
    "Bedroom": 20,
    "Kitchen": 24,
}

SCHEDULE_DB = {
    "device_1": {"time": "18:00", "status": "ON"},
    "device_2": {"time": "22:00", "status": "OFF"},
}

USER_PREFERENCES_DB = {
    "user_x": {"preferred_temp": 21, "location": "Bedroom"},
    "user_x": {"preferred_temp": 21, "location": "Living Room"},
    "user_y": {"preferred_temp": 23, "location": "Living Room"},
}


def reset_data():
  global DEVICE_DB
  global TEMPERATURE_DB
  global SCHEDULE_DB
  global USER_PREFERENCES_DB
  DEVICE_DB = {
      "device_1": {"status": "ON", "location": "Living Room"},
      "device_2": {"status": "OFF", "location": "Bedroom"},
      "device_3": {"status": "OFF", "location": "Kitchen"},
  }

  TEMPERATURE_DB = {
      "Living Room": 22,
      "Bedroom": 20,
      "Kitchen": 24,
  }

  SCHEDULE_DB = {
      "device_1": {"time": "18:00", "status": "ON"},
      "device_2": {"time": "22:00", "status": "OFF"},
  }

  USER_PREFERENCES_DB = {
      "user_x": {"preferred_temp": 21, "location": "Bedroom"},
      "user_x": {"preferred_temp": 21, "location": "Living Room"},
      "user_y": {"preferred_temp": 23, "location": "Living Room"},
  }


def get_device_info(device_id: str) -> dict:
  """Get the current status and location of a AC device.

  Args:
      device_id (str): The unique identifier of the device.

  Returns:
      dict: A dictionary containing the following fields, or 'Device not found'
      if the device_id does not exist:
        - status: The current status of the device (e.g., 'ON', 'OFF')
        - location: The location where the device is installed (e.g., 'Living
        Room', 'Bedroom', ''Kitchen')
  """
  return DEVICE_DB.get(device_id, "Device not found")


# def set_device_info(device_id: str, updates: dict) -> str:
# """Update the information of a AC device, specifically its status and/or location.

# Args:
#     device_id (str): Required. The unique identifier of the device.
#     updates (dict): Required. A dictionary containing the fields to be
#       updated. Supported keys: - "status" (str): The new status to set for the
#       device. Accepted values: 'ON', 'OFF'. **Only these values are allowed.**
#       - "location" (str): The new location to set for the device. Accepted
#       values: 'Living Room', 'Bedroom', 'Kitchen'. **Only these values are
#         allowed.**


# Returns:
#     str: A message indicating whether the device information was successfully
#     updated.
# """
# if device_id in DEVICE_DB:
#   if "status" in updates:
#     DEVICE_DB[device_id]["status"] = updates["status"]
#   if "location" in updates:
#     DEVICE_DB[device_id]["location"] = updates["location"]
#   return f"Device {device_id} information updated: {updates}."
# return "Device not found"
def set_device_info(
    device_id: str, status: str = "", location: str = ""
) -> str:
  """Update the information of a AC device, specifically its status and/or location.

  Args:
      device_id (str): Required. The unique identifier of the device.
      status (str): The new status to set for the
        device. Accepted values: 'ON', 'OFF'. **Only these values are allowed.**
      location (str): The new location to set for the device. Accepted
        values: 'Living Room', 'Bedroom', 'Kitchen'. **Only these values are
          allowed.**

  Returns:
      str: A message indicating whether the device information was successfully
      updated.
  """
  if device_id in DEVICE_DB:
    if status:
      DEVICE_DB[device_id]["status"] = status
      return f"Device {device_id} information updated: status -> {status}."
    if location:
      DEVICE_DB[device_id]["location"] = location
      return f"Device {device_id} information updated: location -> {location}."
  return "Device not found"


def get_temperature(location: str) -> int:
  """Get the current temperature in celsius of a location (e.g., 'Living Room', 'Bedroom', 'Kitchen').

  Args:
      location (str): The location for which to retrieve the temperature (e.g.,
        'Living Room', 'Bedroom', 'Kitchen').

  Returns:
      int: The current temperature in celsius in the specified location, or
      'Location not found' if the location does not exist.
  """
  return TEMPERATURE_DB.get(location, "Location not found")


def set_temperature(location: str, temperature: int) -> str:
  """Set the desired temperature in celsius for a location.

  Acceptable range of temperature: 18-30 celsius. If it's out of the range, do
  not call this tool.

  Args:
      location (str): The location where the temperature should be set.
      temperature (int): The desired temperature as integer to set in celsius.
        Acceptable range: 18-30 celsius.

  Returns:
      str: A message indicating whether the temperature was successfully set.
  """
  if location in TEMPERATURE_DB:
    TEMPERATURE_DB[location] = temperature
    return f"Temperature in {location} set to {temperature}C."
  return "Location not found"


def get_user_preferences(user_id: str) -> dict:
  """Get the temperature preferences and preferred location of a user_id.

  user_id must be provided.

  Args:
      user_id (str): The unique identifier of the user.

  Returns:
      dict: A dictionary containing the following fields, or 'User not found' if
      the user_id does not exist:
        - preferred_temp: The user's preferred temperature.
        - location: The location where the user prefers to be.
  """
  return USER_PREFERENCES_DB.get(user_id, "User not found")


def set_device_schedule(device_id: str, time: str, status: str) -> str:
  """Schedule a device to change its status at a specific time.

  Args:
      device_id (str): The unique identifier of the device.
      time (str): The time at which the device should change its status (format:
        'HH:MM').
      status (str): The status to set for the device at the specified time
        (e.g., 'ON', 'OFF').

  Returns:
      str: A message indicating whether the schedule was successfully set.
  """
  if device_id in DEVICE_DB:
    SCHEDULE_DB[device_id] = {"time": time, "status": status}
    return f"Device {device_id} scheduled to turn {status} at {time}."
  return "Device not found"


def get_device_schedule(device_id: str) -> dict:
  """Retrieve the schedule of a device.

  Args:
      device_id (str): The unique identifier of the device.

  Returns:
      dict: A dictionary containing the following fields, or 'Schedule not
      found' if the device_id does not exist:
        - time: The scheduled time for the device to change its status (format:
        'HH:MM').
        - status: The status that will be set at the scheduled time (e.g., 'ON',
        'OFF').
  """
  return SCHEDULE_DB.get(device_id, "Schedule not found")


def celsius_to_fahrenheit(celsius: int) -> float:
  """Convert Celsius to Fahrenheit.

  You must call this to do the conversion of temperature, so you can get the
  precise number in required format.

  Args:
      celsius (int): Temperature in Celsius.

  Returns:
      float: Temperature in Fahrenheit.
  """
  return (celsius * 9 / 5) + 32


def fahrenheit_to_celsius(fahrenheit: float) -> int:
  """Convert Fahrenheit to Celsius.

  You must call this to do the conversion of temperature, so you can get the
  precise number in required format.

  Args:
      fahrenheit (float): Temperature in Fahrenheit.

  Returns:
      int: Temperature in Celsius.
  """
  return int((fahrenheit - 32) * 5 / 9)


def list_devices(status: str = "", location: str = "") -> list:
  """Retrieve a list of AC devices, filtered by status and/or location when provided.

  For cost efficiency, always apply as many filters (status and location) as
  available in the input arguments.

  Args:
      status (str, optional): The status to filter devices by (e.g., 'ON',
        'OFF'). Defaults to None.
      location (str, optional): The location to filter devices by (e.g., 'Living
        Room', 'Bedroom', ''Kitchen'). Defaults to None.

  Returns:
      list: A list of dictionaries, each containing the device ID, status, and
      location, or an empty list if no devices match the criteria.
  """
  devices = []
  for device_id, info in DEVICE_DB.items():
    if ((not status) or info["status"] == status) and (
        (not location) or info["location"] == location
    ):
      devices.append({
          "device_id": device_id,
          "status": info["status"],
          "location": info["location"],
      })
  return devices if devices else "No devices found matching the criteria."


root_agent = Agent(
    model="gemini-2.0-flash-001",
    name="Home_automation_agent",
    instruction="""
    You are Home Automation Agent. You are responsible for controlling the devices in the home.
    """,
    tools=[
        get_device_info,
        set_device_info,
        get_temperature,
        set_temperature,
        get_user_preferences,
        set_device_schedule,
        get_device_schedule,
        celsius_to_fahrenheit,
        fahrenheit_to_celsius,
        list_devices,
    ],
)

==== tests/integration/fixture/home_automation_agent/simple_test.test.json ====
{
  "eval_set_id": "b305bd06-38c5-4796-b9c7-d9c7454338b9",
  "name": "b305bd06-38c5-4796-b9c7-d9c7454338b9",
  "description": null,
  "eval_cases": [
    {
      "eval_id": "tests/integration/fixture/home_automation_agent/simple_test.test.json",
      "conversation": [
        {
          "invocation_id": "b7982664-0ab6-47cc-ab13-326656afdf75",
          "user_content": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "Turn off device_2 in the Bedroom."
              }
            ],
            "role": "user"
          },
          "final_response": {
            "parts": [
              {
                "video_metadata": null,
                "thought": null,
                "code_execution_result": null,
                "executable_code": null,
                "file_data": null,
                "function_call": null,
                "function_response": null,
                "inline_data": null,
                "text": "I have set the device_2 status to off."
              }
            ],
            "role": "model"
          },
          "intermediate_data": {
            "tool_uses": [
              {
                "id": null,
                "args": {
                  "location": "Bedroom",
                  "device_id": "device_2",
                  "status": "OFF"
                },
                "name": "set_device_info"
              }
            ],
            "intermediate_responses": []
          },
          "creation_timestamp": 1747337309.2360144
        }
      ],
      "session_input": null,
      "creation_timestamp": 1747337309.2360282
    }
  ],
  "creation_timestamp": 1747337309.2360387
}
==== tests/integration/fixture/customer_support_ma/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from . import agent

==== tests/integration/fixture/customer_support_ma/agent.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


from google.adk import Agent
from google.adk.examples import Example
from google.adk.sessions import Session
from google.genai import types


def reset_data():
  pass


def fetch_user_flight_information(customer_email: str) -> str:
  """Fetch user flight information."""
  return """
[{"ticket_no": "7240005432906569", "book_ref": "C46E9F", "flight_id": 19250, "flight_no": "LX0112", "departure_airport": "CDG", "arrival_airport": "BSL", "scheduled_departure": "2024-12-30 12:09:03.561731-04:00", "scheduled_arrival": "2024-12-30 13:39:03.561731-04:00", "seat_no": "18E", "fare_conditions": "Economy"}]
"""


def list_customer_flights(customer_email: str) -> str:
  return "{'flights': [{'book_ref': 'C46E9F'}]}"


def update_ticket_to_new_flight(ticket_no: str, new_flight_id: str) -> str:
  return 'OK, your ticket has been updated.'


def lookup_company_policy(topic: str) -> str:
  """Lookup policies for flight cancelation and rebooking."""
  return """
1. How can I change my booking?
	* The ticket number must start with 724 (SWISS ticket no./plate).
	* The ticket was not paid for by barter or voucher (there are exceptions to voucher payments; if the ticket was paid for in full by voucher, then it may be possible to rebook online under certain circumstances. If it is not possible to rebook online because of the payment method, then you will be informed accordingly during the rebooking process).
	* There must be an active flight booking for your ticket. It is not possible to rebook open tickets or tickets without the corresponding flight segments online at the moment.
	* It is currently only possible to rebook outbound (one-way) tickets or return tickets with single flight routes (point-to-point).
"""


def search_flights(
    departure_airport: str = None,
    arrival_airport: str = None,
    start_time: str = None,
    end_time: str = None,
) -> list[dict]:
  return """
[{"flight_id": 19238, "flight_no": "LX0112", "scheduled_departure": "2024-05-08 12:09:03.561731-04:00", "scheduled_arrival": "2024-05-08 13:39:03.561731-04:00", "departure_airport": "CDG", "arrival_airport": "BSL", "status": "Scheduled", "aircraft_code": "SU9", "actual_departure": null, "actual_arrival": null}, {"flight_id": 19242, "flight_no": "LX0112", "scheduled_departure": "2024-05-09 12:09:03.561731-04:00", "scheduled_arrival": "2024-05-09 13:39:03.561731-04:00", "departure_airport": "CDG", "arrival_airport": "BSL", "status": "Scheduled", "aircraft_code": "SU9", "actual_departure": null, "actual_arrival": null}]"""


def search_hotels(
    location: str = None,
    price_tier: str = None,
    checkin_date: str = None,
    checkout_date: str = None,
) -> list[dict]:
  return """
[{"id": 1, "name": "Hilton Basel", "location": "Basel", "price_tier": "Luxury"}, {"id": 3, "name": "Hyatt Regency Basel", "location": "Basel", "price_tier": "Upper Upscale"}, {"id": 8, "name": "Holiday Inn Basel", "location": "Basel", "price_tier": "Upper Midscale"}]
"""


def book_hotel(hotel_name: str) -> str:
  return 'OK, your hotel has been booked.'


def before_model_call(agent: Agent, session: Session, user_message):
  if 'expedia' in user_message.lower():
    response = types.Content(
        role='model',
        parts=[types.Part(text="Sorry, I can't answer this question.")],
    )
    return response
  return None


def after_model_call(
    agent: Agent, session: Session, content: types.Content
) -> bool:
  model_message = content.parts[0].text
  if 'expedia' in model_message.lower():
    response = types.Content(
        role='model',
        parts=[types.Part(text="Sorry, I can't answer this question.")],
    )
    return response
  return None


flight_agent = Agent(
    model='gemini-1.5-pro',
    name='flight_agent',
    description='Handles flight information, policy and updates',
    instruction="""
      You are a specialized assistant for handling flight updates.
        The primary assistant delegates work to you whenever the user needs help updating their bookings.
      Confirm the updated flight details with the customer and inform them of any additional fees.
        When searching, be persistent. Expand your query bounds if the first search returns no results.
        Remember that a booking isn't completed until after the relevant tool has successfully been used.
      Do not waste the user's time. Do not make up invalid tools or functions.
""",
    tools=[
        list_customer_flights,
        lookup_company_policy,
        fetch_user_flight_information,
        search_flights,
        update_ticket_to_new_flight,
    ],
)

hotel_agent = Agent(
    model='gemini-1.5-pro',
    name='hotel_agent',
    description='Handles hotel information and booking',
    instruction="""
      You are a specialized assistant for handling hotel bookings.
      The primary assistant delegates work to you whenever the user needs help booking a hotel.
      Search for available hotels based on the user's preferences and confirm the booking details with the customer.
        When searching, be persistent. Expand your query bounds if the first search returns no results.
""",
    tools=[search_hotels, book_hotel],
)


root_agent = Agent(
    model='gemini-1.5-pro',
    name='root_agent',
    instruction="""
      You are a helpful customer support assistant for Swiss Airlines.
""",
    sub_agents=[flight_agent, hotel_agent],
    flow='auto',
    examples=[
        Example(
            input=types.Content(
                role='user',
                parts=[types.Part(text='How were you built?')],
            ),
            output=[
                types.Content(
                    role='model',
                    parts=[
                        types.Part(
                            text='I was built with the best agent framework.'
                        )
                    ],
                )
            ],
        ),
    ],
)

==== tests/integration/fixture/context_variable_agent/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from . import agent

==== tests/integration/fixture/context_variable_agent/agent.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from typing import List
from typing import Union

from google.adk import Agent
from google.adk.agents.invocation_context import InvocationContext
from google.adk.planners import PlanReActPlanner
from google.adk.tools import ToolContext


def update_fc(
    data_one: str,
    data_two: Union[int, float, str],
    data_three: list[str],
    data_four: List[Union[int, float, str]],
    tool_context: ToolContext,
) -> str:
  """Simply ask to update these variables in the context"""
  tool_context.actions.update_state('data_one', data_one)
  tool_context.actions.update_state('data_two', data_two)
  tool_context.actions.update_state('data_three', data_three)
  tool_context.actions.update_state('data_four', data_four)
  return 'The function `update_fc` executed successfully'


def echo_info(customer_id: str) -> str:
  """Echo the context variable"""
  return customer_id


def build_global_instruction(invocation_context: InvocationContext) -> str:
  return (
      'This is the gloabl agent instruction for invocation:'
      f' {invocation_context.invocation_id}.'
  )


def build_sub_agent_instruction(invocation_context: InvocationContext) -> str:
  return 'This is the plain text sub agent instruction.'


context_variable_echo_agent = Agent(
    model='gemini-1.5-flash',
    name='context_variable_echo_agent',
    instruction=(
        'Use the echo_info tool to echo {customerId}, {customerInt},'
        ' {customerFloat}, and {customerJson}. Ask for it if you need to.'
    ),
    flow='auto',
    tools=[echo_info],
)

context_variable_with_complicated_format_agent = Agent(
    model='gemini-1.5-flash',
    name='context_variable_echo_agent',
    instruction=(
        'Use the echo_info tool to echo { customerId }, {{customer_int  }, { '
        " non-identifier-float}}, {artifact.fileName}, {'key1': 'value1'} and"
        " {{'key2': 'value2'}}. Ask for it if you need to."
    ),
    flow='auto',
    tools=[echo_info],
)

context_variable_with_nl_planner_agent = Agent(
    model='gemini-1.5-flash',
    name='context_variable_with_nl_planner_agent',
    instruction=(
        'Use the echo_info tool to echo {customerId}. Ask for it if you'
        ' need to.'
    ),
    flow='auto',
    planner=PlanReActPlanner(),
    tools=[echo_info],
)

context_variable_with_function_instruction_agent = Agent(
    model='gemini-1.5-flash',
    name='context_variable_with_function_instruction_agent',
    instruction=build_sub_agent_instruction,
    flow='auto',
)

context_variable_update_agent = Agent(
    model='gemini-1.5-flash',
    name='context_variable_update_agent',
    instruction='Call tools',
    flow='auto',
    tools=[update_fc],
)

root_agent = Agent(
    model='gemini-1.5-flash',
    name='root_agent',
    description='The root agent.',
    flow='auto',
    global_instruction=build_global_instruction,
    sub_agents=[
        context_variable_with_nl_planner_agent,
        context_variable_update_agent,
    ],
)

==== tests/integration/test_with_test_file.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.adk.evaluation import AgentEvaluator
import pytest


@pytest.mark.asyncio
async def test_with_single_test_file():
  """Test the agent's basic ability via session file."""
  await AgentEvaluator.evaluate(
      agent_module="tests.integration.fixture.home_automation_agent",
      eval_dataset_file_path_or_dir="tests/integration/fixture/home_automation_agent/simple_test.test.json",
  )


@pytest.mark.asyncio
async def test_with_folder_of_test_files_long_running():
  """Test the agent's basic ability via a folder of session files."""
  await AgentEvaluator.evaluate(
      agent_module="tests.integration.fixture.home_automation_agent",
      eval_dataset_file_path_or_dir=(
          "tests/integration/fixture/home_automation_agent/test_files"
      ),
      num_runs=4,
  )

==== tests/integration/models/test_google_llm.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.adk.models import LlmRequest
from google.adk.models import LlmResponse
from google.adk.models.google_llm import Gemini
from google.genai import types
from google.genai.types import Content
from google.genai.types import Part
import pytest


@pytest.fixture
def gemini_llm():
  return Gemini(model="gemini-1.5-flash")


@pytest.fixture
def llm_request():
  return LlmRequest(
      model="gemini-1.5-flash",
      contents=[Content(role="user", parts=[Part.from_text(text="Hello")])],
      config=types.GenerateContentConfig(
          temperature=0.1,
          response_modalities=[types.Modality.TEXT],
          system_instruction="You are a helpful assistant",
      ),
  )


@pytest.mark.asyncio
async def test_generate_content_async(gemini_llm, llm_request):
  async for response in gemini_llm.generate_content_async(llm_request):
    assert isinstance(response, LlmResponse)
    assert response.content.parts[0].text


@pytest.mark.asyncio
async def test_generate_content_async_stream(gemini_llm, llm_request):
  responses = [
      resp
      async for resp in gemini_llm.generate_content_async(
          llm_request, stream=True
      )
  ]
  text = ""
  for i in range(len(responses) - 1):
    assert responses[i].partial is True
    assert responses[i].content.parts[0].text
    text += responses[i].content.parts[0].text

  # Last message should be accumulated text
  assert responses[-1].content.parts[0].text == text
  assert not responses[-1].partial

==== tests/integration/models/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

==== tests/integration/test_sub_agent.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.adk.evaluation import AgentEvaluator
import pytest


@pytest.mark.asyncio
async def test_eval_agent():
  """Test hotel sub agent in a multi-agent system."""
  await AgentEvaluator.evaluate(
      agent_module="tests.integration.fixture.trip_planner_agent",
      eval_dataset_file_path_or_dir="tests/integration/fixture/trip_planner_agent/test_files/trip_inquiry_sub_agent.test.json",
      agent_name="identify_agent",
      num_runs=4,
  )

==== tests/integration/test_evalute_agent_in_fixture.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Evaluate all agents in fixture folder if evaluation test files exist."""

import os

from google.adk.evaluation import AgentEvaluator
import pytest


def agent_eval_artifacts_in_fixture():
  """Get all agents from fixture folder."""
  agent_eval_artifacts = []
  fixture_dir = os.path.join(os.path.dirname(__file__), 'fixture')
  for agent_name in os.listdir(fixture_dir):
    agent_dir = os.path.join(fixture_dir, agent_name)
    if not os.path.isdir(agent_dir):
      continue
    for filename in os.listdir(agent_dir):
      # Evaluation test files end with test.json
      if not filename.endswith('test.json'):
        continue
      agent_eval_artifacts.append((
          f'tests.integration.fixture.{agent_name}',
          f'tests/integration/fixture/{agent_name}/{filename}',
      ))

  # This method gets invoked twice, sorting helps ensure that both the
  # invocations have the same view.
  agent_eval_artifacts = sorted(
      agent_eval_artifacts, key=lambda item: f'{item[0]}|{item[1]}'
  )
  return agent_eval_artifacts


@pytest.mark.asyncio
@pytest.mark.parametrize(
    'agent_name, evalfile',
    agent_eval_artifacts_in_fixture(),
    ids=[agent_name for agent_name, _ in agent_eval_artifacts_in_fixture()],
)
async def test_evaluate_agents_long_running_4_runs_per_eval_item(
    agent_name, evalfile
):
  """Test agents evaluation in fixture folder.

  After querying the fixture folder, we have 5 eval items. For each eval item
  we use 4 runs.

  A single eval item is a session that can have multiple queries in it.
  """
  await AgentEvaluator.evaluate(
      agent_module=agent_name,
      eval_dataset_file_path_or_dir=evalfile,
      # Using a slightly higher value helps us manange the variances that may
      # happen in each eval.
      # This, of course, comes at a cost of incrased test run times.
      num_runs=4,
  )

==== tests/integration/conftest.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import os
from typing import Literal
import warnings

from dotenv import load_dotenv
from google.adk import Agent
from pytest import fixture
from pytest import FixtureRequest
from pytest import hookimpl
from pytest import Metafunc

from .utils import TestRunner

logger = logging.getLogger('google_adk.' + __name__)


def load_env_for_tests():
  dotenv_path = os.path.join(os.path.dirname(__file__), '.env')
  if not os.path.exists(dotenv_path):
    warnings.warn(
        f'Missing .env file at {dotenv_path}. See dotenv.sample for an example.'
    )
  else:
    load_dotenv(dotenv_path, override=True, verbose=True)
  if 'GOOGLE_API_KEY' not in os.environ:
    warnings.warn(
        'Missing GOOGLE_API_KEY in the environment variables. GOOGLE_AI backend'
        ' integration tests will fail.'
    )
  for env_var in [
      'GOOGLE_CLOUD_PROJECT',
      'GOOGLE_CLOUD_LOCATION',
  ]:
    if env_var not in os.environ:
      warnings.warn(
          f'Missing {env_var} in the environment variables. Vertex backend'
          ' integration tests will fail.'
      )


load_env_for_tests()

BackendType = Literal['GOOGLE_AI', 'VERTEX']


@fixture
def agent_runner(request: FixtureRequest) -> TestRunner:
  assert isinstance(request.param, dict)

  if 'agent' in request.param:
    assert isinstance(request.param['agent'], Agent)
    return TestRunner(request.param['agent'])
  elif 'agent_name' in request.param:
    assert isinstance(request.param['agent_name'], str)
    return TestRunner.from_agent_name(request.param['agent_name'])

  raise NotImplementedError('Must provide agent or agent_name.')


@fixture(autouse=True)
def llm_backend(request: FixtureRequest):
  # Set backend environment value.
  original_val = os.environ.get('GOOGLE_GENAI_USE_VERTEXAI')
  backend_type = request.param
  if backend_type == 'GOOGLE_AI':
    os.environ['GOOGLE_GENAI_USE_VERTEXAI'] = '0'
  else:
    os.environ['GOOGLE_GENAI_USE_VERTEXAI'] = '1'

  yield  # Run the test

  # Restore the environment
  if original_val is None:
    os.environ.pop('GOOGLE_GENAI_USE_VERTEXAI', None)
  else:
    os.environ['GOOGLE_GENAI_USE_VERTEXAI'] = original_val


@hookimpl(tryfirst=True)
def pytest_generate_tests(metafunc: Metafunc):
  if llm_backend.__name__ in metafunc.fixturenames:
    if not _is_explicitly_marked(llm_backend.__name__, metafunc):
      test_backend = os.environ.get('TEST_BACKEND', 'BOTH')
      if test_backend == 'GOOGLE_AI_ONLY':
        metafunc.parametrize(llm_backend.__name__, ['GOOGLE_AI'], indirect=True)
      elif test_backend == 'VERTEX_ONLY':
        metafunc.parametrize(llm_backend.__name__, ['VERTEX'], indirect=True)
      elif test_backend == 'BOTH':
        metafunc.parametrize(
            llm_backend.__name__, ['GOOGLE_AI', 'VERTEX'], indirect=True
        )
      else:
        raise ValueError(
            f'Invalid TEST_BACKEND value: {test_backend}, should be one of'
            ' [GOOGLE_AI_ONLY, VERTEX_ONLY, BOTH]'
        )


def _is_explicitly_marked(mark_name: str, metafunc: Metafunc) -> bool:
  if hasattr(metafunc.function, 'pytestmark'):
    for mark in metafunc.function.pytestmark:
      if mark.name == 'parametrize' and mark.args[0] == mark_name:
        return True
  return False

==== tests/integration/tools/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

==== tests/integration/test_callback.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from pytest import mark

from ..unittests.utils import simplify_events
from .fixture import callback_agent
from .utils import assert_agent_says
from .utils import TestRunner


@mark.parametrize(
    "agent_runner",
    [{"agent": callback_agent.agent.before_agent_callback_agent}],
    indirect=True,
)
def test_before_agent_call(agent_runner: TestRunner):
  agent_runner.run("Hi.")

  # Assert the response content
  assert_agent_says(
      "End invocation event before agent call.",
      agent_name="before_agent_callback_agent",
      agent_runner=agent_runner,
  )


@mark.parametrize(
    "agent_runner",
    [{"agent": callback_agent.agent.before_model_callback_agent}],
    indirect=True,
)
def test_before_model_call(agent_runner: TestRunner):
  agent_runner.run("Hi.")

  # Assert the response content
  assert_agent_says(
      "End invocation event before model call.",
      agent_name="before_model_callback_agent",
      agent_runner=agent_runner,
  )


# TODO: re-enable vertex by removing below line after fixing.
@mark.parametrize("llm_backend", ["GOOGLE_AI"], indirect=True)
@mark.parametrize(
    "agent_runner",
    [{"agent": callback_agent.agent.after_model_callback_agent}],
    indirect=True,
)
def test_after_model_call(agent_runner: TestRunner):
  events = agent_runner.run("Hi.")

  # Assert the response content
  simplified_events = simplify_events(events)
  assert simplified_events[0][0] == "after_model_callback_agent"
  assert simplified_events[0][1].endswith(
      "Update response event after model call."
  )

==== tests/integration/__init__.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import pytest

# This allows pytest to show the values of the asserts.
pytest.register_assert_rewrite('tests.integration.utils')

==== tests/integration/test_multi_turn.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.adk.evaluation import AgentEvaluator
import pytest


@pytest.mark.asyncio
async def test_simple_multi_turn_conversation():
  """Test a simple multi-turn conversation."""
  await AgentEvaluator.evaluate(
      agent_module="tests.integration.fixture.home_automation_agent",
      eval_dataset_file_path_or_dir="tests/integration/fixture/home_automation_agent/test_files/simple_multi_turn_conversation.test.json",
      num_runs=4,
  )


@pytest.mark.asyncio
async def test_dependent_tool_calls():
  """Test subsequent tool calls that are dependent on previous tool calls."""
  await AgentEvaluator.evaluate(
      agent_module="tests.integration.fixture.home_automation_agent",
      eval_dataset_file_path_or_dir="tests/integration/fixture/home_automation_agent/test_files/dependent_tool_calls.test.json",
      num_runs=4,
  )


@pytest.mark.asyncio
async def test_memorizing_past_events():
  """Test memorizing past events."""
  await AgentEvaluator.evaluate(
      agent_module="tests.integration.fixture.home_automation_agent",
      eval_dataset_file_path_or_dir="tests/integration/fixture/home_automation_agent/test_files/memorizing_past_events/eval_data.test.json",
      num_runs=4,
  )

==== tests/integration/test_tools.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import json

import pytest

# Skip until fixed.
pytest.skip(allow_module_level=True)

from .fixture import tool_agent
from .utils import TestRunner


@pytest.mark.parametrize(
    "agent_runner",
    [{"agent": tool_agent.agent.single_function_agent}],
    indirect=True,
)
def test_single_function_calls_success(agent_runner: TestRunner):
  _call_function_and_assert(
      agent_runner,
      "simple_function",
      "test",
      "success",
  )


@pytest.mark.parametrize(
    "agent_runner",
    [{"agent": tool_agent.agent.root_agent}],
    indirect=True,
)
def test_multiple_function_calls_success(agent_runner: TestRunner):
  _call_function_and_assert(
      agent_runner,
      "simple_function",
      "test",
      "success",
  )
  _call_function_and_assert(
      agent_runner,
      "no_param_function",
      None,
      "Called no param function successfully",
  )
  _call_function_and_assert(
      agent_runner,
      "no_output_function",
      "test",
      "",
  )
  _call_function_and_assert(
      agent_runner,
      "multiple_param_types_function",
      ["test", 1, 2.34, True],
      "success",
  )
  _call_function_and_assert(
      agent_runner,
      "return_list_str_function",
      "test",
      "success",
  )
  _call_function_and_assert(
      agent_runner,
      "list_str_param_function",
      ["test", "test2", "test3", "test4"],
      "success",
  )


@pytest.mark.skip(reason="Currently failing with 400 on MLDev.")
@pytest.mark.parametrize(
    "agent_runner",
    [{"agent": tool_agent.agent.root_agent}],
    indirect=True,
)
def test_complex_function_calls_success(agent_runner: TestRunner):
  param1 = {"name": "Test", "count": 3}
  param2 = [
      {"name": "Function", "count": 2},
      {"name": "Retrieval", "count": 1},
  ]
  _call_function_and_assert(
      agent_runner,
      "complex_function_list_dict",
      [param1, param2],
      "test",
  )


@pytest.mark.parametrize(
    "agent_runner",
    [{"agent": tool_agent.agent.root_agent}],
    indirect=True,
)
def test_repetive_call_success(agent_runner: TestRunner):
  _call_function_and_assert(
      agent_runner,
      "repetive_call_1",
      "test",
      "test_repetive",
  )


@pytest.mark.parametrize(
    "agent_runner",
    [{"agent": tool_agent.agent.root_agent}],
    indirect=True,
)
def test_function_calls_fail(agent_runner: TestRunner):
  _call_function_and_assert(
      agent_runner,
      "throw_error_function",
      "test",
      None,
      ValueError,
  )


@pytest.mark.parametrize(
    "agent_runner",
    [{"agent": tool_agent.agent.root_agent}],
    indirect=True,
)
def test_agent_tools_success(agent_runner: TestRunner):
  _call_function_and_assert(
      agent_runner,
      "no_schema_agent",
      "Hi",
      "Hi",
  )
  _call_function_and_assert(
      agent_runner,
      "schema_agent",
      "Agent_tools",
      "Agent_tools_success",
  )
  _call_function_and_assert(
      agent_runner, "no_input_schema_agent", "Tools", "Tools_success"
  )
  _call_function_and_assert(agent_runner, "no_output_schema_agent", "Hi", "Hi")


@pytest.mark.parametrize(
    "agent_runner",
    [{"agent": tool_agent.agent.root_agent}],
    indirect=True,
)
def test_files_retrieval_success(agent_runner: TestRunner):
  _call_function_and_assert(
      agent_runner,
      "test_case_retrieval",
      "What is the testing strategy of agent 2.0?",
      "test",
  )
  # For non relevant query, the agent should still be running fine, just return
  # response might be different for different calls, so we don't compare the
  # response here.
  _call_function_and_assert(
      agent_runner,
      "test_case_retrieval",
      "What is the whether in bay area?",
      "",
  )


@pytest.mark.parametrize(
    "agent_runner",
    [{"agent": tool_agent.agent.root_agent}],
    indirect=True,
)
def test_rag_retrieval_success(agent_runner: TestRunner):
  _call_function_and_assert(
      agent_runner,
      "valid_rag_retrieval",
      "What is the testing strategy of agent 2.0?",
      "test",
  )
  _call_function_and_assert(
      agent_runner,
      "valid_rag_retrieval",
      "What is the whether in bay area?",
      "No",
  )


@pytest.mark.parametrize(
    "agent_runner",
    [{"agent": tool_agent.agent.root_agent}],
    indirect=True,
)
def test_rag_retrieval_fail(agent_runner: TestRunner):
  _call_function_and_assert(
      agent_runner,
      "invalid_rag_retrieval",
      "What is the testing strategy of agent 2.0?",
      None,
      ValueError,
  )
  _call_function_and_assert(
      agent_runner,
      "non_exist_rag_retrieval",
      "What is the whether in bay area?",
      None,
      ValueError,
  )


@pytest.mark.parametrize(
    "agent_runner",
    [{"agent": tool_agent.agent.root_agent}],
    indirect=True,
)
def test_langchain_tool_success(agent_runner: TestRunner):
  _call_function_and_assert(
      agent_runner,
      "terminal",
      "Run the following shell command 'echo test!'",
      "test",
  )


@pytest.mark.parametrize(
    "agent_runner",
    [{"agent": tool_agent.agent.root_agent}],
    indirect=True,
)
def test_crewai_tool_success(agent_runner: TestRunner):
  _call_function_and_assert(
      agent_runner,
      "directory_read_tool",
      "Find all the file paths",
      "file",
  )


def _call_function_and_assert(
    agent_runner: TestRunner,
    function_name: str,
    params,
    expected=None,
    exception: Exception = None,
):
  param_section = (
      " with params"
      f" {params if isinstance(params, str) else json.dumps(params)}"
      if params is not None
      else ""
  )
  query = f"Call {function_name}{param_section} and show me the result"
  if exception:
    _assert_raises(agent_runner, query, exception)
    return

  _assert_function_output(agent_runner, query, expected)


def _assert_raises(agent_runner: TestRunner, query: str, exception: Exception):
  with pytest.raises(exception):
    agent_runner.run(query)


def _assert_function_output(agent_runner: TestRunner, query: str, expected):
  agent_runner.run(query)

  # Retrieve the latest model response event
  model_response_event = agent_runner.get_events()[-1]

  # Assert the response content
  assert model_response_event.content.role == "model"
  assert (
      expected.lower()
      in model_response_event.content.parts[0].text.strip().lower()
  )

==== tests/integration/test_multi_agent.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.adk.evaluation import AgentEvaluator
import pytest


@pytest.mark.asyncio
async def test_eval_agent():
  await AgentEvaluator.evaluate(
      agent_module="tests.integration.fixture.trip_planner_agent",
      eval_dataset_file_path_or_dir=(
          "tests/integration/fixture/trip_planner_agent/trip_inquiry.test.json"
      ),
      num_runs=4,
  )

==== tests/integration/test_single_agent.py ====
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.adk.evaluation import AgentEvaluator
import pytest


@pytest.mark.asyncio
async def test_eval_agent():
  await AgentEvaluator.evaluate(
      agent_module="tests.integration.fixture.home_automation_agent",
      eval_dataset_file_path_or_dir="tests/integration/fixture/home_automation_agent/simple_test.test.json",
      num_runs=4,
  )
